{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83dfe87-5907-46a9-bc52-19ce4fdabcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763d208140754b3787633eee315d8644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"NTQAI/Nxcode-CQ-7B-orpo\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NTQAI/Nxcode-CQ-7B-orpo\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18717bf-bf9e-4aff-a14a-074b87065548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonlyss/.miniforge3/envs/ml/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Complete the following Python function:\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    \\\"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
    "    given threshold.\n",
    "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
    "    False\n",
    "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
    "    True\n",
    "    \\\"\"\"\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "res = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61b6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Python function that checks if any two numbers in a list are closer to each other than a given threshold:\n",
      "\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "```\n",
      "\n",
      "This function works by iterating over each pair of numbers in the list. If the absolute difference between any two numbers is less than the given threshold, the function immediately returns `True`. If no such pair is found after checking all pairs, the function returns `False`.\n",
      "\n",
      "Here's how you can test the function:\n",
      "\n",
      "```python\n",
      "print(has_close_elements([1.0, 2.0, 3.0], 0.5))  # Output: False\n",
      "print(has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3))  # Output: True\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fb0428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i + 1, len(numbers)):\n",
    "            if abs(numbers[i] - numbers[j]) < threshold:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "print(has_close_elements([1.0, 2.0, 3.0], 0.5))  # Output: False\n",
    "print(has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3))  # Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb4b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonlyss/.miniforge3/envs/ml/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scalar wave equation in 2D is given by:\n",
      "\n",
      "u_tt = c^2 * (u_xx + u_yy)\n",
      "\n",
      "where u is the scalar wave function, t is time, x and y are spatial coordinates, and c is the speed of sound.\n",
      "\n",
      "To implement this equation using the finite element method with the Deal.II C++ library, we will follow these steps:\n",
      "\n",
      "1. Set up the problem domain and mesh.\n",
      "2. Define the finite element space.\n",
      "3. Declare the solution and its derivatives.\n",
      "4. Define the bilinear and linear forms.\n",
      "5. Assemble the system matrix and right-hand side vector.\n",
      "6. Solve the system.\n",
      "7. Output the solution.\n",
      "\n",
      "Here is a simple implementation of the above steps:\n",
      "\n",
      "```cpp\n",
      "#include <deal.II/base/quadrature_lib.h>\n",
      "#include <deal.II/base/function.h>\n",
      "#include <deal.II/base/logstream.h>\n",
      "#include <deal.II/base/utilities.h>\n",
      "\n",
      "#include <deal.II/lac/vector.h>\n",
      "#include <deal.II/lac/full_matrix.h>\n",
      "#include <deal.II/lac/sparse_matrix.h>\n",
      "#include <deal.II/lac/solver_cg.h>\n",
      "#include <deal.II/lac/precondition.h>\n",
      "\n",
      "#include <deal.II/grid/tria.h>\n",
      "#include <deal.II/grid/grid_generator.h>\n",
      "#include <deal.II/grid/grid_refinement.h>\n",
      "\n",
      "#include <deal.II/dofs/dof_handler.h>\n",
      "#include <deal.II/dofs/dof_tools.h>\n",
      "\n",
      "#include <deal.II/fe/fe_q.h>\n",
      "#include <deal.II/fe/fe_system.h>\n",
      "#include <deal.II/fe/fe_values.h>\n",
      "\n",
      "#include <deal.II/numerics/data_out.h>\n",
      "#include <deal.II/numerics/vector_tools.h>\n",
      "#include <deal.II/numerics/solution_transfer.h>\n",
      "\n",
      "#include <fstream>\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "prompt = \"\"\"Implement a numerical scheme for the scalar wave equation in 2D using the finite element method, with the Deal.II C++ library.\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    streamer=streamer,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "res = tokenizer.decode(outputs[0][len(inputs[0]) :], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2eff96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
