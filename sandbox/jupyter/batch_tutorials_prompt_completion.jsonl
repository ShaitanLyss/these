{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_51.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving the convection-diffusion equation with a hybridizable discontinuous Galerkin method using face elements.\nTutorial content :\nThis tutorial depends on [step-7](step_7.html), [step-9](step_9.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_51-Intro)    * [Hybridizable discontinuous Galerkin methods](#step_51-HybridizablediscontinuousGalerkinmethods)       + [Reducing the size of the linear system](#step_51-Reducingthesizeofthelinearsystem) + [Relation with Static Condensation](#step_51-RelationwithStaticCondensation) + [Solution quality and rates of convergence](#step_51-Solutionqualityandratesofconvergence)+ [Alternative approaches](#step_51-Alternativeapproaches)* [HDG applied to the convection-diffusion problem](#step_51-HDGappliedtotheconvectiondiffusionproblem)         + [Post-processing and super-convergence](#step_51-Postprocessingandsuperconvergence)* [Problem specific data](#step_51-Problemspecificdata) * [Implementation](#step_51-Implementation)- [The commented program](#step_51-CommProg)      * [Include files](#step_51-Includefiles)* [Equation data](#step_51-Equationdata)* [The HDG solver class](#step_51-TheHDGsolverclass)* [The HDG class implementation](#step_51-TheHDGclassimplementation)              + [Constructor](#step_51-Constructor)+ [HDG::setup\\_system](#step_51-HDGsetup_system)+ [HDG::PerTaskData](#step_51-HDGPerTaskData)+ [HDG::ScratchData](#step_51-HDGScratchData)+ [HDG::PostProcessScratchData](#step_51-HDGPostProcessScratchData)+ [HDG::assemble\\_system](#step_51-HDGassemble_system)+ [HDG::assemble\\_system\\_one\\_cell](#step_51-HDGassemble_system_one_cell)+ [HDG::copy\\_local\\_to\\_global](#step_51-HDGcopy_local_to_global)+ [HDG::solve](#step_51-HDGsolve)+ [HDG::postprocess](#step_51-HDGpostprocess)+ [HDG::postprocess\\_one\\_cell](#step_51-HDGpostprocess_one_cell)+ [HDG::output\\_results](#step_51-HDGoutput_results)+ [HDG::refine\\_grid](#step_51-HDGrefine_grid)+ [HDG::run](#step_51-HDGrun) | 1. [Results](#step_51-Results)    * [Program output](#step_51-Programoutput)      + [Convergence tables](#step_51-Convergencetables)* [Comparison with continuous finite elements](#step_51-Comparisonwithcontinuousfiniteelements)        + [Results for 2D](#step_51-Resultsfor2D)+ [Results for 3D](#step_51-Resultsfor3D)* [Possibilities for improvements](#step_51-Possibilitiesforimprovements)- [The plain program](#step_51-PlainProg) |\n\n*This program was contributed by Martin Kronbichler and Scott Miller.*\n\nIntroduction\n============\n\nThis tutorial program presents the implementation of a hybridizable discontinuous Galkerin method for the convection-diffusion equation.\n\n### Hybridizable discontinuous Galerkin methods\n\nOne common argument against the use of discontinuous Galerkin elements is the large number of globally coupled degrees of freedom that one must solve in an implicit system. This is because, unlike continuous finite elements, in typical discontinuous elements there is one degree of freedom at each vertex *for each of the adjacent elements*, rather than just one, and similarly for edges and faces. As an example of how fast the number of unknowns grows, consider the [FE\\_DGPMonomial](classFE__DGPMonomial.html) basis: each scalar solution component is represented by polynomials of degree \\(p\\) with \\((1/\\text{dim}!) \\prod\\_{i=1}^{\\text{dim}}(p+i)\\) degrees of freedom per element. Typically, all degrees of freedom in an element are coupled to all of the degrees of freedom in the adjacent elements. The resulting discrete equations yield very large linear systems very quickly, especially for systems of equations in 2 or 3 dimensions.\n\n#### Reducing the size of the linear system\n\nTo alleviate the computational cost of solving such large linear systems, the hybridizable discontinuous Galerkin (HDG) methodology was introduced by Cockburn and co-workers (see the references in the recent HDG overview article by Nguyen and Peraire [[162]](citelist.html#CITEREF_Ngu2012)).\n\nThe HDG method achieves this goal by formulating the mathematical problem using Dirichlet-to-Neumann mappings. The partial differential equations are first written as a first order system, and each field is then discretized via a DG method. At this point, the single-valued \"trace\" values on the skeleton of the mesh, i.e., element faces, are taken to be independent unknown quantities. This yields unknowns in the discrete formulation that fall into two categories:\n\n* Face unknowns that only couple with the cell unknowns from both sides of the face;\n* Cell unknowns that only couple with the cell and face unknowns defined within the same cell. Crucially, no cell interior degree of freedom on one cell ever couples to any interior cell degree of freedom of a different cell.\n\nThe Dirichlet-to-Neumann map concept then permits the following solution procedure:\n\n1. Use local element interior data to enforce a Neumann condition on the skeleton of the triangulation. The global problem is then to solve for the trace values, which are the only globally coupled unknowns.\n2. Use the known skeleton values as Dirichlet data for solving local element-level solutions. This is known as the 'local solver', and is an *embarrassingly parallel* element-by-element solution process.\n\n#### Relation with Static Condensation\n\nThe above procedure also has a linear algebra interpretation—referred to as *static condensation*—that was exploited to reduce the size of the global linear system by Guyan in the context of continuous Finite Elements [[108]](citelist.html#CITEREF_G65), and by Fraeijs de Veubeke for mixed methods [[72]](citelist.html#CITEREF_F65). In the latter case (mixed formulation), the system reduction was achieved through the use of discontinuous fluxes combined with the introduction of an additional auxiliary *hybrid* variable that approximates the trace of the unknown at the boundary of every element. This procedure became known as hybridization and—by analogy—is the reason why the local discontinuous Galerkin method introduced by Cockburn, Gopalakrishnan, and Lazarov in 2009 [[62]](citelist.html#CITEREF_CGL2009), and subsequently developed by their collaborators, eventually came to be known as the *hybridizable discontinuous Galerkin* (HDG) method.\n\nLet us write the complete linear system associated to the HDG problem as a block system with the discrete DG (cell interior) variables \\(U\\) as first block and the skeleton (face) variables \\(\\Lambda\\) as the second block:\n\n\\begin{eqnarray\\*}\n\\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix}\n\\begin{pmatrix} U \\\\ \\Lambda \\end{pmatrix}\n=\n\\begin{pmatrix} F \\\\ G \\end{pmatrix}.\n\\end{eqnarray\\*}\n\nOur aim is now to eliminate the \\(U\\) block with a Schur complement approach similar to [step-20](step_20.html), which results in the following two steps:\n\n\\begin{eqnarray\\*}\n(D - C A^{-1} B) \\Lambda &=& G - C A^{-1} F, \\\\\nA U &=& F - B \\Lambda.\n\\end{eqnarray\\*}\n\nThe point is that the presence of \\(A^{-1}\\) is not a problem because \\(A\\) is a block diagonal matrix where each block corresponds to one cell and is therefore easy enough to invert. The coupling to other cells is introduced by the matrices \\(B\\) and \\(C\\) over the skeleton variable. The block-diagonality of \\(A\\) and the structure in \\(B\\) and \\(C\\) allow us to invert the matrix \\(A\\) element by element (the local solution of the Dirichlet problem) and subtract \\(CA^{-1}B\\) from \\(D\\). The steps in the Dirichlet-to-Neumann map concept hence correspond to\n\n1. constructing the Schur complement matrix \\(D-C A^{-1} B\\) and right hand side \\(G - C A^{-1} F\\) *locally on each cell* and inserting the contribution into the global trace matrix in the usual way,\n2. solving the Schur complement system for \\(\\Lambda\\), and\n3. solving for \\(U\\) using the second equation, given \\(\\Lambda\\).\n\n#### Solution quality and rates of convergence\n\nAnother criticism of traditional DG methods is that the approximate fluxes converge suboptimally. The local HDG solutions can be shown to converge as \\(\\mathcal{O}(h^{p+1})\\), i.e., at optimal order. Additionally, a super-convergence property can be used to post-process a new approximate solution that converges at the rate \\(\\mathcal{O}(h^{p+2})\\).\n\n#### Alternative approaches\n\nThe hybridizable discontinuous Galerkin method is only one way in which the problems of the discontinuous Galerkin method can be addressed. Another idea is what is called the \"weak Galerkin\" method. It is explored in [step-61](step_61.html).\n\n### HDG applied to the convection-diffusion problem\n\nThe HDG formulation used for this example is taken from   \n **N.C. Nguyen, J. Peraire, B. Cockburn: *An implicit high-order hybridizable discontinuous Galerkin method for linear convectionâdiffusion equations*, Journal of Computational [Physics](namespacePhysics.html), 2009, 228:9, 3232-3254. [[DOI]](http://dx.doi.org/10.1016/j.jcp.2009.01.030)**\n\nWe consider the convection-diffusion equation over the domain \\(\\Omega\\) with Dirichlet boundary \\(\\partial \\Omega\\_D\\) and Neumann boundary \\(\\partial \\Omega\\_N\\):\n\n\\begin{eqnarray\\*}\n\\nabla \\cdot (\\mathbf{c} u) - \\nabla \\cdot (\\kappa \\nabla u) &=& f,\n\\quad \\text{ in } \\Omega, \\\\\nu &=& g\\_D, \\quad \\text{ on } \\partial \\Omega\\_D, \\\\\n(\\mathbf{c} u - \\kappa \\nabla u)\\cdot \\mathbf{n} &=& g\\_N,\n\\quad \\text{ on } \\partial \\Omega\\_N.\n\\end{eqnarray\\*}\n\nIntroduce the auxiliary variable \\(\\mathbf{q}=-\\kappa \\nabla u\\) and rewrite the above equation as the first order system:\n\n\\begin{eqnarray\\*}\n\\mathbf{q} + \\kappa \\nabla u &=& 0, \\quad \\text{ in } \\Omega, \\\\\n\\nabla \\cdot (\\mathbf{c} u + \\mathbf{q}) &=& f, \\quad \\text{ in } \\Omega, \\\\\nu &=& g\\_D, \\quad \\text{ on } \\partial \\Omega\\_D, \\\\\n(\\mathbf{q} + \\mathbf{c}u)\\cdot\\mathbf{n} &=& g\\_N,\n\\quad \\text{ on } \\partial \\Omega\\_N.\n\\end{eqnarray\\*}\n\nWe multiply these equations by the weight functions \\(\\mathbf{v}, w\\) and integrate by parts over every element \\(K\\) to obtain:\n\n\\begin{eqnarray\\*}\n(\\mathbf{v}, \\kappa^{-1} \\mathbf{q})\\_K - (\\nabla\\cdot\\mathbf{v}, u)\\_K\n+ \\left<\\mathbf{v}\\cdot\\mathbf{n}, {\\hat{u}}\\right>\\_{\\partial K} &=& 0, \\\\\n- (\\nabla w, \\mathbf{c} u + \\mathbf{q})\\_K\n+ \\left<w, (\\widehat{\\mathbf{c} u}+{\\hat{\\mathbf{q}}})\\cdot\\mathbf{n}\\right>\\_{\\partial K}\n&=& (w,f)\\_K.\n\\end{eqnarray\\*}\n\nThe terms decorated with a hat denote the numerical traces (also commonly referred to as numerical fluxes). They are approximations to the interior values on the boundary of the element. To ensure conservation, these terms must be single-valued on any given element edge \\(\\partial K\\) even though, with discontinuous shape functions, there may of course be multiple values coming from the cells adjacent to an interface. We eliminate the numerical trace \\(\\hat{\\mathbf{q}}\\) by using traces of the form:\n\n\\begin{eqnarray\\*}\n\\widehat{\\mathbf{c} u}+\\hat{\\mathbf{q}} = \\mathbf{c}\\hat{u} + \\mathbf{q}\n+ \\tau(u - \\hat{u})\\mathbf{n} \\quad \\text{ on } \\partial K.\n\\end{eqnarray\\*}\n\nThe variable \\(\\hat {u}\\) is introduced as an additional independent variable and is the one for which we finally set up a globally coupled linear system. As mentioned above, it is defined on the element faces and discontinuous from one face to another wherever faces meet (at vertices in 2d, and at edges and vertices in 3d). Values for \\(u\\) and \\(\\mathbf{q}\\) appearing in the numerical trace function are taken to be the cell's interior solution restricted to the boundary \\(\\partial K\\).\n\nThe local stabilization parameter \\(\\tau\\) has effects on stability and accuracy of HDG solutions; see the literature for a further discussion. A stabilization parameter of unity is reported to be the choice which gives best results. A stabilization parameter \\(\\tau\\) that tends to infinity prohibits jumps in the solution over the element boundaries, making the HDG solution approach the approximation with continuous finite elements. In the program below, we choose the stabilization parameter as\n\n\\begin{eqnarray\\*}\n\\tau = \\frac{\\kappa}{\\ell} + |\\mathbf{c} \\cdot \\mathbf{n}|\n\\end{eqnarray\\*}\n\nwhere we set the diffusion \\(\\kappa=1\\) and the diffusion length scale to \\(\\ell = \\frac{1}{5}\\).\n\nThe trace/skeleton variables in HDG methods are single-valued on element faces. As such, they must strongly represent the Dirichlet data on \\(\\partial\\Omega\\_D\\). This means that\n\n\\begin{equation\\*}\n\\hat{u}|\\_{\\partial \\Omega\\_D} = g\\_D,\n\\end{equation\\*}\n\nwhere the equal sign actually means an \\(L\\_2\\) projection of the boundary function \\(g\\) onto the space of the face variables (e.g. linear functions on the faces). This constraint is then applied to the skeleton variable \\(\\hat{u}\\) using inhomogeneous constraints by the method [VectorTools::project\\_boundary\\_values](namespaceVectorTools.html#a747e71d426643718d52eda904d46bb20).\n\nSumming the elemental contributions across all elements in the triangulation, enforcing the normal component of the numerical flux, and integrating by parts on the equation weighted by \\(w\\), we arrive at the final form of the problem: Find \\((\\mathbf{q}\\_h, u\\_h, \\hat{u}\\_h) \\in\n\\mathcal{V}\\_h^p \\times \\mathcal{W}\\_h^p \\times \\mathcal{M}\\_h^p\\) such that\n\n\\begin{align\\*}\n(\\mathbf{v}, \\kappa^{-1} \\mathbf{q}\\_h)\\_{\\mathcal{T}}\n- ( \\nabla\\cdot\\mathbf{v}, u\\_h)\\_{\\mathcal{T}}\n+ \\left<\\mathbf{v}\\cdot\\mathbf{n}, \\hat{u}\\_h\\right>\\_{\\partial\\mathcal{T}}\n&= 0,\n\\quad &&\\forall \\mathbf{v} \\in \\mathcal{V}\\_h^p,\n\\\\\n- (\\nabla w, \\mathbf{c} u\\_h)\\_{\\mathcal{T}}\n+ (w, \\nabla \\cdot \\mathbf{q}\\_h)\\_{\\mathcal{T}}\n+ (w, (\\mathbf{c}\\cdot\\mathbf{n}) \\hat{u}\\_h)\\_{\\partial \\mathcal{T}}\n+ \\left<w, \\tau (u\\_h - \\hat{u}\\_h)\\right>\\_{\\partial \\mathcal{T}}\n&=\n(w, f)\\_{\\mathcal{T}},\n\\quad &&\\forall w \\in \\mathcal{W}\\_h^p,\n\\\\\n\\left< \\mu, \\hat{u}\\_h\\mathbf{c} \\cdot \\mathbf{n}\n+ \\mathbf{q}\\_h\\cdot \\mathbf{n}\n+ \\tau (u\\_h - \\hat{u}\\_h)\\right>\\_{\\partial \\mathcal{T}}\n&=\n\\left<\\mu, g\\_N\\right>\\_{\\partial\\Omega\\_N},\n\\quad &&\\forall \\mu \\in \\mathcal{M}\\_h^p.\n\\end{align\\*}\n\nThe unknowns \\((\\mathbf{q}\\_h, u\\_h)\\) are referred to as local variables; they are represented as standard DG variables. The unknown \\(\\hat{u}\\_h\\) is the skeleton variable which has support on the codimension-1 surfaces (faces) of the mesh.\n\nWe use the notation \\((\\cdot, \\cdot)\\_{\\mathcal{T}} = \\sum\\_K (\\cdot, \\cdot)\\_K\\) to denote the sum of integrals over all cells and \\(\\left<\\cdot,\n\\cdot\\right>\\_{\\partial \\mathcal{T}} = \\sum\\_K \\left<\\cdot,\n\\cdot\\right>\\_{\\partial K}\\) to denote integration over all faces of all cells, i.e., interior faces are visited twice, once from each side and with the corresponding normal vectors. When combining the contribution from both elements sharing a face, the above equation yields terms familiar from the DG method, with jumps of the solution over the cell boundaries.\n\nIn the equation above, the space \\(\\mathcal {W}\\_h^{p}\\) for the scalar variable \\(u\\_h\\) is defined as the space of functions that are tensor product polynomials of degree \\(p\\) on each cell and discontinuous over the element boundaries \\(\\mathcal Q\\_{-p}\\), i.e., the space described by `FE_DGQ<dim>(p)`. The space for the gradient or flux variable \\(\\mathbf{q}\\_i\\) is a vector element space where each component is a locally polynomial and discontinuous \\(\\mathcal Q\\_{-p}\\). In the code below, we collect these two local parts together in one [FESystem](classFESystem.html) where the first `dim` components denote the gradient part and the last scalar component corresponds to the scalar variable. For the skeleton component \\(\\hat{u}\\_h\\), we define a space that consists of discontinuous tensor product polynomials that live on the element faces, which in deal.II is implemented by the class [FE\\_FaceQ](classFE__FaceQ.html). This space is otherwise similar to [FE\\_DGQ](classFE__DGQ.html), i.e., the solution function is not continuous between two neighboring faces, see also the results section below for an illustration.\n\nIn the weak form given above, we can note the following coupling patterns:\n\n1. The matrix \\(A\\) consists of local-local coupling terms. These arise when the local weighting functions \\((\\mathbf{v}, w)\\) multiply the local solution terms \\((\\mathbf{q}\\_h, u\\_h)\\). Because the elements are discontinuous, \\(A\\) is block diagonal.\n2. The matrix \\(B\\) represents the local-face coupling. These are the terms with weighting functions \\((\\mathbf{v}, w)\\) multiplying the skeleton variable \\(\\hat{u}\\_h\\).\n3. The matrix \\(C\\) represents the face-local coupling, which involves the weighting function \\(\\mu\\) multiplying the local solutions \\((\\mathbf{q}\\_h, u\\_h)\\).\n4. The matrix \\(D\\) is the face-face coupling; terms involve both \\(\\mu\\) and \\(\\hat{u}\\_h\\).\n\n#### Post-processing and super-convergence\n\nOne special feature of the HDG methods is that they typically allow for constructing an enriched solution that gains accuracy. This post-processing takes the HDG solution in an element-by-element fashion and combines it such that one can get \\(\\mathcal O(h^{p+2})\\) order of accuracy when using polynomials of degree \\(p\\). For this to happen, there are two necessary ingredients:\n\n1. The computed solution gradient \\(\\mathbf{q}\\_h\\) converges at optimal rate, i.e., \\(\\mathcal{O}(h^{p+1})\\).\n2. The cell-wise average of the scalar part of the solution, \\(\\frac{(1,u\\_h)\\_K}{\\text{vol}(K)}\\), super-converges at rate \\(\\mathcal{O}(h^{p+2})\\).\n\nWe now introduce a new variable \\(u\\_h^\\* \\in \\mathcal{V}\\_h^{p+1}\\), which we find by minimizing the expression \\(|\\kappa \\nabla u\\_h^\\* + \\mathbf{q}\\_h|^2\\) over the cell \\(K\\) under the constraint \\(\\left(1, u\\_h^\\*\\right)\\_K = \\left(1,\nu\\_h\\right)\\_K\\). The constraint is necessary because the minimization functional does not determine the constant part of \\(u\\_h^\\*\\). This translates to the following system of equations:\n\n\\begin{eqnarray\\*}\n\\left(1, u\\_h^\\*\\right)\\_K &=& \\left(1, u\\_h\\right)\\_K\\\\\n\\left(\\nabla w\\_h^\\*, \\kappa \\nabla u\\_h^\\*\\right)\\_K &=&\n-\\left(\\nabla w\\_h^\\*, \\mathbf{q}\\_h\\right)\\_K\n\\quad \\text{for all } w\\_h^\\* \\in \\mathcal Q^{p+1}.\n\\end{eqnarray\\*}\n\nSince we test by the whole set of basis functions in the space of tensor product polynomials of degree \\(p+1\\) in the second set of equations, this is an overdetermined system with one more equation than unknowns. We fix this in the code below by omitting one of these equations (since the rows in the Laplacian are linearly dependent when representing a constant function). As we will see below, this form of the post-processing gives the desired super-convergence result with rate \\(\\mathcal {O}(h^{p+2})\\). It should be noted that there is some freedom in constructing \\(u\\_h^\\*\\) and this minimization approach to extract the information from the gradient is not the only one. In particular, the post-processed solution defined here does not satisfy the convection-diffusion equation in any sense. As an alternative, the paper by Nguyen, Peraire and Cockburn cited above suggests another somewhat more involved formula for convection-diffusion that can also post-process the flux variable into an \\(H(\\Omega,\\mathrm{div})\\)-conforming variant and better represents the local convection-diffusion operator when the diffusion is small. We leave the implementation of a more sophisticated post-processing as a possible extension to the interested reader.\n\nNote that for vector-valued problems, the post-processing works similarly. One simply sets the constraint for the mean value of each vector component separately and uses the gradient as the main source of information.\n\n### Problem specific data\n\nFor this tutorial program, we consider almost the same test case as in [step-7](step_7.html). The computational domain is \\(\\Omega \\dealcoloneq [-1,1]^d\\) and the exact solution corresponds to the one in [step-7](step_7.html), except for a scaling. We use the following source centers \\(x\\_i\\) for the exponentials\n\n* 1D: \\(\\{x\\_i\\}^1 = \\{ -\\frac{1}{3}, 0, \\frac{1}{3} \\}\\),\n* 2D: \\(\\{\\mathbf{x}\\_i\\}^2 = \\{ (-\\frac{1}{2},\\frac{1}{2}),\n  (-\\frac{1}{2},-\\frac{1}{2}),\n  (\\frac{1}{2},-\\frac{1}{2})\n  \\}\\),\n* 3D: \\(\\{\\mathbf{x}\\_i\\}^3 = \\{ (-\\frac{1}{2},\\frac{1}{2}, \\frac{1}{4}),\n  (-\\frac{3}{5},-\\frac{1}{2}, -\\frac{1}{8}),\n  (\\frac{1}{2},-\\frac{1}{2}, \\frac{1}{2})\n  \\}\\).\n\nWith the exact solution given, we then choose the forcing on the right hand side and the Neumann boundary condition such that we obtain this solution (manufactured solution technique). In this example, we choose the diffusion equal to one and the convection as\n\n\\[\n\\mathbf{c} = \\begin{cases}\n1, & \\textrm{dim}=1 \\\\\n(y, -x), & \\textrm{dim}=2 \\\\\n(y, -x, 1), & \\textrm{dim}=3\n\\end{cases}\n\\]\n\nNote that the convection is divergence-free, \\(\\nabla \\cdot c = 0\\).\n\n### Implementation\n\nBesides implementing the above equations, the implementation below provides the following features:\n\n* [WorkStream](namespaceWorkStream.html) to parallelize local solvers. Workstream has been presented in detail in [step-9](step_9.html).\n* Reconstruct the local DG solution from the trace.\n* Post-processing the solution for superconvergence.\n* [DataOutFaces](classDataOutFaces.html) for direct output of the global skeleton solution.\n\nThe commented program\n=====================\n\n### Include files\n\nMost of the deal.II include files have already been covered in previous examples and are not commented on.\n\n```\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/tensor_function.h>\n   #include <deal.II/base/exceptions.h>\n   #include <deal.II/base/work_stream.h>\n   #include <deal.II/base/convergence_table.h>\n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/solver_bicgstab.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   #include <deal.II/fe/fe_dgq.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/error_estimator.h>\n   #include <deal.II/numerics/data_out.h>\n```\n\nHowever, we do have a few new includes for the example. The first one defines finite element spaces on the faces of the triangulation, which we refer to as the 'skeleton'. These finite elements do not have any support on the element interior, and they represent polynomials that have a single value on each codimension-1 surface, but admit discontinuities on codimension-2 surfaces.\n\n```\n   #include <deal.II/fe/fe_face.h>\n```\n\nThe second new file we include defines a new type of sparse matrix. The regular `SparseMatrix` type stores indices to all non-zero entries. The `ChunkSparseMatrix` takes advantage of the coupled nature of DG solutions. It stores an index to a matrix sub-block of a specified size. In the HDG context, this sub-block-size is actually the number of degrees of freedom per face defined by the skeleton solution field. This reduces the memory consumption of the matrix by up to one third and results in similar speedups when using the matrix in solvers.\n\n```\n   #include <deal.II/lac/chunk_sparse_matrix.h>\n```\n\nThe final new include for this example deals with data output. Since we have a finite element field defined on the skeleton of the mesh, we would like to visualize what that solution actually is. [DataOutFaces](classDataOutFaces.html) does exactly this; the interface is the almost the same as the familiar [DataOut](classDataOut.html), but the output only has codimension-1 data for the simulation.\n\n```\n   #include <deal.II/numerics/data_out_faces.h>\n   \n   #include <iostream>\n```\n\nWe start by putting all of our classes into their own namespace.\n\n```\n   namespace Step51\n   {\n     using namespace dealii;\n```\n\n### Equation data\n\nThe structure of the analytic solution is the same as in [step-7](step_7.html). There are two exceptions. Firstly, we also create a solution for the 3d case, and secondly, we scale the solution so its norm is of order unity for all values of the solution width.\n\n```\n     template <int dim>\n     class SolutionBase\n     {\n     protected:\n       static const unsigned int n_source_centers = 3;\n       static const Point<dim>   source_centers[n_source_centers];\n       static const double       width;\n     };\n   \n   \n     template <>\n     const Point<1>\n       SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\n         {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\n   \n   \n     template <>\n     const Point<2>\n       SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\n         {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\n   \n     template <>\n     const Point<3>\n       SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\n         Point<3>(-0.5, +0.5, 0.25),\n         Point<3>(-0.6, -0.5, -0.125),\n         Point<3>(+0.5, -0.5, 0.5)};\n   \n     template <int dim>\n     const double SolutionBase<dim>::width = 1. / 5.;\n   \n   \n     template <int dim>\n     class Solution : public Function<dim>, protected SolutionBase<dim>\n     {\n     public:\n       virtual double value(const Point<dim> &p,\n                            const unsigned int /*component*/ = 0) const override\n       {\n         double sum = 0;\n         for (unsigned int i = 0; i < this->n_source_centers; ++i)\n           {\n             const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n             sum +=\n               std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\n           }\n   \n         return sum /\n                std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n       }\n   \n       virtual Tensor<1, dim>\n       gradient(const Point<dim> &p,\n                const unsigned int /*component*/ = 0) const override\n       {\n         Tensor<1, dim> sum;\n         for (unsigned int i = 0; i < this->n_source_centers; ++i)\n           {\n             const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n   \n             sum +=\n               (-2 / (this->width * this->width) *\n                std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\n                x_minus_xi);\n           }\n   \n         return sum /\n                std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n       }\n     };\n```\n\nThis class implements a function where the scalar solution and its negative gradient are collected together. This function is used when computing the error of the HDG approximation and its implementation is to simply call value and gradient function of the Solution class.\n\n```\n     template <int dim>\n     class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\n     {\n     public:\n       SolutionAndGradient()\n         : Function<dim>(dim + 1)\n       {}\n   \n       virtual void vector_value(const Point<dim> &p,\n                                 Vector<double>   &v) const override\n       {\n         AssertDimension(v.size(), dim + 1);\n         Solution<dim>  solution;\n         Tensor<1, dim> grad = solution.gradient(p);\n         for (unsigned int d = 0; d < dim; ++d)\n           v[d] = -grad[d];\n         v[dim] = solution.value(p);\n       }\n     };\n```\n\nNext comes the implementation of the convection velocity. As described in the introduction, we choose a velocity field that is \\((y, -x)\\) in 2d and \\((y, -x, 1)\\) in 3d. This gives a divergence-free velocity field.\n\n```\n     template <int dim>\n     class ConvectionVelocity : public TensorFunction<1, dim>\n     {\n     public:\n       ConvectionVelocity()\n         : TensorFunction<1, dim>()\n       {}\n   \n       virtual Tensor<1, dim> value(const Point<dim> &p) const override\n       {\n         Tensor<1, dim> convection;\n         switch (dim)\n           {\n             case 1:\n               convection[0] = 1;\n               break;\n             case 2:\n               convection[0] = p[1];\n               convection[1] = -p[0];\n               break;\n             case 3:\n               convection[0] = p[1];\n               convection[1] = -p[0];\n               convection[2] = 1;\n               break;\n             default:\n               DEAL_II_NOT_IMPLEMENTED();\n           }\n         return convection;\n       }\n     };\n```\n\nThe last function we implement is the right hand side for the manufactured solution. It is very similar to [step-7](step_7.html), with the exception that we now have a convection term instead of the reaction term. Since the velocity field is incompressible, i.e., \\(\\nabla \\cdot \\mathbf{c} =\n0\\), the advection term simply reads \\(\\mathbf{c} \\nabla u\\).\n\n```\n     template <int dim>\n     class RightHandSide : public Function<dim>, protected SolutionBase<dim>\n     {\n     public:\n       virtual double value(const Point<dim> &p,\n                            const unsigned int /*component*/ = 0) const override\n       {\n         ConvectionVelocity<dim> convection_velocity;\n         Tensor<1, dim>          convection = convection_velocity.value(p);\n         double                  sum        = 0;\n         for (unsigned int i = 0; i < this->n_source_centers; ++i)\n           {\n             const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n   \n             sum +=\n               ((2 * dim - 2 * convection * x_minus_xi -\n                 4 * x_minus_xi.norm_square() / (this->width * this->width)) /\n                (this->width * this->width) *\n                std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\n           }\n   \n         return sum /\n                std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n       }\n     };\n```\n\n### The HDG solver class\n\nThe HDG solution procedure follows closely that of [step-7](step_7.html). The major difference is the use of three different sets of [DoFHandler](classDoFHandler.html) and FE objects, along with the [ChunkSparseMatrix](classChunkSparseMatrix.html) and the corresponding solutions vectors. We also use [WorkStream](namespaceWorkStream.html) to enable a multithreaded local solution process which exploits the embarrassingly parallel nature of the local solver. For [WorkStream](namespaceWorkStream.html), we define the local operations on a cell and a copy function into the global matrix and vector. We do this both for the assembly (which is run twice, once when we generate the system matrix and once when we compute the element-interior solutions from the skeleton values) and for the postprocessing where we extract a solution that converges at higher order.\n\n```\n     template <int dim>\n     class HDG\n     {\n     public:\n       enum RefinementMode\n       {\n         global_refinement,\n         adaptive_refinement\n       };\n   \n       HDG(const unsigned int degree, const RefinementMode refinement_mode);\n       void run();\n   \n     private:\n       void setup_system();\n       void assemble_system(const bool reconstruct_trace = false);\n       void solve();\n       void postprocess();\n       void refine_grid(const unsigned int cycle);\n       void output_results(const unsigned int cycle);\n```\n\nData for the assembly and solution of the primal variables.\n\n```\n       struct PerTaskData;\n       struct ScratchData;\n```\n\nPost-processing the solution to obtain \\(u^\\*\\) is an element-by-element procedure; as such, we do not need to assemble any global data and do not declare any 'task data' for [WorkStream](namespaceWorkStream.html) to use.\n\n```\n       struct PostProcessScratchData;\n```\n\nThe following three functions are used by [WorkStream](namespaceWorkStream.html) to do the actual work of the program.\n\n```\n       void assemble_system_one_cell(\n         const typename DoFHandler<dim>::active_cell_iterator &cell,\n         ScratchData                                          &scratch,\n         PerTaskData                                          &task_data);\n   \n       void copy_local_to_global(const PerTaskData &data);\n   \n       void postprocess_one_cell(\n         const typename DoFHandler<dim>::active_cell_iterator &cell,\n         PostProcessScratchData                               &scratch,\n         unsigned int                                         &empty_data);\n   \n   \n       Triangulation<dim> triangulation;\n```\n\nThe 'local' solutions are interior to each element. These represent the primal solution field \\(u\\) as well as the auxiliary field \\(\\mathbf{q}\\).\n\n```\n       const FESystem<dim> fe_local;\n       DoFHandler<dim>     dof_handler_local;\n       Vector<double>      solution_local;\n```\n\nThe new finite element type and corresponding `DoFHandler` are used for the global skeleton solution that couples the element-level local solutions.\n\n```\n       const FE_FaceQ<dim> fe;\n       DoFHandler<dim>     dof_handler;\n       Vector<double>      solution;\n       Vector<double>      system_rhs;\n```\n\nAs stated in the introduction, HDG solutions can be post-processed to attain superconvergence rates of \\(\\mathcal{O}(h^{p+2})\\). The post-processed solution is a discontinuous finite element solution representing the primal variable on the interior of each cell. We define a FE type of degree \\(p+1\\) to represent this post-processed solution, which we only use for output after constructing it.\n\n```\n       const FE_DGQ<dim> fe_u_post;\n       DoFHandler<dim>   dof_handler_u_post;\n       Vector<double>    solution_u_post;\n```\n\nThe degrees of freedom corresponding to the skeleton strongly enforce Dirichlet boundary conditions, just as in a continuous Galerkin finite element method. We can enforce the boundary conditions in an analogous manner via an [AffineConstraints](classAffineConstraints.html) object. In addition, hanging nodes are handled in the same way as for continuous finite elements: For the face elements which only define degrees of freedom on the face, this process sets the solution on the refined side to coincide with the representation on the coarse side.\n\nNote that for HDG, the elimination of hanging nodes is not the only possibility — in terms of the HDG theory, one could also use the unknowns from the refined side and express the local solution on the coarse side through the trace values on the refined side. However, such a setup is not as easily implemented in terms of deal.II loops and not further analyzed.\n\n```\n       AffineConstraints<double> constraints;\n```\n\nThe usage of the [ChunkSparseMatrix](classChunkSparseMatrix.html) class is similar to the usual sparse matrices: You need a sparsity pattern of type [ChunkSparsityPattern](classChunkSparsityPattern.html) and the actual matrix object. When creating the sparsity pattern, we just have to additionally pass the size of local blocks.\n\n```\n       ChunkSparsityPattern      sparsity_pattern;\n       ChunkSparseMatrix<double> system_matrix;\n```\n\nSame as [step-7](step_7.html):\n\n```\n       const RefinementMode refinement_mode;\n       ConvergenceTable     convergence_table;\n     };\n```\n\n### The HDG class implementation\n\n#### Constructor\n\nThe constructor is similar to those in other examples, with the exception of handling multiple [DoFHandler](classDoFHandler.html) and [FiniteElement](classFiniteElement.html) objects. Note that we create a system of finite elements for the local DG part, including the gradient/flux part and the scalar part.\n\n```\n     template <int dim>\n     HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\n       : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\n       , dof_handler_local(triangulation)\n       , fe(degree)\n       , dof_handler(triangulation)\n       , fe_u_post(degree + 1)\n       , dof_handler_u_post(triangulation)\n       , refinement_mode(refinement_mode)\n     {}\n```\n\n#### HDG::setup\\_system\n\nThe system for an HDG solution is setup in an analogous manner to most of the other tutorial programs. We are careful to distribute dofs with all of our [DoFHandler](classDoFHandler.html) objects. The `solution` and `system_matrix` objects go with the global skeleton solution.\n\n```\n     template <int dim>\n     void HDG<dim>::setup_system()\n     {\n       dof_handler_local.distribute_dofs(fe_local);\n       dof_handler.distribute_dofs(fe);\n       dof_handler_u_post.distribute_dofs(fe_u_post);\n   \n       std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n                 << std::endl;\n   \n       solution.reinit(dof_handler.n_dofs());\n       system_rhs.reinit(dof_handler.n_dofs());\n   \n       solution_local.reinit(dof_handler_local.n_dofs());\n       solution_u_post.reinit(dof_handler_u_post.n_dofs());\n   \n       constraints.clear();\n       DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n       std::map<types::boundary_id, const Function<dim> *> boundary_functions;\n       Solution<dim>                                       solution_function;\n       boundary_functions[0] = &solution_function;\n       VectorTools::project_boundary_values(dof_handler,\n                                            boundary_functions,\n                                            QGauss<dim - 1>(fe.degree + 1),\n                                            constraints);\n       constraints.close();\n```\n\nWhen creating the chunk sparsity pattern, we first create the usual dynamic sparsity pattern and then set the chunk size, which is equal to the number of dofs on a face, when copying this into the final sparsity pattern.\n\n```\n       {\n         DynamicSparsityPattern dsp(dof_handler.n_dofs());\n         DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n         sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\n       }\n       system_matrix.reinit(sparsity_pattern);\n     }\n```\n\n#### HDG::PerTaskData\n\nNext comes the definition of the local data structures for the parallel assembly. The first structure `PerTaskData` contains the local vector and matrix that are written into the global matrix, whereas the ScratchData contains all data that we need for the local assembly. There is one variable worth noting here, namely the boolean variable `trace_reconstruct`. As mentioned in the introduction, we solve the HDG system in two steps. First, we create a linear system for the skeleton system where we condense the local part into it via the Schur complement \\(D-CA^{-1}B\\). Then, we solve for the local part using the skeleton solution. For these two steps, we need the same matrices on the elements twice, which we want to compute by two assembly steps. Since most of the code is similar, we do this with the same function but only switch between the two based on a flag that we set when starting the assembly. Since we need to pass this information on to the local worker routines, we store it once in the task data.\n\n```\n     template <int dim>\n     struct HDG<dim>::PerTaskData\n     {\n       FullMatrix<double>                   cell_matrix;\n       Vector<double>                       cell_vector;\n       std::vector<types::global_dof_index> dof_indices;\n   \n       bool trace_reconstruct;\n   \n       PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\n         : cell_matrix(n_dofs, n_dofs)\n         , cell_vector(n_dofs)\n         , dof_indices(n_dofs)\n         , trace_reconstruct(trace_reconstruct)\n       {}\n     };\n```\n\n#### HDG::ScratchData\n\n`ScratchData` contains persistent data for each thread within [WorkStream](namespaceWorkStream.html). The [FEValues](classFEValues.html), matrix, and vector objects should be familiar by now. There are two objects that need to be discussed: `std::vector<std::vector<unsigned int> > fe_local_support_on_face` and `std::vector<std::vector<unsigned int> > fe_support_on_face`. These are used to indicate whether or not the finite elements chosen have support (non-zero values) on a given face of the reference cell for the local part associated to `fe_local` and the skeleton part `fe`. We extract this information in the constructor and store it once for all cells that we work on. Had we not stored this information, we would be forced to assemble a large number of zero terms on each cell, which would significantly slow the program.\n\n```\n     template <int dim>\n     struct HDG<dim>::ScratchData\n     {\n       FEValues<dim>     fe_values_local;\n       FEFaceValues<dim> fe_face_values_local;\n       FEFaceValues<dim> fe_face_values;\n   \n       FullMatrix<double> ll_matrix;\n       FullMatrix<double> lf_matrix;\n       FullMatrix<double> fl_matrix;\n       FullMatrix<double> tmp_matrix;\n       Vector<double>     l_rhs;\n       Vector<double>     tmp_rhs;\n   \n       std::vector<Tensor<1, dim>> q_phi;\n       std::vector<double>         q_phi_div;\n       std::vector<double>         u_phi;\n       std::vector<Tensor<1, dim>> u_phi_grad;\n       std::vector<double>         tr_phi;\n       std::vector<double>         trace_values;\n   \n       std::vector<std::vector<unsigned int>> fe_local_support_on_face;\n       std::vector<std::vector<unsigned int>> fe_support_on_face;\n   \n       ConvectionVelocity<dim> convection_velocity;\n       RightHandSide<dim>      right_hand_side;\n       const Solution<dim>     exact_solution;\n   \n       ScratchData(const FiniteElement<dim> &fe,\n                   const FiniteElement<dim> &fe_local,\n                   const QGauss<dim>        &quadrature_formula,\n                   const QGauss<dim - 1>    &face_quadrature_formula,\n                   const UpdateFlags         local_flags,\n                   const UpdateFlags         local_face_flags,\n                   const UpdateFlags         flags)\n         : fe_values_local(fe_local, quadrature_formula, local_flags)\n         , fe_face_values_local(fe_local,\n                                face_quadrature_formula,\n                                local_face_flags)\n         , fe_face_values(fe, face_quadrature_formula, flags)\n         , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n         , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\n         , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n         , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n         , l_rhs(fe_local.n_dofs_per_cell())\n         , tmp_rhs(fe_local.n_dofs_per_cell())\n         , q_phi(fe_local.n_dofs_per_cell())\n         , q_phi_div(fe_local.n_dofs_per_cell())\n         , u_phi(fe_local.n_dofs_per_cell())\n         , u_phi_grad(fe_local.n_dofs_per_cell())\n         , tr_phi(fe.n_dofs_per_cell())\n         , trace_values(face_quadrature_formula.size())\n         , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\n         , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\n         , exact_solution()\n       {\n         for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\n           for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\n             {\n               if (fe_local.has_support_on_face(i, face_no))\n                 fe_local_support_on_face[face_no].push_back(i);\n             }\n   \n         for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\n           for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\n             {\n               if (fe.has_support_on_face(i, face_no))\n                 fe_support_on_face[face_no].push_back(i);\n             }\n       }\n   \n       ScratchData(const ScratchData &sd)\n         : fe_values_local(sd.fe_values_local.get_fe(),\n                           sd.fe_values_local.get_quadrature(),\n                           sd.fe_values_local.get_update_flags())\n         , fe_face_values_local(sd.fe_face_values_local.get_fe(),\n                                sd.fe_face_values_local.get_quadrature(),\n                                sd.fe_face_values_local.get_update_flags())\n         , fe_face_values(sd.fe_face_values.get_fe(),\n                          sd.fe_face_values.get_quadrature(),\n                          sd.fe_face_values.get_update_flags())\n         , ll_matrix(sd.ll_matrix)\n         , lf_matrix(sd.lf_matrix)\n         , fl_matrix(sd.fl_matrix)\n         , tmp_matrix(sd.tmp_matrix)\n         , l_rhs(sd.l_rhs)\n         , tmp_rhs(sd.tmp_rhs)\n         , q_phi(sd.q_phi)\n         , q_phi_div(sd.q_phi_div)\n         , u_phi(sd.u_phi)\n         , u_phi_grad(sd.u_phi_grad)\n         , tr_phi(sd.tr_phi)\n         , trace_values(sd.trace_values)\n         , fe_local_support_on_face(sd.fe_local_support_on_face)\n         , fe_support_on_face(sd.fe_support_on_face)\n         , exact_solution()\n       {}\n     };\n```\n\n#### HDG::PostProcessScratchData\n\n`PostProcessScratchData` contains the data used by [WorkStream](namespaceWorkStream.html) when post-processing the local solution \\(u^\\*\\). It is similar, but much simpler, than `ScratchData`.\n\n```\n     template <int dim>\n     struct HDG<dim>::PostProcessScratchData\n     {\n       FEValues<dim> fe_values_local;\n       FEValues<dim> fe_values;\n   \n       std::vector<double>         u_values;\n       std::vector<Tensor<1, dim>> u_gradients;\n       FullMatrix<double>          cell_matrix;\n   \n       Vector<double> cell_rhs;\n       Vector<double> cell_sol;\n   \n       PostProcessScratchData(const FiniteElement<dim> &fe,\n                              const FiniteElement<dim> &fe_local,\n                              const QGauss<dim>        &quadrature_formula,\n                              const UpdateFlags         local_flags,\n                              const UpdateFlags         flags)\n         : fe_values_local(fe_local, quadrature_formula, local_flags)\n         , fe_values(fe, quadrature_formula, flags)\n         , u_values(quadrature_formula.size())\n         , u_gradients(quadrature_formula.size())\n         , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\n         , cell_rhs(fe.n_dofs_per_cell())\n         , cell_sol(fe.n_dofs_per_cell())\n       {}\n   \n       PostProcessScratchData(const PostProcessScratchData &sd)\n         : fe_values_local(sd.fe_values_local.get_fe(),\n                           sd.fe_values_local.get_quadrature(),\n                           sd.fe_values_local.get_update_flags())\n         , fe_values(sd.fe_values.get_fe(),\n                     sd.fe_values.get_quadrature(),\n                     sd.fe_values.get_update_flags())\n         , u_values(sd.u_values)\n         , u_gradients(sd.u_gradients)\n         , cell_matrix(sd.cell_matrix)\n         , cell_rhs(sd.cell_rhs)\n         , cell_sol(sd.cell_sol)\n       {}\n     };\n```\n\n#### HDG::assemble\\_system\n\nThe `assemble_system` function is similar to the one on [step-32](step_32.html), where the quadrature formula and the update flags are set up, and then `WorkStream` is used to do the work in a multi-threaded manner. The `trace_reconstruct` input parameter is used to decide whether we are solving for the global skeleton solution (false) or the local solution (true).\n\nOne thing worth noting for the multi-threaded execution of assembly is the fact that the local computations in `assemble_system_one_cell()` call into BLAS and LAPACK functions if those are available in deal.II. Thus, the underlying BLAS/LAPACK library must support calls from multiple threads at the same time. Most implementations do support this, but some libraries need to be built in a specific way to avoid problems. For example, OpenBLAS compiled without multithreading inside the BLAS/LAPACK calls needs to built with a flag called `USE_LOCKING` set to true.\n\n```\n     template <int dim>\n     void HDG<dim>::assemble_system(const bool trace_reconstruct)\n     {\n       const QGauss<dim>     quadrature_formula(fe.degree + 1);\n       const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\n   \n       const UpdateFlags local_flags(update_values | update_gradients |\n                                     update_JxW_values | update_quadrature_points);\n   \n       const UpdateFlags local_face_flags(update_values);\n   \n       const UpdateFlags flags(update_values | update_normal_vectors |\n                               update_quadrature_points | update_JxW_values);\n   \n       PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\n       ScratchData scratch(fe,\n                           fe_local,\n                           quadrature_formula,\n                           face_quadrature_formula,\n                           local_flags,\n                           local_face_flags,\n                           flags);\n   \n       WorkStream::run(dof_handler.begin_active(),\n                       dof_handler.end(),\n                       *this,\n                       &HDG<dim>::assemble_system_one_cell,\n                       &HDG<dim>::copy_local_to_global,\n                       scratch,\n                       task_data);\n     }\n```\n\n#### HDG::assemble\\_system\\_one\\_cell\n\nThe real work of the HDG program is done by `assemble_system_one_cell`. Assembling the local matrices \\(A, B, C\\) is done here, along with the local contributions of the global matrix \\(D\\).\n\n```\n     template <int dim>\n     void HDG<dim>::assemble_system_one_cell(\n       const typename DoFHandler<dim>::active_cell_iterator &cell,\n       ScratchData                                          &scratch,\n       PerTaskData                                          &task_data)\n     {\n```\n\nConstruct iterator for dof\\_handler\\_local for [FEValues](classFEValues.html) reinit function.\n\n```\n       const typename DoFHandler<dim>::active_cell_iterator loc_cell =\n         cell->as_dof_handler_iterator(dof_handler_local);\n   \n       const unsigned int n_q_points =\n         scratch.fe_values_local.get_quadrature().size();\n       const unsigned int n_face_q_points =\n         scratch.fe_face_values_local.get_quadrature().size();\n   \n       const unsigned int loc_dofs_per_cell =\n         scratch.fe_values_local.get_fe().n_dofs_per_cell();\n   \n       const FEValuesExtractors::Vector fluxes(0);\n       const FEValuesExtractors::Scalar scalar(dim);\n   \n       scratch.ll_matrix = 0;\n       scratch.l_rhs     = 0;\n       if (!task_data.trace_reconstruct)\n         {\n           scratch.lf_matrix     = 0;\n           scratch.fl_matrix     = 0;\n           task_data.cell_matrix = 0;\n           task_data.cell_vector = 0;\n         }\n       scratch.fe_values_local.reinit(loc_cell);\n```\n\nWe first compute the cell-interior contribution to `ll_matrix` matrix (referred to as matrix \\(A\\) in the introduction) corresponding to local-local coupling, as well as the local right-hand-side vector. We store the values at each quadrature point for the basis functions, the right-hand-side value, and the convection velocity, in order to have quick access to these fields.\n\n```\n       for (unsigned int q = 0; q < n_q_points; ++q)\n         {\n           const double rhs_value = scratch.right_hand_side.value(\n             scratch.fe_values_local.quadrature_point(q));\n           const Tensor<1, dim> convection = scratch.convection_velocity.value(\n             scratch.fe_values_local.quadrature_point(q));\n           const double JxW = scratch.fe_values_local.JxW(q);\n           for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\n             {\n               scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\n               scratch.q_phi_div[k] =\n                 scratch.fe_values_local[fluxes].divergence(k, q);\n               scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\n               scratch.u_phi_grad[k] =\n                 scratch.fe_values_local[scalar].gradient(k, q);\n             }\n           for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\n             {\n               for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\n                 scratch.ll_matrix(i, j) +=\n                   (scratch.q_phi[i] * scratch.q_phi[j] -\n                    scratch.q_phi_div[i] * scratch.u_phi[j] +\n                    scratch.u_phi[i] * scratch.q_phi_div[j] -\n                    (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\n                   JxW;\n               scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\n             }\n         }\n```\n\nFace terms are assembled on all faces of all elements. This is in contrast to more traditional DG methods, where each face is only visited once in the assembly procedure.\n\n```\n       for (const auto face_no : cell->face_indices())\n         {\n           scratch.fe_face_values_local.reinit(loc_cell, face_no);\n           scratch.fe_face_values.reinit(cell, face_no);\n```\n\nThe already obtained \\(\\hat{u}\\) values are needed when solving for the local variables.\n\n```\n           if (task_data.trace_reconstruct)\n             scratch.fe_face_values.get_function_values(solution,\n                                                        scratch.trace_values);\n   \n           for (unsigned int q = 0; q < n_face_q_points; ++q)\n             {\n               const double     JxW = scratch.fe_face_values.JxW(q);\n               const Point<dim> quadrature_point =\n                 scratch.fe_face_values.quadrature_point(q);\n               const Tensor<1, dim> normal =\n                 scratch.fe_face_values.normal_vector(q);\n               const Tensor<1, dim> convection =\n                 scratch.convection_velocity.value(quadrature_point);\n```\n\nHere we compute the stabilization parameter discussed in the introduction: since the diffusion is one and the diffusion length scale is set to 1/5, it simply results in a contribution of 5 for the diffusion part and the magnitude of convection through the element boundary in a centered scheme for the convection part.\n\n```\n               const double tau_stab = (5. + std::abs(convection * normal));\n```\n\nWe store the non-zero flux and scalar values, making use of the support\\_on\\_face information we created in `ScratchData`.\n\n```\n               for (unsigned int k = 0;\n                    k < scratch.fe_local_support_on_face[face_no].size();\n                    ++k)\n                 {\n                   const unsigned int kk =\n                     scratch.fe_local_support_on_face[face_no][k];\n                   scratch.q_phi[k] =\n                     scratch.fe_face_values_local[fluxes].value(kk, q);\n                   scratch.u_phi[k] =\n                     scratch.fe_face_values_local[scalar].value(kk, q);\n                 }\n```\n\nWhen `trace_reconstruct=false`, we are preparing to assemble the system for the skeleton variable \\(\\hat{u}\\). If this is the case, we must assemble all local matrices associated with the problem: local-local, local-face, face-local, and face-face. The face-face matrix is stored as `TaskData::cell_matrix`, so that it can be assembled into the global system by `copy_local_to_global`.\n\n```\n               if (!task_data.trace_reconstruct)\n                 {\n                   for (unsigned int k = 0;\n                        k < scratch.fe_support_on_face[face_no].size();\n                        ++k)\n                     scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\n                       scratch.fe_support_on_face[face_no][k], q);\n                   for (unsigned int i = 0;\n                        i < scratch.fe_local_support_on_face[face_no].size();\n                        ++i)\n                     for (unsigned int j = 0;\n                          j < scratch.fe_support_on_face[face_no].size();\n                          ++j)\n                       {\n                         const unsigned int ii =\n                           scratch.fe_local_support_on_face[face_no][i];\n                         const unsigned int jj =\n                           scratch.fe_support_on_face[face_no][j];\n                         scratch.lf_matrix(ii, jj) +=\n                           ((scratch.q_phi[i] * normal +\n                             (convection * normal - tau_stab) * scratch.u_phi[i]) *\n                            scratch.tr_phi[j]) *\n                           JxW;\n```\n\nNote the sign of the face\\_no-local matrix. We negate the sign during assembly here so that we can use the [FullMatrix::mmult](classFullMatrix.html#a21b873fcd180999ad0d268c3278a71ec) with addition when computing the Schur complement.\n\n```\n                         scratch.fl_matrix(jj, ii) -=\n                           ((scratch.q_phi[i] * normal +\n                             tau_stab * scratch.u_phi[i]) *\n                            scratch.tr_phi[j]) *\n                           JxW;\n                       }\n   \n                   for (unsigned int i = 0;\n                        i < scratch.fe_support_on_face[face_no].size();\n                        ++i)\n                     for (unsigned int j = 0;\n                          j < scratch.fe_support_on_face[face_no].size();\n                          ++j)\n                       {\n                         const unsigned int ii =\n                           scratch.fe_support_on_face[face_no][i];\n                         const unsigned int jj =\n                           scratch.fe_support_on_face[face_no][j];\n                         task_data.cell_matrix(ii, jj) +=\n                           ((convection * normal - tau_stab) * scratch.tr_phi[i] *\n                            scratch.tr_phi[j]) *\n                           JxW;\n                       }\n   \n                   if (cell->face(face_no)->at_boundary() &&\n                       (cell->face(face_no)->boundary_id() == 1))\n                     {\n                       const double neumann_value =\n                         -scratch.exact_solution.gradient(quadrature_point) *\n                           normal +\n                         convection * normal *\n                           scratch.exact_solution.value(quadrature_point);\n                       for (unsigned int i = 0;\n                            i < scratch.fe_support_on_face[face_no].size();\n                            ++i)\n                         {\n                           const unsigned int ii =\n                             scratch.fe_support_on_face[face_no][i];\n                           task_data.cell_vector(ii) +=\n                             scratch.tr_phi[i] * neumann_value * JxW;\n                         }\n                     }\n                 }\n```\n\nThis last term adds the contribution of the term \\(\\left<w,\\tau\nu\\_h\\right>\\_{\\partial \\mathcal T}\\) to the local matrix. As opposed to the face matrices above, we need it in both assembly stages.\n\n```\n               for (unsigned int i = 0;\n                    i < scratch.fe_local_support_on_face[face_no].size();\n                    ++i)\n                 for (unsigned int j = 0;\n                      j < scratch.fe_local_support_on_face[face_no].size();\n                      ++j)\n                   {\n                     const unsigned int ii =\n                       scratch.fe_local_support_on_face[face_no][i];\n                     const unsigned int jj =\n                       scratch.fe_local_support_on_face[face_no][j];\n                     scratch.ll_matrix(ii, jj) +=\n                       tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\n                   }\n```\n\nWhen `trace_reconstruct=true`, we are solving for the local solutions on an element by element basis. The local right-hand-side is calculated by replacing the basis functions `tr_phi` in the `lf_matrix` computation by the computed values `trace_values`. Of course, the sign of the matrix is now minus since we have moved everything to the other side of the equation.\n\n```\n               if (task_data.trace_reconstruct)\n                 for (unsigned int i = 0;\n                      i < scratch.fe_local_support_on_face[face_no].size();\n                      ++i)\n                   {\n                     const unsigned int ii =\n                       scratch.fe_local_support_on_face[face_no][i];\n                     scratch.l_rhs(ii) -=\n                       (scratch.q_phi[i] * normal +\n                        scratch.u_phi[i] * (convection * normal - tau_stab)) *\n                       scratch.trace_values[q] * JxW;\n                   }\n             }\n         }\n```\n\nOnce assembly of all of the local contributions is complete, we must either: (1) assemble the global system, or (2) compute the local solution values and save them. In either case, the first step is to invert the local-local matrix.\n\n```\n       scratch.ll_matrix.gauss_jordan();\n```\n\nFor (1), we compute the Schur complement and add it to the `cell_matrix`, matrix \\(D\\) in the introduction.\n\n```\n       if (task_data.trace_reconstruct == false)\n         {\n           scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\n           scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\n           scratch.tmp_matrix.mmult(task_data.cell_matrix,\n                                    scratch.lf_matrix,\n                                    true);\n           cell->get_dof_indices(task_data.dof_indices);\n         }\n```\n\nFor (2), we are simply solving (ll\\_matrix).(solution\\_local) = (l\\_rhs). Hence, we multiply `l_rhs` by our already inverted local-local matrix and store the result using the `set_dof_values` function.\n\n```\n       else\n         {\n           scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\n           loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\n         }\n     }\n```\n\n#### HDG::copy\\_local\\_to\\_global\n\nIf we are in the first step of the solution, i.e. `trace_reconstruct=false`, then we assemble the local matrices into the global system.\n\n```\n     template <int dim>\n     void HDG<dim>::copy_local_to_global(const PerTaskData &data)\n     {\n       if (data.trace_reconstruct == false)\n         constraints.distribute_local_to_global(data.cell_matrix,\n                                                data.cell_vector,\n                                                data.dof_indices,\n                                                system_matrix,\n                                                system_rhs);\n     }\n```\n\n#### HDG::solve\n\nThe skeleton solution is solved for by using a BiCGStab solver with identity preconditioner.\n\n```\n     template <int dim>\n     void HDG<dim>::solve()\n     {\n       SolverControl                  solver_control(system_matrix.m() * 10,\n                                    1e-11 * system_rhs.l2_norm());\n       SolverBicgstab<Vector<double>> solver(solver_control);\n       solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\n   \n       std::cout << \"   Number of BiCGStab iterations: \"\n                 << solver_control.last_step() << std::endl;\n   \n       system_matrix.clear();\n       sparsity_pattern.reinit(0, 0, 0, 1);\n   \n       constraints.distribute(solution);\n```\n\nOnce we have solved for the skeleton solution, we can solve for the local solutions in an element-by-element fashion. We do this by re-using the same `assemble_system` function but switching `trace_reconstruct` to true.\n\n```\n       assemble_system(true);\n     }\n```\n\n#### HDG::postprocess\n\nThe postprocess method serves two purposes. First, we want to construct a post-processed scalar variables in the element space of degree \\(p+1\\) that we hope will converge at order \\(p+2\\). This is again an element-by-element process and only involves the scalar solution as well as the gradient on the local cell. To do this, we introduce the already defined scratch data together with some update flags and run the work stream to do this in parallel.\n\nSecondly, we want to compute discretization errors just as we did in [step-7](step_7.html). The overall procedure is similar with calls to [VectorTools::integrate\\_difference](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). The difference is in how we compute the errors for the scalar variable and the gradient variable. In [step-7](step_7.html), we did this by computing `L2_norm` or `H1_seminorm` contributions. Here, we have a [DoFHandler](classDoFHandler.html) with these two contributions computed and sorted by their vector component, `[0, dim)` for the gradient and `dim` for the scalar. To compute their value, we hence use a [ComponentSelectFunction](classComponentSelectFunction.html) with either of them, together with the `SolutionAndGradient` class introduced above that contains the analytic parts of either of them. Eventually, we also compute the L2-error of the post-processed solution and add the results into the convergence table.\n\n```\n     template <int dim>\n     void HDG<dim>::postprocess()\n     {\n       {\n         const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\n         const UpdateFlags local_flags(update_values);\n         const UpdateFlags flags(update_values | update_gradients |\n                                 update_JxW_values);\n   \n         PostProcessScratchData scratch(\n           fe_u_post, fe_local, quadrature_formula, local_flags, flags);\n   \n         WorkStream::run(\n           dof_handler_u_post.begin_active(),\n           dof_handler_u_post.end(),\n           [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\n                  PostProcessScratchData                               &scratch,\n                  unsigned int                                         &data) {\n             this->postprocess_one_cell(cell, scratch, data);\n           },\n           std::function<void(const unsigned int &)>(),\n           scratch,\n           0U);\n       }\n   \n       Vector<float> difference_per_cell(triangulation.n_active_cells());\n   \n       ComponentSelectFunction<dim> value_select(dim, dim + 1);\n       VectorTools::integrate_difference(dof_handler_local,\n                                         solution_local,\n                                         SolutionAndGradient<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::L2_norm,\n                                         &value_select);\n       const double L2_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::L2_norm);\n   \n       ComponentSelectFunction<dim> gradient_select(\n         std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\n       VectorTools::integrate_difference(dof_handler_local,\n                                         solution_local,\n                                         SolutionAndGradient<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::L2_norm,\n                                         &gradient_select);\n       const double grad_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::L2_norm);\n   \n       VectorTools::integrate_difference(dof_handler_u_post,\n                                         solution_u_post,\n                                         Solution<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(fe.degree + 3),\n                                         VectorTools::L2_norm);\n       const double post_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::L2_norm);\n   \n       convergence_table.add_value(\"cells\", triangulation.n_active_cells());\n       convergence_table.add_value(\"dofs\", dof_handler.n_dofs());\n   \n       convergence_table.add_value(\"val L2\", L2_error);\n       convergence_table.set_scientific(\"val L2\", true);\n       convergence_table.set_precision(\"val L2\", 3);\n   \n       convergence_table.add_value(\"grad L2\", grad_error);\n       convergence_table.set_scientific(\"grad L2\", true);\n       convergence_table.set_precision(\"grad L2\", 3);\n   \n       convergence_table.add_value(\"val L2-post\", post_error);\n       convergence_table.set_scientific(\"val L2-post\", true);\n       convergence_table.set_precision(\"val L2-post\", 3);\n     }\n```\n\n#### HDG::postprocess\\_one\\_cell\n\nThis is the actual work done for the postprocessing. According to the discussion in the introduction, we need to set up a system that projects the gradient part of the DG solution onto the gradient of the post-processed variable. Moreover, we need to set the average of the new post-processed variable to equal the average of the scalar DG solution on the cell.\n\nMore technically speaking, the projection of the gradient is a system that would potentially fills our `dofs_per_cell` times `dofs_per_cell` matrix but is singular (the sum of all rows would be zero because the constant function has zero gradient). Therefore, we take one row away and use it for imposing the average of the scalar value. We pick the first row for the scalar part, even though we could pick any row for \\(\\mathcal\nQ\\_{-p}\\) elements. However, had we used [FE\\_DGP](classFE__DGP.html) elements instead, the first row would correspond to the constant part already and deleting e.g. the last row would give us a singular system. This way, our program can also be used for those elements.\n\n```\n     template <int dim>\n     void HDG<dim>::postprocess_one_cell(\n       const typename DoFHandler<dim>::active_cell_iterator &cell,\n       PostProcessScratchData                               &scratch,\n       unsigned int &)\n     {\n       const typename DoFHandler<dim>::active_cell_iterator loc_cell =\n         cell->as_dof_handler_iterator(dof_handler_local);\n   \n       scratch.fe_values_local.reinit(loc_cell);\n       scratch.fe_values.reinit(cell);\n   \n       const FEValuesExtractors::Vector fluxes(0);\n       const FEValuesExtractors::Scalar scalar(dim);\n   \n       const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\n       const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\n   \n       scratch.fe_values_local[scalar].get_function_values(solution_local,\n                                                           scratch.u_values);\n       scratch.fe_values_local[fluxes].get_function_values(solution_local,\n                                                           scratch.u_gradients);\n   \n       double sum = 0;\n       for (unsigned int i = 1; i < dofs_per_cell; ++i)\n         {\n           for (unsigned int j = 0; j < dofs_per_cell; ++j)\n             {\n               sum = 0;\n               for (unsigned int q = 0; q < n_q_points; ++q)\n                 sum += (scratch.fe_values.shape_grad(i, q) *\n                         scratch.fe_values.shape_grad(j, q)) *\n                        scratch.fe_values.JxW(q);\n               scratch.cell_matrix(i, j) = sum;\n             }\n   \n           sum = 0;\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\n                    scratch.fe_values.JxW(q);\n           scratch.cell_rhs(i) = sum;\n         }\n       for (unsigned int j = 0; j < dofs_per_cell; ++j)\n         {\n           sum = 0;\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\n           scratch.cell_matrix(0, j) = sum;\n         }\n       {\n         sum = 0;\n         for (unsigned int q = 0; q < n_q_points; ++q)\n           sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\n         scratch.cell_rhs(0) = sum;\n       }\n```\n\nHaving assembled all terms, we can again go on and solve the linear system. We invert the matrix and then multiply the inverse by the right hand side. An alternative (and more numerically stable) method would have been to only factorize the matrix and apply the factorization.\n\n```\n       scratch.cell_matrix.gauss_jordan();\n       scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\n       cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\n     }\n```\n\n#### HDG::output\\_results\n\nWe have 3 sets of results that we would like to output: the local solution, the post-processed local solution, and the skeleton solution. The former 2 both 'live' on element volumes, whereas the latter lives on codimension-1 surfaces of the triangulation. Our `output_results` function writes all local solutions to the same vtk file, even though they correspond to different [DoFHandler](classDoFHandler.html) objects. The graphical output for the skeleton variable is done through use of the [DataOutFaces](classDataOutFaces.html) class.\n\n```\n     template <int dim>\n     void HDG<dim>::output_results(const unsigned int cycle)\n     {\n       std::string filename;\n       switch (refinement_mode)\n         {\n           case global_refinement:\n             filename = \"solution-global\";\n             break;\n           case adaptive_refinement:\n             filename = \"solution-adaptive\";\n             break;\n           default:\n             DEAL_II_NOT_IMPLEMENTED();\n         }\n   \n       std::string face_out(filename);\n       face_out += \"-face\";\n   \n       filename += \"-q\" + Utilities::int_to_string(fe.degree, 1);\n       filename += \"-\" + Utilities::int_to_string(cycle, 2);\n       filename += \".vtk\";\n       std::ofstream output(filename);\n   \n       DataOut<dim> data_out;\n```\n\nWe first define the names and types of the local solution, and add the data to `data_out`.\n\n```\n       std::vector<std::string> names(dim, \"gradient\");\n       names.emplace_back(\"solution\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         component_interpretation(\n           dim + 1, DataComponentInterpretation::component_is_part_of_vector);\n       component_interpretation[dim] =\n         DataComponentInterpretation::component_is_scalar;\n       data_out.add_data_vector(dof_handler_local,\n                                solution_local,\n                                names,\n                                component_interpretation);\n```\n\nThe second data item we add is the post-processed solution. In this case, it is a single scalar variable belonging to a different [DoFHandler](classDoFHandler.html).\n\n```\n       std::vector<std::string> post_name(1, \"u_post\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         post_comp_type(1, DataComponentInterpretation::component_is_scalar);\n       data_out.add_data_vector(dof_handler_u_post,\n                                solution_u_post,\n                                post_name,\n                                post_comp_type);\n   \n       data_out.build_patches(fe.degree);\n       data_out.write_vtk(output);\n   \n       face_out += \"-q\" + Utilities::int_to_string(fe.degree, 1);\n       face_out += \"-\" + Utilities::int_to_string(cycle, 2);\n       face_out += \".vtk\";\n       std::ofstream face_output(face_out);\n```\n\nThe `DataOutFaces` class works analogously to the `DataOut` class when we have a `DoFHandler` that defines the solution on the skeleton of the triangulation. We treat it as such here, and the code is similar to that above.\n\n```\n       DataOutFaces<dim>        data_out_face(false);\n       std::vector<std::string> face_name(1, \"u_hat\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         face_component_type(1, DataComponentInterpretation::component_is_scalar);\n   \n       data_out_face.add_data_vector(dof_handler,\n                                     solution,\n                                     face_name,\n                                     face_component_type);\n   \n       data_out_face.build_patches(fe.degree);\n       data_out_face.write_vtk(face_output);\n     }\n```\n\n#### HDG::refine\\_grid\n\nWe implement two different refinement cases for HDG, just as in `step-7`: adaptive\\_refinement and global\\_refinement. The global\\_refinement option recreates the entire triangulation every time. This is because we want to use a finer sequence of meshes than what we would get with one refinement step, namely 2, 3, 4, 6, 8, 12, 16, ... elements per direction.\n\nThe adaptive\\_refinement mode uses the `KellyErrorEstimator` to give a decent indication of the non-regular regions in the scalar local solutions.\n\n```\n     template <int dim>\n     void HDG<dim>::refine_grid(const unsigned int cycle)\n     {\n       if (cycle == 0)\n         {\n           GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\n           triangulation.refine_global(3 - dim);\n         }\n       else\n         switch (refinement_mode)\n           {\n             case global_refinement:\n               {\n                 triangulation.clear();\n                 GridGenerator::subdivided_hyper_cube(triangulation,\n                                                      2 + (cycle % 2),\n                                                      -1,\n                                                      1);\n                 triangulation.refine_global(3 - dim + cycle / 2);\n                 break;\n               }\n   \n             case adaptive_refinement:\n               {\n                 Vector<float> estimated_error_per_cell(\n                   triangulation.n_active_cells());\n   \n                 const FEValuesExtractors::Scalar scalar(dim);\n                 std::map<types::boundary_id, const Function<dim> *>\n                   neumann_boundary;\n                 KellyErrorEstimator<dim>::estimate(dof_handler_local,\n                                                    QGauss<dim - 1>(fe.degree + 1),\n                                                    neumann_boundary,\n                                                    solution_local,\n                                                    estimated_error_per_cell,\n                                                    fe_local.component_mask(\n                                                      scalar));\n   \n                 GridRefinement::refine_and_coarsen_fixed_number(\n                   triangulation, estimated_error_per_cell, 0.3, 0.);\n   \n                 triangulation.execute_coarsening_and_refinement();\n   \n                 break;\n               }\n   \n             default:\n               {\n                 DEAL_II_NOT_IMPLEMENTED();\n               }\n           }\n```\n\nJust as in [step-7](step_7.html), we set the boundary indicator of two of the faces to 1 where we want to specify Neumann boundary conditions instead of Dirichlet conditions. Since we re-create the triangulation every time for global refinement, the flags are set in every refinement step, not just at the beginning.\n\n```\n       for (const auto &cell : triangulation.cell_iterators())\n         for (const auto &face : cell->face_iterators())\n           if (face->at_boundary())\n             if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\n                 (std::fabs(face->center()[1] - (-1)) < 1e-12))\n               face->set_boundary_id(1);\n     }\n```\n\n#### HDG::run\n\nThe functionality here is basically the same as `step-7`. We loop over 10 cycles, refining the grid on each one. At the end, convergence tables are created.\n\n```\n     template <int dim>\n     void HDG<dim>::run()\n     {\n       for (unsigned int cycle = 0; cycle < 10; ++cycle)\n         {\n           std::cout << \"Cycle \" << cycle << ':' << std::endl;\n   \n           refine_grid(cycle);\n           setup_system();\n           assemble_system(false);\n           solve();\n           postprocess();\n           output_results(cycle);\n         }\n```\n\nThere is one minor change for the convergence table compared to [step-7](step_7.html): Since we did not refine our mesh by a factor two in each cycle (but rather used the sequence 2, 3, 4, 6, 8, 12, ...), we need to tell the convergence rate evaluation about this. We do this by setting the number of cells as a reference column and additionally specifying the dimension of the problem, which gives the necessary information for the relation between number of cells and mesh size.\n\n```\n       if (refinement_mode == global_refinement)\n         {\n           convergence_table.evaluate_convergence_rates(\n             \"val L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n           convergence_table.evaluate_convergence_rates(\n             \"grad L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n           convergence_table.evaluate_convergence_rates(\n             \"val L2-post\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n         }\n       convergence_table.write_text(std::cout);\n     }\n   \n   } // end of namespace Step51\n   \n   \n   \n   int main()\n   {\n     const unsigned int dim = 2;\n   \n     try\n       {\n```\n\nNow for the three calls to the main class in complete analogy to [step-7](step_7.html).\n\n```\n         {\n           std::cout << \"Solving with Q1 elements, adaptive refinement\"\n                     << std::endl\n                     << \"=============================================\"\n                     << std::endl\n                     << std::endl;\n   \n           Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\n           hdg_problem.run();\n   \n           std::cout << std::endl;\n         }\n   \n         {\n           std::cout << \"Solving with Q1 elements, global refinement\" << std::endl\n                     << \"===========================================\" << std::endl\n                     << std::endl;\n   \n           Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\n           hdg_problem.run();\n   \n           std::cout << std::endl;\n         }\n   \n         {\n           std::cout << \"Solving with Q3 elements, global refinement\" << std::endl\n                     << \"===========================================\" << std::endl\n                     << std::endl;\n   \n           Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\n           hdg_problem.run();\n   \n           std::cout << std::endl;\n         }\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### Program output\n\nWe first have a look at the output generated by the program when run in 2D. In the four images below, we show the solution for polynomial degree \\(p=1\\) and cycles 2, 3, 4, and 8 of the program. In the plots, we overlay the data generated from the internal data (DG part) with the skeleton part ( \\(\\hat{u}\\)) into the same plot. We had to generate two different data sets because cells and faces represent different geometric entities, the combination of which (in the same file) is not supported in the VTK output of deal.II.\n\nThe images show the distinctive features of HDG: The cell solution (colored surfaces) is discontinuous between the cells. The solution on the skeleton variable sits on the faces and ties together the local parts. The skeleton solution is not continuous on the vertices where the faces meet, even though its values are quite close along lines in the same coordinate direction. The skeleton solution can be interpreted as a rubber spring between the two sides that balances the jumps in the solution (or rather, the flux \\(\\kappa \\nabla u\n+ \\mathbf{c} u\\)). From the picture at the top left, it is clear that the bulk solution frequently over- and undershoots and that the skeleton variable in indeed a better approximation to the exact solution; this explains why we can get a better solution using a postprocessing step.\n\nAs the mesh is refined, the jumps between the cells get small (we represent a smooth solution), and the skeleton solution approaches the interior parts. For cycle 8, there is no visible difference in the two variables. We also see how boundary conditions are implemented weakly and that the interior variables do not exactly satisfy boundary conditions. On the lower and left boundaries, we set Neumann boundary conditions, whereas we set Dirichlet conditions on the right and top boundaries.\n\n|  |  |\n| --- | --- |\n|  |  |\n|  |  |\n\nNext, we have a look at the post-processed solution, again at cycles 2, 3, 4, and 8. This is a discontinuous solution that is locally described by second order polynomials. While the solution does not look very good on the mesh of cycle two, it looks much better for cycles three and four. As shown by the convergence table below, we find that is also converges more quickly to the analytical solution.\n\n|  |  |\n| --- | --- |\n|  |  |\n|  |  |\n\nFinally, we look at the solution for \\(p=3\\) at cycle 2. Despite the coarse mesh with only 64 cells, the post-processed solution is similar in quality to the linear solution (not post-processed) at cycle 8 with 4,096 cells. This clearly shows the superiority of high order methods for smooth solutions.\n\n|  |  |\n| --- | --- |\n|  |  |\n\n#### Convergence tables\n\nWhen the program is run, it also outputs information about the respective steps and convergence tables with errors in the various components in the end. In 2D, the convergence tables look the following:\n\n```\nQ1 elements, adaptive refinement:\ncells dofs   val L2    grad L2  val L2-post\n   16    80 1.804e+01 2.207e+01   1.798e+01\n   31   170 9.874e+00 1.322e+01   9.798e+00\n   61   314 7.452e-01 3.793e+00   4.891e-01\n  121   634 3.240e-01 1.511e+00   2.616e-01\n  238  1198 8.585e-02 8.212e-01   1.808e-02\n  454  2290 4.802e-02 5.178e-01   2.195e-02\n  898  4378 2.561e-02 2.947e-01   4.318e-03\n 1720  7864 1.306e-02 1.664e-01   2.978e-03\n 3271 14638 7.025e-03 9.815e-02   1.075e-03\n 6217 27214 4.119e-03 6.407e-02   9.975e-04\n \nQ1 elements, global refinement:\ncells dofs      val L2        grad L2      val L2-post\n   16    80 1.804e+01    - 2.207e+01    - 1.798e+01    -\n   36   168 6.125e+00 2.66 9.472e+00 2.09 6.084e+00 2.67\n   64   288 9.785e-01 6.38 4.260e+00 2.78 7.102e-01 7.47\n  144   624 2.730e-01 3.15 1.866e+00 2.04 6.115e-02 6.05\n  256  1088 1.493e-01 2.10 1.046e+00 2.01 2.880e-02 2.62\n  576  2400 6.965e-02 1.88 4.846e-01 1.90 9.204e-03 2.81\n 1024  4224 4.018e-02 1.91 2.784e-01 1.93 4.027e-03 2.87\n 2304  9408 1.831e-02 1.94 1.264e-01 1.95 1.236e-03 2.91\n 4096 16640 1.043e-02 1.96 7.185e-02 1.96 5.306e-04 2.94\n 9216 37248 4.690e-03 1.97 3.228e-02 1.97 1.599e-04 2.96\n \nQ3 elements, global refinement:\ncells dofs      val L2        grad L2      val L2-post\n   16   160 3.613e-01    - 1.891e+00    - 3.020e-01    -\n   36   336 6.411e-02 4.26 5.081e-01 3.24 3.238e-02 5.51\n   64   576 3.480e-02 2.12 2.533e-01 2.42 5.277e-03 6.31\n  144  1248 8.297e-03 3.54 5.924e-02 3.58 6.330e-04 5.23\n  256  2176 2.254e-03 4.53 1.636e-02 4.47 1.403e-04 5.24\n  576  4800 4.558e-04 3.94 3.277e-03 3.96 1.844e-05 5.01\n 1024  8448 1.471e-04 3.93 1.052e-03 3.95 4.378e-06 5.00\n 2304 18816 2.956e-05 3.96 2.104e-04 3.97 5.750e-07 5.01\n 4096 33280 9.428e-06 3.97 6.697e-05 3.98 1.362e-07 5.01\n 9216 74496 1.876e-06 3.98 1.330e-05 3.99 1.788e-08 5.01\n```\n\nOne can see the error reduction upon grid refinement, and for the cases where global refinement was performed, also the convergence rates. The quadratic convergence rates of Q1 elements in the \\(L\\_2\\) norm for both the scalar variable and the gradient variable is apparent, as is the cubic rate for the postprocessed scalar variable in the \\(L\\_2\\) norm. Note this distinctive feature of an HDG solution. In typical continuous finite elements, the gradient of the solution of order \\(p\\) converges at rate \\(p\\) only, as opposed to \\(p+1\\) for the actual solution. Even though superconvergence results for finite elements are also available (e.g. superconvergent patch recovery first introduced by Zienkiewicz and Zhu), these are typically limited to structured meshes and other special cases. For Q3 HDG variables, the scalar variable and gradient converge at fourth order and the postprocessed scalar variable at fifth order.\n\nThe same convergence rates are observed in 3d.\n\n```\nQ1 elements, adaptive refinement:\ncells   dofs    val L2    grad L2  val L2-post\n     8     144 7.122e+00 1.941e+01   6.102e+00\n    29     500 3.309e+00 1.023e+01   2.145e+00\n   113    1792 2.204e+00 1.023e+01   1.912e+00\n   379    5732 6.085e-01 5.008e+00   2.233e-01\n  1317   19412 1.543e-01 1.464e+00   4.196e-02\n  4579   64768 5.058e-02 5.611e-01   9.521e-03\n 14596  199552 2.129e-02 3.122e-01   4.569e-03\n 46180  611400 1.033e-02 1.622e-01   1.684e-03\n144859 1864212 5.007e-03 8.371e-02   7.364e-04\n451060 5684508 2.518e-03 4.562e-02   3.070e-04\n \nQ1 elements, global refinement:\ncells   dofs       val L2          grad L2       val L2-post\n     8     144 7.122e+00    - 1.941e+01     - 6.102e+00    -\n    27     432 5.491e+00 0.64 2.184e+01 -0.29 4.448e+00 0.78\n    64     960 3.646e+00 1.42 1.299e+01  1.81 3.306e+00 1.03\n   216    3024 1.595e+00 2.04 8.550e+00  1.03 1.441e+00 2.05\n   512    6912 6.922e-01 2.90 5.306e+00  1.66 2.511e-01 6.07\n  1728   22464 2.915e-01 2.13 2.490e+00  1.87 8.588e-02 2.65\n  4096   52224 1.684e-01 1.91 1.453e+00  1.87 4.055e-02 2.61\n 13824  172800 7.972e-02 1.84 6.861e-01  1.85 1.335e-02 2.74\n 32768  405504 4.637e-02 1.88 3.984e-01  1.89 5.932e-03 2.82\n110592 1354752 2.133e-02 1.92 1.830e-01  1.92 1.851e-03 2.87\n \nQ3 elements, global refinement:\ncells   dofs       val L2        grad L2      val L2-post\n     8     576 5.670e+00    - 1.868e+01    - 5.462e+00    -\n    27    1728 1.048e+00 4.16 6.988e+00 2.42 8.011e-01 4.73\n    64    3840 2.831e-01 4.55 2.710e+00 3.29 1.363e-01 6.16\n   216   12096 7.883e-02 3.15 7.721e-01 3.10 2.158e-02 4.55\n   512   27648 3.642e-02 2.68 3.305e-01 2.95 5.231e-03 4.93\n  1728   89856 8.546e-03 3.58 7.581e-02 3.63 7.640e-04 4.74\n  4096  208896 2.598e-03 4.14 2.313e-02 4.13 1.783e-04 5.06\n 13824  691200 5.314e-04 3.91 4.697e-03 3.93 2.355e-05 4.99\n 32768 1622016 1.723e-04 3.91 1.517e-03 3.93 5.602e-06 4.99\n110592 5419008 3.482e-05 3.94 3.055e-04 3.95 7.374e-07 5.00\n```\n\n### Comparison with continuous finite elements\n\n#### Results for 2D\n\nThe convergence tables verify the expected convergence rates stated in the introduction. Now, we want to show a quick comparison of the computational efficiency of the HDG method compared to a usual finite element (continuous Galkerin) method on the problem of this tutorial. Of course, stability aspects of the HDG method compared to continuous finite elements for transport-dominated problems are also important in practice, which is an aspect not seen on a problem with smooth analytic solution. In the picture below, we compare the \\(L\\_2\\) error as a function of the number of degrees of freedom (left) and of the computing time spent in the linear solver (right) for two space dimensions of continuous finite elements (CG) and the hybridized discontinuous Galerkin method presented in this tutorial. As opposed to the tutorial where we only use unpreconditioned BiCGStab, the times shown in the figures below use the Trilinos algebraic multigrid preconditioner in [TrilinosWrappers::PreconditionAMG](classTrilinosWrappers_1_1PreconditionAMG.html). For the HDG part, a wrapper around [ChunkSparseMatrix](classChunkSparseMatrix.html) for the trace variable has been used in order to utilize the block structure in the matrix on the finest level.\n\n|  |  |\n| --- | --- |\n|  |  |\n\nThe results in the graphs show that the HDG method is slower than continuous finite elements at \\(p=1\\), about equally fast for cubic elements and faster for sixth order elements. However, we have seen above that the HDG method actually produces solutions which are more accurate than what is represented in the original variables. Therefore, in the next two plots below we instead display the error of the post-processed solution for HDG (denoted by \\(p=1^\\*\\) for example). We now see a clear advantage of HDG for the same amount of work for both \\(p=3\\) and \\(p=6\\), and about the same quality for \\(p=1\\).\n\n|  |  |\n| --- | --- |\n|  |  |\n\nSince the HDG method actually produces results converging as \\(h^{p+2}\\), we should compare it to a continuous Galerkin solution with the same asymptotic convergence behavior, i.e., [FE\\_Q](classFE__Q.html) with degree \\(p+1\\). If we do this, we get the convergence curves below. We see that CG with second order polynomials is again clearly better than HDG with linears. However, the advantage of HDG for higher orders remains.\n\n|  |  |\n| --- | --- |\n|  |  |\n\nThe results are in line with properties of DG methods in general: Best performance is typically not achieved for linear elements, but rather at somewhat higher order, usually around \\(p=3\\). This is because of a volume-to-surface effect for discontinuous solutions with too much of the solution living on the surfaces and hence duplicating work when the elements are linear. Put in other words, DG methods are often most efficient when used at relatively high order, despite their focus on a discontinuous (and hence, seemingly low accurate) representation of solutions.\n\n#### Results for 3D\n\nWe now show the same figures in 3D: The first row shows the number of degrees of freedom and computing time versus the \\(L\\_2\\) error in the scalar variable \\(u\\) for CG and HDG at order \\(p\\), the second row shows the post-processed HDG solution instead of the original one, and the third row compares the post-processed HDG solution with CG at order \\(p+1\\). In 3D, the volume-to-surface effect makes the cost of HDG somewhat higher and the CG solution is clearly better than HDG for linears by any metric. For cubics, HDG and CG are of similar quality, whereas HDG is again more efficient for sixth order polynomials. One can alternatively also use the combination of [FE\\_DGP](classFE__DGP.html) and [FE\\_FaceP](classFE__FaceP.html) instead of ([FE\\_DGQ](classFE__DGQ.html), [FE\\_FaceQ](classFE__FaceQ.html)), which do not use tensor product polynomials of degree \\(p\\) but Legendre polynomials of *complete* degree \\(p\\). There are fewer degrees of freedom on the skeleton variable for [FE\\_FaceP](classFE__FaceP.html) for a given mesh size, but the solution quality (error vs. number of DoFs) is very similar to the results for [FE\\_FaceQ](classFE__FaceQ.html).\n\n|  |  |\n| --- | --- |\n|  |  |\n|  |  |\n|  |  |\n\nOne final note on the efficiency comparison: We tried to use general-purpose sparse matrix structures and similar solvers (optimal AMG preconditioners for both without particular tuning of the AMG parameters on any of them) to give a fair picture of the cost versus accuracy of two methods, on a toy example. It should be noted however that geometric multigrid (GMG) for continuous finite elements is about a factor four to five faster for \\(p=3\\) and \\(p=6\\). As of 2019, optimal-complexity iterative solvers for HDG are still under development in the research community. Also, there are other implementation aspects for CG available such as fast matrix-free approaches as shown in [step-37](step_37.html) that make higher order continuous elements more competitive. Again, it is not clear to the authors of the tutorial whether similar improvements could be made for HDG. We refer to [Kronbichler and Wall (2018)](https://dx.doi.org/10.1137/16M110455X) for a recent efficiency evaluation.\n\n### Possibilities for improvements\n\nAs already mentioned in the introduction, one possibility is to implement another post-processing technique as discussed in the literature.\n\nA second item that is not done optimally relates to the performance of this program, which is of course an issue in practical applications (weighing in also the better solution quality of (H)DG methods for transport-dominated problems). Let us look at the computing time of the tutorial program and the share of the individual components:\n\n|  |  | Setup | Assemble | Solve | Trace reconstruct | Post-processing | Output |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n|  | Total time | Relative share | | | | | |\n| 2D, Q1, cycle 9, 37,248 dofs | 5.34s | 0.7% | 1.2% | 89.5% | 0.9% | 2.3% | 5.4% |\n| 2D, Q3, cycle 9, 74,496 dofs | 22.2s | 0.4% | 4.3% | 84.1% | 4.1% | 3.5% | 3.6% |\n| 3D, Q1, cycle 7, 172,800 dofs | 9.06s | 3.1% | 8.9% | 42.7% | 7.0% | 20.6% | 17.7% |\n| 3D, Q3, cycle 7, 691,200 dofs | 516s | 0.6% | 34.5% | 13.4% | 32.8% | 17.1% | 1.5% |\n\nAs can be seen from the table, the solver and assembly calls dominate the runtime of the program. This also gives a clear indication of where improvements would make the most sense:\n\n1. Better linear solvers: We use a BiCGStab iterative solver without preconditioner, where the number of iteration increases with increasing problem size (the number of iterations for Q1 elements and global refinements starts at 35 for the small sizes but increase up to 701 for the largest size). To do better, one could for example use an algebraic multigrid preconditioner from Trilinos, or some more advanced variants as the one discussed in [Kronbichler and Wall (2018)](https://dx.doi.org/10.1137/16M110455X). For diffusion-dominated problems such as the problem at hand with finer meshes, such a solver can be designed that uses the matrix-vector products from the more efficient [ChunkSparseMatrix](classChunkSparseMatrix.html) on the finest level, as long as we are not working in parallel with MPI. For MPI-parallelized computations, a standard [TrilinosWrappers::SparseMatrix](classTrilinosWrappers_1_1SparseMatrix.html) can be used.\n2. Speed up assembly by pre-assembling parts that do not change from one cell to another (those that do neither contain variable coefficients nor mapping-dependent terms).\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2013 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Martin Kronbichler, Technical University of Munich,\n *         Scott T. Miller, The Pennsylvania State University, 2013\n */\n \n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/tensor_function.h>\n#include <deal.II/base/exceptions.h>\n#include <deal.II/base/work_stream.h>\n#include <deal.II/base/convergence_table.h>\n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/solver_bicgstab.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n#include <deal.II/fe/fe_dgq.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/error_estimator.h>\n#include <deal.II/numerics/data_out.h>\n \n#include <deal.II/fe/fe_face.h>\n \n#include <deal.II/lac/chunk_sparse_matrix.h>\n \n#include <deal.II/numerics/data_out_faces.h>\n \n#include <iostream>\n \n \n \nnamespace Step51\n{\n using namespace dealii;\n \n template <int dim>\n class SolutionBase\n  {\n protected:\n static const unsigned int n_source_centers = 3;\n static const Point<dim>   source_centers[n_source_centers];\n static const double       width;\n  };\n \n \n template <>\n const Point<1>\n    SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\n      {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\n \n \n template <>\n const Point<2>\n    SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\n      {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\n \n template <>\n const Point<3>\n    SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\n Point<3>(-0.5, +0.5, 0.25),\n Point<3>(-0.6, -0.5, -0.125),\n Point<3>(+0.5, -0.5, 0.5)};\n \n template <int dim>\n const double SolutionBase<dim>::width = 1. / 5.;\n \n \n template <int dim>\n class Solution : public Function<dim>, protected SolutionBase<dim>\n  {\n public:\n virtual double value(const Point<dim> &p,\n const unsigned int /*component*/ = 0) const override\n {\n double sum = 0;\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\n        {\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n sum +=\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\n        }\n \n return sum /\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n    }\n \n virtual Tensor<1, dim>\n gradient(const Point<dim> &p,\n const unsigned int /*component*/ = 0) const override\n {\n Tensor<1, dim> sum;\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\n        {\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n \n sum +=\n            (-2 / (this->width * this->width) *\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\n             x_minus_xi);\n        }\n \n return sum /\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n    }\n  };\n \n \n \n template <int dim>\n class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\n  {\n public:\n    SolutionAndGradient()\n      : Function<dim>(dim + 1)\n    {}\n \n virtual void vector_value(const Point<dim> &p,\n Vector<double>   &v) const override\n {\n AssertDimension(v.size(), dim + 1);\n      Solution<dim>  solution;\n Tensor<1, dim> grad = solution.gradient(p);\n for (unsigned int d = 0; d < dim; ++d)\n        v[d] = -grad[d];\n      v[dim] = solution.value(p);\n    }\n  };\n \n \n \n template <int dim>\n class ConvectionVelocity : public TensorFunction<1, dim>\n  {\n public:\n    ConvectionVelocity()\n      : TensorFunction<1, dim>()\n    {}\n \n virtual Tensor<1, dim> value(const Point<dim> &p) const override\n {\n Tensor<1, dim> convection;\n switch (dim)\n        {\n case 1:\n            convection[0] = 1;\n break;\n case 2:\n            convection[0] = p[1];\n            convection[1] = -p[0];\n break;\n case 3:\n            convection[0] = p[1];\n            convection[1] = -p[0];\n            convection[2] = 1;\n break;\n default:\n DEAL_II_NOT_IMPLEMENTED();\n        }\n return convection;\n    }\n  };\n \n \n \n template <int dim>\n class RightHandSide : public Function<dim>, protected SolutionBase<dim>\n  {\n public:\n virtual double value(const Point<dim> &p,\n const unsigned int /*component*/ = 0) const override\n {\n      ConvectionVelocity<dim> convection_velocity;\n Tensor<1, dim>          convection = convection_velocity.value(p);\n double sum        = 0;\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\n        {\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\n \n sum +=\n            ((2 * dim - 2 * convection * x_minus_xi -\n              4 * x_minus_xi.norm_square() / (this->width * this->width)) /\n             (this->width * this->width) *\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\n        }\n \n return sum /\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\n    }\n  };\n \n \n \n \n template <int dim>\n class HDG\n  {\n public:\n enum RefinementMode\n    {\n      global_refinement,\n      adaptive_refinement\n    };\n \n    HDG(const unsigned int degree, const RefinementMode refinement_mode);\n void run();\n \n private:\n void setup_system();\n void assemble_system(const bool reconstruct_trace = false);\n void solve();\n void postprocess();\n void refine_grid(const unsigned int cycle);\n void output_results(const unsigned int cycle);\n \n struct PerTaskData;\n struct ScratchData;\n \n struct PostProcessScratchData;\n \n void assemble_system_one_cell(\n const typename DoFHandler<dim>::active_cell_iterator &cell,\n      ScratchData                                          &scratch,\n      PerTaskData                                          &task_data);\n \n void copy_local_to_global(const PerTaskData &data);\n \n void postprocess_one_cell(\n const typename DoFHandler<dim>::active_cell_iterator &cell,\n      PostProcessScratchData                               &scratch,\n unsigned int                                         &empty_data);\n \n \n Triangulation<dim> triangulation;\n \n const FESystem<dim> fe_local;\n DoFHandler<dim>     dof_handler_local;\n Vector<double>      solution_local;\n \n const FE_FaceQ<dim> fe;\n DoFHandler<dim>     dof_handler;\n Vector<double>      solution;\n Vector<double>      system_rhs;\n \n const FE_DGQ<dim> fe_u_post;\n DoFHandler<dim>   dof_handler_u_post;\n Vector<double>    solution_u_post;\n \n AffineConstraints<double> constraints;\n \n ChunkSparsityPattern      sparsity_pattern;\n ChunkSparseMatrix<double> system_matrix;\n \n const RefinementMode refinement_mode;\n ConvergenceTable     convergence_table;\n  };\n \n \n template <int dim>\n  HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\n    : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\n    , dof_handler_local(triangulation)\n    , fe(degree)\n    , dof_handler(triangulation)\n    , fe_u_post(degree + 1)\n    , dof_handler_u_post(triangulation)\n    , refinement_mode(refinement_mode)\n  {}\n \n \n \n template <int dim>\n void HDG<dim>::setup_system()\n  {\n    dof_handler_local.distribute_dofs(fe_local);\n    dof_handler.distribute_dofs(fe);\n    dof_handler_u_post.distribute_dofs(fe_u_post);\n \n    std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n              << std::endl;\n \n    solution.reinit(dof_handler.n_dofs());\n    system_rhs.reinit(dof_handler.n_dofs());\n \n    solution_local.reinit(dof_handler_local.n_dofs());\n    solution_u_post.reinit(dof_handler_u_post.n_dofs());\n \n    constraints.clear();\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n    std::map<types::boundary_id, const Function<dim> *> boundary_functions;\n    Solution<dim>                                       solution_function;\n    boundary_functions[0] = &solution_function;\n VectorTools::project_boundary_values(dof_handler,\n                                         boundary_functions,\n QGauss<dim - 1>(fe.degree + 1),\n                                         constraints);\n    constraints.close();\n \n    {\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n      sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\n    }\n    system_matrix.reinit(sparsity_pattern);\n  }\n \n \n \n template <int dim>\n struct HDG<dim>::PerTaskData\n  {\n FullMatrix<double> cell_matrix;\n Vector<double>                       cell_vector;\n    std::vector<types::global_dof_index> dof_indices;\n \n bool trace_reconstruct;\n \n    PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\n      : cell_matrix(n_dofs, n_dofs)\n      , cell_vector(n_dofs)\n      , dof_indices(n_dofs)\n      , trace_reconstruct(trace_reconstruct)\n    {}\n  };\n \n \n \n template <int dim>\n struct HDG<dim>::ScratchData\n  {\n FEValues<dim>     fe_values_local;\n FEFaceValues<dim> fe_face_values_local;\n FEFaceValues<dim> fe_face_values;\n \n FullMatrix<double> ll_matrix;\n FullMatrix<double> lf_matrix;\n FullMatrix<double> fl_matrix;\n FullMatrix<double> tmp_matrix;\n Vector<double>     l_rhs;\n Vector<double>     tmp_rhs;\n \n    std::vector<Tensor<1, dim>> q_phi;\n    std::vector<double>         q_phi_div;\n    std::vector<double>         u_phi;\n    std::vector<Tensor<1, dim>> u_phi_grad;\n    std::vector<double>         tr_phi;\n    std::vector<double>         trace_values;\n \n    std::vector<std::vector<unsigned int>> fe_local_support_on_face;\n    std::vector<std::vector<unsigned int>> fe_support_on_face;\n \n    ConvectionVelocity<dim> convection_velocity;\n    RightHandSide<dim>      right_hand_side;\n const Solution<dim>     exact_solution;\n \n    ScratchData(const FiniteElement<dim> &fe,\n const FiniteElement<dim> &fe_local,\n const QGauss<dim>        &quadrature_formula,\n const QGauss<dim - 1>    &face_quadrature_formula,\n const UpdateFlags         local_flags,\n const UpdateFlags         local_face_flags,\n const UpdateFlags         flags)\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\n      , fe_face_values_local(fe_local,\n                             face_quadrature_formula,\n                             local_face_flags)\n      , fe_face_values(fe, face_quadrature_formula, flags)\n      , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n      , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\n      , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n      , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\n      , l_rhs(fe_local.n_dofs_per_cell())\n      , tmp_rhs(fe_local.n_dofs_per_cell())\n      , q_phi(fe_local.n_dofs_per_cell())\n      , q_phi_div(fe_local.n_dofs_per_cell())\n      , u_phi(fe_local.n_dofs_per_cell())\n      , u_phi_grad(fe_local.n_dofs_per_cell())\n      , tr_phi(fe.n_dofs_per_cell())\n      , trace_values(face_quadrature_formula.size())\n      , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\n      , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\n      , exact_solution()\n    {\n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\n        for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\n          {\n if (fe_local.has_support_on_face(i, face_no))\n              fe_local_support_on_face[face_no].push_back(i);\n          }\n \n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\n        for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\n          {\n if (fe.has_support_on_face(i, face_no))\n              fe_support_on_face[face_no].push_back(i);\n          }\n    }\n \n    ScratchData(const ScratchData &sd)\n      : fe_values_local(sd.fe_values_local.get_fe(),\n                        sd.fe_values_local.get_quadrature(),\n                        sd.fe_values_local.get_update_flags())\n      , fe_face_values_local(sd.fe_face_values_local.get_fe(),\n                             sd.fe_face_values_local.get_quadrature(),\n                             sd.fe_face_values_local.get_update_flags())\n      , fe_face_values(sd.fe_face_values.get_fe(),\n                       sd.fe_face_values.get_quadrature(),\n                       sd.fe_face_values.get_update_flags())\n      , ll_matrix(sd.ll_matrix)\n      , lf_matrix(sd.lf_matrix)\n      , fl_matrix(sd.fl_matrix)\n      , tmp_matrix(sd.tmp_matrix)\n      , l_rhs(sd.l_rhs)\n      , tmp_rhs(sd.tmp_rhs)\n      , q_phi(sd.q_phi)\n      , q_phi_div(sd.q_phi_div)\n      , u_phi(sd.u_phi)\n      , u_phi_grad(sd.u_phi_grad)\n      , tr_phi(sd.tr_phi)\n      , trace_values(sd.trace_values)\n      , fe_local_support_on_face(sd.fe_local_support_on_face)\n      , fe_support_on_face(sd.fe_support_on_face)\n      , exact_solution()\n    {}\n  };\n \n \n \n template <int dim>\n struct HDG<dim>::PostProcessScratchData\n  {\n FEValues<dim> fe_values_local;\n FEValues<dim> fe_values;\n \n    std::vector<double>         u_values;\n    std::vector<Tensor<1, dim>> u_gradients;\n FullMatrix<double> cell_matrix;\n \n Vector<double> cell_rhs;\n Vector<double> cell_sol;\n \n    PostProcessScratchData(const FiniteElement<dim> &fe,\n const FiniteElement<dim> &fe_local,\n const QGauss<dim>        &quadrature_formula,\n const UpdateFlags         local_flags,\n const UpdateFlags         flags)\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\n      , fe_values(fe, quadrature_formula, flags)\n      , u_values(quadrature_formula.size())\n      , u_gradients(quadrature_formula.size())\n      , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\n      , cell_rhs(fe.n_dofs_per_cell())\n      , cell_sol(fe.n_dofs_per_cell())\n    {}\n \n    PostProcessScratchData(const PostProcessScratchData &sd)\n      : fe_values_local(sd.fe_values_local.get_fe(),\n                        sd.fe_values_local.get_quadrature(),\n                        sd.fe_values_local.get_update_flags())\n      , fe_values(sd.fe_values.get_fe(),\n                  sd.fe_values.get_quadrature(),\n                  sd.fe_values.get_update_flags())\n      , u_values(sd.u_values)\n      , u_gradients(sd.u_gradients)\n      , cell_matrix(sd.cell_matrix)\n      , cell_rhs(sd.cell_rhs)\n      , cell_sol(sd.cell_sol)\n    {}\n  };\n \n \n \n template <int dim>\n void HDG<dim>::assemble_system(const bool trace_reconstruct)\n  {\n const QGauss<dim>     quadrature_formula(fe.degree + 1);\n const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\n \n const UpdateFlags local_flags(update_values | update_gradients |\n update_JxW_values | update_quadrature_points);\n \n const UpdateFlags local_face_flags(update_values);\n \n const UpdateFlags flags(update_values | update_normal_vectors |\n update_quadrature_points | update_JxW_values);\n \n    PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\n    ScratchData scratch(fe,\n                        fe_local,\n                        quadrature_formula,\n                        face_quadrature_formula,\n                        local_flags,\n                        local_face_flags,\n                        flags);\n \n WorkStream::run(dof_handler.begin_active(),\n                    dof_handler.end(),\n                    *this,\n                    &HDG<dim>::assemble_system_one_cell,\n                    &HDG<dim>::copy_local_to_global,\n                    scratch,\n                    task_data);\n  }\n \n \n \n template <int dim>\n void HDG<dim>::assemble_system_one_cell(\n const typename DoFHandler<dim>::active_cell_iterator &cell,\n    ScratchData                                          &scratch,\n    PerTaskData                                          &task_data)\n  {\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\n      cell->as_dof_handler_iterator(dof_handler_local);\n \n const unsigned int n_q_points =\n      scratch.fe_values_local.get_quadrature().size();\n const unsigned int n_face_q_points =\n      scratch.fe_face_values_local.get_quadrature().size();\n \n const unsigned int loc_dofs_per_cell =\n      scratch.fe_values_local.get_fe().n_dofs_per_cell();\n \n const FEValuesExtractors::Vector fluxes(0);\n const FEValuesExtractors::Scalar scalar(dim);\n \n    scratch.ll_matrix = 0;\n    scratch.l_rhs     = 0;\n if (!task_data.trace_reconstruct)\n      {\n        scratch.lf_matrix     = 0;\n        scratch.fl_matrix     = 0;\n        task_data.cell_matrix = 0;\n        task_data.cell_vector = 0;\n      }\n    scratch.fe_values_local.reinit(loc_cell);\n \n for (unsigned int q = 0; q < n_q_points; ++q)\n      {\n const double rhs_value = scratch.right_hand_side.value(\n          scratch.fe_values_local.quadrature_point(q));\n const Tensor<1, dim> convection = scratch.convection_velocity.value(\n          scratch.fe_values_local.quadrature_point(q));\n const double JxW = scratch.fe_values_local.JxW(q);\n for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\n          {\n            scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\n            scratch.q_phi_div[k] =\n              scratch.fe_values_local[fluxes].divergence(k, q);\n            scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\n            scratch.u_phi_grad[k] =\n              scratch.fe_values_local[scalar].gradient(k, q);\n          }\n for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\n          {\n for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\n              scratch.ll_matrix(i, j) +=\n                (scratch.q_phi[i] * scratch.q_phi[j] -\n                 scratch.q_phi_div[i] * scratch.u_phi[j] +\n                 scratch.u_phi[i] * scratch.q_phi_div[j] -\n                 (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\n                JxW;\n            scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\n          }\n      }\n \n for (const auto face_no : cell->face_indices())\n      {\n        scratch.fe_face_values_local.reinit(loc_cell, face_no);\n        scratch.fe_face_values.reinit(cell, face_no);\n \n if (task_data.trace_reconstruct)\n          scratch.fe_face_values.get_function_values(solution,\n                                                     scratch.trace_values);\n \n for (unsigned int q = 0; q < n_face_q_points; ++q)\n          {\n const double     JxW = scratch.fe_face_values.JxW(q);\n const Point<dim> quadrature_point =\n              scratch.fe_face_values.quadrature_point(q);\n const Tensor<1, dim> normal =\n              scratch.fe_face_values.normal_vector(q);\n const Tensor<1, dim> convection =\n              scratch.convection_velocity.value(quadrature_point);\n \n const double tau_stab = (5. + std::abs(convection * normal));\n \n for (unsigned int k = 0;\n                 k < scratch.fe_local_support_on_face[face_no].size();\n                 ++k)\n              {\n const unsigned int kk =\n                  scratch.fe_local_support_on_face[face_no][k];\n                scratch.q_phi[k] =\n                  scratch.fe_face_values_local[fluxes].value(kk, q);\n                scratch.u_phi[k] =\n                  scratch.fe_face_values_local[scalar].value(kk, q);\n              }\n \n if (!task_data.trace_reconstruct)\n              {\n for (unsigned int k = 0;\n                     k < scratch.fe_support_on_face[face_no].size();\n                     ++k)\n                  scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\n                    scratch.fe_support_on_face[face_no][k], q);\n for (unsigned int i = 0;\n                     i < scratch.fe_local_support_on_face[face_no].size();\n                     ++i)\n for (unsigned int j = 0;\n                       j < scratch.fe_support_on_face[face_no].size();\n                       ++j)\n                    {\n const unsigned int ii =\n                        scratch.fe_local_support_on_face[face_no][i];\n const unsigned int jj =\n                        scratch.fe_support_on_face[face_no][j];\n                      scratch.lf_matrix(ii, jj) +=\n                        ((scratch.q_phi[i] * normal +\n                          (convection * normal - tau_stab) * scratch.u_phi[i]) *\n                         scratch.tr_phi[j]) *\n                        JxW;\n \n                      scratch.fl_matrix(jj, ii) -=\n                        ((scratch.q_phi[i] * normal +\n                          tau_stab * scratch.u_phi[i]) *\n                         scratch.tr_phi[j]) *\n                        JxW;\n                    }\n \n for (unsigned int i = 0;\n                     i < scratch.fe_support_on_face[face_no].size();\n                     ++i)\n for (unsigned int j = 0;\n                       j < scratch.fe_support_on_face[face_no].size();\n                       ++j)\n                    {\n const unsigned int ii =\n                        scratch.fe_support_on_face[face_no][i];\n const unsigned int jj =\n                        scratch.fe_support_on_face[face_no][j];\n                      task_data.cell_matrix(ii, jj) +=\n                        ((convection * normal - tau_stab) * scratch.tr_phi[i] *\n                         scratch.tr_phi[j]) *\n                        JxW;\n                    }\n \n if (cell->face(face_no)->at_boundary() &&\n                    (cell->face(face_no)->boundary_id() == 1))\n                  {\n const double neumann_value =\n                      -scratch.exact_solution.gradient(quadrature_point) *\n                        normal +\n                      convection * normal *\n                        scratch.exact_solution.value(quadrature_point);\n for (unsigned int i = 0;\n                         i < scratch.fe_support_on_face[face_no].size();\n                         ++i)\n                      {\n const unsigned int ii =\n                          scratch.fe_support_on_face[face_no][i];\n                        task_data.cell_vector(ii) +=\n                          scratch.tr_phi[i] * neumann_value * JxW;\n                      }\n                  }\n              }\n \n for (unsigned int i = 0;\n                 i < scratch.fe_local_support_on_face[face_no].size();\n                 ++i)\n for (unsigned int j = 0;\n                   j < scratch.fe_local_support_on_face[face_no].size();\n                   ++j)\n                {\n const unsigned int ii =\n                    scratch.fe_local_support_on_face[face_no][i];\n const unsigned int jj =\n                    scratch.fe_local_support_on_face[face_no][j];\n                  scratch.ll_matrix(ii, jj) +=\n                    tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\n                }\n \n if (task_data.trace_reconstruct)\n for (unsigned int i = 0;\n                   i < scratch.fe_local_support_on_face[face_no].size();\n                   ++i)\n                {\n const unsigned int ii =\n                    scratch.fe_local_support_on_face[face_no][i];\n                  scratch.l_rhs(ii) -=\n                    (scratch.q_phi[i] * normal +\n                     scratch.u_phi[i] * (convection * normal - tau_stab)) *\n                    scratch.trace_values[q] * JxW;\n                }\n          }\n      }\n \n    scratch.ll_matrix.gauss_jordan();\n \n if (task_data.trace_reconstruct == false)\n      {\n        scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\n        scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\n        scratch.tmp_matrix.mmult(task_data.cell_matrix,\n                                 scratch.lf_matrix,\n true);\n        cell->get_dof_indices(task_data.dof_indices);\n      }\n else\n      {\n        scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\n        loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\n      }\n  }\n \n \n \n template <int dim>\n void HDG<dim>::copy_local_to_global(const PerTaskData &data)\n  {\n if (data.trace_reconstruct == false)\n      constraints.distribute_local_to_global(data.cell_matrix,\n                                             data.cell_vector,\n                                             data.dof_indices,\n                                             system_matrix,\n                                             system_rhs);\n  }\n \n \n \n template <int dim>\n void HDG<dim>::solve()\n  {\n SolverControl                  solver_control(system_matrix.m() * 10,\n                                 1e-11 * system_rhs.l2_norm());\n SolverBicgstab<Vector<double>> solver(solver_control);\n    solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\n \n    std::cout << \"   Number of BiCGStab iterations: \"\n              << solver_control.last_step() << std::endl;\n \n    system_matrix.clear();\n    sparsity_pattern.reinit(0, 0, 0, 1);\n \n    constraints.distribute(solution);\n \n    assemble_system(true);\n  }\n \n \n \n \n template <int dim>\n void HDG<dim>::postprocess()\n  {\n    {\n const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\n const UpdateFlags local_flags(update_values);\n const UpdateFlags flags(update_values | update_gradients |\n update_JxW_values);\n \n      PostProcessScratchData scratch(\n        fe_u_post, fe_local, quadrature_formula, local_flags, flags);\n \n WorkStream::run(\n        dof_handler_u_post.begin_active(),\n        dof_handler_u_post.end(),\n        [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\n               PostProcessScratchData                               &scratch,\n unsigned int                                         &data) {\n          this->postprocess_one_cell(cell, scratch, data);\n        },\n        std::function<void(const unsigned int &)>(),\n        scratch,\n        0U);\n    }\n \n Vector<float> difference_per_cell(triangulation.n_active_cells());\n \n ComponentSelectFunction<dim> value_select(dim, dim + 1);\n VectorTools::integrate_difference(dof_handler_local,\n                                      solution_local,\n                                      SolutionAndGradient<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(fe.degree + 2),\n VectorTools::L2_norm,\n                                      &value_select);\n const double L2_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::L2_norm);\n \n ComponentSelectFunction<dim> gradient_select(\n      std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\n VectorTools::integrate_difference(dof_handler_local,\n                                      solution_local,\n                                      SolutionAndGradient<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(fe.degree + 2),\n VectorTools::L2_norm,\n                                      &gradient_select);\n const double grad_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::L2_norm);\n \n VectorTools::integrate_difference(dof_handler_u_post,\n                                      solution_u_post,\n                                      Solution<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(fe.degree + 3),\n VectorTools::L2_norm);\n const double post_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::L2_norm);\n \n    convergence_table.add_value(\"cells\", triangulation.n_active_cells());\n    convergence_table.add_value(\"dofs\", dof_handler.n_dofs());\n \n    convergence_table.add_value(\"val L2\", L2_error);\n    convergence_table.set_scientific(\"val L2\", true);\n    convergence_table.set_precision(\"val L2\", 3);\n \n    convergence_table.add_value(\"grad L2\", grad_error);\n    convergence_table.set_scientific(\"grad L2\", true);\n    convergence_table.set_precision(\"grad L2\", 3);\n \n    convergence_table.add_value(\"val L2-post\", post_error);\n    convergence_table.set_scientific(\"val L2-post\", true);\n    convergence_table.set_precision(\"val L2-post\", 3);\n  }\n \n \n \n template <int dim>\n void HDG<dim>::postprocess_one_cell(\n const typename DoFHandler<dim>::active_cell_iterator &cell,\n    PostProcessScratchData                               &scratch,\n unsigned int &)\n  {\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\n      cell->as_dof_handler_iterator(dof_handler_local);\n \n    scratch.fe_values_local.reinit(loc_cell);\n    scratch.fe_values.reinit(cell);\n \n const FEValuesExtractors::Vector fluxes(0);\n const FEValuesExtractors::Scalar scalar(dim);\n \n const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\n const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\n \n    scratch.fe_values_local[scalar].get_function_values(solution_local,\n                                                        scratch.u_values);\n    scratch.fe_values_local[fluxes].get_function_values(solution_local,\n                                                        scratch.u_gradients);\n \n double sum = 0;\n for (unsigned int i = 1; i < dofs_per_cell; ++i)\n      {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n          {\n sum = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n              sum += (scratch.fe_values.shape_grad(i, q) *\n                      scratch.fe_values.shape_grad(j, q)) *\n                     scratch.fe_values.JxW(q);\n            scratch.cell_matrix(i, j) = sum;\n          }\n \n sum = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n          sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\n                 scratch.fe_values.JxW(q);\n        scratch.cell_rhs(i) = sum;\n      }\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n      {\n sum = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n          sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\n        scratch.cell_matrix(0, j) = sum;\n      }\n    {\n sum = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n        sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\n      scratch.cell_rhs(0) = sum;\n    }\n \n    scratch.cell_matrix.gauss_jordan();\n    scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\n    cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\n  }\n \n \n \n template <int dim>\n void HDG<dim>::output_results(const unsigned int cycle)\n  {\n    std::string filename;\n switch (refinement_mode)\n      {\n case global_refinement:\n          filename = \"solution-global\";\n break;\n case adaptive_refinement:\n          filename = \"solution-adaptive\";\n break;\n default:\n DEAL_II_NOT_IMPLEMENTED();\n      }\n \n    std::string face_out(filename);\n    face_out += \"-face\";\n \n    filename += \"-q\" + Utilities::int_to_string(fe.degree, 1);\n    filename += \"-\" + Utilities::int_to_string(cycle, 2);\n    filename += \".vtk\";\n    std::ofstream output(filename);\n \n DataOut<dim> data_out;\n \n    std::vector<std::string> names(dim, \"gradient\");\n    names.emplace_back(\"solution\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      component_interpretation(\n        dim + 1, DataComponentInterpretation::component_is_part_of_vector);\n    component_interpretation[dim] =\n DataComponentInterpretation::component_is_scalar;\n    data_out.add_data_vector(dof_handler_local,\n                             solution_local,\n                             names,\n                             component_interpretation);\n \n    std::vector<std::string> post_name(1, \"u_post\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      post_comp_type(1, DataComponentInterpretation::component_is_scalar);\n    data_out.add_data_vector(dof_handler_u_post,\n                             solution_u_post,\n                             post_name,\n                             post_comp_type);\n \n    data_out.build_patches(fe.degree);\n    data_out.write_vtk(output);\n \n    face_out += \"-q\" + Utilities::int_to_string(fe.degree, 1);\n    face_out += \"-\" + Utilities::int_to_string(cycle, 2);\n    face_out += \".vtk\";\n    std::ofstream face_output(face_out);\n \n DataOutFaces<dim>        data_out_face(false);\n    std::vector<std::string> face_name(1, \"u_hat\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      face_component_type(1, DataComponentInterpretation::component_is_scalar);\n \n    data_out_face.add_data_vector(dof_handler,\n                                  solution,\n                                  face_name,\n                                  face_component_type);\n \n    data_out_face.build_patches(fe.degree);\n    data_out_face.write_vtk(face_output);\n  }\n \n \n \n template <int dim>\n void HDG<dim>::refine_grid(const unsigned int cycle)\n  {\n if (cycle == 0)\n      {\n GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\n triangulation.refine_global(3 - dim);\n      }\n else\n switch (refinement_mode)\n        {\n case global_refinement:\n            {\n triangulation.clear();\n GridGenerator::subdivided_hyper_cube(triangulation,\n                                                   2 + (cycle % 2),\n                                                   -1,\n                                                   1);\n triangulation.refine_global(3 - dim + cycle / 2);\n break;\n            }\n \n case adaptive_refinement:\n            {\n Vector<float> estimated_error_per_cell(\n triangulation.n_active_cells());\n \n const FEValuesExtractors::Scalar scalar(dim);\n              std::map<types::boundary_id, const Function<dim> *>\n                neumann_boundary;\n KellyErrorEstimator<dim>::estimate(dof_handler_local,\n QGauss<dim - 1>(fe.degree + 1),\n                                                 neumann_boundary,\n                                                 solution_local,\n                                                 estimated_error_per_cell,\n                                                 fe_local.component_mask(\n                                                   scalar));\n \n GridRefinement::refine_and_coarsen_fixed_number(\n triangulation, estimated_error_per_cell, 0.3, 0.);\n \n triangulation.execute_coarsening_and_refinement();\n \n break;\n            }\n \n default:\n            {\n DEAL_II_NOT_IMPLEMENTED();\n            }\n        }\n \n for (const auto &cell : triangulation.cell_iterators())\n      for (const auto &face : cell->face_iterators())\n        if (face->at_boundary())\n          if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\n              (std::fabs(face->center()[1] - (-1)) < 1e-12))\n            face->set_boundary_id(1);\n  }\n \n template <int dim>\n void HDG<dim>::run()\n  {\n for (unsigned int cycle = 0; cycle < 10; ++cycle)\n      {\n        std::cout << \"Cycle \" << cycle << ':' << std::endl;\n \n        refine_grid(cycle);\n        setup_system();\n        assemble_system(false);\n        solve();\n        postprocess();\n        output_results(cycle);\n      }\n \n if (refinement_mode == global_refinement)\n      {\n        convergence_table.evaluate_convergence_rates(\n \"val L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n        convergence_table.evaluate_convergence_rates(\n \"grad L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n        convergence_table.evaluate_convergence_rates(\n \"val L2-post\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\n      }\n    convergence_table.write_text(std::cout);\n  }\n \n} // end of namespace Step51\n \n \n \nint main()\n{\n const unsigned int dim = 2;\n \n try\n    {\n      {\n        std::cout << \"Solving with Q1 elements, adaptive refinement\"\n                  << std::endl\n                  << \"=============================================\"\n                  << std::endl\n                  << std::endl;\n \n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\n        hdg_problem.run();\n \n        std::cout << std::endl;\n      }\n \n      {\n        std::cout << \"Solving with Q1 elements, global refinement\" << std::endl\n                  << \"===========================================\" << std::endl\n                  << std::endl;\n \n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\n        hdg_problem.run();\n \n        std::cout << std::endl;\n      }\n \n      {\n        std::cout << \"Solving with Q3 elements, global refinement\" << std::endl\n                  << \"===========================================\" << std::endl\n                  << std::endl;\n \n        Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\n        hdg_problem.run();\n \n        std::cout << std::endl;\n      }\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_52.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving the time dependent neutron diffusion equation using Runge-Kutta methods. Explicit and implicit time stepping.\nTutorial content :\nThis tutorial depends on [step-26](step_26.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_52-Intro)    * [Problem statement](#step_52-Problemstatement)* [Runge-Kutta methods](#step_52-RungeKuttamethods)        + [Explicit Runge-Kutta methods](#step_52-ExplicitRungeKuttamethods)+ [Embedded Runge-Kutta methods](#step_52-EmbeddedRungeKuttamethods)+ [Implicit Runge-Kutta methods](#step_52-ImplicitRungeKuttamethods)* [Spatially discrete formulation](#step_52-Spatiallydiscreteformulation)* [Notes on the testcase](#step_52-Notesonthetestcase)- [The commented program](#step_52-CommProg)      * [Include files](#step_52-Includefiles)* [The `Diffusion` class](#step_52-ThecodeDiffusioncodeclass)          + [`Diffusion::setup_system`](#step_52-codeDiffusionsetup_systemcode)+ [`Diffusion::assemble_system`](#step_52-codeDiffusionassemble_systemcode)+ [`Diffusion::get_source`](#step_52-codeDiffusionget_sourcecode)+ [`Diffusion::evaluate_diffusion`](#step_52-codeDiffusionevaluate_diffusioncode)+ [`Diffusion::id_minus_tau_J_inverse`](#step_52-codeDiffusionid_minus_tau_J_inversecode)+ [`Diffusion::output_results`](#step_52-codeDiffusionoutput_resultscode)+ [`Diffusion::explicit_method`](#step_52-codeDiffusionexplicit_methodcode)+ [`Diffusion::implicit_method`](#step_52-codeDiffusionimplicit_methodcode)+ [`Diffusion::embedded_explicit_method`](#step_52-codeDiffusionembedded_explicit_methodcode)+ [`Diffusion::run`](#step_52-codeDiffusionruncode)* [The `main()` function](#step_52-Thecodemaincodefunction) | 1. [Results](#step_52-Results)    - [The plain program](#step_52-PlainProg) |\n\n*This program was contributed by Bruno Turcksin and Damien Lebrun-Grandie.*\n\nNote\n:   In order to run this program, deal.II must be configured to use the UMFPACK sparse direct solver. Refer to the [ReadMe](../../readme.html#umfpack) for instructions how to do this.\n\nIntroduction\n============\n\nThis program shows how to use Runge-Kutta methods to solve a time-dependent problem. It solves a small variation of the heat equation discussed first in [step-26](step_26.html) but, since the purpose of this program is only to demonstrate using more advanced ways to interface with deal.II's time stepping algorithms, only solves a simple problem on a uniformly refined mesh.\n\nNote\n:   At the end of the day, time stepping is a problem that is only solved efficiently if you use adaptive time step selection and error control. This is implemented in many external libraries, but not in deal.II itself. You may want to consider looking at [step-86](step_86.html) for a worked out example. In the meantime, this program is deprecated and will be removed after the deal.II 9.6 release.\n\n### Problem statement\n\nIn this example, we solve the one-group time-dependent diffusion approximation of the neutron transport equation (see [step-28](step_28.html) for the time-independent multigroup diffusion). This is a model for how neutrons move around highly scattering media, and consequently it is a variant of the time-dependent diffusion equation – which is just a different name for the heat equation discussed in [step-26](step_26.html), plus some extra terms. We assume that the medium is not fissible and therefore, the neutron flux satisfies the following equation:\n\n\\begin{eqnarray\\*}\n\\frac{1}{v}\\frac{\\partial \\phi(x,t)}{\\partial t} = \\nabla \\cdot D(x) \\nabla \\phi(x,t)\n- \\Sigma\\_a(x) \\phi(x,t) + S(x,t)\n\\end{eqnarray\\*}\n\naugmented by appropriate boundary conditions. Here, \\(v\\) is the velocity of neutrons (for simplicity we assume it is equal to 1 which can be achieved by simply scaling the time variable), \\(D\\) is the diffusion coefficient, \\(\\Sigma\\_a\\) is the absorption cross section, and \\(S\\) is a source. Because we are only interested in the time dependence, we assume that \\(D\\) and \\(\\Sigma\\_a\\) are constant.\n\nSince this program only intends to demonstrate how to use advanced time stepping algorithms, we will only look for the solutions of relatively simple problems. Specifically, we are looking for a solution on a square domain \\([0,b]\\times[0,b]\\) of the form\n\n\\begin{eqnarray\\*}\n\\phi(x,t) = A\\sin(\\omega t)(bx-x^2).\n\\end{eqnarray\\*}\n\nBy using quadratic finite elements, we can represent this function exactly at any particular time, and all the error will be due to the time discretization. We do this because it is then easy to observe the order of convergence of the various time stepping schemes we will consider, without having to separate spatial and temporal errors.\n\nWe impose the following boundary conditions: homogeneous Dirichlet for \\(x=0\\) and \\(x=b\\) and homogeneous Neumann conditions for \\(y=0\\) and \\(y=b\\). We choose the source term so that the corresponding solution is in fact of the form stated above:\n\n\\begin{eqnarray\\*}\nS=A\\left(\\frac{1}{v}\\omega \\cos(\\omega t)(bx -x^2) + \\sin(\\omega t)\n\\left(\\Sigma\\_a (bx-x^2)+2D\\right) \\right).\n\\end{eqnarray\\*}\n\nBecause the solution is a sine in time, we know that the exact solution satisfies \\(\\phi\\left(x,\\frac{\\pi}{\\omega}\\right) = 0\\). Therefore, the error at time \\(t=\\frac{\\pi}{\\omega}\\) is simply the norm of the numerical solution, i.e., \\(\\|e(\\cdot,t=\\frac{\\pi}{\\omega})\\|\\_{L\\_2} = \\|\\phi\\_h(\\cdot,t=\\frac{\\pi}{\\omega})\\|\\_{L\\_2}\\), and is particularly easily evaluated. In the code, we evaluate the \\(l\\_2\\) norm of the vector of nodal values of \\(\\phi\\_h\\) instead of the \\(L\\_2\\) norm of the associated spatial function, since the former is simpler to compute; however, on uniform meshes, the two are just related by a constant and we can consequently observe the temporal convergence order with either.\n\n### Runge-Kutta methods\n\nThe Runge-Kutta methods implemented in deal.II assume that the equation to be solved can be written as:\n\n\\begin{eqnarray\\*}\n\\frac{dy}{dt} = g(t,y).\n\\end{eqnarray\\*}\n\nOn the other hand, when using finite elements, discretized time derivatives always result in the presence of a [mass matrix](DEALGlossary.html#GlossMassMatrix) on the left hand side. This can easily be seen by considering that if the solution vector \\(y(t)\\) in the equation above is in fact the vector of nodal coefficients \\(U(t)\\) for a variable of the form\n\n\\begin{eqnarray\\*}\nu\\_h(x,t) = \\sum\\_j U\\_j(t) \\varphi\\_j(x)\n\\end{eqnarray\\*}\n\nwith spatial shape functions \\(\\varphi\\_j(x)\\), then multiplying an equation of the form\n\n\\begin{eqnarray\\*}\n\\frac{\\partial u(x,t)}{\\partial t} = q(t,u(x,t))\n\\end{eqnarray\\*}\n\nby test functions, integrating over \\(\\Omega\\), substituting \\(u\\rightarrow u\\_h\\) and restricting the test functions to the \\(\\varphi\\_i(x)\\) from above, then this spatially discretized equation has the form\n\n\\begin{eqnarray\\*}\nM\\frac{dU}{dt} = f(t,U),\n\\end{eqnarray\\*}\n\nwhere \\(M\\) is the mass matrix and \\(f(t,U)\\) is the spatially discretized version of \\(q(t,u(x,t))\\) (where \\(q\\) is typically the place where spatial derivatives appear, but this is not of much concern for the moment given that we only consider time derivatives). In other words, this form fits the general scheme above if we write\n\n\\begin{eqnarray\\*}\n\\frac{dy}{dt} = g(t,y) = M^{-1}f(t,y).\n\\end{eqnarray\\*}\n\nRunke-Kutta methods are time stepping schemes that approximate \\(y(t\\_n)\\approx\ny\\_{n}\\) through a particular one-step approach. They are typically written in the form\n\n\\begin{eqnarray\\*}\ny\\_{n+1} = y\\_n + \\sum\\_{i=1}^s b\\_i k\\_i\n\\end{eqnarray\\*}\n\nwhere for the form of the right hand side above\n\n\\begin{eqnarray\\*}\nk\\_i = \\Delta t \\, M^{-1} f\\left(t\\_n+c\\_ih,y\\_n+\\sum\\_{j=1}^sa\\_{ij}k\\_j\\right).\n\\end{eqnarray\\*}\n\nHere \\(a\\_{ij}\\), \\(b\\_i\\), and \\(c\\_i\\) are known coefficients that identify which particular Runge-Kutta scheme you want to use, and \\(\\Delta t=t\\_{n+1}-t\\_n\\) is the time step used. Different time stepping methods of the Runge-Kutta class differ in the number of stages \\(s\\) and the values they use for the coefficients \\(a\\_{ij}\\), \\(b\\_i\\), and \\(c\\_i\\) but are otherwise easy to implement since one can look up tabulated values for these coefficients. (These tables are often called Butcher tableaus.)\n\nAt the time of the writing of this tutorial, the methods implemented in deal.II can be divided in three categories:\n\n1. Explicit Runge-Kutta; in order for a method to be explicit, it is necessary that in the formula above defining \\(k\\_i\\), \\(k\\_i\\) does not appear on the right hand side. In other words, these methods have to satisfy \\(a\\_{ii}=0, i=1,\\ldots,s\\).\n2. Embedded (or adaptive) Runge-Kutta; we will discuss their properties below.\n3. Implicit Runge-Kutta; this class of methods require the solution of a possibly nonlinear system the stages \\(k\\_i\\) above, i.e., they have \\(a\\_{ii}\\neq 0\\) for at least one of the stages \\(i=1,\\ldots,s\\).\n\nMany well known time stepping schemes that one does not typically associate with the names Runge or Kutta can in fact be written in a way so that they, too, can be expressed in these categories. They oftentimes represent the lowest-order members of these families; one example is the simple explicit Euler method.\n\n#### Explicit Runge-Kutta methods\n\nThese methods, only require a function to evaluate \\(M^{-1}f(t,y)\\) but not (as implicit methods) to solve an equation that involves \\(f(t,y)\\) for \\(y\\). As all explicit time stepping methods, they become unstable when the time step chosen is too large.\n\nWell known methods in this class include forward Euler, third order Runge-Kutta, and fourth order Runge-Kutta (often abbreviated as RK4).\n\n#### Embedded Runge-Kutta methods\n\nThese methods use both a lower and a higher order method to estimate the error and decide if the time step needs to be shortened or can be increased. The term \"embedded\" refers to the fact that the lower-order method does not require additional evaluates of the function \\(M^{-1}f(\\cdot,\\cdot)\\) but reuses data that has to be computed for the high order method anyway. It is, in other words, essentially free, and we get the error estimate as a side product of using the higher order method.\n\nThis class of methods include Heun-Euler, Bogacki-Shampine, Dormand-Prince (ode45 in Matlab and often abbreviated as RK45 to indicate that the lower and higher order methods used here are 4th and 5th order Runge-Kutta methods, respectively), Fehlberg, and Cash-Karp.\n\nAt the time of the writing, only embedded explicit methods have been implemented.\n\n#### Implicit Runge-Kutta methods\n\nImplicit methods require the solution of (possibly nonlinear) systems of the form \\(\\alpha y = f(t,y)\\) for \\(y\\) in each (sub-)timestep. Internally, this is done using a Newton-type method and, consequently, they require that the user provide functions that can evaluate \\(M^{-1}f(t,y)\\) and \\(\\left(I-\\tau M^{-1} \\frac{\\partial f}{\\partial y}\\right)^{-1}\\) or equivalently \\(\\left(M - \\tau \\frac{\\partial f}{\\partial y}\\right)^{-1} M\\).\n\nThe particular form of this operator results from the fact that each Newton step requires the solution of an equation of the form\n\n\\begin{align\\*}\n\\left(M - \\tau \\frac{\\partial f}{\\partial y}\\right) \\Delta y\n= -M h(t,y)\n\\end{align\\*}\n\nfor some (given) \\(h(t,y)\\). Implicit methods are always stable, regardless of the time step size, but too large time steps of course affect the *accuracy* of the solution, even if the numerical solution remains stable and bounded.\n\nMethods in this class include backward Euler, implicit midpoint, Crank-Nicolson, and the two stage SDIRK method (short for \"singly diagonally\nimplicit Runge-Kutta\", a term coined to indicate that the diagonal elements \\(a\\_{ii}\\) defining the time stepping method are all equal; this property allows for the Newton matrix \\(I-\\tau M^{-1}\\frac{\\partial f}{\\partial y}\\) to be re-used between stages because \\(\\tau\\) is the same every time).\n\n### Spatially discrete formulation\n\nBy expanding the solution of our model problem as always using shape functions \\(\\psi\\_j\\) and writing\n\n\\begin{eqnarray\\*}\n\\phi\\_h(x,t) = \\sum\\_j U\\_j(t) \\psi\\_j(x),\n\\end{eqnarray\\*}\n\nwe immediately get the spatially discretized version of the diffusion equation as\n\n\\begin{eqnarray\\*}\nM \\frac{dU(t)}{dt}\n= -{\\cal D} U(t) - {\\cal A} U(t) + {\\cal S}(t)\n\\end{eqnarray\\*}\n\nwhere\n\n\\begin{eqnarray\\*}\nM\\_{ij} &=& (\\psi\\_i,\\psi\\_j), \\\\\n{\\cal D}\\_{ij} &=& (D\\nabla\\psi\\_i,\\nabla\\psi\\_j)\\_\\Omega, \\\\\n{\\cal A}\\_{ij} &=& (\\Sigma\\_a\\psi\\_i,\\psi\\_j)\\_\\Omega, \\\\\n{\\cal S}\\_{i}(t) &=& (\\psi\\_i,S(x,t))\\_\\Omega.\n\\end{eqnarray\\*}\n\nSee also [step-24](step_24.html) and [step-26](step_26.html) to understand how we arrive here. Boundary terms are not necessary due to the chosen boundary conditions for the current problem. To use the Runge-Kutta methods, we recast this as follows:\n\n\\begin{eqnarray\\*}\nf(y) = -{\\cal D}y - {\\cal A}y + {\\cal S}.\n\\end{eqnarray\\*}\n\nIn the code, we will need to be able to evaluate this function \\(f(U)\\) along with its derivative,\n\n\\begin{eqnarray\\*}\n\\frac{\\partial f}{\\partial y} = -{\\cal D} - {\\cal A}.\n\\end{eqnarray\\*}\n\n### Notes on the testcase\n\nTo simplify the problem, the domain is two dimensional and the mesh is uniformly refined (there is no need to adapt the mesh since we use quadratic finite elements and the exact solution is quadratic). Going from a two dimensional domain to a three dimensional domain is not very challenging. However if you intend to solve more complex problems where the mesh must be adapted (as is done, for example, in [step-26](step_26.html)), then it is important to remember the following issues:\n\n1. You will need to project the solution to the new mesh when the mesh is changed. Of course, the mesh used should be the same from the beginning to the end of each time step, a question that arises because Runge-Kutta methods use multiple evaluations of the equations within each time step.\n2. You will need to update the mass matrix and its inverse every time the mesh is changed.\n\nThe techniques for these steps are readily available by looking at [step-26](step_26.html).\n\nThe commented program\n=====================\n\n### Include files\n\nThe first task as usual is to include the functionality of these well-known deal.II library files and some C++ header files.\n\n```\n   #include <deal.II/base/discrete_time.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/quadrature_lib.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_out.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_values.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/sparse_direct.h>\n   \n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n   \n   #include <fstream>\n   #include <iostream>\n   #include <cmath>\n   #include <map>\n```\n\nThis is the only include file that is new: It includes all the Runge-Kutta methods.\n\n```\n   #include <deal.II/base/time_stepping.h>\n```\n\nThe next step is like in all previous tutorial programs: We put everything into a namespace of its own and then import the deal.II classes and functions into it.\n\n```\n   namespace Step52\n   {\n     using namespace dealii;\n```\n\n### The `Diffusion` class\n\nThe next piece is the declaration of the main class. Most of the functions in this class are not new and have been explained in previous tutorials. The only interesting functions are `evaluate_diffusion()` and `id_minus_tau_J_inverse()`. `evaluate_diffusion()` evaluates the diffusion equation, \\(M^{-1}(f(t,y))\\), at a given time and a given \\(y\\). `id_minus_tau_J_inverse()` evaluates \\(\\left(I-\\tau\nM^{-1} \\frac{\\partial f(t,y)}{\\partial y}\\right)^{-1}\\) or equivalently \\(\\left(M-\\tau \\frac{\\partial f}{\\partial y}\\right)^{-1} M\\) at a given time, for a given \\(\\tau\\) and \\(y\\). This function is needed when an implicit method is used.\n\n```\n     class Diffusion\n     {\n     public:\n       Diffusion();\n   \n       void run();\n   \n     private:\n       void setup_system();\n   \n       void assemble_system();\n   \n       double get_source(const double time, const Point<2> &point) const;\n   \n       Vector<double> evaluate_diffusion(const double          time,\n                                         const Vector<double> &y) const;\n   \n       Vector<double> id_minus_tau_J_inverse(const double          time,\n                                             const double          tau,\n                                             const Vector<double> &y);\n   \n       void output_results(const double                     time,\n                           const unsigned int               time_step,\n                           TimeStepping::runge_kutta_method method) const;\n```\n\nThe next three functions are the drivers for the explicit methods, the implicit methods, and the embedded explicit methods respectively. The driver function for embedded explicit methods returns the number of steps executed given that it only takes the number of time steps passed as an argument as a hint, but internally computed the optimal time step itself.\n\n```\n       void explicit_method(const TimeStepping::runge_kutta_method method,\n                            const unsigned int                     n_time_steps,\n                            const double                           initial_time,\n                            const double                           final_time);\n   \n       void implicit_method(const TimeStepping::runge_kutta_method method,\n                            const unsigned int                     n_time_steps,\n                            const double                           initial_time,\n                            const double                           final_time);\n   \n       unsigned int\n       embedded_explicit_method(const TimeStepping::runge_kutta_method method,\n                                const unsigned int n_time_steps,\n                                const double       initial_time,\n                                const double       final_time);\n   \n   \n       const unsigned int fe_degree;\n   \n       const double diffusion_coefficient;\n       const double absorption_cross_section;\n   \n       Triangulation<2> triangulation;\n   \n       const FE_Q<2> fe;\n   \n       DoFHandler<2> dof_handler;\n   \n       AffineConstraints<double> constraint_matrix;\n   \n       SparsityPattern sparsity_pattern;\n   \n       SparseMatrix<double> system_matrix;\n       SparseMatrix<double> mass_matrix;\n       SparseMatrix<double> mass_minus_tau_Jacobian;\n   \n       SparseDirectUMFPACK inverse_mass_matrix;\n   \n       Vector<double> solution;\n     };\n```\n\nWe choose quadratic finite elements and we initialize the parameters.\n\n```\n     Diffusion::Diffusion()\n       : fe_degree(2)\n       , diffusion_coefficient(1. / 30.)\n       , absorption_cross_section(1.)\n       , fe(fe_degree)\n       , dof_handler(triangulation)\n     {}\n```\n\n#### `Diffusion::setup_system`\n\nNow, we create the constraint matrix and the sparsity pattern. Then, we initialize the matrices and the solution vector.\n\n```\n     void Diffusion::setup_system()\n     {\n       dof_handler.distribute_dofs(fe);\n   \n       VectorTools::interpolate_boundary_values(dof_handler,\n                                                1,\n                                                Functions::ZeroFunction<2>(),\n                                                constraint_matrix);\n       constraint_matrix.close();\n   \n       DynamicSparsityPattern dsp(dof_handler.n_dofs());\n       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraint_matrix);\n       sparsity_pattern.copy_from(dsp);\n   \n       system_matrix.reinit(sparsity_pattern);\n       mass_matrix.reinit(sparsity_pattern);\n       mass_minus_tau_Jacobian.reinit(sparsity_pattern);\n       solution.reinit(dof_handler.n_dofs());\n     }\n```\n\n#### `Diffusion::assemble_system`\n\nIn this function, we compute \\(-\\int D \\nabla b\\_i \\cdot \\nabla b\\_j\nd\\boldsymbol{r} - \\int \\Sigma\\_a b\\_i b\\_j d\\boldsymbol{r}\\) and the mass matrix \\(\\int b\\_i b\\_j d\\boldsymbol{r}\\). The [mass matrix](DEALGlossary.html#GlossMassMatrix) is then inverted using a direct solver; the `inverse_mass_matrix` variable will then store the inverse of the mass matrix so that \\(M^{-1}\\) can be applied to a vector using the `vmult()` function of that object. (Internally, UMFPACK does not really store the inverse of the matrix, but its LU factors; applying the inverse matrix is then equivalent to doing one forward and one backward solves with these two factors, which has the same complexity as applying an explicit inverse of the matrix).\n\n```\n     void Diffusion::assemble_system()\n     {\n       system_matrix = 0.;\n       mass_matrix   = 0.;\n   \n       const QGauss<2> quadrature_formula(fe_degree + 1);\n   \n       FEValues<2> fe_values(fe,\n                             quadrature_formula,\n                             update_values | update_gradients | update_JxW_values);\n   \n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n       FullMatrix<double> cell_mass_matrix(dofs_per_cell, dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           cell_matrix      = 0.;\n           cell_mass_matrix = 0.;\n   \n           fe_values.reinit(cell);\n   \n           for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n             for (unsigned int i = 0; i < dofs_per_cell; ++i)\n               for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                 {\n                   cell_matrix(i, j) +=\n                     ((-diffusion_coefficient *                // (-D\n                         fe_values.shape_grad(i, q_point) *    //  * grad phi_i\n                         fe_values.shape_grad(j, q_point)      //  * grad phi_j\n                       - absorption_cross_section *            //  -Sigma\n                           fe_values.shape_value(i, q_point) * //  * phi_i\n                           fe_values.shape_value(j, q_point))  //  * phi_j)\n                      * fe_values.JxW(q_point));               // * dx\n                   cell_mass_matrix(i, j) += fe_values.shape_value(i, q_point) *\n                                             fe_values.shape_value(j, q_point) *\n                                             fe_values.JxW(q_point);\n                 }\n   \n           cell->get_dof_indices(local_dof_indices);\n   \n           constraint_matrix.distribute_local_to_global(cell_matrix,\n                                                        local_dof_indices,\n                                                        system_matrix);\n           constraint_matrix.distribute_local_to_global(cell_mass_matrix,\n                                                        local_dof_indices,\n                                                        mass_matrix);\n         }\n   \n       inverse_mass_matrix.initialize(mass_matrix);\n     }\n```\n\n#### `Diffusion::get_source`\n\nIn this function, the source term of the equation for a given time and a given point is computed.\n\n```\n     double Diffusion::get_source(const double time, const Point<2> &point) const\n     {\n       const double intensity = 10.;\n       const double frequency = numbers::PI / 10.;\n       const double b         = 5.;\n       const double x         = point[0];\n   \n       return intensity *\n              (frequency * std::cos(frequency * time) * (b * x - x * x) +\n               std::sin(frequency * time) *\n                 (absorption_cross_section * (b * x - x * x) +\n                  2. * diffusion_coefficient));\n     }\n```\n\n#### `Diffusion::evaluate_diffusion`\n\nNext, we evaluate the weak form of the diffusion equation at a given time \\(t\\) and for a given vector \\(y\\). In other words, as outlined in the introduction, we evaluate \\(M^{-1}(-{\\cal D}y - {\\cal A}y + {\\cal\nS})\\). For this, we have to apply the matrix \\(-{\\cal D} - {\\cal A}\\) (previously computed and stored in the variable `system_matrix`) to \\(y\\) and then add the source term which we integrate as we usually do. (Integrating up the solution could be done using [VectorTools::create\\_right\\_hand\\_side()](namespaceVectorTools.html#a6e325333a138893e181da47f29ac680a) if you wanted to save a few lines of code, or wanted to take advantage of doing the integration in parallel.) The result is then multiplied by \\(M^{-1}\\).\n\n```\n     Vector<double> Diffusion::evaluate_diffusion(const double          time,\n                                                  const Vector<double> &y) const\n     {\n       Vector<double> tmp(dof_handler.n_dofs());\n       tmp = 0.;\n       system_matrix.vmult(tmp, y);\n   \n       const QGauss<2> quadrature_formula(fe_degree + 1);\n   \n       FEValues<2> fe_values(fe,\n                             quadrature_formula,\n                             update_values | update_quadrature_points |\n                               update_JxW_values);\n   \n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       Vector<double> cell_source(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           cell_source = 0.;\n   \n           fe_values.reinit(cell);\n   \n           for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n             {\n               const double source =\n                 get_source(time, fe_values.quadrature_point(q_point));\n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 cell_source(i) += fe_values.shape_value(i, q_point) * // phi_i(x)\n                                   source *                            // * S(x)\n                                   fe_values.JxW(q_point);             // * dx\n             }\n   \n           cell->get_dof_indices(local_dof_indices);\n   \n           constraint_matrix.distribute_local_to_global(cell_source,\n                                                        local_dof_indices,\n                                                        tmp);\n         }\n   \n       Vector<double> value(dof_handler.n_dofs());\n       inverse_mass_matrix.vmult(value, tmp);\n   \n       return value;\n     }\n```\n\n#### `Diffusion::id_minus_tau_J_inverse`\n\nWe compute \\(\\left(M-\\tau \\frac{\\partial f}{\\partial y}\\right)^{-1} M\\). This is done in several steps:\n\n* compute \\(M-\\tau \\frac{\\partial f}{\\partial y}\\)\n* invert the matrix to get \\(\\left(M-\\tau \\frac{\\partial f}\n  {\\partial y}\\right)^{-1}\\)\n* compute \\(tmp=My\\)\n* compute \\(z=\\left(M-\\tau \\frac{\\partial f}{\\partial y}\\right)^{-1} tmp =\n  \\left(M-\\tau \\frac{\\partial f}{\\partial y}\\right)^{-1} My\\)\n* return z.\n\n```\n     Vector<double> Diffusion::id_minus_tau_J_inverse(const double /*time*/,\n                                                      const double          tau,\n                                                      const Vector<double> &y)\n     {\n       SparseDirectUMFPACK inverse_mass_minus_tau_Jacobian;\n   \n       mass_minus_tau_Jacobian.copy_from(mass_matrix);\n       mass_minus_tau_Jacobian.add(-tau, system_matrix);\n   \n       inverse_mass_minus_tau_Jacobian.initialize(mass_minus_tau_Jacobian);\n   \n       Vector<double> tmp(dof_handler.n_dofs());\n       mass_matrix.vmult(tmp, y);\n   \n       Vector<double> result(y);\n       inverse_mass_minus_tau_Jacobian.vmult(result, tmp);\n   \n       return result;\n     }\n```\n\n#### `Diffusion::output_results`\n\nThe following function then outputs the solution in vtu files indexed by the number of the time step and the name of the time stepping method. Of course, the (exact) result should really be the same for all time stepping method, but the output here at least allows us to compare them.\n\n```\n     void Diffusion::output_results(const double                     time,\n                                    const unsigned int               time_step,\n                                    TimeStepping::runge_kutta_method method) const\n     {\n       std::string method_name;\n   \n       switch (method)\n         {\n           case TimeStepping::FORWARD_EULER:\n             {\n               method_name = \"forward_euler\";\n               break;\n             }\n           case TimeStepping::RK_THIRD_ORDER:\n             {\n               method_name = \"rk3\";\n               break;\n             }\n           case TimeStepping::RK_CLASSIC_FOURTH_ORDER:\n             {\n               method_name = \"rk4\";\n               break;\n             }\n           case TimeStepping::BACKWARD_EULER:\n             {\n               method_name = \"backward_euler\";\n               break;\n             }\n           case TimeStepping::IMPLICIT_MIDPOINT:\n             {\n               method_name = \"implicit_midpoint\";\n               break;\n             }\n           case TimeStepping::SDIRK_TWO_STAGES:\n             {\n               method_name = \"sdirk\";\n               break;\n             }\n           case TimeStepping::HEUN_EULER:\n             {\n               method_name = \"heun_euler\";\n               break;\n             }\n           case TimeStepping::BOGACKI_SHAMPINE:\n             {\n               method_name = \"bogacki_shampine\";\n               break;\n             }\n           case TimeStepping::DOPRI:\n             {\n               method_name = \"dopri\";\n               break;\n             }\n           case TimeStepping::FEHLBERG:\n             {\n               method_name = \"fehlberg\";\n               break;\n             }\n           case TimeStepping::CASH_KARP:\n             {\n               method_name = \"cash_karp\";\n               break;\n             }\n           default:\n             {\n               break;\n             }\n         }\n   \n       DataOut<2> data_out;\n   \n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(solution, \"solution\");\n   \n       data_out.build_patches();\n   \n       data_out.set_flags(DataOutBase::VtkFlags(time, time_step));\n   \n       const std::string filename = \"solution_\" + method_name + \"-\" +\n                                    Utilities::int_to_string(time_step, 3) +\n                                    \".vtu\";\n       std::ofstream output(filename);\n       data_out.write_vtu(output);\n   \n       static std::vector<std::pair<double, std::string>> times_and_names;\n   \n       static std::string method_name_prev = \"\";\n       static std::string pvd_filename;\n       if (method_name_prev != method_name)\n         {\n           times_and_names.clear();\n           method_name_prev = method_name;\n           pvd_filename     = \"solution_\" + method_name + \".pvd\";\n         }\n       times_and_names.emplace_back(time, filename);\n       std::ofstream pvd_output(pvd_filename);\n       DataOutBase::write_pvd_record(pvd_output, times_and_names);\n     }\n```\n\n#### `Diffusion::explicit_method`\n\nThis function is the driver for all the explicit methods. At the top it initializes the time stepping and the solution (by setting it to zero and then ensuring that boundary value and hanging node constraints are respected; of course, with the mesh we use here, hanging node constraints are not in fact an issue). It then calls `evolve_one_time_step` which performs one time step. Time is stored and incremented through a [DiscreteTime](classDiscreteTime.html) object.\n\nFor explicit methods, `evolve_one_time_step` needs to evaluate \\(M^{-1}(f(t,y))\\), i.e, it needs `evaluate_diffusion`. Because `evaluate_diffusion` is a member function, it needs to be bound to `this`. After each evolution step, we again apply the correct boundary values and hanging node constraints.\n\nFinally, the solution is output every 10 time steps.\n\n```\n     void Diffusion::explicit_method(const TimeStepping::runge_kutta_method method,\n                                     const unsigned int n_time_steps,\n                                     const double       initial_time,\n                                     const double       final_time)\n     {\n       const double time_step =\n         (final_time - initial_time) / static_cast<double>(n_time_steps);\n   \n       solution = 0.;\n       constraint_matrix.distribute(solution);\n   \n       TimeStepping::ExplicitRungeKutta<Vector<double>> explicit_runge_kutta(\n         method);\n       output_results(initial_time, 0, method);\n       DiscreteTime time(initial_time, final_time, time_step);\n       while (time.is_at_end() == false)\n         {\n           explicit_runge_kutta.evolve_one_time_step(\n             [this](const double time, const Vector<double> &y) {\n               return this->evaluate_diffusion(time, y);\n             },\n             time.get_current_time(),\n             time.get_next_step_size(),\n             solution);\n           time.advance_time();\n   \n           constraint_matrix.distribute(solution);\n   \n           if (time.get_step_number() % 10 == 0)\n             output_results(time.get_current_time(),\n                            time.get_step_number(),\n                            method);\n         }\n     }\n```\n\n#### `Diffusion::implicit_method`\n\nThis function is equivalent to `explicit_method` but for implicit methods. When using implicit methods, we need to evaluate \\(M^{-1}(f(t,y))\\) and \\(\\left(I-\\tau M^{-1} \\frac{\\partial f(t,y)}{\\partial\ny}\\right)^{-1}\\) for which we use the two member functions previously introduced.\n\n```\n     void Diffusion::implicit_method(const TimeStepping::runge_kutta_method method,\n                                     const unsigned int n_time_steps,\n                                     const double       initial_time,\n                                     const double       final_time)\n     {\n       const double time_step =\n         (final_time - initial_time) / static_cast<double>(n_time_steps);\n   \n       solution = 0.;\n       constraint_matrix.distribute(solution);\n   \n       TimeStepping::ImplicitRungeKutta<Vector<double>> implicit_runge_kutta(\n         method);\n       output_results(initial_time, 0, method);\n       DiscreteTime time(initial_time, final_time, time_step);\n       while (time.is_at_end() == false)\n         {\n           implicit_runge_kutta.evolve_one_time_step(\n             [this](const double time, const Vector<double> &y) {\n               return this->evaluate_diffusion(time, y);\n             },\n             [this](const double time, const double tau, const Vector<double> &y) {\n               return this->id_minus_tau_J_inverse(time, tau, y);\n             },\n             time.get_current_time(),\n             time.get_next_step_size(),\n             solution);\n           time.advance_time();\n   \n           constraint_matrix.distribute(solution);\n   \n           if (time.get_step_number() % 10 == 0)\n             output_results(time.get_current_time(),\n                            time.get_step_number(),\n                            method);\n         }\n     }\n```\n\n#### `Diffusion::embedded_explicit_method`\n\nThis function is the driver for the embedded explicit methods. It requires more parameters:\n\n* coarsen\\_param: factor multiplying the current time step when the error is below the threshold.\n* refine\\_param: factor multiplying the current time step when the error is above the threshold.\n* min\\_delta: smallest time step acceptable.\n* max\\_delta: largest time step acceptable.\n* refine\\_tol: threshold above which the time step is refined.\n* coarsen\\_tol: threshold below which the time step is coarsen.\n\nEmbedded methods use a guessed time step. If the error using this time step is too large, the time step will be reduced. If the error is below the threshold, a larger time step will be tried for the next time step. `delta_t_guess` is the guessed time step produced by the embedded method. In summary, time step size is potentially modified in three ways:\n\n* Reducing or increasing time step size within [TimeStepping::EmbeddedExplicitRungeKutta::evolve\\_one\\_time\\_step()](classTimeStepping_1_1EmbeddedExplicitRungeKutta.html#accb05cdd9b6519c4d4ffe9ea996cee87).\n* Using the calculated `delta_t_guess`.\n* Automatically adjusting the step size of the last time step to ensure simulation ends precisely at `final_time`. This adjustment is handled inside the [DiscreteTime](classDiscreteTime.html) instance.\n\n```\n     unsigned int Diffusion::embedded_explicit_method(\n       const TimeStepping::runge_kutta_method method,\n       const unsigned int                     n_time_steps,\n       const double                           initial_time,\n       const double                           final_time)\n     {\n       const double time_step =\n         (final_time - initial_time) / static_cast<double>(n_time_steps);\n       const double coarsen_param = 1.2;\n       const double refine_param  = 0.8;\n       const double min_delta     = 1e-8;\n       const double max_delta     = 10 * time_step;\n       const double refine_tol    = 1e-1;\n       const double coarsen_tol   = 1e-5;\n   \n       solution = 0.;\n       constraint_matrix.distribute(solution);\n   \n       TimeStepping::EmbeddedExplicitRungeKutta<Vector<double>>\n         embedded_explicit_runge_kutta(method,\n                                       coarsen_param,\n                                       refine_param,\n                                       min_delta,\n                                       max_delta,\n                                       refine_tol,\n                                       coarsen_tol);\n       output_results(initial_time, 0, method);\n       DiscreteTime time(initial_time, final_time, time_step);\n       while (time.is_at_end() == false)\n         {\n           const double new_time =\n             embedded_explicit_runge_kutta.evolve_one_time_step(\n               [this](const double time, const Vector<double> &y) {\n                 return this->evaluate_diffusion(time, y);\n               },\n               time.get_current_time(),\n               time.get_next_step_size(),\n               solution);\n           time.set_next_step_size(new_time - time.get_current_time());\n           time.advance_time();\n   \n           constraint_matrix.distribute(solution);\n   \n           if (time.get_step_number() % 10 == 0)\n             output_results(time.get_current_time(),\n                            time.get_step_number(),\n                            method);\n   \n           time.set_desired_next_step_size(\n             embedded_explicit_runge_kutta.get_status().delta_t_guess);\n         }\n   \n       return time.get_step_number();\n     }\n```\n\n#### `Diffusion::run`\n\nThe following is the main function of the program. At the top, we create the grid (a \\([0,5]\\times [0,5]\\) square) and refine it four times to get a mesh that has 16 by 16 cells, for a total of 256. We then set the boundary indicator to 1 for those parts of the boundary where \\(x=0\\) and \\(x=5\\).\n\n```\n     void Diffusion::run()\n     {\n       GridGenerator::hyper_cube(triangulation, 0., 5.);\n       triangulation.refine_global(4);\n   \n       for (const auto &cell : triangulation.active_cell_iterators())\n         for (const auto &face : cell->face_iterators())\n           if (face->at_boundary())\n             {\n               if ((face->center()[0] == 0.) || (face->center()[0] == 5.))\n                 face->set_boundary_id(1);\n               else\n                 face->set_boundary_id(0);\n             }\n```\n\nNext, we set up the linear systems and fill them with content so that they can be used throughout the time stepping process:\n\n```\n       setup_system();\n   \n       assemble_system();\n```\n\nFinally, we solve the diffusion problem using several of the Runge-Kutta methods implemented in namespace [TimeStepping](namespaceTimeStepping.html), each time outputting the error at the end time. (As explained in the introduction, since the exact solution is zero at the final time, the error equals the numerical solution and can be computed by just taking the \\(l\\_2\\) norm of the solution vector.)\n\n```\n       unsigned int       n_steps      = 0;\n       const unsigned int n_time_steps = 200;\n       const double       initial_time = 0.;\n       const double       final_time   = 10.;\n   \n       std::cout << \"Explicit methods:\" << std::endl;\n       explicit_method(TimeStepping::FORWARD_EULER,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Forward Euler:            error=\" << solution.l2_norm()\n                 << std::endl;\n   \n       explicit_method(TimeStepping::RK_THIRD_ORDER,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Third order Runge-Kutta:  error=\" << solution.l2_norm()\n                 << std::endl;\n   \n       explicit_method(TimeStepping::RK_CLASSIC_FOURTH_ORDER,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Fourth order Runge-Kutta: error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << std::endl;\n   \n   \n       std::cout << \"Implicit methods:\" << std::endl;\n       implicit_method(TimeStepping::BACKWARD_EULER,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Backward Euler:           error=\" << solution.l2_norm()\n                 << std::endl;\n   \n       implicit_method(TimeStepping::IMPLICIT_MIDPOINT,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Implicit Midpoint:        error=\" << solution.l2_norm()\n                 << std::endl;\n   \n       implicit_method(TimeStepping::CRANK_NICOLSON,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   Crank-Nicolson:           error=\" << solution.l2_norm()\n                 << std::endl;\n   \n       implicit_method(TimeStepping::SDIRK_TWO_STAGES,\n                       n_time_steps,\n                       initial_time,\n                       final_time);\n       std::cout << \"   SDIRK:                    error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << std::endl;\n   \n   \n       std::cout << \"Embedded explicit methods:\" << std::endl;\n       n_steps = embedded_explicit_method(TimeStepping::HEUN_EULER,\n                                          n_time_steps,\n                                          initial_time,\n                                          final_time);\n       std::cout << \"   Heun-Euler:               error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << \"                   steps performed=\" << n_steps << std::endl;\n   \n       n_steps = embedded_explicit_method(TimeStepping::BOGACKI_SHAMPINE,\n                                          n_time_steps,\n                                          initial_time,\n                                          final_time);\n       std::cout << \"   Bogacki-Shampine:         error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << \"                   steps performed=\" << n_steps << std::endl;\n   \n       n_steps = embedded_explicit_method(TimeStepping::DOPRI,\n                                          n_time_steps,\n                                          initial_time,\n                                          final_time);\n       std::cout << \"   Dopri:                    error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << \"                   steps performed=\" << n_steps << std::endl;\n   \n       n_steps = embedded_explicit_method(TimeStepping::FEHLBERG,\n                                          n_time_steps,\n                                          initial_time,\n                                          final_time);\n       std::cout << \"   Fehlberg:                 error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << \"                   steps performed=\" << n_steps << std::endl;\n   \n       n_steps = embedded_explicit_method(TimeStepping::CASH_KARP,\n                                          n_time_steps,\n                                          initial_time,\n                                          final_time);\n       std::cout << \"   Cash-Karp:                error=\" << solution.l2_norm()\n                 << std::endl;\n       std::cout << \"                   steps performed=\" << n_steps << std::endl;\n     }\n   } // namespace Step52\n```\n\n### The `main()` function\n\nThe following `main` function is similar to previous examples and need not be commented on.\n\n```\n   int main()\n   {\n     try\n       {\n         Step52::Diffusion diffusion;\n         diffusion.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       };\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nThe point of this program is less to show particular results, but instead to show how it is done. This we have already demonstrated simply by discussing the code above. Consequently, the output the program yields is relatively sparse and consists only of the console output and the solutions given in VTU format for visualization.\n\nThe console output contains both errors and, for some of the methods, the number of steps they performed:\n\n```\nExplicit methods:\n   Forward Euler:            error=1.00883\n   Third order Runge-Kutta:  error=0.000227982\n   Fourth order Runge-Kutta: error=1.90541e-06\n \nImplicit methods:\n   Backward Euler:           error=1.03428\n   Implicit Midpoint:        error=0.00862702\n   Crank-Nicolson:           error=0.00862675\n   SDIRK:                    error=0.0042349\n \nEmbedded explicit methods:\n   Heun-Euler:               error=0.0073012\n                   steps performed=284\n   Bogacki-Shampine:         error=0.000408407\n                   steps performed=181\n   Dopri:                    error=0.000836695\n                   steps performed=120\n   Fehlberg:                 error=0.00248922\n                   steps performed=106\n   Cash-Karp:                error=0.0787735\n                   steps performed=106\n```\n\nAs expected the higher order methods give (much) more accurate solutions. We also see that the (rather inaccurate) Heun-Euler method increased the number of time steps in order to satisfy the tolerance. On the other hand, the other embedded methods used a lot less time steps than what was prescribed.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2014 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Damien Lebrun-Grandie, Bruno Turcksin, 2014\n */\n \n \n#include <deal.II/base/discrete_time.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/quadrature_lib.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_out.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_values.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/sparse_direct.h>\n \n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n \n#include <fstream>\n#include <iostream>\n#include <cmath>\n#include <map>\n \n#include <deal.II/base/time_stepping.h>\n \n \nnamespace Step52\n{\n using namespace dealii;\n \n \n class Diffusion\n  {\n public:\n    Diffusion();\n \n void run();\n \n private:\n void setup_system();\n \n void assemble_system();\n \n double get_source(const double time, const Point<2> &point) const;\n \n Vector<double> evaluate_diffusion(const double          time,\n const Vector<double> &y) const;\n \n Vector<double> id_minus_tau_J_inverse(const double          time,\n const double          tau,\n const Vector<double> &y);\n \n void output_results(const double                     time,\n const unsigned int               time_step,\n TimeStepping::runge_kutta_method method) const;\n \n void explicit_method(const TimeStepping::runge_kutta_method method,\n const unsigned int                     n_time_steps,\n const double                           initial_time,\n const double                           final_time);\n \n void implicit_method(const TimeStepping::runge_kutta_method method,\n const unsigned int                     n_time_steps,\n const double                           initial_time,\n const double                           final_time);\n \n unsigned int\n    embedded_explicit_method(const TimeStepping::runge_kutta_method method,\n const unsigned int n_time_steps,\n const double       initial_time,\n const double       final_time);\n \n \n const unsigned int fe_degree;\n \n const double diffusion_coefficient;\n const double absorption_cross_section;\n \n Triangulation<2> triangulation;\n \n const FE_Q<2> fe;\n \n DoFHandler<2> dof_handler;\n \n AffineConstraints<double> constraint_matrix;\n \n SparsityPattern sparsity_pattern;\n \n SparseMatrix<double> system_matrix;\n SparseMatrix<double> mass_matrix;\n SparseMatrix<double> mass_minus_tau_Jacobian;\n \n SparseDirectUMFPACK inverse_mass_matrix;\n \n Vector<double> solution;\n  };\n \n \n \n  Diffusion::Diffusion()\n    : fe_degree(2)\n    , diffusion_coefficient(1. / 30.)\n    , absorption_cross_section(1.)\n    , fe(fe_degree)\n    , dof_handler(triangulation)\n  {}\n \n \n \n void Diffusion::setup_system()\n  {\n    dof_handler.distribute_dofs(fe);\n \n VectorTools::interpolate_boundary_values(dof_handler,\n                                             1,\n Functions::ZeroFunction<2>(),\n                                             constraint_matrix);\n    constraint_matrix.close();\n \n DynamicSparsityPattern dsp(dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraint_matrix);\n    sparsity_pattern.copy_from(dsp);\n \n    system_matrix.reinit(sparsity_pattern);\n mass_matrix.reinit(sparsity_pattern);\n    mass_minus_tau_Jacobian.reinit(sparsity_pattern);\n    solution.reinit(dof_handler.n_dofs());\n  }\n \n \n \n void Diffusion::assemble_system()\n  {\n    system_matrix = 0.;\n mass_matrix   = 0.;\n \n const QGauss<2> quadrature_formula(fe_degree + 1);\n \n FEValues<2> fe_values(fe,\n                          quadrature_formula,\n update_values | update_gradients | update_JxW_values);\n \n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n FullMatrix<double> cell_mass_matrix(dofs_per_cell, dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n cell_matrix      = 0.;\n        cell_mass_matrix = 0.;\n \n        fe_values.reinit(cell);\n \n for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n              {\n cell_matrix(i, j) +=\n                  ((-diffusion_coefficient *                // (-D\n                      fe_values.shape_grad(i, q_point) *    //  * grad phi_i\n                      fe_values.shape_grad(j, q_point)      //  * grad phi_j\n                    - absorption_cross_section *            //  -Sigma\n                        fe_values.shape_value(i, q_point) * //  * phi_i\n                        fe_values.shape_value(j, q_point))  //  * phi_j)\n                   * fe_values.JxW(q_point));               // * dx\n                cell_mass_matrix(i, j) += fe_values.shape_value(i, q_point) *\n                                          fe_values.shape_value(j, q_point) *\n                                          fe_values.JxW(q_point);\n              }\n \n        cell->get_dof_indices(local_dof_indices);\n \n        constraint_matrix.distribute_local_to_global(cell_matrix,\n                                                     local_dof_indices,\n                                                     system_matrix);\n        constraint_matrix.distribute_local_to_global(cell_mass_matrix,\n                                                     local_dof_indices,\n                                                     mass_matrix);\n      }\n \n    inverse_mass_matrix.initialize(mass_matrix);\n  }\n \n \n \n double Diffusion::get_source(const double time, const Point<2> &point) const\n {\n const double intensity = 10.;\n const double frequency = numbers::PI / 10.;\n const double b         = 5.;\n const double x         = point[0];\n \n return intensity *\n           (frequency * std::cos(frequency * time) * (b * x - x * x) +\n std::sin(frequency * time) *\n              (absorption_cross_section * (b * x - x * x) +\n               2. * diffusion_coefficient));\n  }\n \n \n \n Vector<double> Diffusion::evaluate_diffusion(const double          time,\n const Vector<double> &y) const\n {\n Vector<double> tmp(dof_handler.n_dofs());\n    tmp = 0.;\n    system_matrix.vmult(tmp, y);\n \n const QGauss<2> quadrature_formula(fe_degree + 1);\n \n FEValues<2> fe_values(fe,\n                          quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values);\n \n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n Vector<double> cell_source(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        cell_source = 0.;\n \n        fe_values.reinit(cell);\n \n for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n          {\n const double source =\n              get_source(time, fe_values.quadrature_point(q_point));\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              cell_source(i) += fe_values.shape_value(i, q_point) * // phi_i(x)\n                                source *                            // * S(x)\n                                fe_values.JxW(q_point);             // * dx\n          }\n \n        cell->get_dof_indices(local_dof_indices);\n \n        constraint_matrix.distribute_local_to_global(cell_source,\n                                                     local_dof_indices,\n                                                     tmp);\n      }\n \n Vector<double> value(dof_handler.n_dofs());\n    inverse_mass_matrix.vmult(value, tmp);\n \n return value;\n  }\n \n \n Vector<double> Diffusion::id_minus_tau_J_inverse(const double /*time*/,\n const double          tau,\n const Vector<double> &y)\n  {\n SparseDirectUMFPACK inverse_mass_minus_tau_Jacobian;\n \n    mass_minus_tau_Jacobian.copy_from(mass_matrix);\n    mass_minus_tau_Jacobian.add(-tau, system_matrix);\n \n    inverse_mass_minus_tau_Jacobian.initialize(mass_minus_tau_Jacobian);\n \n Vector<double> tmp(dof_handler.n_dofs());\n mass_matrix.vmult(tmp, y);\n \n Vector<double> result(y);\n    inverse_mass_minus_tau_Jacobian.vmult(result, tmp);\n \n return result;\n  }\n \n \n \n void Diffusion::output_results(const double                     time,\n const unsigned int               time_step,\n TimeStepping::runge_kutta_method method) const\n {\n    std::string method_name;\n \n switch (method)\n      {\n case TimeStepping::FORWARD_EULER:\n          {\n            method_name = \"forward_euler\";\n break;\n          }\n case TimeStepping::RK_THIRD_ORDER:\n          {\n            method_name = \"rk3\";\n break;\n          }\n case TimeStepping::RK_CLASSIC_FOURTH_ORDER:\n          {\n            method_name = \"rk4\";\n break;\n          }\n case TimeStepping::BACKWARD_EULER:\n          {\n            method_name = \"backward_euler\";\n break;\n          }\n case TimeStepping::IMPLICIT_MIDPOINT:\n          {\n            method_name = \"implicit_midpoint\";\n break;\n          }\n case TimeStepping::SDIRK_TWO_STAGES:\n          {\n            method_name = \"sdirk\";\n break;\n          }\n case TimeStepping::HEUN_EULER:\n          {\n            method_name = \"heun_euler\";\n break;\n          }\n case TimeStepping::BOGACKI_SHAMPINE:\n          {\n            method_name = \"bogacki_shampine\";\n break;\n          }\n case TimeStepping::DOPRI:\n          {\n            method_name = \"dopri\";\n break;\n          }\n case TimeStepping::FEHLBERG:\n          {\n            method_name = \"fehlberg\";\n break;\n          }\n case TimeStepping::CASH_KARP:\n          {\n            method_name = \"cash_karp\";\n break;\n          }\n default:\n          {\n break;\n          }\n      }\n \n DataOut<2> data_out;\n \n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(solution, \"solution\");\n \n    data_out.build_patches();\n \n    data_out.set_flags(DataOutBase::VtkFlags(time, time_step));\n \n const std::string filename = \"solution_\" + method_name + \"-\" +\n Utilities::int_to_string(time_step, 3) +\n \".vtu\";\n    std::ofstream output(filename);\n    data_out.write_vtu(output);\n \n static std::vector<std::pair<double, std::string>> times_and_names;\n \n static std::string method_name_prev = \"\";\n static std::string pvd_filename;\n if (method_name_prev != method_name)\n      {\n        times_and_names.clear();\n        method_name_prev = method_name;\n        pvd_filename     = \"solution_\" + method_name + \".pvd\";\n      }\n    times_and_names.emplace_back(time, filename);\n    std::ofstream pvd_output(pvd_filename);\n DataOutBase::write_pvd_record(pvd_output, times_and_names);\n  }\n \n \n void Diffusion::explicit_method(const TimeStepping::runge_kutta_method method,\n const unsigned int n_time_steps,\n const double       initial_time,\n const double       final_time)\n  {\n const double time_step =\n      (final_time - initial_time) / static_cast<double>(n_time_steps);\n \n    solution = 0.;\n    constraint_matrix.distribute(solution);\n \n TimeStepping::ExplicitRungeKutta<Vector<double>> explicit_runge_kutta(\n      method);\n    output_results(initial_time, 0, method);\n DiscreteTime time(initial_time, final_time, time_step);\n while (time.is_at_end() == false)\n      {\n        explicit_runge_kutta.evolve_one_time_step(\n          [this](const double time, const Vector<double> &y) {\n return this->evaluate_diffusion(time, y);\n          },\n          time.get_current_time(),\n          time.get_next_step_size(),\n          solution);\n        time.advance_time();\n \n        constraint_matrix.distribute(solution);\n \n if (time.get_step_number() % 10 == 0)\n          output_results(time.get_current_time(),\n                         time.get_step_number(),\n                         method);\n      }\n  }\n \n \n \n void Diffusion::implicit_method(const TimeStepping::runge_kutta_method method,\n const unsigned int n_time_steps,\n const double       initial_time,\n const double       final_time)\n  {\n const double time_step =\n      (final_time - initial_time) / static_cast<double>(n_time_steps);\n \n    solution = 0.;\n    constraint_matrix.distribute(solution);\n \n TimeStepping::ImplicitRungeKutta<Vector<double>> implicit_runge_kutta(\n      method);\n    output_results(initial_time, 0, method);\n DiscreteTime time(initial_time, final_time, time_step);\n while (time.is_at_end() == false)\n      {\n        implicit_runge_kutta.evolve_one_time_step(\n          [this](const double time, const Vector<double> &y) {\n return this->evaluate_diffusion(time, y);\n          },\n          [this](const double time, const double tau, const Vector<double> &y) {\n return this->id_minus_tau_J_inverse(time, tau, y);\n          },\n          time.get_current_time(),\n          time.get_next_step_size(),\n          solution);\n        time.advance_time();\n \n        constraint_matrix.distribute(solution);\n \n if (time.get_step_number() % 10 == 0)\n          output_results(time.get_current_time(),\n                         time.get_step_number(),\n                         method);\n      }\n  }\n \n \n \n unsigned int Diffusion::embedded_explicit_method(\n const TimeStepping::runge_kutta_method method,\n const unsigned int                     n_time_steps,\n const double                           initial_time,\n const double                           final_time)\n  {\n const double time_step =\n      (final_time - initial_time) / static_cast<double>(n_time_steps);\n const double coarsen_param = 1.2;\n const double refine_param  = 0.8;\n const double min_delta     = 1e-8;\n const double max_delta     = 10 * time_step;\n const double refine_tol    = 1e-1;\n const double coarsen_tol   = 1e-5;\n \n    solution = 0.;\n    constraint_matrix.distribute(solution);\n \n TimeStepping::EmbeddedExplicitRungeKutta<Vector<double>>\n      embedded_explicit_runge_kutta(method,\n                                    coarsen_param,\n                                    refine_param,\n                                    min_delta,\n                                    max_delta,\n                                    refine_tol,\n                                    coarsen_tol);\n    output_results(initial_time, 0, method);\n DiscreteTime time(initial_time, final_time, time_step);\n while (time.is_at_end() == false)\n      {\n const double new_time =\n          embedded_explicit_runge_kutta.evolve_one_time_step(\n            [this](const double time, const Vector<double> &y) {\n return this->evaluate_diffusion(time, y);\n            },\n            time.get_current_time(),\n            time.get_next_step_size(),\n            solution);\n        time.set_next_step_size(new_time - time.get_current_time());\n        time.advance_time();\n \n        constraint_matrix.distribute(solution);\n \n if (time.get_step_number() % 10 == 0)\n          output_results(time.get_current_time(),\n                         time.get_step_number(),\n                         method);\n \n        time.set_desired_next_step_size(\n          embedded_explicit_runge_kutta.get_status().delta_t_guess);\n      }\n \n return time.get_step_number();\n  }\n \n \n \n void Diffusion::run()\n  {\n GridGenerator::hyper_cube(triangulation, 0., 5.);\n triangulation.refine_global(4);\n \n for (const auto &cell : triangulation.active_cell_iterators())\n      for (const auto &face : cell->face_iterators())\n        if (face->at_boundary())\n          {\n if ((face->center()[0] == 0.) || (face->center()[0] == 5.))\n              face->set_boundary_id(1);\n else\n              face->set_boundary_id(0);\n          }\n \n    setup_system();\n \n    assemble_system();\n \n unsigned int       n_steps      = 0;\n const unsigned int n_time_steps = 200;\n const double       initial_time = 0.;\n const double       final_time   = 10.;\n \n    std::cout << \"Explicit methods:\" << std::endl;\n    explicit_method(TimeStepping::FORWARD_EULER,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Forward Euler:            error=\" << solution.l2_norm()\n              << std::endl;\n \n    explicit_method(TimeStepping::RK_THIRD_ORDER,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Third order Runge-Kutta:  error=\" << solution.l2_norm()\n              << std::endl;\n \n    explicit_method(TimeStepping::RK_CLASSIC_FOURTH_ORDER,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Fourth order Runge-Kutta: error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << std::endl;\n \n \n    std::cout << \"Implicit methods:\" << std::endl;\n    implicit_method(TimeStepping::BACKWARD_EULER,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Backward Euler:           error=\" << solution.l2_norm()\n              << std::endl;\n \n    implicit_method(TimeStepping::IMPLICIT_MIDPOINT,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Implicit Midpoint:        error=\" << solution.l2_norm()\n              << std::endl;\n \n    implicit_method(TimeStepping::CRANK_NICOLSON,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   Crank-Nicolson:           error=\" << solution.l2_norm()\n              << std::endl;\n \n    implicit_method(TimeStepping::SDIRK_TWO_STAGES,\n                    n_time_steps,\n                    initial_time,\n                    final_time);\n    std::cout << \"   SDIRK:                    error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << std::endl;\n \n \n    std::cout << \"Embedded explicit methods:\" << std::endl;\n    n_steps = embedded_explicit_method(TimeStepping::HEUN_EULER,\n                                       n_time_steps,\n                                       initial_time,\n                                       final_time);\n    std::cout << \"   Heun-Euler:               error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << \"                   steps performed=\" << n_steps << std::endl;\n \n    n_steps = embedded_explicit_method(TimeStepping::BOGACKI_SHAMPINE,\n                                       n_time_steps,\n                                       initial_time,\n                                       final_time);\n    std::cout << \"   Bogacki-Shampine:         error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << \"                   steps performed=\" << n_steps << std::endl;\n \n    n_steps = embedded_explicit_method(TimeStepping::DOPRI,\n                                       n_time_steps,\n                                       initial_time,\n                                       final_time);\n    std::cout << \"   Dopri:                    error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << \"                   steps performed=\" << n_steps << std::endl;\n \n    n_steps = embedded_explicit_method(TimeStepping::FEHLBERG,\n                                       n_time_steps,\n                                       initial_time,\n                                       final_time);\n    std::cout << \"   Fehlberg:                 error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << \"                   steps performed=\" << n_steps << std::endl;\n \n    n_steps = embedded_explicit_method(TimeStepping::CASH_KARP,\n                                       n_time_steps,\n                                       initial_time,\n                                       final_time);\n    std::cout << \"   Cash-Karp:                error=\" << solution.l2_norm()\n              << std::endl;\n    std::cout << \"                   steps performed=\" << n_steps << std::endl;\n  }\n} // namespace Step52\n \n \n \nint main()\n{\n try\n    {\n      Step52::Diffusion diffusion;\n      diffusion.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    };\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_53.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nDescribing the geometry of complex domains and curved boundaries.\nTutorial content :\nThis tutorial depends on [step-49](step_49.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_53-Intro)    * [Where geometry and meshes intersect](#step_53-Wheregeometryandmeshesintersect)* [The example case](#step_53-Theexamplecase)* [Implementation](#step_53-Implementation)- [The commented program](#step_53-CommProg)      * [Describing topography: AfricaTopography](#step_53-DescribingtopographyAfricaTopography)* [Describing the geometry: AfricaGeometry](#step_53-DescribingthegeometryAfricaGeometry)* [Creating the mesh](#step_53-Creatingthemesh)* [The main function](#step_53-Themainfunction) | 1. [Results](#step_53-Results)    * [Issues with adaptively refined meshes generated this way](#step_53-Issueswithadaptivelyrefinedmeshesgeneratedthisway)- [The plain program](#step_53-PlainProg) |\n\n*This program was contributed by Wolfgang Bangerth and Luca Heltai, using data provided by D. Sarah Stamps.*\n\nNote\n:   This program elaborates on concepts of geometry and the classes that implement it. These classes are grouped into the documentation topic on [Manifold description for triangulations](group__manifold.html). See there for additional information.\n:   This tutorial is also available as a Jupyter Python notebook that uses the deal.II python interface. The notebook is available in the same directory as the original C++ program. Rendered notebook can also be viewed on the [github](https://github.com/dealii/dealii/blob/master/examples/step-53/step-53.ipynb).\n\nIntroduction\n============\n\nPartial differential equations for realistic problems are often posed on domains with complicated geometries. To provide just a few examples, consider these cases:\n\n* Among the two arguably most important industrial applications for the finite element method, aerodynamics and more generally fluid dynamics is one. Computer simulations today are used in the design of every airplane, car, train and ship. The domain in which the partial differential equation is posed is, in these cases, the air surrounding the plane with its wings, flaps and engines; the air surrounding the car with its wheel, wheel wells, mirrors and, in the case of race cars, all sorts of aerodynamic equipment; the air surrounding the train with its wheels and gaps between cars. In the case of ships, the domain is the water surrounding the ship with its rudders and propellers.\n* The other of the two big applications of the finite element method is structural engineering in which the domains are bridges, airplane nacelles and wings, and other solid bodies of often complicated shapes.\n* Finite element modeling is also often used to describe the generation and propagation of earthquake waves. In these cases, one needs to accurately represent the geometry of faults in the Earth crust. Since faults intersect, dip at angles, and are often not completely straight, domains are frequently very complex. One could cite many more examples of complicated geometries in which one wants to pose and solve a partial differential equation. What this shows is that the \"real\" world is much more complicated than what we have shown in almost all of the tutorial programs preceding this one.\n\nThis program is therefore devoted to showing how one deals with complex geometries using a concrete application. In particular, what it shows is how we make a mesh fit the domain we want to solve on. On the other hand, what the program does not show is how to create a coarse mesh for a domain. The process to arrive at a coarse mesh is called \"mesh generation\" and there are a number of high-quality programs that do this much better than we could ever implement. However, deal.II does have the ability to read in meshes in many formats generated by mesh generators and then make them fit a given shape, either by deforming a mesh or refining it a number of times until it fits. The deal.II Frequently Asked Questions page referenced from <http://www.dealii.org/> provides resources to mesh generators.\n\n### Where geometry and meshes intersect\n\nLet us assume that you have a complex domain and that you already have a coarse mesh that somehow represents the general features of the domain. Then there are two situations in which it is necessary to describe to a deal.II program the details of your geometry:\n\n* Mesh refinement: Whenever a cell is refined, it is necessary to introduce new vertices in the [Triangulation](classTriangulation.html). In the simplest case, one assumes that the objects that make up the [Triangulation](classTriangulation.html) are straight line segments, a bi-linear surface or a tri-linear volume. The next vertex is then simply put into the middle of the old ones. However, for curved boundaries or if we want to solve a PDE on a curved, lower-dimensional manifold embedded in a higher-dimensional space, this is insufficient since it will not respect the actual geometry. We will therefore have to tell [Triangulation](classTriangulation.html) where to put new points.\n* Integration: When using higher order finite element methods, it is often necessary to compute integrals using curved approximations of the boundary, i.e., describe each edge or face of cells as curves, instead of straight line segments or bilinear patches. The same is, of course, true when integrating boundary terms (e.g., inhomogeneous Neumann boundary conditions). For the purpose of integration, the various [Mapping](classMapping.html \"Abstract base class for mapping classes.\") classes then provide the transformation from the reference cell to the actual cell.\n\nIn both cases, we need a way to provide information about the geometry of the domain at the level of an individual cell, its faces and edges. This is where the [Manifold](classManifold.html) class comes into play. [Manifold](classManifold.html) is an abstract base class that only defines an interface by which the [Triangulation](classTriangulation.html) and [Mapping](classMapping.html \"Abstract base class for mapping classes.\") classes can query geometric information about the domain. Conceptually, [Manifold](classManifold.html) sees the world in a way not dissimilar to how the mathematical subdiscipline geometry sees it: a domain is essentially just a collection of points that is somehow equipped with the notion of a distance between points so that we can obtain a point \"in the middle\" of some other points.\n\ndeal.II provides a number of classes that implement the interface provided by [Manifold](classManifold.html) for a variety of common geometries. On the other hand, in this program we will consider only a very common and much simpler case, namely the situation where (a part of) the domain we want to solve on can be described by transforming a much simpler domain (we will call this the \"reference domain\"). In the language of mathematics, this means that the (part of the) domain is a [chart](http://en.wikipedia.org/wiki/Chart_%28topology%29). Charts are described by a smooth function that maps from the simpler domain to the chart (the \"push-forward\" function) and its inverse (the \"pull-back\" function). If the domain as a whole is not a chart (e.g., the surface of a sphere), then it can often be described as a collection of charts (e.g., the northern hemisphere and the southern hemisphere are each charts) and the domain can then be describe by an [atlas](http://en.wikipedia.org/wiki/Atlas_%28topology%29).\n\nIf a domain can be decomposed into an atlas, all we need to do is provide the pull-back and push-forward functions for each of the charts. In deal.II, this means providing a class derived from [ChartManifold](classChartManifold.html), and this is precisely what we will do in this program.\n\n### The example case\n\nTo illustrate how one describes geometries using charts in deal.II, we will consider a case that originates in an application of the [ASPECT mantle convection code](https://aspect.geodynamics.org), using a data set provided by D. Sarah Stamps. In the concrete application, we were interested in describing flow in the Earth mantle under the [East African Rift](http://en.wikipedia.org/wiki/East_African_rift), a zone where two continental plates drift apart. Not to beat around the bush, the geometry we want to describe looks like this:\n\n![](images/steps/developer/step-53.topo.png)\n\nIn particular, though you cannot see this here, the top surface is not just colored by the elevation but is, in fact, deformed to follow the correct topography. While the actual application is not relevant here, the geometry is. The domain we are interested in is a part of the Earth that ranges from the surface to a depth of 500km, from 26 to 35 degrees East of the Greenwich meridian, and from 5 degrees North of the equator to 10 degrees South.\n\nThis description of the geometry suggests to start with a box \\(\\hat U=[26,35]\\times[-10,5]\\times[-500000,0]\\) (measured in degrees, degrees, and meters) and to provide a map \\(\\varphi\\) so that \\(\\varphi^{-1}(\\hat U)=\\Omega\\) where \\(\\Omega\\) is the domain we seek. \\((\\Omega,\\varphi)\\) is then a chart, \\(\\varphi\\) the pull-back operator, and \\(\\varphi^{-1}\\) the push-forward operator. If we need a point \\(q\\) that is the \"average\" of other points \\(q\\_i\\in\\Omega\\), the [ChartManifold](classChartManifold.html) class then first applies the pull-back to obtain \\(\\hat q\\_i=\\varphi(q\\_i)\\), averages these to a point \\(\\hat p\\) and then computes \\(p=\\varphi^{-1}(\\hat p)\\).\n\nOur goal here is therefore to implement a class that describes \\(\\varphi\\) and \\(\\varphi^{-1}\\). If Earth was a sphere, then this would not be difficult: if we denote by \\((\\hat \\phi,\\hat \\theta,\\hat d)\\) the points of \\(\\hat U\\) (i.e., longitude counted eastward, latitude counted northward, and elevation relative to zero depth), then\n\n\\[\n\\mathbf x = \\varphi^{-1}(\\hat \\phi,\\hat \\theta,\\hat d)\n= (R+\\hat d) (\\cos\\hat \\phi\\cos\\hat \\theta, \\sin\\hat \\phi\\cos\\hat \\theta, \\sin\\hat \\theta)^T\n\\]\n\nprovides coordinates in a Cartesian coordinate system, where \\(R\\) is the radius of the sphere. However, the Earth is not a sphere:\n\n1. It is flattened at the poles and larger at the equator: the semi-major axis is approximately 22km longer than the semi-minor axis. We will account for this using the [WGS 84](http://en.wikipedia.org/wiki/WGS84) reference standard for the Earth shape. The formula used in WGS 84 to obtain a position in Cartesian coordinates from longitude, latitude, and elevation is\n\n   \\[\n   \\mathbf x = \\varphi\\_\\text{WGS84}^{-1}(\\phi,\\theta,d)\n   = \\left(\n   \\begin{array}{c}\n   (\\bar R(\\theta)+d) \\cos\\phi\\cos\\theta, \\\\\n   (\\bar R(\\theta)+d) \\sin\\phi\\cos\\theta, \\\\\n   ((1-e^2)\\bar R(\\theta)+d) \\sin\\theta\n   \\end{array}\n   \\right),\n   \\]\n\n   where \\(\\bar R(\\theta)=\\frac{R}{\\sqrt{1-(e \\sin\\theta)^2}}\\), and radius and ellipticity are given by \\(R=6378137\\text{m}, e=0.081819190842622\\). In this formula, we assume that the arguments to sines and cosines are evaluated in degree, not radians (though we will have to change this assumption in the code).\n2. It has topography in the form of mountains and valleys. We will account for this using real topography data (see below for a description of where this data comes from). Using this data set, we can look up elevations on a latitude-longitude mesh laid over the surface of the Earth. Starting with the box \\(\\hat U=[26,35]\\times[-10,5]\\times[-500000,0]\\), we will therefore first stretch it in vertical direction before handing it off to the WGS 84 function: if \\(h(\\hat\\phi,\\hat\\theta)\\) is the height at longitude \\(\\hat\\phi\\) and latitude \\(\\hat\\theta\\), then we define\n\n   \\[\n   (\\phi,\\theta,d) =\n   \\varphi\\_\\text{topo}^{-1}(\\hat\\phi,\\hat\\theta,\\hat d)\n   = \\left(\n   \\hat\\phi,\n   \\hat\\theta,\n   \\hat d + \\frac{\\hat d+500000}{500000}h(\\hat\\phi,\\hat\\theta)\n   \\right).\n   \\]\n\n   Using this function, the top surface of the box \\(\\hat U\\) is displaced to the correct topography, the bottom surface remains where it was, and points in between are linearly interpolated.\n\nUsing these two functions, we can then define the entire push-forward function \\(\\varphi^{-1}: \\hat U \\rightarrow \\Omega\\) as\n\n\\[\n\\mathbf x\n=\n\\varphi^{-1}(\\hat\\phi,\\hat\\theta,\\hat d)\n=\n\\varphi\\_\\text{WGS84}^{-1}(\\varphi\\_\\text{topo}^{-1}(\\hat\\phi,\\hat\\theta,\\hat d)).\n\\]\n\nIn addition, we will have to define the inverse of this function, the pull-back operation, which we can write as\n\n\\[\n(\\hat\\phi,\\hat\\theta,\\hat d)\n=\n\\varphi(\\mathbf x)\n=\n\\varphi\\_\\text{topo}(\\varphi\\_\\text{WGS84}(\\mathbf x)).\n\\]\n\nWe can obtain one of the components of this function by inverting the formula above:\n\n\\[\n(\\hat\\phi,\\hat\\theta,\\hat d) =\n\\varphi\\_\\text{topo}(\\phi,\\theta,d)\n= \\left(\n\\phi,\n\\theta,\n500000\\frac{d-h(\\phi,\\theta)}{500000+h(\\phi,\\theta)}\n\\right).\n\\]\n\nComputing \\(\\varphi\\_\\text{WGS84}(\\mathbf x)\\) is also possible though a lot more awkward. We won't show the formula here but instead only provide the implementation in the program.\n\n### Implementation\n\nThere are a number of issues we need to address in the program. At the largest scale, we need to write a class that implements the interface of [ChartManifold](classChartManifold.html). This involves a function `push_forward()` that takes a point in the reference domain \\(\\hat U\\) and transform it into real space using the function \\(\\varphi^{-1}\\) outlined above, and its inverse function `pull_back()` implementing \\(\\varphi\\). We will do so in the `AfricaGeometry` class below that looks, in essence, like this:\n\n```\nclass AfricaGeometry : public ChartManifold<3,3>\n{\npublic:\n virtual\n Point<3>\n pull_back(const Point<3> &space_point) const;\n \n virtual\n Point<3>\n push_forward(const Point<3> &chart_point) const;\n \nprivate:\n  ... some member variables and other member functions...;\n};\n```\n\nThe transformations above have two parts: the WGS 84 transformations and the topography transformation. Consequently, the `AfricaGeometry` class will have additional (non-virtual) member functions `AfricaGeometry::push_forward_wgs84()` and `AfricaGeometry::push_forward_topo()` that implement these two pieces, and corresponding pull back functions.\n\nThe WGS 84 transformation functions are not particularly interesting (even though the formulas they implement are impressive). The more interesting part is the topography transformation. Recall that for this, we needed to evaluate the elevation function \\(h(\\hat\\phi,\\hat\\theta)\\). There is of course no formula for this: Earth is what it is, the best one can do is look up the altitude from some table. This is, in fact what we will do.\n\nThe data we use was originally created by the [Shuttle Radar Topography Mission](http://en.wikipedia.org/wiki/Shuttle_Radar_Topography_Mission), was downloaded from the US Geologic Survey (USGS) and processed by D. Sarah Stamps who also wrote the initial version of the WGS 84 transformation functions. The topography data so processed is stored in a file `topography.txt.gz` that, when unpacked looks like this:\n\n```\n6.983333 25.000000 700\n6.983333 25.016667 692\n6.983333 25.033333 701\n6.983333 25.050000 695\n6.983333 25.066667 710\n6.983333 25.083333 702\n...\n-11.983333 35.950000 707\n-11.983333 35.966667 687\n-11.983333 35.983333 659\n```\n\nThe data is formatted as `latitude longitude elevation` where the first two columns are provided in degrees North of the equator and degrees East of the Greenwich meridian. The final column is given in meters above the WGS 84 zero elevation.\n\nIn the transformation functions, we need to evaluate \\(h(\\hat\\phi,\\hat\\theta)\\) for a given longitude \\(\\hat\\phi\\) and latitude \\(\\hat\\theta\\). In general, this data point will not be available and we will have to interpolate between adjacent data points. Writing such an interpolation routine is not particularly difficult, but it is a bit tedious and error prone. Fortunately, we can somehow shoehorn this data set into an existing class: [Functions::InterpolatedUniformGridData](classFunctions_1_1InterpolatedUniformGridData.html) . Unfortunately, the class does not fit the bill quite exactly and so we need to work around it a bit. The problem comes from the way we initialize this class: in its simplest form, it takes a stream of values that it assumes form an equispaced mesh in the \\(x-y\\) plane (or, here, the \\(\\phi-\\theta\\) plane). Which is what they do here, sort of: they are ordered latitude first, longitude second; and more awkwardly, the first column starts at the largest values and counts down, rather than the usual other way around.\n\nNow, while tutorial programs are meant to illustrate how to code with deal.II, they do not necessarily have to satisfy the same quality standards as one would have to do with production codes. In a production code, we would write a function that reads the data and (i) automatically determines the extents of the first and second column, (ii) automatically determines the number of data points in each direction, (iii) does the interpolation regardless of the order in which data is arranged, if necessary by switching the order between reading and presenting it to the [Functions::InterpolatedUniformGridData](classFunctions_1_1InterpolatedUniformGridData.html) class.\n\nOn the other hand, tutorial programs are best if they are short and demonstrate key points rather than dwell on unimportant aspects and, thereby, obscure what we really want to show. Consequently, we will allow ourselves a bit of leeway:\n\n* since this program is intended solely for a particular geometry around the area of the East-African rift and since this is precisely the area described by the data file, we will hardcode in the program that there are \\(1139\\times 660\\) pieces of data;\n* we will hardcode the boundaries of the data \\([-11.98333^\\circ,6.983333^\\circ]\\times[25^\\circ,35.98333^\\circ]\\);\n* we will lie to the [Functions::InterpolatedUniformGridData](classFunctions_1_1InterpolatedUniformGridData.html) class: the class will only see the data in the last column of this data file, and we will pretend that the data is arranged in a way that there are 1139 data points in the first coordinate direction that are arranged in *ascending* order but in an interval \\([-6.983333^\\circ,11.98333^\\circ]\\) (not the negated bounds). Then, when we need to look something up for a latitude \\(\\hat\\theta\\), we can ask the interpolating table class for a value at \\(-\\hat\\theta\\). With this little trick, we can avoid having to switch around the order of data as read from file.\n\nAll of this then calls for a class that essentially looks like this:\n\n```\nclass AfricaTopography\n{\npublic:\n  AfricaTopography ()\n    :\n    topography_data (...initialize somehow...)\n  {}\n \n double value (const double lon, const double lat) const\n {\n return topography_data.value (Point<2>(-lat * 180/numbers::PI,\n                                           lon * 180/numbers::PI));\n  }\n \nprivate:\n const Functions::InterpolatedUniformGridData<2> topography_data;\n};\n```\n\nNote how the `value()` function negates the latitude. It also switches from the format \\(\\phi,\\theta\\) that we use everywhere else to the latitude-longitude format used in the table. Finally, it takes its arguments in radians as that is what we do everywhere else in the program, but then converts them to the degree-based system used for table lookup. As you will see in the implementation below, the function has a few more (static) member functions that we will call in the initialization of the `topography_data` member variable: the class type of this variable has a constructor that allows us to set everything right at construction time, rather than having to fill data later on, but this constructor takes a number of objects that can't be constructed in-place (at least not in C++98). Consequently, the construction of each of the objects we want to pass in the initialization happens in a number of static member functions.\n\nHaving discussed the general outline of how we want to implement things, let us go to the program and show how it is done in practice.\n\nThe commented program\n=====================\n\nLet us start with the include files we need here. Obviously, we need the ones that describe the triangulation (`tria.h`), and that allow us to create and output triangulations (`grid_generator.h` and `grid_out.h`). Furthermore, we need the header file that declares the [Manifold](classManifold.html) and [ChartManifold](classChartManifold.html) classes that we will need to describe the geometry (`manifold.h`). We will then also need the [GridTools::transform()](namespaceGridTools.html#a212e99cf0d923cebfa04f1d23fa60b04) function from the last of the following header files; the purpose for this function will become discussed at the point where we use it.\n\n```\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_out.h>\n   #include <deal.II/grid/manifold.h>\n   #include <deal.II/grid/grid_tools.h>\n```\n\nThe remainder of the include files relate to reading the topography data. As explained in the introduction, we will read it from a file and then use the [Functions::InterpolatedUniformGridData](classFunctions_1_1InterpolatedUniformGridData.html) class that is declared in the first of the following header files. Because the data is large, the file we read from is stored as gzip compressed data and we make use of some BOOST-provided functionality to read directly from gzipped data.\n\n```\n   #include <deal.II/base/function_lib.h>\n   \n   #include <boost/iostreams/filtering_stream.hpp>\n   #include <boost/iostreams/filter/gzip.hpp>\n   #include <boost/iostreams/device/file.hpp>\n   \n   #include <fstream>\n   #include <iostream>\n   #include <memory>\n```\n\nThe final part of the top matter is to open a namespace into which to put everything, and then to import the dealii namespace into it.\n\n```\n   namespace Step53\n   {\n     using namespace dealii;\n```\n\n### Describing topography: AfricaTopography\n\nThe first significant part of this program is the class that describes the topography \\(h(\\hat phi,\\hat \\theta)\\) as a function of longitude and latitude. As discussed in the introduction, we will make our life a bit easier here by not writing the class in the most general way possible but by only writing it for the particular purpose we are interested in here: interpolating data obtained from one very specific data file that contains information about a particular area of the world for which we know the extents.\n\nThe general layout of the class has been discussed already above. Following is its declaration, including three static member functions that we will need in initializing the `topography_data` member variable.\n\n```\n     class AfricaTopography\n     {\n     public:\n       AfricaTopography();\n   \n       double value(const double lon, const double lat) const;\n   \n     private:\n       const Functions::InterpolatedUniformGridData<2> topography_data;\n   \n       static std::vector<double> get_data();\n     };\n```\n\nLet us move to the implementation of the class. The interesting parts of the class are the constructor and the `value()` function. The former initializes the [Functions::InterpolatedUniformGridData](classFunctions_1_1InterpolatedUniformGridData.html) member variable and we will use the constructor that requires us to pass in the end points of the 2-dimensional data set we want to interpolate (which are here given by the intervals \\([-6.983333, 11.98333]\\), using the trick of switching end points discussed in the introduction, and \\([25, 35.983333]\\), both given in degrees), the number of intervals into which the data is split (379 in latitude direction and 219 in longitude direction, for a total of \\(380\\times 220\\) data points), and a [Table](classTable.html) object that contains the data. The data then of course has size \\(380\\times 220\\) and we initialize it by providing an iterator to the first of the 83,600 elements of a std::vector object returned by the `get_data()` function below. Note that all of the member functions we call here are static because (i) they do not access any member variables of the class, and (ii) because they are called at a time when the object is not initialized fully anyway.\n\n```\n     AfricaTopography::AfricaTopography()\n       : topography_data({{std::make_pair(-6.983333, 11.966667),\n                           std::make_pair(25, 35.95)}},\n                         {{379, 219}},\n                         Table<2, double>(380, 220, get_data().begin()))\n     {}\n   \n   \n     double AfricaTopography::value(const double lon, const double lat) const\n     {\n       return topography_data.value(\n         Point<2>(-lat * 180 / numbers::PI, lon * 180 / numbers::PI));\n     }\n```\n\nThe only other function of greater interest is the `get_data()` function. It returns a temporary vector that contains all 83,600 data points describing the altitude and is read from the file `topography.txt.gz`. Because the file is compressed by gzip, we cannot just read it through an object of type std::ifstream, but there are convenient methods in the BOOST library (see <http://www.boost.org>) that allows us to read from compressed files without first having to uncompress it on disk. The result is, basically, just another input stream that, for all practical purposes, looks just like the ones we always use.\n\nWhen reading the data, we read the three columns but ignore the first two. The datum in the last column is appended to an array that we the return and that will be copied into the table from which `topography_data` is initialized. Since the BOOST.iostreams library does not provide a very useful exception when the input file does not exist, is not readable, or does not contain the correct number of data lines, we catch all exceptions it may produce and create our own one. To this end, in the `catch` clause, we let the program run into an `AssertThrow(false, ...)` statement. Since the condition is always false, this always triggers an exception. In other words, this is equivalent to writing `throw ExcMessage(\"...\")` but it also fills certain fields in the exception object that will later be printed on the screen identifying the function, file and line where the exception happened.\n\n```\n     std::vector<double> AfricaTopography::get_data()\n     {\n       std::vector<double> data;\n   \n       boost::iostreams::filtering_istream in;\n       in.push(boost::iostreams::basic_gzip_decompressor<>());\n       in.push(boost::iostreams::file_source(\"topography.txt.gz\"));\n   \n       for (unsigned int line = 0; line < 83600; ++line)\n         {\n           try\n             {\n               double lat, lon, elevation;\n               in >> lat >> lon >> elevation;\n   \n               data.push_back(elevation);\n             }\n           catch (...)\n             {\n               AssertThrow(false,\n                           ExcMessage(\"Could not read all 83,600 data points \"\n                                      \"from the file <topography.txt.gz>!\"));\n             }\n         }\n   \n       return data;\n     }\n```\n\n### Describing the geometry: AfricaGeometry\n\nThe following class is then the main one of this program. Its structure has been described in much detail in the introduction and does not need much introduction any more.\n\n```\n     class AfricaGeometry : public ChartManifold<3, 3>\n     {\n     public:\n       virtual Point<3> pull_back(const Point<3> &space_point) const override;\n   \n       virtual Point<3> push_forward(const Point<3> &chart_point) const override;\n   \n       virtual std::unique_ptr<Manifold<3, 3>> clone() const override;\n   \n     private:\n       static const double R;\n       static const double ellipticity;\n   \n       const AfricaTopography topography;\n   \n       Point<3> push_forward_wgs84(const Point<3> &phi_theta_d) const;\n       Point<3> pull_back_wgs84(const Point<3> &x) const;\n   \n       Point<3> push_forward_topo(const Point<3> &phi_theta_d_hat) const;\n       Point<3> pull_back_topo(const Point<3> &phi_theta_d) const;\n     };\n   \n   \n     const double AfricaGeometry::R           = 6378137;\n     const double AfricaGeometry::ellipticity = 8.1819190842622e-2;\n```\n\nThe implementation, as well, is pretty straightforward if you have read the introduction. In particular, both of the pull back and push forward functions are just concatenations of the respective functions of the WGS 84 and topography mappings:\n\n```\n     Point<3> AfricaGeometry::pull_back(const Point<3> &space_point) const\n     {\n       return pull_back_topo(pull_back_wgs84(space_point));\n     }\n   \n     Point<3> AfricaGeometry::push_forward(const Point<3> &chart_point) const\n     {\n       return push_forward_wgs84(push_forward_topo(chart_point));\n     }\n```\n\nThe next function is required by the interface of the [Manifold](classManifold.html) base class, and allows cloning the AfricaGeometry class. Notice that, while the function returns a `std::unique_ptr<Manifold<3,3>>`, we internally create a `unique_ptr<AfricaGeometry>`. In other words, the library requires a pointer-to-base-class, which we provide by creating a pointer-to-derived-class.\n\n```\n     std::unique_ptr<Manifold<3, 3>> AfricaGeometry::clone() const\n     {\n       return std::make_unique<AfricaGeometry>();\n     }\n```\n\nThe following two functions then define the forward and inverse transformations that correspond to the WGS 84 reference shape of Earth. The forward transform follows the formula shown in the introduction. The inverse transform is significantly more complicated and is, at the very least, not intuitive. It also suffers from the fact that it returns an angle that at the end of the function we need to clip back into the interval \\([0,2\\pi]\\) if it should have escaped from there.\n\n```\n     Point<3> AfricaGeometry::push_forward_wgs84(const Point<3> &phi_theta_d) const\n     {\n       const double phi   = phi_theta_d[0];\n       const double theta = phi_theta_d[1];\n       const double d     = phi_theta_d[2];\n   \n       const double R_bar = R / std::sqrt(1 - (ellipticity * ellipticity *\n                                               std::sin(theta) * std::sin(theta)));\n   \n       return {(R_bar + d) * std::cos(phi) * std::cos(theta),\n               (R_bar + d) * std::sin(phi) * std::cos(theta),\n               ((1 - ellipticity * ellipticity) * R_bar + d) * std::sin(theta)};\n     }\n   \n     Point<3> AfricaGeometry::pull_back_wgs84(const Point<3> &x) const\n     {\n       const double b   = std::sqrt(R * R * (1 - ellipticity * ellipticity));\n       const double ep  = std::sqrt((R * R - b * b) / (b * b));\n       const double p   = std::sqrt(x[0] * x[0] + x[1] * x[1]);\n       const double th  = std::atan2(R * x[2], b * p);\n       const double phi = std::atan2(x[1], x[0]);\n       const double theta =\n         std::atan2(x[2] + ep * ep * b * Utilities::fixed_power<3>(std::sin(th)),\n                    (p - (ellipticity * ellipticity * R *\n                          Utilities::fixed_power<3>(std::cos(th)))));\n       const double R_bar =\n         R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) *\n                              std::sin(theta)));\n       const double R_plus_d = p / std::cos(theta);\n   \n       Point<3> phi_theta_d;\n       if (phi < 0)\n         phi_theta_d[0] = phi + 2 * numbers::PI;\n       else if (phi > 2 * numbers::PI)\n         phi_theta_d[0] = phi - 2 * numbers::PI;\n       else\n         phi_theta_d[0] = phi;\n       phi_theta_d[1] = theta;\n       phi_theta_d[2] = R_plus_d - R_bar;\n       return phi_theta_d;\n     }\n```\n\nIn contrast, the topography transformations follow exactly the description in the introduction. There is not consequently not much to add:\n\n```\n     Point<3>\n     AfricaGeometry::push_forward_topo(const Point<3> &phi_theta_d_hat) const\n     {\n       const double d_hat = phi_theta_d_hat[2];\n       const double h = topography.value(phi_theta_d_hat[0], phi_theta_d_hat[1]);\n       const double d = d_hat + (d_hat + 500000) / 500000 * h;\n       return {phi_theta_d_hat[0], phi_theta_d_hat[1], d};\n     }\n   \n     Point<3> AfricaGeometry::pull_back_topo(const Point<3> &phi_theta_d) const\n     {\n       const double d     = phi_theta_d[2];\n       const double h     = topography.value(phi_theta_d[0], phi_theta_d[1]);\n       const double d_hat = 500000 * (d - h) / (500000 + h);\n       return {phi_theta_d[0], phi_theta_d[1], d_hat};\n     }\n```\n\n### Creating the mesh\n\nHaving so described the properties of the geometry, not it is time to deal with the mesh used to discretize it. To this end, we create objects for the geometry and triangulation, and then proceed to create a \\(1\\times 2\\times 1\\) rectangular mesh that corresponds to the reference domain \\(\\hat U=[26,35]\\times[-10,5]\\times[-500000,0]\\). We choose this number of subdivisions because it leads to cells that are roughly like cubes instead of stretched in one direction or another.\n\nOf course, we are not actually interested in meshing the reference domain. We are interested in meshing the real domain. Consequently, we will use the [GridTools::transform()](namespaceGridTools.html#a212e99cf0d923cebfa04f1d23fa60b04) function that simply moves every point of a triangulation according to a given transformation. The transformation function it wants is a function that takes as its single argument a point in the reference domain and returns the corresponding location in the domain that we want to map to. This is, of course, exactly the push forward function of the geometry we use. We wrap it by a lambda function to obtain the kind of function object required for the transformation.\n\n```\n     void run()\n     {\n       AfricaGeometry   geometry;\n       Triangulation<3> triangulation;\n   \n       {\n         const Point<3> corner_points[2] = {\n           Point<3>(26 * numbers::PI / 180, -10 * numbers::PI / 180, -500000),\n           Point<3>(35 * numbers::PI / 180, 5 * numbers::PI / 180, 0)};\n         std::vector<unsigned int> subdivisions(3);\n         subdivisions[0] = 1;\n         subdivisions[1] = 2;\n         subdivisions[2] = 1;\n         GridGenerator::subdivided_hyper_rectangle(\n           triangulation, subdivisions, corner_points[0], corner_points[1], true);\n   \n         GridTools::transform(\n           [&geometry](const Point<3> &chart_point) {\n             return geometry.push_forward(chart_point);\n           },\n           triangulation);\n       }\n```\n\nThe next step is to explain to the triangulation to use our geometry object whenever a new point is needed upon refining the mesh. We do this by telling the triangulation to use our geometry for everything that has manifold indicator zero, and then proceed to mark all cells and their bounding faces and edges with manifold indicator zero. This ensures that the triangulation consults our geometry object every time a new vertex is needed. Since manifold indicators are inherited from mother to children, this also happens after several recursive refinement steps.\n\n```\n       triangulation.set_manifold(0, geometry);\n       for (const auto &cell : triangulation.active_cell_iterators())\n         cell->set_all_manifold_ids(0);\n```\n\nThe last step is to refine the mesh beyond its initial \\(1\\times 2\\times\n1\\) coarse mesh. We could just refine globally a number of times, but since for the purpose of this tutorial program we're really only interested in what is happening close to the surface, we just refine 6 times all of the cells that have a face at a boundary with indicator 5. Looking this up in the documentation of the [GridGenerator::subdivided\\_hyper\\_rectangle()](namespaceGridGenerator.html#ac76417d7404b75cf53c732f456e6e971) function we have used above reveals that boundary indicator 5 corresponds to the top surface of the domain (and this is what the last `true` argument in the call to [GridGenerator::subdivided\\_hyper\\_rectangle()](namespaceGridGenerator.html#ac76417d7404b75cf53c732f456e6e971) above meant: to \"color\" the boundaries by assigning each boundary a unique boundary indicator).\n\n```\n       for (unsigned int i = 0; i < 6; ++i)\n         {\n           for (const auto &cell : triangulation.active_cell_iterators())\n             for (const auto &face : cell->face_iterators())\n               if (face->boundary_id() == 5)\n                 {\n                   cell->set_refine_flag();\n                   break;\n                 }\n           triangulation.execute_coarsening_and_refinement();\n   \n           std::cout << \"Refinement step \" << i + 1 << \": \"\n                     << triangulation.n_active_cells() << \" cells, \"\n                     << GridTools::minimal_cell_diameter(triangulation) / 1000\n                     << \"km minimal cell diameter\" << std::endl;\n         }\n```\n\nHaving done this all, we can now output the mesh into a file of its own:\n\n```\n       const std::string filename = \"mesh.vtu\";\n       std::ofstream     out(filename);\n       GridOut           grid_out;\n       grid_out.write_vtu(triangulation, out);\n     }\n   } // namespace Step53\n```\n\n### The main function\n\nFinally, the main function, which follows the same scheme used in all tutorial programs starting with [step-6](step_6.html). There isn't much to do here, only to call the single `run()` function.\n\n```\n   int main()\n   {\n     try\n       {\n         Step53::run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   }\n```\n\nResults\n=======\n\nRunning the program produces a mesh file `mesh.vtu` that we can visualize with any of the usual visualization programs that can read the VTU file format. If one just looks at the mesh itself, it is actually very difficult to see anything that doesn't just look like a perfectly round piece of a sphere (though if one modified the program so that it does produce a sphere and looked at them at the same time, the difference between the overall sphere and WGS 84 shape is quite apparent). Apparently, Earth is actually quite a flat place. Of course we already know this from satellite pictures. However, we can tease out something more by coloring cells by their volume. This both produces slight variations in hue along the top surface and something for the visualization programs to apply their shading algorithms to (because the top surfaces of the cells are now no longer just tangential to a sphere but tilted):\n\n![](images/steps/developer/step-53.mesh.png)\n\nYet, at least as far as visualizations are concerned, this is still not too impressive. Rather, let us visualize things in a way so that we show the actual elevation along the top surface. In other words, we want a picture like this, with an incredible amount of detail:\n\n![](images/steps/developer/step-53.topo.png)\n\nA zoom-in of this picture shows the vertical displacement quite clearly (here, looking from the West-Northwest over the rift valley, the triple peaks of [Mount Stanley](http://en.wikipedia.org/wiki/Mount_Stanley), [Mount Speke](http://en.wikipedia.org/wiki/Mount_Speke), and [Mount Baker](http://en.wikipedia.org/wiki/Mount_Baker_%28Uganda%29) in the [Rwenzori Range](http://en.wikipedia.org/wiki/Rwenzori_Mountains), [Lake George](http://en.wikipedia.org/wiki/Lake_George_%28Uganda%29) and toward the great flatness of [Lake Victoria](http://en.wikipedia.org/wiki/Lake_Victoria)):\n\n![](images/steps/developer/step-53.topozoom.png)\n\nThese image were produced with three small modifications:\n\n1. An additional seventh mesh refinement towards the top surface for the first of these two pictures, and a total of nine for the second. In the second image, the horizontal mesh size is approximately 1.5km, and just under 1km in vertical direction. (The picture was also created using a more resolved data set; however, it is too big to distribute as part of the tutorial.)\n2. The addition of the following function that, given a point `x` computes the elevation by converting the point to reference WGS 84 coordinates and only keeping the depth variable (the function is, consequently, a simplified version of the `AfricaGeometry::pull_back_wgs84()` function):\n\n   ```\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n    \n    \n   double get_elevation (const Point<3> &x)\n     {\n    const double R           = 6378137;\n    const double ellipticity = 8.1819190842622e-2;\n    \n    const double b     = std::sqrt(R * R * (1 - ellipticity * ellipticity));\n    const double ep    = std::sqrt((R * R - b * b) / (b * b));\n    const double p     = std::sqrt(x(0) * x(0) + x(1) * x(1));\n    const double th    = std::atan2(R * x(2), b * p);\n    const double theta = std::atan2((x(2) + ep * ep * b * std::sin(th) * std::sin(th) * std::sin(th)),\n                                         (p - (ellipticity * ellipticity * R  * (std::cos(th) * std::cos(th) * std::cos(th)))));\n    const double R_bar = R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) * std::sin(theta)));\n    const double R_plus_d = p / std::cos(theta);\n    \n    return R_plus_d - R_bar;\n     }\n   ```\n3. Adding the following piece to the bottom of the `run()` function:\n\n   ```\n   FE_Q<3>       fe(1);\n   DoFHandler<3> dof_handler (triangulation);\n   dof_handler.distribute_dofs(fe);\n    \n   Vector<double> elevation (dof_handler.n_dofs());\n   {\n     std::map<unsigned int,double> boundary_values;\n    VectorTools::interpolate_boundary_values(dof_handler,\n                                              5,\n    ScalarFunctionFromFunctionObject<3>(get_elevation),\n                                              boundary_values);\n    for (std::map<unsigned int,double>::const_iterator p = boundary_values.begin();\n          p!=boundary_values.end(); ++p)\n       elevation[p->first] = p->second;\n   }\n    \n   DataOut<3>    data_out;\n   data_out.attach_dof_handler(dof_handler);\n   data_out.add_data_vector (elevation, \"elevation\");\n   data_out.build_patches();\n    \n   std::ofstream out (\"data.vtu\");\n   data_out.write_vtu (out);\n   ```\n\nThis last piece of code first creates a \\(Q\\_1\\) finite element space on the mesh. It then (ab)uses [VectorTools::interpolate\\_boundary\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) to evaluate the elevation function for every node at the top boundary (the one with boundary indicator 5). We here wrap the call to `get_elevation()` with the [ScalarFunctionFromFunctionObject](classScalarFunctionFromFunctionObject.html) class to make a regular C++ function look like an object of a class derived from the [Function](classFunction.html) class that we want to use in [VectorTools::interpolate\\_boundary\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a). Having so gotten a list of degrees of freedom located at the top boundary and corresponding elevation values, we just go down this list and set these elevations in the `elevation` vector (leaving all interior degrees of freedom at their original zero value). This vector is then output using [DataOut](classDataOut.html) as usual and can be visualized as shown above.\n\n### Issues with adaptively refined meshes generated this way\n\nIf you zoomed in on the mesh shown above and looked closely enough, you would find that at hanging nodes, the two small edges connecting to the hanging nodes are not in exactly the same location as the large edge of the neighboring cell. This can be shown more clearly by using a different surface description in which we enlarge the vertical topography to enhance the effect (courtesy of Alexander Grayver):\n\n![](images/steps/developer/step-53.smooth-geometry.png)\n\nSo what is happening here? Partly, this is only a result of visualization, but there is an underlying real cause as well:\n\n* When you visualize a mesh using any of the common visualization programs, what they really show you is just a set of edges that are plotted as straight lines in three-dimensional space. This is so because almost all data file formats for visualizing data only describe hexahedral cells as a collection of eight vertices in 3d space, and do not allow to any more complicated descriptions. (This is the main reason why [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646) takes an argument that can be set to something larger than one.) These linear edges may be the edges of the cell you do actual computations on, or they may not, depending on what kind of mapping you use when you do your integrations using [FEValues](classFEValues.html). By default, of course, [FEValues](classFEValues.html) uses a linear mapping (i.e., an object of class [MappingQ1](classMappingQ1.html)) and in that case a 3d cell is indeed described exclusively by its 8 vertices and the volume it fills is a trilinear interpolation between these points, resulting in linear edges. But, you could also have used tri-quadratic, tri-cubic, or even higher order mappings and in these cases the volume of each cell will be bounded by quadratic, cubic or higher order polynomial curves. Yet, you only get to see these with linear edges in the visualization program because, as mentioned, file formats do not allow to describe the real geometry of cells.\n* That said, let us for simplicity assume that you are indeed using a trilinear mapping, then the image shown above is a faithful representation of the cells on which you form your integrals. In this case, indeed the small cells at a hanging nodes do not, in general, snugly fit against the large cell but leave a gap or may intersect the larger cell. Why is this? Because when the triangulation needs a new vertex on an edge it wants to refine, it asks the manifold description where this new vertex is supposed to be, and the manifold description duly returns such a point by (in the case of a geometry derived from [ChartManifold](classChartManifold.html)) pulling the adjacent points of the line back to the reference domain, averaging their locations, and pushing forward this new location to the real domain. But this new location is not usually along a straight line (in real space) between the adjacent vertices and consequently the two small straight lines forming the refined edge do not lie exactly on the one large straight line forming the unrefined side of the hanging node.\n\nThe situation is slightly more complicated if you use a higher order mapping using the [MappingQ](classMappingQ.html) class, but not fundamentally different. Let's take a quadratic mapping for the moment (nothing fundamental changes with even higher order mappings). Then you need to imagine each edge of the cells you integrate on as a quadratic curve despite the fact that you will never actually see it plotted that way by a visualization program. But imagine it that way for a second. So which quadratic curve does [MappingQ](classMappingQ.html) take? It is the quadratic curve that goes through the two vertices at the end of the edge as well as a point in the middle that it queries from the manifold. In the case of the long edge on the unrefined side, that's of course exactly the location of the hanging node, so the quadratic curve describing the long edge does go through the hanging node, unlike in the case of the linear mapping. But the two small edges are also quadratic curves; for example, the left small edge will go through the left vertex of the long edge and the hanging node, plus a point it queries halfway in between from the manifold. Because, as before, the point the manifold returns halfway along the left small edge is rarely exactly on the quadratic curve describing the long edge, the quadratic short edge will typically not coincide with the left half of the quadratic long edge, and the same is true for the right short edge. In other words, again, the geometries of the large cell and its smaller neighbors at hanging nodes do not touch snuggly.\n\nThis all begs two questions: first, does it matter, and second, could this be fixed. Let us discuss these in the following:\n\n* Does it matter? It is almost certainly true that this depends on the equation you are solving. For example, it is known that solving the Euler equations of gas dynamics on complex geometries requires highly accurate boundary descriptions to ensure convergence of quantities that are measure the flow close to the boundary. On the other hand, equations with elliptic components (e.g., the Laplace or Stokes equations) are typically rather forgiving of these issues: one does quadrature anyway to approximate integrals, and further approximating the geometry may not do as much harm as one could fear given that the volume of the overlaps or gaps at every hanging node is only \\({\\cal O}(h^d)\\) even with a linear mapping and \\({\\cal\n  O}(h^{d+p-1})\\) for a mapping of degree \\(p\\). (You can see this by considering that in 2d the gap/overlap is a triangle with base \\(h\\) and height \\({\\cal\n  O}(h)\\); in 3d, it is a pyramid-like structure with base area \\(h^2\\) and height \\({\\cal O}(h)\\). Similar considerations apply for higher order mappings where the height of the gaps/overlaps is \\({\\cal O}(h^p)\\).) In other words, if you use a linear mapping with linear elements, the error in the volume you integrate over is already at the same level as the integration error using the usual Gauss quadrature. Of course, for higher order elements one would have to choose matching mapping objects.\n\n  Another point of view on why it is probably not worth worrying too much about the issue is that there is certainly no narrative in the community of numerical analysts that these issues are a major concern one needs to watch out for when using complex geometries. If it does not seem to be discussed often among practitioners, if ever at all, then it is at least not something people have identified as a common problem.\n\n  This issue is not dissimilar to having hanging nodes at curved boundaries where the geometry description of the boundary typically pulls a hanging node onto the boundary whereas the large edge remains straight, making the adjacent small and large cells not match each other. Although this behavior existed in deal.II since its beginning, 15 years before manifold descriptions became available, it did not ever come up in mailing list discussions or conversations with colleagues.\n* Could it be fixed? In principle, yes, but it's a complicated issue. Let's assume for the moment that we would only ever use the [MappingQ1](classMappingQ1.html) class, i.e., linear mappings. In that case, whenever the triangulation class requires a new vertex along an edge that would become a hanging node, it would just take the mean value of the adjacent vertices *in real space*, i.e., without asking the manifold description. This way, the point lies on the long straight edge and the two short straight edges would match the one long edge. Only when all adjacent cells have been refined and the point is no longer a hanging node would we replace its coordinates by coordinates we get by a manifold. This may be awkward to implement, but it would certainly be possible.\n\n  The more complicated issue arises because people may want to use a higher order [MappingQ](classMappingQ.html) object. In that case, the [Triangulation](classTriangulation.html) class may freely choose the location of the hanging node (because the quadratic curve for the long edge can be chosen in such a way that it goes through the hanging node) but the [MappingQ](classMappingQ.html) class, when determining the location of mid-edge points must make sure that if the edge is one half of a long edge of a neighboring coarser cell, then the midpoint cannot be obtained from the manifold but must be chosen along the long quadratic edge. For cubic (and all other odd) mappings, the matter is again a bit complicated because one typically arranges the cubic edge to go through points 1/3 and 2/3 along the edge, and thus necessarily through the hanging node, but this could probably be worked out. In any case, even then, there are two problems with this:\n\n  + When refining the triangulation, the [Triangulation](classTriangulation.html) class can not know what mapping will be used. In fact it is not uncommon for a triangulation to be used differently in different contexts within the same program. If the mapping used determines whether we can freely choose a point or not, how, then, should the triangulation locate new vertices?\n  + Mappings are purely local constructs: they only work on a cell in isolation, and this is one of the important features of the finite element method. Having to ask whether one of the vertices of an edge is a hanging node requires querying the neighborhood of a cell; furthermore, such a query does not just involve the 6 face neighbors of a cell in 3d, but may require traversing a possibly very large number of other cells that connect to an edge. Even if it can be done, one still needs to do different things depending on how the neighborhood looks like, producing code that is likely very complex, hard to maintain, and possibly slow.\n\n  Consequently, at least for the moment, none of these ideas are implemented. This leads to the undesirable consequence of discontinuous geometries, but, as discussed above, the effects of this do not appear to pose problem in actual practice.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2014 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Wolfgang Bangerth, Texas A&M University, 2014\n *          Luca Heltai, SISSA, 2014\n *          D. Sarah Stamps, MIT, 2014\n */\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_out.h>\n#include <deal.II/grid/manifold.h>\n#include <deal.II/grid/grid_tools.h>\n \n#include <deal.II/base/function_lib.h>\n \n#include <boost/iostreams/filtering_stream.hpp>\n#include <boost/iostreams/filter/gzip.hpp>\n#include <boost/iostreams/device/file.hpp>\n \n#include <fstream>\n#include <iostream>\n#include <memory>\n \n \nnamespace Step53\n{\n using namespace dealii;\n \n \n class AfricaTopography\n  {\n public:\n    AfricaTopography();\n \n double value(const double lon, const double lat) const;\n \n private:\n const Functions::InterpolatedUniformGridData<2> topography_data;\n \n static std::vector<double> get_data();\n  };\n \n \n  AfricaTopography::AfricaTopography()\n    : topography_data({{std::make_pair(-6.983333, 11.966667),\n                        std::make_pair(25, 35.95)}},\n                      {{379, 219}},\n Table<2, double>(380, 220, get_data().begin()))\n  {}\n \n \n double AfricaTopography::value(const double lon, const double lat) const\n {\n return topography_data.value(\n Point<2>(-lat * 180 / numbers::PI, lon * 180 / numbers::PI));\n  }\n \n \n  std::vector<double> AfricaTopography::get_data()\n  {\n    std::vector<double> data;\n \n    boost::iostreams::filtering_istream in;\n    in.push(boost::iostreams::basic_gzip_decompressor<>());\n    in.push(boost::iostreams::file_source(\"topography.txt.gz\"));\n \n for (unsigned int line = 0; line < 83600; ++line)\n      {\n try\n          {\n double lat, lon, elevation;\n            in >> lat >> lon >> elevation;\n \n            data.push_back(elevation);\n          }\n catch (...)\n          {\n AssertThrow(false,\n                        ExcMessage(\"Could not read all 83,600 data points \"\n \"from the file <topography.txt.gz>!\"));\n          }\n      }\n \n return data;\n  }\n \n \n class AfricaGeometry : public ChartManifold<3, 3>\n  {\n public:\n virtual Point<3> pull_back(const Point<3> &space_point) const override;\n \n virtual Point<3> push_forward(const Point<3> &chart_point) const override;\n \n virtual std::unique_ptr<Manifold<3, 3>> clone() const override;\n \n private:\n static const double R;\n static const double ellipticity;\n \n const AfricaTopography topography;\n \n Point<3> push_forward_wgs84(const Point<3> &phi_theta_d) const;\n Point<3> pull_back_wgs84(const Point<3> &x) const;\n \n Point<3> push_forward_topo(const Point<3> &phi_theta_d_hat) const;\n Point<3> pull_back_topo(const Point<3> &phi_theta_d) const;\n  };\n \n \n const double AfricaGeometry::R           = 6378137;\n const double AfricaGeometry::ellipticity = 8.1819190842622e-2;\n \n \n Point<3> AfricaGeometry::pull_back(const Point<3> &space_point) const\n {\n return pull_back_topo(pull_back_wgs84(space_point));\n  }\n \n Point<3> AfricaGeometry::push_forward(const Point<3> &chart_point) const\n {\n return push_forward_wgs84(push_forward_topo(chart_point));\n  }\n \n \n  std::unique_ptr<Manifold<3, 3>> AfricaGeometry::clone() const\n {\n return std::make_unique<AfricaGeometry>();\n  }\n \n \n Point<3> AfricaGeometry::push_forward_wgs84(const Point<3> &phi_theta_d) const\n {\n const double phi   = phi_theta_d[0];\n const double theta = phi_theta_d[1];\n const double d     = phi_theta_d[2];\n \n const double R_bar = R / std::sqrt(1 - (ellipticity * ellipticity *\n std::sin(theta) * std::sin(theta)));\n \n return {(R_bar + d) * std::cos(phi) * std::cos(theta),\n            (R_bar + d) * std::sin(phi) * std::cos(theta),\n            ((1 - ellipticity * ellipticity) * R_bar + d) * std::sin(theta)};\n  }\n \n Point<3> AfricaGeometry::pull_back_wgs84(const Point<3> &x) const\n {\n const double b   = std::sqrt(R * R * (1 - ellipticity * ellipticity));\n const double ep  = std::sqrt((R * R - b * b) / (b * b));\n const double p   = std::sqrt(x[0] * x[0] + x[1] * x[1]);\n const double th  = std::atan2(R * x[2], b * p);\n const double phi = std::atan2(x[1], x[0]);\n const double theta =\n      std::atan2(x[2] + ep * ep * b * Utilities::fixed_power<3>(std::sin(th)),\n                 (p - (ellipticity * ellipticity * R *\n Utilities::fixed_power<3>(std::cos(th)))));\n const double R_bar =\n      R / (std::sqrt(1 - ellipticity * ellipticity * std::sin(theta) *\n std::sin(theta)));\n const double R_plus_d = p / std::cos(theta);\n \n Point<3> phi_theta_d;\n if (phi < 0)\n      phi_theta_d[0] = phi + 2 * numbers::PI;\n else if (phi > 2 * numbers::PI)\n      phi_theta_d[0] = phi - 2 * numbers::PI;\n else\n      phi_theta_d[0] = phi;\n    phi_theta_d[1] = theta;\n    phi_theta_d[2] = R_plus_d - R_bar;\n return phi_theta_d;\n  }\n \n \n Point<3>\n  AfricaGeometry::push_forward_topo(const Point<3> &phi_theta_d_hat) const\n {\n const double d_hat = phi_theta_d_hat[2];\n const double h = topography.value(phi_theta_d_hat[0], phi_theta_d_hat[1]);\n const double d = d_hat + (d_hat + 500000) / 500000 * h;\n return {phi_theta_d_hat[0], phi_theta_d_hat[1], d};\n  }\n \n Point<3> AfricaGeometry::pull_back_topo(const Point<3> &phi_theta_d) const\n {\n const double d     = phi_theta_d[2];\n const double h     = topography.value(phi_theta_d[0], phi_theta_d[1]);\n const double d_hat = 500000 * (d - h) / (500000 + h);\n return {phi_theta_d[0], phi_theta_d[1], d_hat};\n  }\n \n \n void run()\n  {\n    AfricaGeometry   geometry;\n Triangulation<3> triangulation;\n \n    {\n const Point<3> corner_points[2] = {\n Point<3>(26 * numbers::PI / 180, -10 * numbers::PI / 180, -500000),\n Point<3>(35 * numbers::PI / 180, 5 * numbers::PI / 180, 0)};\n      std::vector<unsigned int> subdivisions(3);\n      subdivisions[0] = 1;\n      subdivisions[1] = 2;\n      subdivisions[2] = 1;\n GridGenerator::subdivided_hyper_rectangle(\n triangulation, subdivisions, corner_points[0], corner_points[1], true);\n \n GridTools::transform(\n        [&geometry](const Point<3> &chart_point) {\n return geometry.push_forward(chart_point);\n        },\n triangulation);\n    }\n \n triangulation.set_manifold(0, geometry);\n for (const auto &cell : triangulation.active_cell_iterators())\n      cell->set_all_manifold_ids(0);\n \n for (unsigned int i = 0; i < 6; ++i)\n      {\n for (const auto &cell : triangulation.active_cell_iterators())\n          for (const auto &face : cell->face_iterators())\n            if (face->boundary_id() == 5)\n              {\n                cell->set_refine_flag();\n break;\n              }\n triangulation.execute_coarsening_and_refinement();\n \n        std::cout << \"Refinement step \" << i + 1 << \": \"\n                  << triangulation.n_active_cells() << \" cells, \"\n                  << GridTools::minimal_cell_diameter(triangulation) / 1000\n                  << \"km minimal cell diameter\" << std::endl;\n      }\n \n const std::string filename = \"mesh.vtu\";\n    std::ofstream     out(filename);\n GridOut           grid_out;\n    grid_out.write_vtu(triangulation, out);\n  }\n} // namespace Step53\n \n \n \n \nint main()\n{\n try\n    {\n      Step53::run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_54.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nUsing CAD files to describe the boundary of your domain.\nTutorial content :\nThis tutorial depends on [step-53](step_53.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_54-Intro)    * [CAD surfaces](#step_54-CADsurfaces) * [The CAD boundary projector classes](#step_54-TheCADboundaryprojectorclasses) * [The testcase](#step_54-Thetestcase)- [The commented program](#step_54-CommProg)      * [Include files](#step_54-Includefiles)* [The TriangulationOnCAD class](#step_54-TheTriangulationOnCADclass)          + [TriangulationOnCAD::TriangulationOnCAD](#step_54-TriangulationOnCADTriangulationOnCAD)+ [TriangulationOnCAD::read\\_domain](#step_54-TriangulationOnCADread_domain)+ [TriangulationOnCAD::refine\\_mesh](#step_54-TriangulationOnCADrefine_mesh)+ [TriangulationOnCAD::output\\_results](#step_54-TriangulationOnCADoutput_results)+ [TriangulationOnCAD::run](#step_54-TriangulationOnCADrun)* [The main() function](#step_54-Themainfunction) | 1. [Results](#step_54-Results)    - [The plain program](#step_54-PlainProg) |\n\n*This program was contributed by Andrea Mola and Luca Heltai.*\n\nNote\n:   This program elaborates on concepts of industrial geometry, using tools that interface with the [OpenCASCADE](namespaceOpenCASCADE.html) library (<http://www.opencascade.org>) that allow the specification of arbitrary IGES files to describe the boundaries for your geometries.\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.546220](https://zenodo.org/badge/DOI/10.5281/zenodo.546220.svg)](https://doi.org/10.5281/zenodo.546220)\n\nIntroduction\n============\n\nIn some of the previous tutorial programs ([step-1](step_1.html), [step-3](step_3.html), [step-5](step_5.html), [step-6](step_6.html) and [step-49](step_49.html) among others) we have learned how to use the mesh refinement methods provided in deal.II. These tutorials have shown how to employ such tools to produce a fine grid for a single simulation, as done in [step-3](step_3.html); or to start from a coarse grid and carry out a series of simulations on adaptively refined grids, as is the case of [step-6](step_6.html). Regardless of which approach is taken, the mesh refinement requires a suitable geometrical description of the computational domain boundary in order to place, at each refinement, the new mesh nodes onto the boundary surface. For instance, [step-5](step_5.html) shows how creating a circular grid automatically attaches a circular manifold object to the computational domain, so that the faces lying on the boundary are refined onto the circle. [step-53](step_53.html) shows how to do this with a [Manifold](classManifold.html) defined by experimentally obtained data. But, at least as far as elementary boundary shapes are concerned, deal.II really only provides circles, spheres, boxes and other elementary combinations. In this tutorial, we will show how to use a set of classes developed to import arbitrary CAD geometries, assign them to the desired boundary of the computational domain, and refine a computational grid on such complex shapes.\n\n### CAD surfaces\n\nIn the most common industrial practice, the geometrical models of arbitrarily shaped objects are realized by means of Computer Aided Design (CAD) tools. The use of CAD modelers has spread in the last decades, as they allow for the generation of a full virtual model of each designed object, which through a computer can be visualized, inspected, and analyzed in its finest details well before it is physically crafted. From a mathematical perspective, the engine lying under the hood of CAD modelers is represented by analytical geometry, and in particular by parametric curves and surfaces such as B-splines and NURBS that are rich enough that they can represent most surfaces of practical interest. Once a virtual model is ready, all the geometrical features of the desired object are stored in files which materially contain the coefficients of the parametric surfaces and curves composing the object. Depending on the specific CAD tool used to define the geometrical model, there are of course several different file formats in which the information of a CAD model can be organized. To provide a common ground to exchange data across CAD tools, the U.S. National Bureau of Standards published in 1980 the Initial Graphics Exchange Representation (IGES) neutral file format, which is used in this example.\n\n### The CAD boundary projector classes\n\nTo import and interrogate CAD models, the deal.II library implements a series of wrapper functions for the [OpenCASCADE](namespaceOpenCASCADE.html) open source library for CAD modeling. These functions allow to import IGES files into [OpenCASCADE](namespaceOpenCASCADE.html) native objects, and wrap them inside a series of [Manifold](classManifold.html) classes.\n\nOnce imported from an IGES file, the model is stored in a `TopoDS_Shape`, which is the generic topological entity defined in the [OpenCASCADE](namespaceOpenCASCADE.html) framework. From a `TopoDS_Shape`, it is then possible to access all the sub-shapes (such as vertices, edges and faces) composing it, along with their geometrical description. In the deal.II framework, the topological entities composing a shape are used to create a corresponding [Manifold](classManifold.html) representation. In [step-6](step_6.html) we saw how to use [GridGenerator::hyper\\_sphere()](namespaceGridGenerator.html#ab2dc2f16fc52cf1e51b9afdc4264ac70) to create a hyper sphere, which automatically attaches a [SphericalManifold](classSphericalManifold.html) to all boundary faces. This guarantees that boundary faces stay on a sphere or circle during mesh refinement. The functions of the CAD modeling interface have been designed to retain the same structure, allowing the user to build a projector object using the imported CAD shapes, maintaining the same procedure we used in other tutorial programs, i.e., assigning such projector object to cells, faces or edges of a coarse mesh. At each refinement cycle, the new mesh nodes will be then automatically generated by projecting a midpoint of an existing object onto the specified geometry.\n\nDifferently from a spherical or circular boundary, a boundary with a complex geometry poses problems as to where it is best to place the new nodes created upon refinement on the prescribed shape. [PolarManifold](classPolarManifold.html), for example, transforms the surrounding points to polar coordinates, calculates the average in that coordinate system (for each coordinate individually) and finally transforms the point back to Cartesian coordinates.\n\nIn the case of an arbitrary and complex shape though, an appropriate choice for the placement of a new node cannot be identified that easily. The [OpenCASCADE](namespaceOpenCASCADE.html) wrappers in deal.II provide several projector classes that employ different projection strategies. A first projector, implemented in the [OpenCASCADE::ArclengthProjectionLineManifold](classOpenCASCADE_1_1ArclengthProjectionLineManifold.html) class, is to be used only for edge refinement. It is built assigning it a topological shape of dimension one, either a `TopoDS_Edge` or a `TopoDS_Wire` (which is a compound shape, made of several connected `TopoDS_Edge`s) and refines a mesh edge finding the new vertex as the point splitting in two even parts the curvilinear length of the CAD curve portion that lies between the vertices of the original edge.\n\n![](images/steps/developer/step-54.CurveSplit.png)\n\nA different projection strategy has been implemented in the [OpenCASCADE::NormalProjectionManifold](classOpenCASCADE_1_1NormalProjectionManifold.html) class. The `TopoDS_Shape` assigned at construction time can be arbitrary (a collection of shapes, faces, edges or a single face or edge will all work). The new cell nodes are first computed by averaging the surrounding points in the same way as [FlatManifold](classFlatManifold.html) does. In a second step, all the new nodes will be projected onto the `TopoDS_Shape` along the direction normal to the shape. If no normal projection is available, the point which is closest to the shape—typically lying on the shape boundary—is selected. If the shape is composed of several sub-shapes, the projection is carried out onto every single sub-shape, and the closest projection point is selected.\n\n![](images/steps/developer/step-54.NormalProjectionEdge.png) ![](images/steps/developer/step-54.NormalProjection.png)\n\nAs we are about to experience, for some shapes, setting the projection direction as that normal to the CAD surface will not lead to surface mesh elements of suitable quality. This is because the direction normal to the CAD surface has in principle nothing to do with the direction along which the mesh needs the new nodes to be located. The [OpenCASCADE::DirectionalProjectionManifold](classOpenCASCADE_1_1DirectionalProjectionManifold.html) class, in this case, can help. This class is constructed assigning a `TopoDS_Shape` (containing at least a face) and a direction along which all the projections will be carried out. New points will be computed by first averaging the surrounding points (as in the [FlatManifold](classFlatManifold.html) case), and then taking the closest intersection between the topological shape and the line passing through the resulting point, along the direction used at construction time. In this way, the user will have a higher control on the projection direction to be enforced to ensure good mesh quality.\n\n![](images/steps/developer/step-54.DirectionalProjection.png)\n\nOf course the latter approach is effective only when the orientation of the surface is rather uniform, so that a single projection direction can be identified. In cases in which the surface direction is approaching the projection direction, it is even possible that the directional projection is not found. To overcome these problems, the [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) class implements a third projection algorithm. The [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) class is built assigning a `TopoDS_Shape` (containing at least one face) to the constructor, and works exactly like a OpenCASCADE::DirectionalProjection. But, as the name of the class suggests, [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) tries to come up with a suitable estimate of the direction normal to the mesh elements to be refined, and uses it for the projection of the new nodes onto the CAD surface. If we consider a mesh edge in a 2D space, the direction of its axis is a direction along which to split it in order to give rise to two new cells of the same length. We here extended this concept in 3D, and project all new nodes in a direction that approximates the cell normal.\n\nIn the next figure, which is inspired by the geometry considered in this tutorial, we make an attempt to compare the behavior of the three projectors considered. As can be seen on the left, given the original cell (in blue), the new point found with the normal projection is in a position which does not allow for the generation of evenly spaced new elements (in red). The situation will get worse in further refinement steps. Since the geometry we considered is somehow perpendicular to the horizontal direction, the directional projection (central image) defined with horizontal direction as the projection direction, does a rather good job in getting the new mesh point. Yet, since the surface is almost horizontal at the bottom of the picture, we can expect problems in those regions when further refinement steps are carried out. Finally, the picture on the right shows that a node located on the cell axis will result in two new cells having the same length. Of course the situation in 3D gets a little more complicated than that described in this simple 2D case. Nevertheless, the results of this test confirm that the normal to the mesh direction is the best approach among the three tested, when arbitrarily shaped surfaces are considered, and unless you have a geometry for which a more specific approach is known to be appropriate.\n\n![](images/steps/developer/step-54.ProjectionComparisons.png)\n\n### The testcase\n\nIn this program, we will consider creating a surface mesh for a real geometry describing the bow of a ship (this geometry is frequently used in CAD and mesh generation comparisons and is freely available). The surface mesh we get from this could then be used to solve a boundary element equation to simulate the flow of water around the ship (in a way similar to [step-34](step_34.html)) but we will not try to do this here. To already give you an idea of the geometry we consider, here is a picture:\n\n![](images/steps/developer/step-54.bare.png)\n\nIn the program, we read both the geometry and a coarse mesh from files, and then employ several of the options discussed above to place new vertices for a sequence of mesh refinement steps.\n\nThe commented program\n=====================\n\n### Include files\n\nWe start with including a bunch of files that we will use in the various parts of the program. Most of them have been discussed in previous tutorials already:\n\n```\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_in.h>\n   #include <deal.II/grid/grid_out.h>\n   #include <deal.II/numerics/data_out.h>\n```\n\nThese are the headers of the opencascade support classes and functions. Notice that these will contain sensible data only if you compiled your deal.II library with support for [OpenCASCADE](namespaceOpenCASCADE.html), i.e., specifying `-DDEAL_II_WITH_OPENCASCADE=ON` and `-DOPENCASCADE_DIR=/path/to/your/opencascade/installation` when calling `cmake` during deal.II configuration.\n\n```\n   #include <deal.II/opencascade/manifold_lib.h>\n   #include <deal.II/opencascade/utilities.h>\n```\n\nFinally, a few C++ standard header files\n\n```\n   #include <cmath>\n   #include <iostream>\n   #include <fstream>\n   #include <string>\n```\n\nWe isolate the rest of the program in its own namespace\n\n```\n   namespace Step54\n   {\n     using namespace dealii;\n```\n\n### The TriangulationOnCAD class\n\nThis is the main class. All it really does is store names for input and output files, and a triangulation. It then provides a function that generates such a triangulation from a coarse mesh, using one of the strategies discussed in the introduction and listed in the enumeration type at the top of the class.\n\nThe member functions of this class are similar to what you can find in most of the other tutorial programs in the setup stage of the grid for the simulations.\n\n```\n     class TriangulationOnCAD\n     {\n     public:\n       enum ProjectionType\n       {\n         NormalProjection       = 0,\n         DirectionalProjection  = 1,\n         NormalToMeshProjection = 2\n       };\n   \n   \n       TriangulationOnCAD(\n         const std::string   &initial_mesh_filename,\n         const std::string   &cad_file_name,\n         const std::string   &output_filename,\n         const ProjectionType surface_projection_kind = NormalProjection);\n   \n       void run();\n   \n     private:\n       void read_domain();\n   \n       void refine_mesh();\n   \n       void output_results(const unsigned int cycle);\n   \n       Triangulation<2, 3> tria;\n   \n       const std::string initial_mesh_filename;\n       const std::string cad_file_name;\n       const std::string output_filename;\n   \n       const ProjectionType surface_projection_kind;\n     };\n```\n\n#### TriangulationOnCAD::TriangulationOnCAD\n\nThe constructor of the TriangulationOnCAD class is very simple. The input arguments are strings for the input and output file names, and the enumeration type that determines which kind of surface projector is used in the mesh refinement cycles (see below for details).\n\n```\n     TriangulationOnCAD::TriangulationOnCAD(\n       const std::string   &initial_mesh_filename,\n       const std::string   &cad_file_name,\n       const std::string   &output_filename,\n       const ProjectionType surface_projection_kind)\n       : initial_mesh_filename(initial_mesh_filename)\n       , cad_file_name(cad_file_name)\n       , output_filename(output_filename)\n       , surface_projection_kind(surface_projection_kind)\n     {}\n```\n\n#### TriangulationOnCAD::read\\_domain\n\nThe following function represents the core of this program. In this function we import the CAD shape upon which we want to generate and refine our triangulation. We assume that the CAD surface is contained in the `cad_file_name` file (we provide an example IGES file in the input directory called \"input/DTMB-5415\\_bulbous\\_bow.iges\" that represents the bulbous bow of a ship). The presence of several convex and concave high curvature regions makes the geometry we provided a particularly meaningful example.\n\nAfter importing the hull bow surface, we extract some of the curves and surfaces composing it, and use them to generate a set of projectors. Such projectors define the rules the [Triangulation](classTriangulation.html) has to follow to position each new node during cell refinement.\n\nTo initialize the [Triangulation](classTriangulation.html), as done in previous tutorial programs, we import a pre-existing grid saved in VTK format. We assume here that the user has generated a coarse mesh externally, which matches the IGES geometry. At the moment of writing this tutorial, the deal.II library does not automatically support generation of such meshes, but there are several tools which can provide you with reasonable initial meshes starting from CAD files. In our example, the imported mesh is composed of a single quadrilateral cell whose vertices have been placed on the CAD shape.\n\nAfter importing both the IGES geometry and the initial mesh, we assign the projectors previously discussed to each of the edges and cells which will have to be refined on the CAD surface.\n\nIn this tutorial, we will test the three different CAD surface projectors described in the introduction, and will analyze the results obtained with each of them. As mentioned, each of these projection strategies has been implemented in a different class, and objects of these types can be assigned to a triangulation using the [Triangulation::set\\_manifold](group__manifold.html#ga9f9d720f5fbdcdf3dcbb445feefbdb9f) method.\n\nThe following function then first imports the given CAD file. The function arguments are a string containing the desired file name, and a scale factor. In this example, the scale factor is set to 1e-3, as the original geometry is written in millimeters (which is the typical unit of measure for most IGES files), while we prefer to work in meters. The output of the function is an object of [OpenCASCADE](namespaceOpenCASCADE.html) generic topological shape class, namely a `TopoDS_Shape`.\n\n```\n     void TriangulationOnCAD::read_domain()\n     {\n       TopoDS_Shape bow_surface = OpenCASCADE::read_IGES(cad_file_name, 1e-3);\n       std::cout << \" Read \" << cad_file_name << std::endl;\n```\n\nEach CAD geometrical object is defined along with a tolerance, which indicates possible inaccuracy of its placement. For instance, the tolerance `tol` of a vertex indicates that it can be located in any point contained in a sphere centered in the nominal position and having radius `tol`. While projecting a point onto a surface (which will in turn have its tolerance) we must keep in mind that the precision of the projection will be limited by the tolerance with which the surface is built.\n\nThe following method extracts the tolerance of the given shape and makes it a bit bigger to stay our of trouble:\n\n```\n       const double tolerance = OpenCASCADE::get_shape_tolerance(bow_surface) * 5;\n```\n\nWe now want to extract a set of composite sub-shapes from the generic shape. In particular, each face of the CAD file is composed of a trimming curve of type `TopoDS_Wire`, which is the collection of `TopoDS_Edges` that compose the boundary of a surface, and a NURBS description of the surface itself. We will use a line projector to associate the boundary of our [Triangulation](classTriangulation.html) to the wire delimiting the surface. To extract all compound sub-shapes, like wires, shells, or solids, we resort to a method of the [OpenCASCADE](namespaceOpenCASCADE.html) namespace. The input of [OpenCASCADE::extract\\_compound\\_shapes](namespaceOpenCASCADE.html#a1e49f50433c835c841eed35f40862560) is a shape and a set of empty std::vectors of subshapes, which will be filled with all compound shapes found in the given topological shape:\n\n```\n       std::vector<TopoDS_Compound>  compounds;\n       std::vector<TopoDS_CompSolid> compsolids;\n       std::vector<TopoDS_Solid>     solids;\n       std::vector<TopoDS_Shell>     shells;\n       std::vector<TopoDS_Wire>      wires;\n   \n       OpenCASCADE::extract_compound_shapes(\n         bow_surface, compounds, compsolids, solids, shells, wires);\n```\n\nThe next few steps are more familiar, and allow us to import an existing mesh from an external VTK file, and convert it to a deal triangulation.\n\n```\n       std::ifstream in;\n   \n       in.open(initial_mesh_filename);\n   \n       GridIn<2, 3> gi;\n       gi.attach_triangulation(tria);\n       gi.read_vtk(in);\n```\n\nWe output this initial mesh saving it as the refinement step 0.\n\n```\n       output_results(0);\n```\n\nThe mesh imported has a single, two-dimensional cell located in three-dimensional space. We now want to ensure that it is refined according to the CAD geometry imported above. This this end, we get an iterator to that cell and assign to it the manifold\\_id 1 (see [this glossary entry](DEALGlossary.html#GlossManifoldIndicator)). We also get an iterator to its four faces, and assign each of them the manifold\\_id 2:\n\n```\n       Triangulation<2, 3>::active_cell_iterator cell = tria.begin_active();\n       cell->set_manifold_id(1);\n   \n       for (const auto &face : cell->face_iterators())\n         face->set_manifold_id(2);\n```\n\nOnce both the CAD geometry and the initial mesh have been imported and digested, we use the CAD surfaces and curves to define the projectors and assign them to the manifold ids just specified.\n\nA first projector is defined using the single wire contained in our CAD file. The ArclengthProjectionLineManifold will make sure that every mesh edge located on the wire is refined with a point that lies on the wire and splits it into two equal arcs lying between the edge vertices. We first check that the wires vector contains at least one element and then create a [Manifold](classManifold.html) object for it.\n\nOnce the projector is created, we then assign it to all the parts of the triangulation with manifold\\_id = 2:\n\n```\n       Assert(\n         wires.size() > 0,\n         ExcMessage(\n           \"I could not find any wire in the CAD file you gave me. Bailing out.\"));\n   \n       OpenCASCADE::ArclengthProjectionLineManifold<2, 3> line_projector(\n         wires[0], tolerance);\n   \n       tria.set_manifold(2, line_projector);\n```\n\nThe surface projector is created according to what is specified with the `surface_projection_kind` option of the constructor. In particular, if the surface\\_projection\\_kind value equals `NormalProjection`, we select the [OpenCASCADE::NormalProjectionManifold](classOpenCASCADE_1_1NormalProjectionManifold.html). The new mesh points will then initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along its normal direction. The NormalProjectionManifold constructor only needs a shape and a tolerance, and we then assign it to the triangulation for use with all parts that manifold having id 1:\n\n```\n       switch (surface_projection_kind)\n         {\n           case NormalProjection:\n             {\n               OpenCASCADE::NormalProjectionManifold<2, 3> normal_projector(\n                 bow_surface, tolerance);\n               tria.set_manifold(1, normal_projector);\n   \n               break;\n             }\n```\n\n`If` surface\\_projection\\_kind value is `DirectionalProjection`, we select the [OpenCASCADE::DirectionalProjectionManifold](classOpenCASCADE_1_1DirectionalProjectionManifold.html) class. The new mesh points will then initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along a direction that is specified to the [OpenCASCADE::DirectionalProjectionManifold](classOpenCASCADE_1_1DirectionalProjectionManifold.html) constructor. In this case, the projection is done along the y-axis.\n\n```\n           case DirectionalProjection:\n             {\n               OpenCASCADE::DirectionalProjectionManifold<2, 3>\n                 directional_projector(bow_surface,\n                                       Point<3>(0.0, 1.0, 0.0),\n                                       tolerance);\n               tria.set_manifold(1, directional_projector);\n   \n               break;\n             }\n```\n\nAs a third option, if `surface_projection_kind` value is `NormalToMeshProjection`, we select the [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html). The new mesh points will again initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along a direction that is an estimate of the mesh normal direction. The [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) constructor only requires a shape (containing at least a face) and a tolerance.\n\n```\n           case NormalToMeshProjection:\n             {\n               OpenCASCADE::NormalToMeshProjectionManifold<2, 3>\n                 normal_to_mesh_projector(bow_surface, tolerance);\n               tria.set_manifold(1, normal_to_mesh_projector);\n   \n               break;\n             }\n```\n\nFinally, we use good software cleanliness by ensuring that this really covers all possible options of the `case` statement. If we get any other value, we simply abort the program:\n\n```\n           default:\n             AssertThrow(false, ExcInternalError());\n         }\n     }\n```\n\n#### TriangulationOnCAD::refine\\_mesh\n\nThis function globally refines the mesh. In other tutorials, it would typically also distribute degrees of freedom, and resize matrices and vectors. These tasks are not carried out here, since we are not running any simulation on the [Triangulation](classTriangulation.html) produced.\n\nWhile the function looks innocent, this is where most of the work we are interested in for this tutorial program actually happens. In particular, when refining the quads and lines that define the surface of the ship's hull, the [Triangulation](classTriangulation.html) class will ask the various objects we have assigned to handle individual manifold ids for where the new vertices should lie.\n\n```\n     void TriangulationOnCAD::refine_mesh()\n     {\n       tria.refine_global(1);\n     }\n```\n\n#### TriangulationOnCAD::output\\_results\n\nOutputting the results of our computations is a rather mechanical task. All the components of this function have been discussed before:\n\n```\n     void TriangulationOnCAD::output_results(const unsigned int cycle)\n     {\n       const std::string filename =\n         (output_filename + \"_\" + Utilities::int_to_string(cycle) + \".vtk\");\n       std::ofstream vtk_file(filename);\n       GridOut       grid_out;\n       grid_out.write_vtk(tria, vtk_file);\n       std::cout << \" Wrote \" << filename << std::endl;\n     }\n```\n\n#### TriangulationOnCAD::run\n\nThis is the main function. It should be self explanatory in its briefness:\n\n```\n     void TriangulationOnCAD::run()\n     {\n       read_domain();\n   \n       const unsigned int n_cycles = 5;\n       for (unsigned int cycle = 0; cycle < n_cycles; ++cycle)\n         {\n           refine_mesh();\n           output_results(cycle + 1);\n         }\n     }\n   } // namespace Step54\n```\n\n### The main() function\n\nThis is the main function of this program. It is in its basic structure like all previous tutorial programs, but runs the main class through the three possibilities of new vertex placement:\n\n```\n   int main()\n   {\n     try\n       {\n         using namespace Step54;\n   \n         const std::string in_mesh_filename = \"input/initial_mesh_3d.vtk\";\n         const std::string cad_file_name    = \"input/DTMB-5415_bulbous_bow.iges\";\n   \n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << \"Testing projection in direction normal to CAD surface\"\n                   << std::endl;\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::string        out_mesh_filename = (\"3d_mesh_normal_projection\");\n         TriangulationOnCAD tria_on_cad_norm(in_mesh_filename,\n                                             cad_file_name,\n                                             out_mesh_filename,\n                                             TriangulationOnCAD::NormalProjection);\n         tria_on_cad_norm.run();\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << std::endl;\n         std::cout << std::endl;\n   \n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << \"Testing projection in y-axis direction\" << std::endl;\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         out_mesh_filename = (\"3d_mesh_directional_projection\");\n         TriangulationOnCAD tria_on_cad_dir(\n           in_mesh_filename,\n           cad_file_name,\n           out_mesh_filename,\n           TriangulationOnCAD::DirectionalProjection);\n         tria_on_cad_dir.run();\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << std::endl;\n         std::cout << std::endl;\n   \n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << \"Testing projection in direction normal to mesh elements\"\n                   << std::endl;\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         out_mesh_filename = (\"3d_mesh_normal_to_mesh_projection\");\n         TriangulationOnCAD tria_on_cad_norm_to_mesh(\n           in_mesh_filename,\n           cad_file_name,\n           out_mesh_filename,\n           TriangulationOnCAD::NormalToMeshProjection);\n         tria_on_cad_norm_to_mesh.run();\n         std::cout << \"----------------------------------------------------------\"\n                   << std::endl;\n         std::cout << std::endl;\n         std::cout << std::endl;\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nThe program execution produces a series of mesh files `3d_mesh_*.vtk` that we can visualize with any of the usual visualization programs that can read the VTK file format.\n\nThe following table illustrates the results obtained employing the normal projection strategy. The first two rows of the table show side views of the grids obtained for progressive levels of refinement, overlain on a very fine rendering of the exact geometry. The dark and light red areas simply indicate whether the current mesh or the fine geometry is closer to the observer; the distinction does not carry any particularly deep meaning. The last row of pictures depict front views (mirrored to both sides of the geometry) of the same grids shown in the second row.\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n\nAs can be seen in the pictures—and as we anticipated—the normal refinement strategy is unable to produce nicely shaped elements when applied to surfaces with significant curvature changes. This is particularly apparent at the bulb of the hull where all new points have been placed in the upper part of the bulb and the lower part remains completely unresolved.\n\nThe following table, which is arranged as the previous one, illustrates the results obtained adopting the directional projection approach, in which the projection direction selected was the y-axis (which is indicated with a small yellow arrow at the bottom left of each image).\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n\nThe images confirm that the quality of the mesh obtained with a directional projection is sensibly higher than that obtained projecting along the surface normal. Yet, a number of elements elongated in the y-direction are observed around the bottom of the bulb, where the surface is almost parallel to the direction chosen for the projection.\n\nThe final test shows results using instead the projection normal to the faces:\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n\nThe pictures confirm that the normal to mesh projection approach leads to grids that remain evenly spaced throughout the refinement steps. At the same time, these meshes represent rather well the original geometry even in the bottom region of the bulb, which is not well recovered employing the directional projector or the normal projector.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2014 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n *  Authors: Andrea Mola, Luca Heltai, 2014\n */\n \n \n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_in.h>\n#include <deal.II/grid/grid_out.h>\n#include <deal.II/numerics/data_out.h>\n \n#include <deal.II/opencascade/manifold_lib.h>\n#include <deal.II/opencascade/utilities.h>\n \n \n#include <cmath>\n#include <iostream>\n#include <fstream>\n#include <string>\n \nnamespace Step54\n{\n using namespace dealii;\n \n \n \n \n \n class TriangulationOnCAD\n  {\n public:\n enum ProjectionType\n    {\n      NormalProjection       = 0,\n      DirectionalProjection  = 1,\n      NormalToMeshProjection = 2\n    };\n \n \n    TriangulationOnCAD(\n const std::string   &initial_mesh_filename,\n const std::string   &cad_file_name,\n const std::string   &output_filename,\n const ProjectionType surface_projection_kind = NormalProjection);\n \n void run();\n \n private:\n void read_domain();\n \n void refine_mesh();\n \n void output_results(const unsigned int cycle);\n \n Triangulation<2, 3> tria;\n \n const std::string initial_mesh_filename;\n const std::string cad_file_name;\n const std::string output_filename;\n \n const ProjectionType surface_projection_kind;\n  };\n \n \n \n \n  TriangulationOnCAD::TriangulationOnCAD(\n const std::string   &initial_mesh_filename,\n const std::string   &cad_file_name,\n const std::string   &output_filename,\n const ProjectionType surface_projection_kind)\n    : initial_mesh_filename(initial_mesh_filename)\n    , cad_file_name(cad_file_name)\n    , output_filename(output_filename)\n    , surface_projection_kind(surface_projection_kind)\n  {}\n \n \n \n \n void TriangulationOnCAD::read_domain()\n  {\n    TopoDS_Shape bow_surface = OpenCASCADE::read_IGES(cad_file_name, 1e-3);\n    std::cout << \" Read \" << cad_file_name << std::endl;\n \n \n const double tolerance = OpenCASCADE::get_shape_tolerance(bow_surface) * 5;\n \n    std::vector<TopoDS_Compound>  compounds;\n    std::vector<TopoDS_CompSolid> compsolids;\n    std::vector<TopoDS_Solid>     solids;\n    std::vector<TopoDS_Shell>     shells;\n    std::vector<TopoDS_Wire>      wires;\n \n OpenCASCADE::extract_compound_shapes(\n      bow_surface, compounds, compsolids, solids, shells, wires);\n \n    std::ifstream in;\n \n    in.open(initial_mesh_filename);\n \n GridIn<2, 3> gi;\n    gi.attach_triangulation(tria);\n    gi.read_vtk(in);\n \n    output_results(0);\n \n Triangulation<2, 3>::active_cell_iterator cell = tria.begin_active();\n    cell->set_manifold_id(1);\n \n for (const auto &face : cell->face_iterators())\n      face->set_manifold_id(2);\n \n \n Assert(\n      wires.size() > 0,\n      ExcMessage(\n \"I could not find any wire in the CAD file you gave me. Bailing out.\"));\n \n OpenCASCADE::ArclengthProjectionLineManifold<2, 3> line_projector(\n      wires[0], tolerance);\n \n    tria.set_manifold(2, line_projector);\n \n switch (surface_projection_kind)\n      {\n case NormalProjection:\n          {\n OpenCASCADE::NormalProjectionManifold<2, 3> normal_projector(\n              bow_surface, tolerance);\n            tria.set_manifold(1, normal_projector);\n \n break;\n          }\n \n case DirectionalProjection:\n          {\n OpenCASCADE::DirectionalProjectionManifold<2, 3>\n              directional_projector(bow_surface,\n Point<3>(0.0, 1.0, 0.0),\n                                    tolerance);\n            tria.set_manifold(1, directional_projector);\n \n break;\n          }\n \n case NormalToMeshProjection:\n          {\n OpenCASCADE::NormalToMeshProjectionManifold<2, 3>\n              normal_to_mesh_projector(bow_surface, tolerance);\n            tria.set_manifold(1, normal_to_mesh_projector);\n \n break;\n          }\n \n default:\n AssertThrow(false, ExcInternalError());\n      }\n  }\n \n \n \n void TriangulationOnCAD::refine_mesh()\n  {\n    tria.refine_global(1);\n  }\n \n \n \n \n void TriangulationOnCAD::output_results(const unsigned int cycle)\n  {\n const std::string filename =\n      (output_filename + \"_\" + Utilities::int_to_string(cycle) + \".vtk\");\n    std::ofstream vtk_file(filename);\n GridOut       grid_out;\n    grid_out.write_vtk(tria, vtk_file);\n    std::cout << \" Wrote \" << filename << std::endl;\n  }\n \n \n \n void TriangulationOnCAD::run()\n  {\n    read_domain();\n \n const unsigned int n_cycles = 5;\n for (unsigned int cycle = 0; cycle < n_cycles; ++cycle)\n      {\n        refine_mesh();\n        output_results(cycle + 1);\n      }\n  }\n} // namespace Step54\n \n \n \nint main()\n{\n try\n    {\n using namespace Step54;\n \n const std::string in_mesh_filename = \"input/initial_mesh_3d.vtk\";\n const std::string cad_file_name    = \"input/DTMB-5415_bulbous_bow.iges\";\n \n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << \"Testing projection in direction normal to CAD surface\"\n                << std::endl;\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::string        out_mesh_filename = (\"3d_mesh_normal_projection\");\n      TriangulationOnCAD tria_on_cad_norm(in_mesh_filename,\n                                          cad_file_name,\n                                          out_mesh_filename,\n                                          TriangulationOnCAD::NormalProjection);\n      tria_on_cad_norm.run();\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << std::endl;\n      std::cout << std::endl;\n \n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << \"Testing projection in y-axis direction\" << std::endl;\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      out_mesh_filename = (\"3d_mesh_directional_projection\");\n      TriangulationOnCAD tria_on_cad_dir(\n        in_mesh_filename,\n        cad_file_name,\n        out_mesh_filename,\n        TriangulationOnCAD::DirectionalProjection);\n      tria_on_cad_dir.run();\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << std::endl;\n      std::cout << std::endl;\n \n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << \"Testing projection in direction normal to mesh elements\"\n                << std::endl;\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      out_mesh_filename = (\"3d_mesh_normal_to_mesh_projection\");\n      TriangulationOnCAD tria_on_cad_norm_to_mesh(\n        in_mesh_filename,\n        cad_file_name,\n        out_mesh_filename,\n        TriangulationOnCAD::NormalToMeshProjection);\n      tria_on_cad_norm_to_mesh.run();\n      std::cout << \"----------------------------------------------------------\"\n                << std::endl;\n      std::cout << std::endl;\n      std::cout << std::endl;\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_55.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving the Stokes problem in parallel.\nTutorial content :\nThis tutorial depends on [step-40](step_40.html), [step-22](step_22.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_55-Intro)    * [Optimal preconditioners](#step_55-Optimalpreconditioners)* [The solver and preconditioner](#step_55-Thesolverandpreconditioner)* [The testcase](#step_55-Thetestcase)- [The commented program](#step_55-CommProg)      * [Linear solvers and preconditioners](#step_55-Linearsolversandpreconditioners)* [Problem setup](#step_55-Problemsetup)* [The main program](#step_55-Themainprogram)* [System Setup](#step_55-SystemSetup)* [Assembly](#step_55-Assembly)* [Solving](#step_55-Solving)* [The rest](#step_55-Therest) | 1. [Results](#step_55-Results)    * [Possibilities for extensions](#step_55-Possibilitiesforextensions)      + [Investigate Trilinos iterations](#step_55-InvestigateTrilinositerations)+ [Solve the Oseen problem instead of the Stokes system](#step_55-SolvetheOseenprobleminsteadoftheStokessystem)+ [Adaptive refinement](#step_55-Adaptiverefinement)- [The plain program](#step_55-PlainProg) |\n\n*This program was contributed by Timo Heister. Special thanks to Sander Rhebergen for the inspiration to finally write this tutorial.*\n\n*This material is based upon work partially supported by National Science Foundation grant DMS1522191 and the Computational Infrastructure in Geodynamics initiative (CIG), through the National Science Foundation under Award No. EAR-0949446 and The University of California-Davis.*\n\n*The authors would like to thank the Isaac Newton Institute for Mathematical Sciences, Cambridge, for support and hospitality during the programme Melt in the Mantle where work on this tutorial was undertaken. This work was supported by EPSRC grant no EP/K032208/1.*\n\nNote\n:   As a prerequisite of this program, you need to have PETSc or Trilinos and the p4est library installed. The installation of deal.II together with these additional libraries is described in the [README](../../readme.html) file.\n\nIntroduction\n============\n\nBuilding on [step-40](step_40.html), this tutorial shows how to solve linear PDEs with several components in parallel using MPI with PETSc or Trilinos for the linear algebra. For this, we return to the Stokes equations as discussed in [step-22](step_22.html). The motivation for writing this tutorial is to provide an intermediate step (pun intended) between [step-40](step_40.html) (parallel Laplace) and [step-32](step_32.html) (parallel coupled Stokes with Boussinesq for a time dependent problem).\n\nThe learning outcomes for this tutorial are:\n\n* You are able to solve PDEs with several variables in parallel and can apply this to different problems.\n* You understand the concept of optimal preconditioners and are able to check this for a particular problem.\n* You are able to construct manufactured solutions using the free computer algreba system SymPy (<https://sympy.org>).\n* You can implement various other tasks for parallel programs: error computation, writing graphical output, etc.\n* You can visualize vector fields, stream lines, and contours of vector quantities.\n\nWe are solving for a velocity \\(\\textbf{u}\\) and pressure \\(p\\) that satisfy the Stokes equation, which reads\n\n\\begin{eqnarray\\*}\n- \\triangle \\textbf{u} + \\nabla p &=& \\textbf{f}, \\\\\n-\\textrm{div}\\; \\textbf{u} &=& 0.\n\\end{eqnarray\\*}\n\n### Optimal preconditioners\n\nMake sure that you read (even better: try) what is described in \"Block Schur\ncomplement preconditioner\" in the \"Possible Extensions\" section in [step-22](step_22.html). Like described there, we are going to solve the block system using a Krylov method and a block preconditioner.\n\nOur goal here is to construct a very simple (maybe the simplest?) optimal preconditioner for the linear system. A preconditioner is called \"optimal\" or \"of optimal complexity\", if the number of iterations of the preconditioned system is independent of the mesh size \\(h\\). You can extend that definition to also require independence of the number of processors used (we will discuss that in the results section), the computational domain and the mesh quality, the test case itself, the polynomial degree of the finite element space, and more.\n\nWhy is a constant number of iterations considered to be \"optimal\"? Assume the discretized PDE gives a linear system with N unknowns. Because the matrix coming from the FEM discretization is sparse, a matrix-vector product can be done in O(N) time. A preconditioner application can also only be O(N) at best (for example doable with multigrid methods). If the number of iterations required to solve the linear system is independent of \\(h\\) (and therefore N), the total cost of solving the system will be O(N). It is not possible to beat this complexity, because even looking at all the entries of the right-hand side already takes O(N) time. For more information see [[79]](citelist.html#CITEREF_elman2005), Chapter 2.5 ([Multigrid](classMultigrid.html)).\n\nThe preconditioner described here is even simpler than the one described in [step-22](step_22.html) and will typically require more iterations and consequently time to solve. When considering preconditioners, optimality is not the only important metric. But an optimal and expensive preconditioner is typically more desirable than a cheaper, non-optimal one. This is because, eventually, as the mesh size becomes smaller and smaller and linear problems become bigger and bigger, the former will eventually beat the latter.\n\n### The solver and preconditioner\n\nWe precondition the linear system\n\n\\begin{eqnarray\\*}\n\\left(\\begin{array}{cc}\nA & B^T \\\\ B & 0\n\\end{array}\\right)\n\\left(\\begin{array}{c}\nU \\\\ P\n\\end{array}\\right)\n=\n\\left(\\begin{array}{c}\nF \\\\ 0\n\\end{array}\\right),\n\\end{eqnarray\\*}\n\nwith the block diagonal preconditioner\n\n\\begin{eqnarray\\*}\nP^{-1}\n=\n\\left(\\begin{array}{cc}\nA & 0 \\\\ 0 & S\n\\end{array}\\right) ^{-1},\n=\n\\left(\\begin{array}{cc}\nA^{-1} & 0 \\\\ 0 & S^{-1}\n\\end{array}\\right),\n\\end{eqnarray\\*}\n\nwhere \\(S=-BA^{-1} B^T\\) is the Schur complement.\n\nWith this choice of \\(P\\), assuming that we handle \\(A^{-1}\\) and \\(S^{-1}\\) exactly (which is an \"idealized\" situation), the preconditioned linear system has three distinct eigenvalues independent of \\(h\\) and is therefore \"optimal\". See section 6.2.1 (especially p. 292) in [[79]](citelist.html#CITEREF_elman2005). For comparison, using the ideal version of the upper block-triangular preconditioner in [step-22](step_22.html) (also used in [step-56](step_56.html)) would have all eigenvalues be equal to one.\n\nWe will use approximations of the inverse operations in \\(P^{-1}\\) that are (nearly) independent of \\(h\\). In this situation, one can again show, that the eigenvalues are independent of \\(h\\). For the Krylov method we choose MINRES, which is attractive for the analysis (iteration count is proven to be independent of \\(h\\), see the remainder of the chapter 6.2.1 in [[79]](citelist.html#CITEREF_elman2005)), great from the computational standpoint (simpler and cheaper than GMRES for example), and applicable (matrix and preconditioner are symmetric).\n\nFor the approximations we will use a CG solve with the [mass matrix](DEALGlossary.html#GlossMassMatrix) in the pressure space for approximating the action of \\(S^{-1}\\). Note that the mass matrix is spectrally equivalent to \\(S\\). We can expect the number of CG iterations to be independent of \\(h\\), even with a simple preconditioner like ILU.\n\nFor the approximation of the velocity block \\(A\\) we will perform a single AMG V-cycle. In practice this choice is not exactly independent of \\(h\\), which can explain the slight increase in iteration numbers. A possible explanation is that the coarsest level will be solved exactly and the number of levels and size of the coarsest matrix is not predictable.\n\n### The testcase\n\nWe will construct a manufactured solution based on the classical Kovasznay problem, see [[134]](citelist.html#CITEREF_kovasznay1948laminar). Here is an image of the solution colored by the x velocity including streamlines of the velocity:\n\n![](images/steps/developer/step-55.solution.png)\n\nWe have to cheat here, though, because we are not solving the non-linear Navier-Stokes equations, but the linear Stokes system without convective term. Therefore, to recreate the exact same solution, we use the method of manufactured solutions with the solution of the Kovasznay problem. This will effectively move the convective term into the right-hand side \\(f\\).\n\nThe right-hand side is computed using the script \"reference.py\" and we use the exact solution for boundary conditions and error computation.\n\nThe commented program\n=====================\n\n```\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/timer.h>\n```\n\nThe following chunk out code is identical to [step-40](step_40.html) and allows switching between PETSc and Trilinos:\n\n```\n   #include <deal.II/lac/generic_linear_algebra.h>\n   \n   /* #define FORCE_USE_OF_TRILINOS */\n   \n   namespace LA\n   {\n   #if defined(DEAL_II_WITH_PETSC) && !defined(DEAL_II_PETSC_WITH_COMPLEX) && \\\n     !(defined(DEAL_II_WITH_TRILINOS) && defined(FORCE_USE_OF_TRILINOS))\n     using namespace dealii::LinearAlgebraPETSc;\n   #  define USE_PETSC_LA\n   #elif defined(DEAL_II_WITH_TRILINOS)\n     using namespace dealii::LinearAlgebraTrilinos;\n   #else\n   #  error DEAL_II_WITH_PETSC or DEAL_II_WITH_TRILINOS required\n   #endif\n   } // namespace LA\n   \n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/solver_gmres.h>\n   #include <deal.II/lac/solver_minres.h>\n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   \n   #include <deal.II/lac/petsc_sparse_matrix.h>\n   #include <deal.II/lac/petsc_vector.h>\n   #include <deal.II/lac/petsc_solver.h>\n   #include <deal.II/lac/petsc_precondition.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/manifold_lib.h>\n   #include <deal.II/grid/grid_tools.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n   \n   #include <deal.II/base/utilities.h>\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/index_set.h>\n   #include <deal.II/lac/sparsity_tools.h>\n   #include <deal.II/distributed/tria.h>\n   #include <deal.II/distributed/grid_refinement.h>\n   \n   #include <cmath>\n   #include <fstream>\n   #include <iostream>\n   \n   namespace Step55\n   {\n     using namespace dealii;\n```\n\n### Linear solvers and preconditioners\n\nWe need a few helper classes to represent our solver strategy described in the introduction.\n\n```\n     namespace LinearSolvers\n     {\n```\n\nThis class exposes the action of applying the inverse of a giving matrix via the function InverseMatrix::vmult(). Internally, the inverse is not formed explicitly. Instead, a linear solver with CG is performed. This class extends the InverseMatrix class in [step-22](step_22.html) with an option to specify a preconditioner, and to allow for different vector types in the vmult function. We use the same mechanism as in [step-31](step_31.html) to convert a run-time exception into a failed assertion should the inner solver not converge.\n\n```\n       template <class Matrix, class Preconditioner>\n       class InverseMatrix : public Subscriptor\n       {\n       public:\n         InverseMatrix(const Matrix &m, const Preconditioner &preconditioner);\n   \n         template <typename VectorType>\n         void vmult(VectorType &dst, const VectorType &src) const;\n   \n       private:\n         const SmartPointer<const Matrix> matrix;\n         const Preconditioner            &preconditioner;\n       };\n   \n   \n       template <class Matrix, class Preconditioner>\n       InverseMatrix<Matrix, Preconditioner>::InverseMatrix(\n         const Matrix         &m,\n         const Preconditioner &preconditioner)\n         : matrix(&m)\n         , preconditioner(preconditioner)\n       {}\n   \n   \n   \n       template <class Matrix, class Preconditioner>\n       template <typename VectorType>\n       void\n       InverseMatrix<Matrix, Preconditioner>::vmult(VectorType       &dst,\n                                                    const VectorType &src) const\n       {\n         SolverControl        solver_control(src.size(), 1e-8 * src.l2_norm());\n         SolverCG<VectorType> cg(solver_control);\n         dst = 0;\n   \n         try\n           {\n             cg.solve(*matrix, dst, src, preconditioner);\n           }\n         catch (std::exception &e)\n           {\n             Assert(false, ExcMessage(e.what()));\n           }\n       }\n```\n\nThe class A template class for a simple block diagonal preconditioner for 2x2 matrices.\n\n```\n       template <class PreconditionerA, class PreconditionerS>\n       class BlockDiagonalPreconditioner : public Subscriptor\n       {\n       public:\n         BlockDiagonalPreconditioner(const PreconditionerA &preconditioner_A,\n                                     const PreconditionerS &preconditioner_S);\n   \n         void vmult(LA::MPI::BlockVector       &dst,\n                    const LA::MPI::BlockVector &src) const;\n   \n       private:\n         const PreconditionerA &preconditioner_A;\n         const PreconditionerS &preconditioner_S;\n       };\n   \n       template <class PreconditionerA, class PreconditionerS>\n       BlockDiagonalPreconditioner<PreconditionerA, PreconditionerS>::\n         BlockDiagonalPreconditioner(const PreconditionerA &preconditioner_A,\n                                     const PreconditionerS &preconditioner_S)\n         : preconditioner_A(preconditioner_A)\n         , preconditioner_S(preconditioner_S)\n       {}\n   \n   \n       template <class PreconditionerA, class PreconditionerS>\n       void BlockDiagonalPreconditioner<PreconditionerA, PreconditionerS>::vmult(\n         LA::MPI::BlockVector       &dst,\n         const LA::MPI::BlockVector &src) const\n       {\n         preconditioner_A.vmult(dst.block(0), src.block(0));\n         preconditioner_S.vmult(dst.block(1), src.block(1));\n       }\n   \n     } // namespace LinearSolvers\n```\n\n### Problem setup\n\nThe following classes represent the right hand side and the exact solution for the test problem.\n\n```\n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       RightHandSide()\n         : Function<dim>(dim + 1)\n       {}\n   \n       virtual void vector_value(const Point<dim> &p,\n                                 Vector<double>   &value) const override;\n     };\n   \n   \n     template <int dim>\n     void RightHandSide<dim>::vector_value(const Point<dim> &p,\n                                           Vector<double>   &values) const\n     {\n       const double R_x = p[0];\n       const double R_y = p[1];\n   \n       constexpr double pi  = numbers::PI;\n       constexpr double pi2 = numbers::PI * numbers::PI;\n```\n\nvelocity\n\n```\n       values[0] = -1.0L / 2.0L * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0) *\n                     std::exp(R_x * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0)) -\n                   0.4 * pi2 * std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                     std::cos(2 * R_y * pi) +\n                   0.1 *\n                     Utilities::fixed_power<2>(-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n                     std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                     std::cos(2 * R_y * pi);\n       values[1] = 0.2 * pi * (-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n                     std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                     std::sin(2 * R_y * pi) -\n                   0.05 *\n                     Utilities::fixed_power<3>(-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n                     std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                     std::sin(2 * R_y * pi) / pi;\n```\n\npressure\n\n```\n       values[dim] = 0;\n     }\n   \n   \n     template <int dim>\n     class ExactSolution : public Function<dim>\n     {\n     public:\n       ExactSolution()\n         : Function<dim>(dim + 1)\n       {}\n   \n       virtual void vector_value(const Point<dim> &p,\n                                 Vector<double>   &values) const override;\n     };\n   \n     template <int dim>\n     void ExactSolution<dim>::vector_value(const Point<dim> &p,\n                                           Vector<double>   &values) const\n     {\n       const double R_x = p[0];\n       const double R_y = p[1];\n   \n       constexpr double pi  = numbers::PI;\n       constexpr double pi2 = numbers::PI * numbers::PI;\n```\n\nvelocity\n\n```\n       values[0] = -std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                     std::cos(2 * R_y * pi) +\n                   1;\n       values[1] = (1.0L / 2.0L) * (-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n                   std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n                   std::sin(2 * R_y * pi) / pi;\n```\n\npressure\n\n```\n       values[dim] =\n         -1.0L / 2.0L * std::exp(R_x * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0)) -\n         2.0 *\n           (-6538034.74494422 +\n            0.0134758939981709 * std::exp(4 * std::sqrt(25.0 + 4 * pi2))) /\n           (-80.0 * std::exp(3 * std::sqrt(25.0 + 4 * pi2)) +\n            16.0 * std::sqrt(25.0 + 4 * pi2) *\n              std::exp(3 * std::sqrt(25.0 + 4 * pi2))) -\n         1634508.68623606 * std::exp(-3.0 * std::sqrt(25.0 + 4 * pi2)) /\n           (-10.0 + 2.0 * std::sqrt(25.0 + 4 * pi2)) +\n         (-0.00673794699908547 * std::exp(std::sqrt(25.0 + 4 * pi2)) +\n          3269017.37247211 * std::exp(-3 * std::sqrt(25.0 + 4 * pi2))) /\n           (-8 * std::sqrt(25.0 + 4 * pi2) + 40.0) +\n         0.00336897349954273 * std::exp(1.0 * std::sqrt(25.0 + 4 * pi2)) /\n           (-10.0 + 2.0 * std::sqrt(25.0 + 4 * pi2));\n     }\n```\n\n### The main program\n\nThe main class is very similar to [step-40](step_40.html), except that matrices and vectors are now block versions, and we store a std::vector<IndexSet> for owned and relevant DoFs instead of a single [IndexSet](classIndexSet.html). We have exactly two IndexSets, one for all velocity unknowns and one for all pressure unknowns.\n\n```\n     template <int dim>\n     class StokesProblem\n     {\n     public:\n       StokesProblem(unsigned int velocity_degree);\n   \n       void run();\n   \n     private:\n       void make_grid();\n       void setup_system();\n       void assemble_system();\n       void solve();\n       void refine_grid();\n       void output_results(const unsigned int cycle);\n   \n       const unsigned int velocity_degree;\n       const double       viscosity;\n       MPI_Comm           mpi_communicator;\n   \n       const FESystem<dim>                       fe;\n       parallel::distributed::Triangulation<dim> triangulation;\n       DoFHandler<dim>                           dof_handler;\n   \n       std::vector<IndexSet> owned_partitioning;\n       std::vector<IndexSet> relevant_partitioning;\n   \n       AffineConstraints<double> constraints;\n   \n       LA::MPI::BlockSparseMatrix system_matrix;\n       LA::MPI::BlockSparseMatrix preconditioner_matrix;\n       LA::MPI::BlockVector       locally_relevant_solution;\n       LA::MPI::BlockVector       system_rhs;\n   \n       ConditionalOStream pcout;\n       TimerOutput        computing_timer;\n     };\n   \n   \n   \n     template <int dim>\n     StokesProblem<dim>::StokesProblem(unsigned int velocity_degree)\n       : velocity_degree(velocity_degree)\n       , viscosity(0.1)\n       , mpi_communicator(MPI_COMM_WORLD)\n       , fe(FE_Q<dim>(velocity_degree) ^ dim, FE_Q<dim>(velocity_degree - 1))\n       , triangulation(mpi_communicator,\n                       typename Triangulation<dim>::MeshSmoothing(\n                         Triangulation<dim>::smoothing_on_refinement |\n                         Triangulation<dim>::smoothing_on_coarsening))\n       , dof_handler(triangulation)\n       , pcout(std::cout,\n               (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n       , computing_timer(mpi_communicator,\n                         pcout,\n                         TimerOutput::never,\n                         TimerOutput::wall_times)\n     {}\n```\n\nThe Kovasznay flow is defined on the domain [-0.5, 1.5]^2, which we create by passing the min and max values to [GridGenerator::hyper\\_cube](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403).\n\n```\n     template <int dim>\n     void StokesProblem<dim>::make_grid()\n     {\n       GridGenerator::hyper_cube(triangulation, -0.5, 1.5);\n       triangulation.refine_global(3);\n     }\n```\n\n### System Setup\n\nThe construction of the block matrices and vectors is new compared to [step-40](step_40.html) and is different compared to serial codes like [step-22](step_22.html), because we need to supply the set of rows that belong to our processor.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::setup_system()\n     {\n       TimerOutput::Scope t(computing_timer, \"setup\");\n   \n       dof_handler.distribute_dofs(fe);\n```\n\nPut all dim velocities into block 0 and the pressure into block 1, then reorder the unknowns by block. Finally count how many unknowns we have per block.\n\n```\n       std::vector<unsigned int> stokes_sub_blocks(dim + 1, 0);\n       stokes_sub_blocks[dim] = 1;\n       DoFRenumbering::component_wise(dof_handler, stokes_sub_blocks);\n   \n       const std::vector<types::global_dof_index> dofs_per_block =\n         DoFTools::count_dofs_per_fe_block(dof_handler, stokes_sub_blocks);\n   \n       const unsigned int n_u = dofs_per_block[0];\n       const unsigned int n_p = dofs_per_block[1];\n   \n       pcout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs() << \" (\"\n             << n_u << '+' << n_p << ')' << std::endl;\n```\n\nWe split up the [IndexSet](classIndexSet.html) for locally owned and locally relevant DoFs into two IndexSets based on how we want to create the block matrices and vectors.\n\n```\n       const IndexSet &locally_owned_dofs = dof_handler.locally_owned_dofs();\n       owned_partitioning                 = {locally_owned_dofs.get_view(0, n_u),\n                                             locally_owned_dofs.get_view(n_u, n_u + n_p)};\n   \n       const IndexSet locally_relevant_dofs =\n         DoFTools::extract_locally_relevant_dofs(dof_handler);\n       relevant_partitioning = {locally_relevant_dofs.get_view(0, n_u),\n                                locally_relevant_dofs.get_view(n_u, n_u + n_p)};\n```\n\nSetting up the constraints for boundary conditions and hanging nodes is identical to [step-40](step_40.html). Even though we don't have any hanging nodes because we only perform global refinement, it is still a good idea to put this function call in, in case adaptive refinement gets introduced later.\n\n```\n       {\n         constraints.reinit(locally_owned_dofs, locally_relevant_dofs);\n   \n         const FEValuesExtractors::Vector velocities(0);\n         DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n         VectorTools::interpolate_boundary_values(dof_handler,\n                                                  0,\n                                                  ExactSolution<dim>(),\n                                                  constraints,\n                                                  fe.component_mask(velocities));\n         constraints.close();\n       }\n```\n\nNow we create the system matrix based on a [BlockDynamicSparsityPattern](classBlockDynamicSparsityPattern.html). We know that we won't have coupling between different velocity components (because we use the laplace and not the deformation tensor) and no coupling between pressure with its test functions, so we use a [Table](classTable.html) to communicate this coupling information to [DoFTools::make\\_sparsity\\_pattern](group__constraints.html#ga432d35b9ef18d1802d48b576300b04fd).\n\n```\n       {\n         system_matrix.clear();\n   \n         Table<2, DoFTools::Coupling> coupling(dim + 1, dim + 1);\n         for (unsigned int c = 0; c < dim + 1; ++c)\n           for (unsigned int d = 0; d < dim + 1; ++d)\n             if (c == dim && d == dim)\n               coupling[c][d] = DoFTools::none;\n             else if (c == dim || d == dim || c == d)\n               coupling[c][d] = DoFTools::always;\n             else\n               coupling[c][d] = DoFTools::none;\n   \n         BlockDynamicSparsityPattern dsp(relevant_partitioning);\n   \n         DoFTools::make_sparsity_pattern(\n           dof_handler, coupling, dsp, constraints, false);\n   \n         SparsityTools::distribute_sparsity_pattern(\n           dsp,\n           dof_handler.locally_owned_dofs(),\n           mpi_communicator,\n           locally_relevant_dofs);\n   \n         system_matrix.reinit(owned_partitioning, dsp, mpi_communicator);\n       }\n```\n\nThe preconditioner matrix has a different coupling (we only fill in the 1,1 block with the [mass matrix](DEALGlossary.html#GlossMassMatrix)), otherwise this code is identical to the construction of the system\\_matrix above.\n\n```\n       {\n         preconditioner_matrix.clear();\n   \n         Table<2, DoFTools::Coupling> coupling(dim + 1, dim + 1);\n         for (unsigned int c = 0; c < dim + 1; ++c)\n           for (unsigned int d = 0; d < dim + 1; ++d)\n             if (c == dim && d == dim)\n               coupling[c][d] = DoFTools::always;\n             else\n               coupling[c][d] = DoFTools::none;\n   \n         BlockDynamicSparsityPattern dsp(relevant_partitioning);\n   \n         DoFTools::make_sparsity_pattern(\n           dof_handler, coupling, dsp, constraints, false);\n         SparsityTools::distribute_sparsity_pattern(\n           dsp,\n           Utilities::MPI::all_gather(mpi_communicator,\n                                      dof_handler.locally_owned_dofs()),\n           mpi_communicator,\n           locally_relevant_dofs);\n         preconditioner_matrix.reinit(owned_partitioning, dsp, mpi_communicator);\n       }\n```\n\nFinally, we construct the block vectors with the right sizes. The function call with two std::vector<IndexSet> will create a ghosted vector.\n\n```\n       locally_relevant_solution.reinit(owned_partitioning,\n                                        relevant_partitioning,\n                                        mpi_communicator);\n       system_rhs.reinit(owned_partitioning, mpi_communicator);\n     }\n```\n\n### Assembly\n\nThis function assembles the system matrix, the preconditioner matrix, and the right hand side. The code is pretty standard.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::assemble_system()\n     {\n       TimerOutput::Scope t(computing_timer, \"assembly\");\n   \n       system_matrix         = 0;\n       preconditioner_matrix = 0;\n       system_rhs            = 0;\n   \n       const QGauss<dim> quadrature_formula(velocity_degree + 1);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_gradients |\n                                 update_quadrature_points | update_JxW_values);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<double> system_cell_matrix(dofs_per_cell, dofs_per_cell);\n       FullMatrix<double> preconditioner_cell_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<double>     cell_rhs(dofs_per_cell);\n   \n       const RightHandSide<dim>    right_hand_side;\n       std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim + 1));\n   \n       std::vector<Tensor<2, dim>> grad_phi_u(dofs_per_cell);\n       std::vector<double>         div_phi_u(dofs_per_cell);\n       std::vector<double>         phi_p(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n       const FEValuesExtractors::Vector     velocities(0);\n       const FEValuesExtractors::Scalar     pressure(dim);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             system_cell_matrix         = 0;\n             preconditioner_cell_matrix = 0;\n             cell_rhs                   = 0;\n   \n             fe_values.reinit(cell);\n             right_hand_side.vector_value_list(fe_values.get_quadrature_points(),\n                                               rhs_values);\n             for (unsigned int q = 0; q < n_q_points; ++q)\n               {\n                 for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                   {\n                     grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                     div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                     phi_p[k]      = fe_values[pressure].value(k, q);\n                   }\n   \n                 for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                   {\n                     for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                       {\n                         system_cell_matrix(i, j) +=\n                           (viscosity *\n                              scalar_product(grad_phi_u[i], grad_phi_u[j]) -\n                            div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j]) *\n                           fe_values.JxW(q);\n   \n                         preconditioner_cell_matrix(i, j) += 1.0 / viscosity *\n                                                             phi_p[i] * phi_p[j] *\n                                                             fe_values.JxW(q);\n                       }\n   \n                     const unsigned int component_i =\n                       fe.system_to_component_index(i).first;\n                     cell_rhs(i) += fe_values.shape_value(i, q) *\n                                    rhs_values[q](component_i) * fe_values.JxW(q);\n                   }\n               }\n   \n   \n             cell->get_dof_indices(local_dof_indices);\n             constraints.distribute_local_to_global(system_cell_matrix,\n                                                    cell_rhs,\n                                                    local_dof_indices,\n                                                    system_matrix,\n                                                    system_rhs);\n   \n             constraints.distribute_local_to_global(preconditioner_cell_matrix,\n                                                    local_dof_indices,\n                                                    preconditioner_matrix);\n           }\n   \n       system_matrix.compress(VectorOperation::add);\n       preconditioner_matrix.compress(VectorOperation::add);\n       system_rhs.compress(VectorOperation::add);\n     }\n```\n\n### Solving\n\nThis function solves the linear system with MINRES with a block diagonal preconditioner and AMG for the two diagonal blocks as described in the introduction. The preconditioner applies a v cycle to the 0,0 block and a CG with the mass matrix for the 1,1 block (the Schur complement).\n\n```\n     template <int dim>\n     void StokesProblem<dim>::solve()\n     {\n       TimerOutput::Scope t(computing_timer, \"solve\");\n   \n       LA::MPI::PreconditionAMG prec_A;\n       {\n         LA::MPI::PreconditionAMG::AdditionalData data;\n   \n   #ifdef USE_PETSC_LA\n         data.symmetric_operator = true;\n   #endif\n         prec_A.initialize(system_matrix.block(0, 0), data);\n       }\n   \n       LA::MPI::PreconditionAMG prec_S;\n       {\n         LA::MPI::PreconditionAMG::AdditionalData data;\n   \n   #ifdef USE_PETSC_LA\n         data.symmetric_operator = true;\n   #endif\n         prec_S.initialize(preconditioner_matrix.block(1, 1), data);\n       }\n```\n\nThe InverseMatrix is used to solve for the mass matrix:\n\n```\n       using mp_inverse_t = LinearSolvers::InverseMatrix<LA::MPI::SparseMatrix,\n                                                         LA::MPI::PreconditionAMG>;\n       const mp_inverse_t mp_inverse(preconditioner_matrix.block(1, 1), prec_S);\n```\n\nThis constructs the block preconditioner based on the preconditioners for the individual blocks defined above.\n\n```\n       const LinearSolvers::BlockDiagonalPreconditioner<LA::MPI::PreconditionAMG,\n                                                        mp_inverse_t>\n         preconditioner(prec_A, mp_inverse);\n```\n\nWith that, we can finally set up the linear solver and solve the system:\n\n```\n       SolverControl solver_control(system_matrix.m(),\n                                    1e-10 * system_rhs.l2_norm());\n   \n       SolverMinRes<LA::MPI::BlockVector> solver(solver_control);\n   \n       LA::MPI::BlockVector distributed_solution(owned_partitioning,\n                                                 mpi_communicator);\n   \n       constraints.set_zero(distributed_solution);\n   \n       solver.solve(system_matrix,\n                    distributed_solution,\n                    system_rhs,\n                    preconditioner);\n   \n       pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n             << std::endl;\n   \n       constraints.distribute(distributed_solution);\n```\n\nLike in [step-56](step_56.html), we subtract the mean pressure to allow error computations against our reference solution, which has a mean value of zero.\n\n```\n       locally_relevant_solution = distributed_solution;\n       const double mean_pressure =\n         VectorTools::compute_mean_value(dof_handler,\n                                         QGauss<dim>(velocity_degree + 2),\n                                         locally_relevant_solution,\n                                         dim);\n       distributed_solution.block(1).add(-mean_pressure);\n       locally_relevant_solution.block(1) = distributed_solution.block(1);\n     }\n```\n\n### The rest\n\nThe remainder of the code that deals with mesh refinement, output, and the main loop is pretty standard.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::refine_grid()\n     {\n       TimerOutput::Scope t(computing_timer, \"refine\");\n   \n       triangulation.refine_global();\n     }\n   \n   \n   \n     template <int dim>\n     void StokesProblem<dim>::output_results(const unsigned int cycle)\n     {\n       TimerOutput::Scope t(computing_timer, \"output\");\n   \n       {\n         const ComponentSelectFunction<dim> pressure_mask(dim, dim + 1);\n         const ComponentSelectFunction<dim> velocity_mask(std::make_pair(0, dim),\n                                                          dim + 1);\n   \n         Vector<double>    cellwise_errors(triangulation.n_active_cells());\n         const QGauss<dim> quadrature(velocity_degree + 2);\n   \n         VectorTools::integrate_difference(dof_handler,\n                                           locally_relevant_solution,\n                                           ExactSolution<dim>(),\n                                           cellwise_errors,\n                                           quadrature,\n                                           VectorTools::L2_norm,\n                                           &velocity_mask);\n   \n         const double error_u_l2 =\n           VectorTools::compute_global_error(triangulation,\n                                             cellwise_errors,\n                                             VectorTools::L2_norm);\n   \n         VectorTools::integrate_difference(dof_handler,\n                                           locally_relevant_solution,\n                                           ExactSolution<dim>(),\n                                           cellwise_errors,\n                                           quadrature,\n                                           VectorTools::L2_norm,\n                                           &pressure_mask);\n   \n         const double error_p_l2 =\n           VectorTools::compute_global_error(triangulation,\n                                             cellwise_errors,\n                                             VectorTools::L2_norm);\n   \n         pcout << \"error: u_0: \" << error_u_l2 << \" p_0: \" << error_p_l2\n               << std::endl;\n       }\n   \n   \n       std::vector<std::string> solution_names(dim, \"velocity\");\n       solution_names.emplace_back(\"pressure\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           dim, DataComponentInterpretation::component_is_part_of_vector);\n       data_component_interpretation.push_back(\n         DataComponentInterpretation::component_is_scalar);\n   \n       DataOut<dim> data_out;\n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(locally_relevant_solution,\n                                solution_names,\n                                DataOut<dim>::type_dof_data,\n                                data_component_interpretation);\n   \n       LA::MPI::BlockVector interpolated;\n       interpolated.reinit(owned_partitioning, MPI_COMM_WORLD);\n       VectorTools::interpolate(dof_handler, ExactSolution<dim>(), interpolated);\n   \n       LA::MPI::BlockVector interpolated_relevant(owned_partitioning,\n                                                  relevant_partitioning,\n                                                  MPI_COMM_WORLD);\n       interpolated_relevant = interpolated;\n       {\n         std::vector<std::string> solution_names(dim, \"ref_u\");\n         solution_names.emplace_back(\"ref_p\");\n         data_out.add_data_vector(interpolated_relevant,\n                                  solution_names,\n                                  DataOut<dim>::type_dof_data,\n                                  data_component_interpretation);\n       }\n   \n   \n       Vector<float> subdomain(triangulation.n_active_cells());\n       for (unsigned int i = 0; i < subdomain.size(); ++i)\n         subdomain(i) = triangulation.locally_owned_subdomain();\n       data_out.add_data_vector(subdomain, \"subdomain\");\n   \n       data_out.build_patches();\n   \n       data_out.write_vtu_with_pvtu_record(\n         \"./\", \"solution\", cycle, mpi_communicator, 2);\n     }\n   \n   \n   \n     template <int dim>\n     void StokesProblem<dim>::run()\n     {\n   #ifdef USE_PETSC_LA\n       pcout << \"Running using PETSc.\" << std::endl;\n   #else\n       pcout << \"Running using Trilinos.\" << std::endl;\n   #endif\n       const unsigned int n_cycles = 5;\n       for (unsigned int cycle = 0; cycle < n_cycles; ++cycle)\n         {\n           pcout << \"Cycle \" << cycle << ':' << std::endl;\n   \n           if (cycle == 0)\n             make_grid();\n           else\n             refine_grid();\n   \n           setup_system();\n   \n           assemble_system();\n           solve();\n   \n           if (Utilities::MPI::n_mpi_processes(mpi_communicator) <= 32)\n             output_results(cycle);\n   \n           computing_timer.print_summary();\n           computing_timer.reset();\n   \n           pcout << std::endl;\n         }\n     }\n   } // namespace Step55\n   \n   \n   \n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         using namespace dealii;\n         using namespace Step55;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n   \n         StokesProblem<2> problem(2);\n         problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nAs expected from the discussion above, the number of iterations is independent of the number of processors and only very slightly dependent on \\(h\\):\n\n| PETSc | | number of processors | | | | | | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| cycle | dofs | 1 | 2 | 4 | 8 | 16 | 32 | 64 | 128 |\n| 0 | 659 | 49 | 49 | 49 | 51 | 51 | 51 | 49 | 49 |\n| 1 | 2467 | 52 | 52 | 52 | 52 | 52 | 54 | 54 | 53 |\n| 2 | 9539 | 56 | 56 | 56 | 54 | 56 | 56 | 54 | 56 |\n| 3 | 37507 | 57 | 57 | 57 | 57 | 57 | 56 | 57 | 56 |\n| 4 | 148739 | 58 | 59 | 57 | 59 | 57 | 57 | 57 | 57 |\n| 5 | 592387 | 60 | 60 | 59 | 59 | 59 | 59 | 59 | 59 |\n| 6 | 2364419 | 62 | 62 | 61 | 61 | 61 | 61 | 61 | 61 |\n\n| Trilinos | | number of processors | | | | | | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| cycle | dofs | 1 | 2 | 4 | 8 | 16 | 32 | 64 | 128 |\n| 0 | 659 | 37 | 37 | 37 | 37 | 37 | 37 | 37 | 37 |\n| 1 | 2467 | 92 | 89 | 89 | 82 | 86 | 81 | 78 | 78 |\n| 2 | 9539 | 102 | 99 | 96 | 95 | 95 | 88 | 83 | 95 |\n| 3 | 37507 | 107 | 105 | 104 | 99 | 100 | 96 | 96 | 90 |\n| 4 | 148739 | 112 | 112 | 111 | 111 | 127 | 126 | 115 | 117 |\n| 5 | 592387 | 116 | 115 | 114 | 112 | 118 | 120 | 131 | 130 |\n| 6 | 2364419 | 130 | 126 | 120 | 120 | 121 | 122 | 121 | 123 |\n\nWhile the PETSc results show a constant number of iterations, the iterations increase when using Trilinos. This is likely because of the different settings used for the AMG preconditioner. For performance reasons we do not allow coarsening below a couple thousand unknowns. As the coarse solver is an exact solve (we are using LU by default), a change in number of levels will influence the quality of a V-cycle. Therefore, a V-cycle is closer to an exact solver for smaller problem sizes.\n\n### Possibilities for extensions\n\n#### Investigate Trilinos iterations\n\nPlay with the smoothers, smoothing steps, and other properties for the Trilinos AMG to achieve an optimal preconditioner.\n\n#### Solve the Oseen problem instead of the Stokes system\n\nThis change requires changing the outer solver to GMRES or BiCGStab, because the system is no longer symmetric.\n\nYou can prescribe the exact flow solution as \\(b\\) in the convective term \\(b\n\\cdot \\nabla u\\). This should give the same solution as the original problem, if you set the right hand side to zero.\n\n#### Adaptive refinement\n\nSo far, this tutorial program refines the mesh globally in each step. Replacing the code in StokesProblem::refine\\_grid() by something like\n\n```\nVector<float> estimated_error_per_cell(triangulation.n_active_cells());\n \nFEValuesExtractors::Vector velocities(0);\nKellyErrorEstimator<dim>::estimate(\n  dof_handler,\n QGauss<dim - 1>(fe.degree + 1),\n  std::map<types::boundary_id, const Function<dim> *>(),\n  locally_relevant_solution,\n  estimated_error_per_cell,\n  fe.component_mask(velocities));\nparallel::distributed::GridRefinement::refine_and_coarsen_fixed_number(\n triangulation, estimated_error_per_cell, 0.3, 0.0);\ntriangulation.execute_coarsening_and_refinement();\n```\n\nmakes it simple to explore adaptive mesh refinement.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2016 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Timo Heister, Clemson University, 2016\n */\n \n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/timer.h>\n \n \n#include <deal.II/lac/generic_linear_algebra.h>\n \n/* #define FORCE_USE_OF_TRILINOS */\n \nnamespace LA\n{\n#if defined(DEAL_II_WITH_PETSC) && !defined(DEAL_II_PETSC_WITH_COMPLEX) && \\\n  !(defined(DEAL_II_WITH_TRILINOS) && defined(FORCE_USE_OF_TRILINOS))\n using namespace dealii::LinearAlgebraPETSc;\n#  define USE_PETSC_LA\n#elif defined(DEAL_II_WITH_TRILINOS)\n using namespace dealii::LinearAlgebraTrilinos;\n#else\n#  error DEAL_II_WITH_PETSC or DEAL_II_WITH_TRILINOS required\n#endif\n} // namespace LA\n \n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/solver_gmres.h>\n#include <deal.II/lac/solver_minres.h>\n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n \n#include <deal.II/lac/petsc_sparse_matrix.h>\n#include <deal.II/lac/petsc_vector.h>\n#include <deal.II/lac/petsc_solver.h>\n#include <deal.II/lac/petsc_precondition.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/manifold_lib.h>\n#include <deal.II/grid/grid_tools.h>\n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n \n#include <deal.II/base/utilities.h>\n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/index_set.h>\n#include <deal.II/lac/sparsity_tools.h>\n#include <deal.II/distributed/tria.h>\n#include <deal.II/distributed/grid_refinement.h>\n \n#include <cmath>\n#include <fstream>\n#include <iostream>\n \nnamespace Step55\n{\n using namespace dealii;\n \n \n \n namespace LinearSolvers\n  {\n template <class Matrix, class Preconditioner>\n class InverseMatrix : public Subscriptor\n    {\n public:\n      InverseMatrix(const Matrix &m, const Preconditioner &preconditioner);\n \n template <typename VectorType>\n void vmult(VectorType &dst, const VectorType &src) const;\n \n private:\n const SmartPointer<const Matrix> matrix;\n const Preconditioner            &preconditioner;\n    };\n \n \n template <class Matrix, class Preconditioner>\n    InverseMatrix<Matrix, Preconditioner>::InverseMatrix(\n const Matrix         &m,\n const Preconditioner &preconditioner)\n      : matrix(&m)\n      , preconditioner(preconditioner)\n    {}\n \n \n \n template <class Matrix, class Preconditioner>\n template <typename VectorType>\n void\n    InverseMatrix<Matrix, Preconditioner>::vmult(VectorType       &dst,\n const VectorType &src) const\n {\n SolverControl        solver_control(src.size(), 1e-8 * src.l2_norm());\n SolverCG<VectorType> cg(solver_control);\n      dst = 0;\n \n try\n        {\n          cg.solve(*matrix, dst, src, preconditioner);\n        }\n catch (std::exception &e)\n        {\n Assert(false, ExcMessage(e.what()));\n        }\n    }\n \n \n template <class PreconditionerA, class PreconditionerS>\n class BlockDiagonalPreconditioner : public Subscriptor\n    {\n public:\n      BlockDiagonalPreconditioner(const PreconditionerA &preconditioner_A,\n const PreconditionerS &preconditioner_S);\n \n void vmult(LA::MPI::BlockVector       &dst,\n const LA::MPI::BlockVector &src) const;\n \n private:\n const PreconditionerA &preconditioner_A;\n const PreconditionerS &preconditioner_S;\n    };\n \n template <class PreconditionerA, class PreconditionerS>\n    BlockDiagonalPreconditioner<PreconditionerA, PreconditionerS>::\n      BlockDiagonalPreconditioner(const PreconditionerA &preconditioner_A,\n const PreconditionerS &preconditioner_S)\n      : preconditioner_A(preconditioner_A)\n      , preconditioner_S(preconditioner_S)\n    {}\n \n \n template <class PreconditionerA, class PreconditionerS>\n void BlockDiagonalPreconditioner<PreconditionerA, PreconditionerS>::vmult(\n      LA::MPI::BlockVector       &dst,\n const LA::MPI::BlockVector &src) const\n {\n      preconditioner_A.vmult(dst.block(0), src.block(0));\n      preconditioner_S.vmult(dst.block(1), src.block(1));\n    }\n \n  } // namespace LinearSolvers\n \n \n \n template <int dim>\n class RightHandSide : public Function<dim>\n  {\n public:\n    RightHandSide()\n      : Function<dim>(dim + 1)\n    {}\n \n virtual void vector_value(const Point<dim> &p,\n Vector<double>   &value) const override;\n  };\n \n \n template <int dim>\n void RightHandSide<dim>::vector_value(const Point<dim> &p,\n Vector<double>   &values) const\n {\n const double R_x = p[0];\n const double R_y = p[1];\n \n constexpr double pi  = numbers::PI;\n constexpr double pi2 = numbers::PI * numbers::PI;\n \n    values[0] = -1.0L / 2.0L * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0) *\n std::exp(R_x * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0)) -\n                0.4 * pi2 * std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::cos(2 * R_y * pi) +\n                0.1 *\n Utilities::fixed_power<2>(-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::cos(2 * R_y * pi);\n    values[1] = 0.2 * pi * (-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::sin(2 * R_y * pi) -\n                0.05 *\n Utilities::fixed_power<3>(-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::sin(2 * R_y * pi) / pi;\n \n    values[dim] = 0;\n  }\n \n \n template <int dim>\n class ExactSolution : public Function<dim>\n  {\n public:\n    ExactSolution()\n      : Function<dim>(dim + 1)\n    {}\n \n virtual void vector_value(const Point<dim> &p,\n Vector<double>   &values) const override;\n  };\n \n template <int dim>\n void ExactSolution<dim>::vector_value(const Point<dim> &p,\n Vector<double>   &values) const\n {\n const double R_x = p[0];\n const double R_y = p[1];\n \n constexpr double pi  = numbers::PI;\n constexpr double pi2 = numbers::PI * numbers::PI;\n \n    values[0] = -std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::cos(2 * R_y * pi) +\n                1;\n    values[1] = (1.0L / 2.0L) * (-std::sqrt(25.0 + 4 * pi2) + 5.0) *\n std::exp(R_x * (-std::sqrt(25.0 + 4 * pi2) + 5.0)) *\n std::sin(2 * R_y * pi) / pi;\n \n    values[dim] =\n      -1.0L / 2.0L * std::exp(R_x * (-2 * std::sqrt(25.0 + 4 * pi2) + 10.0)) -\n      2.0 *\n        (-6538034.74494422 +\n         0.0134758939981709 * std::exp(4 * std::sqrt(25.0 + 4 * pi2))) /\n        (-80.0 * std::exp(3 * std::sqrt(25.0 + 4 * pi2)) +\n         16.0 * std::sqrt(25.0 + 4 * pi2) *\n std::exp(3 * std::sqrt(25.0 + 4 * pi2))) -\n      1634508.68623606 * std::exp(-3.0 * std::sqrt(25.0 + 4 * pi2)) /\n        (-10.0 + 2.0 * std::sqrt(25.0 + 4 * pi2)) +\n      (-0.00673794699908547 * std::exp(std::sqrt(25.0 + 4 * pi2)) +\n       3269017.37247211 * std::exp(-3 * std::sqrt(25.0 + 4 * pi2))) /\n        (-8 * std::sqrt(25.0 + 4 * pi2) + 40.0) +\n      0.00336897349954273 * std::exp(1.0 * std::sqrt(25.0 + 4 * pi2)) /\n        (-10.0 + 2.0 * std::sqrt(25.0 + 4 * pi2));\n  }\n \n \n \n template <int dim>\n class StokesProblem\n  {\n public:\n    StokesProblem(unsigned int velocity_degree);\n \n void run();\n \n private:\n void make_grid();\n void setup_system();\n void assemble_system();\n void solve();\n void refine_grid();\n void output_results(const unsigned int cycle);\n \n const unsigned int velocity_degree;\n const double       viscosity;\n MPI_Comm           mpi_communicator;\n \n const FESystem<dim>                       fe;\n parallel::distributed::Triangulation<dim> triangulation;\n DoFHandler<dim>                           dof_handler;\n \n    std::vector<IndexSet> owned_partitioning;\n    std::vector<IndexSet> relevant_partitioning;\n \n AffineConstraints<double> constraints;\n \n    LA::MPI::BlockSparseMatrix system_matrix;\n    LA::MPI::BlockSparseMatrix preconditioner_matrix;\n    LA::MPI::BlockVector       locally_relevant_solution;\n    LA::MPI::BlockVector       system_rhs;\n \n ConditionalOStream pcout;\n TimerOutput        computing_timer;\n  };\n \n \n \n template <int dim>\n  StokesProblem<dim>::StokesProblem(unsigned int velocity_degree)\n    : velocity_degree(velocity_degree)\n    , viscosity(0.1)\n    , mpi_communicator(MPI_COMM_WORLD)\n    , fe(FE_Q<dim>(velocity_degree) ^ dim, FE_Q<dim>(velocity_degree - 1))\n    , triangulation(mpi_communicator,\n                    typename Triangulation<dim>::MeshSmoothing(\n Triangulation<dim>::smoothing_on_refinement |\n Triangulation<dim>::smoothing_on_coarsening))\n    , dof_handler(triangulation)\n    , pcout(std::cout,\n            (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n    , computing_timer(mpi_communicator,\n                      pcout,\n TimerOutput::never,\n TimerOutput::wall_times)\n  {}\n \n \n template <int dim>\n void StokesProblem<dim>::make_grid()\n  {\n GridGenerator::hyper_cube(triangulation, -0.5, 1.5);\n triangulation.refine_global(3);\n  }\n \n template <int dim>\n void StokesProblem<dim>::setup_system()\n  {\n TimerOutput::Scope t(computing_timer, \"setup\");\n \n    dof_handler.distribute_dofs(fe);\n \n    std::vector<unsigned int> stokes_sub_blocks(dim + 1, 0);\n    stokes_sub_blocks[dim] = 1;\n DoFRenumbering::component_wise(dof_handler, stokes_sub_blocks);\n \n const std::vector<types::global_dof_index> dofs_per_block =\n DoFTools::count_dofs_per_fe_block(dof_handler, stokes_sub_blocks);\n \n const unsigned int n_u = dofs_per_block[0];\n const unsigned int n_p = dofs_per_block[1];\n \n    pcout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs() << \" (\"\n          << n_u << '+' << n_p << ')' << std::endl;\n \n const IndexSet &locally_owned_dofs = dof_handler.locally_owned_dofs();\n    owned_partitioning                 = {locally_owned_dofs.get_view(0, n_u),\n                                          locally_owned_dofs.get_view(n_u, n_u + n_p)};\n \n const IndexSet locally_relevant_dofs =\n DoFTools::extract_locally_relevant_dofs(dof_handler);\n    relevant_partitioning = {locally_relevant_dofs.get_view(0, n_u),\n                             locally_relevant_dofs.get_view(n_u, n_u + n_p)};\n \n    {\n      constraints.reinit(locally_owned_dofs, locally_relevant_dofs);\n \n const FEValuesExtractors::Vector velocities(0);\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                               0,\n                                               ExactSolution<dim>(),\n                                               constraints,\n                                               fe.component_mask(velocities));\n      constraints.close();\n    }\n \n    {\n      system_matrix.clear();\n \n Table<2, DoFTools::Coupling> coupling(dim + 1, dim + 1);\n for (unsigned int c = 0; c < dim + 1; ++c)\n for (unsigned int d = 0; d < dim + 1; ++d)\n if (c == dim && d == dim)\n            coupling[c][d] = DoFTools::none;\n else if (c == dim || d == dim || c == d)\n            coupling[c][d] = DoFTools::always;\n else\n            coupling[c][d] = DoFTools::none;\n \n BlockDynamicSparsityPattern dsp(relevant_partitioning);\n \n DoFTools::make_sparsity_pattern(\n        dof_handler, coupling, dsp, constraints, false);\n \n SparsityTools::distribute_sparsity_pattern(\n        dsp,\n        dof_handler.locally_owned_dofs(),\n        mpi_communicator,\n        locally_relevant_dofs);\n \n      system_matrix.reinit(owned_partitioning, dsp, mpi_communicator);\n    }\n \n    {\n      preconditioner_matrix.clear();\n \n Table<2, DoFTools::Coupling> coupling(dim + 1, dim + 1);\n for (unsigned int c = 0; c < dim + 1; ++c)\n for (unsigned int d = 0; d < dim + 1; ++d)\n if (c == dim && d == dim)\n            coupling[c][d] = DoFTools::always;\n else\n            coupling[c][d] = DoFTools::none;\n \n BlockDynamicSparsityPattern dsp(relevant_partitioning);\n \n DoFTools::make_sparsity_pattern(\n        dof_handler, coupling, dsp, constraints, false);\n SparsityTools::distribute_sparsity_pattern(\n        dsp,\n Utilities::MPI::all_gather(mpi_communicator,\n                                   dof_handler.locally_owned_dofs()),\n        mpi_communicator,\n        locally_relevant_dofs);\n      preconditioner_matrix.reinit(owned_partitioning, dsp, mpi_communicator);\n    }\n \n    locally_relevant_solution.reinit(owned_partitioning,\n                                     relevant_partitioning,\n                                     mpi_communicator);\n    system_rhs.reinit(owned_partitioning, mpi_communicator);\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::assemble_system()\n  {\n TimerOutput::Scope t(computing_timer, \"assembly\");\n \n    system_matrix         = 0;\n    preconditioner_matrix = 0;\n    system_rhs            = 0;\n \n const QGauss<dim> quadrature_formula(velocity_degree + 1);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points | update_JxW_values);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<double> system_cell_matrix(dofs_per_cell, dofs_per_cell);\n FullMatrix<double> preconditioner_cell_matrix(dofs_per_cell, dofs_per_cell);\n Vector<double>     cell_rhs(dofs_per_cell);\n \n const RightHandSide<dim>    right_hand_side;\n    std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim + 1));\n \n    std::vector<Tensor<2, dim>> grad_phi_u(dofs_per_cell);\n    std::vector<double>         div_phi_u(dofs_per_cell);\n    std::vector<double>         phi_p(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n const FEValuesExtractors::Vector     velocities(0);\n const FEValuesExtractors::Scalar     pressure(dim);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n          system_cell_matrix         = 0;\n          preconditioner_cell_matrix = 0;\n          cell_rhs                   = 0;\n \n          fe_values.reinit(cell);\n          right_hand_side.vector_value_list(fe_values.get_quadrature_points(),\n                                            rhs_values);\n for (unsigned int q = 0; q < n_q_points; ++q)\n            {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                {\n                  grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                  div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                  phi_p[k]      = fe_values[pressure].value(k, q);\n                }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                    {\n                      system_cell_matrix(i, j) +=\n                        (viscosity *\n                           scalar_product(grad_phi_u[i], grad_phi_u[j]) -\n                         div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j]) *\n                        fe_values.JxW(q);\n \n                      preconditioner_cell_matrix(i, j) += 1.0 / viscosity *\n                                                          phi_p[i] * phi_p[j] *\n                                                          fe_values.JxW(q);\n                    }\n \n const unsigned int component_i =\n                    fe.system_to_component_index(i).first;\n                  cell_rhs(i) += fe_values.shape_value(i, q) *\n                                 rhs_values[q](component_i) * fe_values.JxW(q);\n                }\n            }\n \n \n          cell->get_dof_indices(local_dof_indices);\n          constraints.distribute_local_to_global(system_cell_matrix,\n                                                 cell_rhs,\n                                                 local_dof_indices,\n                                                 system_matrix,\n                                                 system_rhs);\n \n          constraints.distribute_local_to_global(preconditioner_cell_matrix,\n                                                 local_dof_indices,\n                                                 preconditioner_matrix);\n        }\n \n    system_matrix.compress(VectorOperation::add);\n    preconditioner_matrix.compress(VectorOperation::add);\n    system_rhs.compress(VectorOperation::add);\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::solve()\n  {\n TimerOutput::Scope t(computing_timer, \"solve\");\n \n    LA::MPI::PreconditionAMG prec_A;\n    {\n      LA::MPI::PreconditionAMG::AdditionalData data;\n \n#ifdef USE_PETSC_LA\n      data.symmetric_operator = true;\n#endif\n      prec_A.initialize(system_matrix.block(0, 0), data);\n    }\n \n    LA::MPI::PreconditionAMG prec_S;\n    {\n      LA::MPI::PreconditionAMG::AdditionalData data;\n \n#ifdef USE_PETSC_LA\n      data.symmetric_operator = true;\n#endif\n      prec_S.initialize(preconditioner_matrix.block(1, 1), data);\n    }\n \n using mp_inverse_t = LinearSolvers::InverseMatrix<LA::MPI::SparseMatrix,\n                                                      LA::MPI::PreconditionAMG>;\n const mp_inverse_t mp_inverse(preconditioner_matrix.block(1, 1), prec_S);\n \n const LinearSolvers::BlockDiagonalPreconditioner<LA::MPI::PreconditionAMG,\n                                                     mp_inverse_t>\n      preconditioner(prec_A, mp_inverse);\n \n SolverControl solver_control(system_matrix.m(),\n                                 1e-10 * system_rhs.l2_norm());\n \n SolverMinRes<LA::MPI::BlockVector> solver(solver_control);\n \n    LA::MPI::BlockVector distributed_solution(owned_partitioning,\n                                              mpi_communicator);\n \n    constraints.set_zero(distributed_solution);\n \n    solver.solve(system_matrix,\n                 distributed_solution,\n                 system_rhs,\n                 preconditioner);\n \n    pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n          << std::endl;\n \n    constraints.distribute(distributed_solution);\n \n    locally_relevant_solution = distributed_solution;\n const double mean_pressure =\n VectorTools::compute_mean_value(dof_handler,\n QGauss<dim>(velocity_degree + 2),\n                                      locally_relevant_solution,\n                                      dim);\n    distributed_solution.block(1).add(-mean_pressure);\n    locally_relevant_solution.block(1) = distributed_solution.block(1);\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::refine_grid()\n  {\n TimerOutput::Scope t(computing_timer, \"refine\");\n \n triangulation.refine_global();\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::output_results(const unsigned int cycle)\n  {\n TimerOutput::Scope t(computing_timer, \"output\");\n \n    {\n const ComponentSelectFunction<dim> pressure_mask(dim, dim + 1);\n const ComponentSelectFunction<dim> velocity_mask(std::make_pair(0, dim),\n                                                       dim + 1);\n \n Vector<double>    cellwise_errors(triangulation.n_active_cells());\n const QGauss<dim> quadrature(velocity_degree + 2);\n \n VectorTools::integrate_difference(dof_handler,\n                                        locally_relevant_solution,\n                                        ExactSolution<dim>(),\n                                        cellwise_errors,\n                                        quadrature,\n VectorTools::L2_norm,\n                                        &velocity_mask);\n \n const double error_u_l2 =\n VectorTools::compute_global_error(triangulation,\n                                          cellwise_errors,\n VectorTools::L2_norm);\n \n VectorTools::integrate_difference(dof_handler,\n                                        locally_relevant_solution,\n                                        ExactSolution<dim>(),\n                                        cellwise_errors,\n                                        quadrature,\n VectorTools::L2_norm,\n                                        &pressure_mask);\n \n const double error_p_l2 =\n VectorTools::compute_global_error(triangulation,\n                                          cellwise_errors,\n VectorTools::L2_norm);\n \n      pcout << \"error: u_0: \" << error_u_l2 << \" p_0: \" << error_p_l2\n            << std::endl;\n    }\n \n \n    std::vector<std::string> solution_names(dim, \"velocity\");\n    solution_names.emplace_back(\"pressure\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        dim, DataComponentInterpretation::component_is_part_of_vector);\n    data_component_interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n DataOut<dim> data_out;\n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(locally_relevant_solution,\n                             solution_names,\n DataOut<dim>::type_dof_data,\n                             data_component_interpretation);\n \n    LA::MPI::BlockVector interpolated;\n    interpolated.reinit(owned_partitioning, MPI_COMM_WORLD);\n VectorTools::interpolate(dof_handler, ExactSolution<dim>(), interpolated);\n \n    LA::MPI::BlockVector interpolated_relevant(owned_partitioning,\n                                               relevant_partitioning,\n                                               MPI_COMM_WORLD);\n    interpolated_relevant = interpolated;\n    {\n      std::vector<std::string> solution_names(dim, \"ref_u\");\n      solution_names.emplace_back(\"ref_p\");\n      data_out.add_data_vector(interpolated_relevant,\n                               solution_names,\n DataOut<dim>::type_dof_data,\n                               data_component_interpretation);\n    }\n \n \n Vector<float> subdomain(triangulation.n_active_cells());\n for (unsigned int i = 0; i < subdomain.size(); ++i)\n      subdomain(i) = triangulation.locally_owned_subdomain();\n    data_out.add_data_vector(subdomain, \"subdomain\");\n \n    data_out.build_patches();\n \n    data_out.write_vtu_with_pvtu_record(\n \"./\", \"solution\", cycle, mpi_communicator, 2);\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::run()\n  {\n#ifdef USE_PETSC_LA\n    pcout << \"Running using PETSc.\" << std::endl;\n#else\n    pcout << \"Running using Trilinos.\" << std::endl;\n#endif\n const unsigned int n_cycles = 5;\n for (unsigned int cycle = 0; cycle < n_cycles; ++cycle)\n      {\n        pcout << \"Cycle \" << cycle << ':' << std::endl;\n \n if (cycle == 0)\n          make_grid();\n else\n          refine_grid();\n \n        setup_system();\n \n        assemble_system();\n        solve();\n \n if (Utilities::MPI::n_mpi_processes(mpi_communicator) <= 32)\n          output_results(cycle);\n \n        computing_timer.print_summary();\n        computing_timer.reset();\n \n        pcout << std::endl;\n      }\n  }\n} // namespace Step55\n \n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n using namespace dealii;\n using namespace Step55;\n \n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n \n      StokesProblem<2> problem(2);\n      problem.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_56.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nGeometricMultigridfor Stokes.\nTutorial content :\nThis tutorial depends on [step-16](step_16.html), [step-22](step_22.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_56-Intro)    * [Stokes Problem](#step_56-StokesProblem) * [Linear Solver and Preconditioning Issues](#step_56-LinearSolverandPreconditioningIssues) * [Reference Solution](#step_56-ReferenceSolution) * [Computing Errors](#step_56-ComputingErrors) * [DoF Handlers](#step_56-DoFHandlers) * [Differences from the Step 22 tutorial](#step_56-DifferencesfromtheStep22tutorial)- [The commented program](#step_56-CommProg)      * [Include files](#step_56-Includefiles)* [Functions for Solution and Righthand side](#step_56-FunctionsforSolutionandRighthandside)* [ASPECT BlockSchurPreconditioner](#step_56-ASPECTBlockSchurPreconditioner)* [The StokesProblem class](#step_56-TheStokesProblemclass)              + [StokesProblem::setup\\_dofs](#step_56-StokesProblemsetup_dofs)+ [StokesProblem::assemble\\_system](#step_56-StokesProblemassemble_system)+ [StokesProblem::assemble\\_multigrid](#step_56-StokesProblemassemble_multigrid)+ [StokesProblem::solve](#step_56-StokesProblemsolve)+ [StokesProblem::process\\_solution](#step_56-StokesProblemprocess_solution)+ [StokesProblem::output\\_results](#step_56-StokesProblemoutput_results)+ [StokesProblem::run](#step_56-StokesProblemrun)* [The main function](#step_56-Themainfunction) | 1. [Results](#step_56-Results)    * [Errors](#step_56-Errors) * [Timing Results](#step_56-TimingResults) * [Possibilities for extensions](#step_56-Possibilitiesforextensions)           + [Check higher order discretizations](#step_56-Checkhigherorderdiscretizations) + [Compare with cheap preconditioner](#step_56-Comparewithcheappreconditioner)- [The plain program](#step_56-PlainProg) |\n\n*This program was contributed by Ryan Grove and Timo Heister.*\n\n*This material is based upon work partially supported by National Science Foundation grant DMS1522191 and the Computational Infrastructure in Geodynamics initiative (CIG), through the National Science Foundation under Award No. EAR-0949446 and The University of California-Davis.*\n\n*The authors would like to thank the Isaac Newton Institute for Mathematical Sciences, Cambridge, for support and hospitality during the programme Melt in the Mantle where work on this tutorial was undertaken. This work was supported by EPSRC grant no EP/K032208/1.*\n\nNote\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.400995](https://zenodo.org/badge/DOI/10.5281/zenodo.400995.svg)](https://doi.org/10.5281/zenodo.400995)\n\nIntroduction\n============\n\n### Stokes Problem\n\nThe purpose of this tutorial is to create an efficient linear solver for the Stokes equation and compare it to alternative approaches. Here, we will use FGMRES with geometric multigrid as a preconditioner velocity block, and we will show in the results section that this is a fundamentally better approach than the linear solvers used in [step-22](step_22.html) (including the scheme described in \"Possible Extensions\"). Fundamentally, this is because only with multigrid it is possible to get \\(O(n)\\) solve time, where \\(n\\) is the number of unknowns of the linear system. Using the [Timer](classTimer.html) class, we collect some statistics to compare setup times, solve times, and number of iterations. We also compute errors to make sure that what we have implemented is correct.\n\nLet \\(u \\in H\\_0^1 = \\{ u \\in H^1(\\Omega), u|\\_{\\partial \\Omega} = 0 \\}\\) and \\(p \\in L\\_\\*^2 = \\{ p \\in L^2(\\Omega), \\int\\_\\Omega p = 0\n\\}\\). The Stokes equations read as follows in non-dimensionalized form:\n\n\\begin{eqnarray\\*}\n- 2 \\text{div} \\frac {1}{2} \\left[ (\\nabla \\textbf{u})\n+ (\\nabla \\textbf{u})^T\\right] + \\nabla p & =& f \\\\\n- \\nabla \\cdot u &=& 0\n\\end{eqnarray\\*}\n\nNote that we are using the deformation tensor instead of \\(\\Delta u\\) (a detailed description of the difference between the two can be found in [step-22](step_22.html), but in summary, the deformation tensor is more physical as well as more expensive).\n\n### Linear Solver and Preconditioning Issues\n\nThe weak form of the discrete equations naturally leads to the following linear system for the nodal values of the velocity and pressure fields:\n\n\\begin{eqnarray\\*}\n\\left(\\begin{array}{cc} A & B^T \\\\ B & 0\n\\end{array}\\right) \\left(\\begin{array}{c} U \\\\ P \\end{array}\\right) =\n\\left(\\begin{array}{c} F \\\\ 0 \\end{array}\\right).\n\\end{eqnarray\\*}\n\nOur goal is to compare several solution approaches. While [step-22](step_22.html) solves the linear system using a \"Schur complement approach\" in two separate steps, we instead attack the block system at once using FMGRES with an efficient preconditioner, in the spirit of the approach outlined in the \"Results\" section of [step-22](step_22.html). The idea is as follows: if we find a block preconditioner \\(P\\) such that the matrix\n\n\\begin{eqnarray\\*}\n\\left(\\begin{array}{cc} A & B^T \\\\ B & 0 \\end{array}\\right) P^{-1}\n\\end{eqnarray\\*}\n\nis simple, then an iterative solver with that preconditioner will converge in a few iterations. Notice that we are doing right preconditioning here. Using the Schur complement \\(S=BA^{-1}B^T\\), we find that\n\n\\begin{eqnarray\\*}\nP^{-1} = \\left(\\begin{array}{cc} A & B^T \\\\ 0 &\nS \\end{array}\\right)^{-1}\n\\end{eqnarray\\*}\n\nis a good choice. Let \\(\\widetilde{A^{-1}}\\) be an approximation of \\(A^{-1}\\) and \\(\\widetilde{S^{-1}}\\) of \\(S^{-1}\\), we see\n\n\\begin{eqnarray\\*}\nP^{-1} =\n\\left(\\begin{array}{cc} A^{-1} & 0 \\\\ 0 & I \\end{array}\\right)\n\\left(\\begin{array}{cc} I & B^T \\\\ 0 & -I \\end{array}\\right)\n\\left(\\begin{array}{cc} I & 0 \\\\ 0 & S^{-1} \\end{array}\\right)\n\\approx\n\\left(\\begin{array}{cc} \\widetilde{A^{-1}} & 0 \\\\ 0 & I \\end{array}\\right)\n\\left(\\begin{array}{cc} I & B^T \\\\ 0 & -I \\end{array}\\right)\n\\left(\\begin{array}{cc} I & 0 \\\\ 0 & \\widetilde{S^{-1}} \\end{array}\\right).\n\\end{eqnarray\\*}\n\nSince \\(P\\) is aimed to be a preconditioner only, we shall use the approximations on the right in the equation above.\n\nAs discussed in [step-22](step_22.html), \\(-M\\_p^{-1}=:\\widetilde{S^{-1}} \\approx\nS^{-1}\\), where \\(M\\_p\\) is the pressure [mass matrix](DEALGlossary.html#GlossMassMatrix) and is solved approximately by using CG with ILU as a preconditioner, and \\(\\widetilde{A^{-1}}\\) is obtained by one of multiple methods: solving a linear system with CG and ILU as preconditioner, just using one application of an ILU, solving a linear system with CG and GMG (Geometric [Multigrid](classMultigrid.html) as described in [step-16](step_16.html)) as a preconditioner, or just performing a single V-cycle of GMG.\n\nAs a comparison, instead of FGMRES, we also use the direct solver UMFPACK on the whole system to compare our results with. If you want to use a direct solver (like UMFPACK), the system needs to be invertible. To avoid the one dimensional null space given by the constant pressures, we fix the first pressure unknown to zero. This is not necessary for the iterative solvers.\n\n### Reference Solution\n\nThe test problem is a \"Manufactured Solution\" (see [step-7](step_7.html) for details), and we choose \\(u=(u\\_1,u\\_2,u\\_3)=(2\\sin (\\pi x), - \\pi y \\cos\n(\\pi x),- \\pi z \\cos (\\pi x))\\) and \\(p = \\sin (\\pi x)\\cos (\\pi y)\\sin\n(\\pi z)\\). We apply Dirichlet boundary conditions for the velocity on the whole boundary of the domain \\(\\Omega=[0,1]\\times[0,1]\\times[0,1]\\). To enforce the boundary conditions we can just use our reference solution.\n\nIf you look up in the deal.II manual what is needed to create a class derived from `Function<dim>`, you will find that this class has numerous `virtual` functions, including [Function::value()](classFunction.html#acbfcab66b2fc63bfea59268f40772bb4), [Function::vector\\_value()](classFunction.html#ae316ebc05d21989d573024f8a23c49cb), [Function::value\\_list()](classFunction.html#abe86ee7f7f12cf4041d1e714c0fb42f3), etc., all of which can be overloaded. Different parts of deal.II will require different ones of these particular functions. This can be confusing at first, but luckily the only thing you actually have to implement is `value()`. The other virtual functions in the [Function](classFunction.html) class have default implementations inside that will call your implementation of `value` by default.\n\nNotice that our reference solution fulfills \\(\\nabla \\cdot u = 0\\). In addition, the pressure is chosen to have a mean value of zero. For the \"Method of Manufactured Solutions\" of [step-7](step_7.html), we need to find \\(\\bf\nf\\) such that:\n\n\\begin{align\\*}\n{\\bf f} = - 2 \\text{div} \\frac {1}{2} \\left[ (\\nabla \\textbf{u}) + (\\nabla \\textbf{u})^T\\right] + \\nabla p.\n\\end{align\\*}\n\nUsing the reference solution above, we obtain:\n\n\\begin{eqnarray\\*}\n{\\bf f} &=& (2 \\pi^2 \\sin (\\pi x),- \\pi^3 y \\cos(\\pi\nx),- \\pi^3 z \\cos(\\pi x))\\\\ & & + (\\pi \\cos(\\pi x) \\cos(\\pi y)\n\\sin(\\pi z) ,- \\pi \\sin(\\pi y) \\sin(\\pi x) \\sin(\\pi z), \\pi \\cos(\\pi\nz) \\sin(\\pi x) \\cos(\\pi y)) \\end{eqnarray\\*}\n\n### Computing Errors\n\nBecause we do not enforce the mean pressure to be zero for our numerical solution in the linear system, we need to post process the solution after solving. To do this we use the [VectorTools::compute\\_mean\\_value()](namespaceVectorTools.html#a70a5364f86637b8304f5d81329de660f) function to compute the mean value of the pressure to subtract it from the pressure.\n\n### DoF Handlers\n\nThe way we implement geometric multigrid here only executes it on the velocity variables (i.e., the \\(A\\) matrix described above) but not the pressure. One could implement this in different ways, including one in which one considers all coarse grid operations as acting on \\(2\\times\n2\\) block systems where we only consider the top left block. Alternatively, we can implement things by really only considering a linear system on the velocity part of the overall finite element discretization. The latter is the way we want to use here.\n\nTo implement this, one would need to be able to ask questions such as \"May I have just part of a DoFHandler?\". This is not possible at the time when this program was written, so in order to answer this request for our needs, we simply create a separate, second [DoFHandler](classDoFHandler.html) for just the velocities. We then build linear systems for the multigrid preconditioner based on only this second [DoFHandler](classDoFHandler.html), and simply transfer the first block of (overall) vectors into corresponding vectors for the entire second [DoFHandler](classDoFHandler.html). To make this work, we have to assure that the *order* in which the (velocity) degrees of freedom are ordered in the two [DoFHandler](classDoFHandler.html) objects is the same. This is in fact the case by first distributing degrees of freedom on both, and then using the same sequence of [DoFRenumbering](namespaceDoFRenumbering.html) operations on both.\n\n### Differences from the Step 22 tutorial\n\nThe main difference between [step-56](step_56.html) and [step-22](step_22.html) is that we use block solvers instead of the Schur Complement approach used in [step-22](step_22.html). Details of this approach can be found under the \"Block Schur\ncomplement preconditioner\" subsection of the \"Possible Extensions\" section of [step-22](step_22.html). For the preconditioner of the velocity block, we borrow a class from [ASPECT](https://aspect.geodynamics.org) called `BlockSchurPreconditioner` that has the option to solve for the inverse of \\(A\\) or just apply one preconditioner sweep for it instead, which provides us with an expensive and cheap approach, respectively.\n\nThe commented program\n=====================\n\n### Include files\n\n```\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/utilities.h>\n   \n   #include <deal.II/lac/block_vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/block_sparse_matrix.h>\n   #include <deal.II/lac/block_sparsity_pattern.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/solver_gmres.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_tools.h>\n   #include <deal.II/grid/grid_refinement.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   \n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n   \n   #include <deal.II/lac/sparse_direct.h>\n   \n   #include <deal.II/lac/sparse_ilu.h>\n   #include <deal.II/grid/grid_out.h>\n```\n\nWe need to include the following file to do timings:\n\n```\n   #include <deal.II/base/timer.h>\n```\n\nThis includes the files necessary for us to use geometric [Multigrid](classMultigrid.html)\n\n```\n   #include <deal.II/multigrid/multigrid.h>\n   #include <deal.II/multigrid/mg_transfer.h>\n   #include <deal.II/multigrid/mg_tools.h>\n   #include <deal.II/multigrid/mg_coarse.h>\n   #include <deal.II/multigrid/mg_smoother.h>\n   #include <deal.II/multigrid/mg_matrix.h>\n   \n   #include <iostream>\n   #include <fstream>\n   \n   namespace Step56\n   {\n     using namespace dealii;\n```\n\nIn order to make it easy to switch between the different solvers that are being used, we declare an enum that can be passed as an argument to the constructor of the main class.\n\n```\n     enum class SolverType\n     {\n       FGMRES_ILU,\n       FGMRES_GMG,\n       UMFPACK\n     };\n```\n\n### [Functions](namespaceFunctions.html) for Solution and Righthand side\n\nThe class Solution is used to define the boundary conditions and to compute errors of the numerical solution. Note that we need to define the values and gradients in order to compute L2 and H1 errors. Here we decided to separate the implementations for 2d and 3d using template specialization.\n\nNote that the first dim components are the velocity components and the last is the pressure.\n\n```\n     template <int dim>\n     class Solution : public Function<dim>\n     {\n     public:\n       Solution()\n         : Function<dim>(dim + 1)\n       {}\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n       virtual Tensor<1, dim>\n       gradient(const Point<dim>  &p,\n                const unsigned int component = 0) const override;\n     };\n   \n     template <>\n     double Solution<2>::value(const Point<2>    &p,\n                               const unsigned int component) const\n     {\n       Assert(component <= 2 + 1, ExcIndexRange(component, 0, 2 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n   \n       if (component == 0)\n         return sin(PI * x);\n       if (component == 1)\n         return -PI * y * cos(PI * x);\n       if (component == 2)\n         return sin(PI * x) * cos(PI * y);\n   \n       return 0;\n     }\n   \n     template <>\n     double Solution<3>::value(const Point<3>    &p,\n                               const unsigned int component) const\n     {\n       Assert(component <= 3 + 1, ExcIndexRange(component, 0, 3 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n       const double z = p[2];\n   \n       if (component == 0)\n         return 2.0 * sin(PI * x);\n       if (component == 1)\n         return -PI * y * cos(PI * x);\n       if (component == 2)\n         return -PI * z * cos(PI * x);\n       if (component == 3)\n         return sin(PI * x) * cos(PI * y) * sin(PI * z);\n   \n       return 0;\n     }\n```\n\nNote that for the gradient we need to return a [Tensor<1,dim>](classTensor.html)\n\n```\n     template <>\n     Tensor<1, 2> Solution<2>::gradient(const Point<2>    &p,\n                                        const unsigned int component) const\n     {\n       Assert(component <= 2, ExcIndexRange(component, 0, 2 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n   \n       Tensor<1, 2> return_value;\n       if (component == 0)\n         {\n           return_value[0] = PI * cos(PI * x);\n           return_value[1] = 0.0;\n         }\n       else if (component == 1)\n         {\n           return_value[0] = y * PI * PI * sin(PI * x);\n           return_value[1] = -PI * cos(PI * x);\n         }\n       else if (component == 2)\n         {\n           return_value[0] = PI * cos(PI * x) * cos(PI * y);\n           return_value[1] = -PI * sin(PI * x) * sin(PI * y);\n         }\n   \n       return return_value;\n     }\n   \n     template <>\n     Tensor<1, 3> Solution<3>::gradient(const Point<3>    &p,\n                                        const unsigned int component) const\n     {\n       Assert(component <= 3, ExcIndexRange(component, 0, 3 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n       const double z = p[2];\n   \n       Tensor<1, 3> return_value;\n       if (component == 0)\n         {\n           return_value[0] = 2 * PI * cos(PI * x);\n           return_value[1] = 0.0;\n           return_value[2] = 0.0;\n         }\n       else if (component == 1)\n         {\n           return_value[0] = y * PI * PI * sin(PI * x);\n           return_value[1] = -PI * cos(PI * x);\n           return_value[2] = 0.0;\n         }\n       else if (component == 2)\n         {\n           return_value[0] = z * PI * PI * sin(PI * x);\n           return_value[1] = 0.0;\n           return_value[2] = -PI * cos(PI * x);\n         }\n       else if (component == 3)\n         {\n           return_value[0] = PI * cos(PI * x) * cos(PI * y) * sin(PI * z);\n           return_value[1] = -PI * sin(PI * x) * sin(PI * y) * sin(PI * z);\n           return_value[2] = PI * sin(PI * x) * cos(PI * y) * cos(PI * z);\n         }\n   \n       return return_value;\n     }\n```\n\nImplementation of \\(f\\). See the introduction for more information.\n\n```\n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       RightHandSide()\n         : Function<dim>(dim + 1)\n       {}\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n     };\n   \n     template <>\n     double RightHandSide<2>::value(const Point<2>    &p,\n                                    const unsigned int component) const\n     {\n       Assert(component <= 2, ExcIndexRange(component, 0, 2 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n       if (component == 0)\n         return PI * PI * sin(PI * x) + PI * cos(PI * x) * cos(PI * y);\n       if (component == 1)\n         return -PI * PI * PI * y * cos(PI * x) - PI * sin(PI * y) * sin(PI * x);\n       if (component == 2)\n         return 0;\n   \n       return 0;\n     }\n   \n     template <>\n     double RightHandSide<3>::value(const Point<3>    &p,\n                                    const unsigned int component) const\n     {\n       Assert(component <= 3, ExcIndexRange(component, 0, 3 + 1));\n   \n       using numbers::PI;\n       const double x = p[0];\n       const double y = p[1];\n       const double z = p[2];\n       if (component == 0)\n         return 2 * PI * PI * sin(PI * x) +\n                PI * cos(PI * x) * cos(PI * y) * sin(PI * z);\n       if (component == 1)\n         return -PI * PI * PI * y * cos(PI * x) +\n                PI * (-1) * sin(PI * y) * sin(PI * x) * sin(PI * z);\n       if (component == 2)\n         return -PI * PI * PI * z * cos(PI * x) +\n                PI * cos(PI * z) * sin(PI * x) * cos(PI * y);\n       if (component == 3)\n         return 0;\n   \n       return 0;\n     }\n```\n\n### ASPECT BlockSchurPreconditioner\n\nIn the following, we will implement a preconditioner that expands on the ideas discussed in the Results section of [step-22](step_22.html). Specifically, we\n\n1. use an upper block-triangular preconditioner because we want to use right preconditioning.\n2. optionally allow using an inner solver for the velocity block instead of a single preconditioner application.\n3. do not use InverseMatrix but explicitly call [SolverCG](classSolverCG.html). This approach is also used in the ASPECT code (see <https://aspect.geodynamics.org>) that solves the Stokes equations in the context of simulating convection in the earth mantle, and which has been used to solve problems on many thousands of processors.\n\nThe bool flag `do_solve_A` in the constructor allows us to either apply the preconditioner for the velocity block once or use an inner iterative solver for a more accurate approximation instead.\n\nNotice how we keep track of the sum of the inner iterations (preconditioner applications).\n\n```\n     template <class PreconditionerAType, class PreconditionerSType>\n     class BlockSchurPreconditioner : public Subscriptor\n     {\n     public:\n       BlockSchurPreconditioner(\n         const BlockSparseMatrix<double> &system_matrix,\n         const SparseMatrix<double>      &schur_complement_matrix,\n         const PreconditionerAType       &preconditioner_A,\n         const PreconditionerSType       &preconditioner_S,\n         const bool                       do_solve_A);\n   \n       void vmult(BlockVector<double> &dst, const BlockVector<double> &src) const;\n   \n       mutable unsigned int n_iterations_A;\n       mutable unsigned int n_iterations_S;\n   \n     private:\n       const BlockSparseMatrix<double> &system_matrix;\n       const SparseMatrix<double>      &schur_complement_matrix;\n       const PreconditionerAType       &preconditioner_A;\n       const PreconditionerSType       &preconditioner_S;\n   \n       const bool do_solve_A;\n     };\n   \n     template <class PreconditionerAType, class PreconditionerSType>\n     BlockSchurPreconditioner<PreconditionerAType, PreconditionerSType>::\n       BlockSchurPreconditioner(\n         const BlockSparseMatrix<double> &system_matrix,\n         const SparseMatrix<double>      &schur_complement_matrix,\n         const PreconditionerAType       &preconditioner_A,\n         const PreconditionerSType       &preconditioner_S,\n         const bool                       do_solve_A)\n       : n_iterations_A(0)\n       , n_iterations_S(0)\n       , system_matrix(system_matrix)\n       , schur_complement_matrix(schur_complement_matrix)\n       , preconditioner_A(preconditioner_A)\n       , preconditioner_S(preconditioner_S)\n       , do_solve_A(do_solve_A)\n     {}\n   \n   \n   \n     template <class PreconditionerAType, class PreconditionerSType>\n     void\n     BlockSchurPreconditioner<PreconditionerAType, PreconditionerSType>::vmult(\n       BlockVector<double>       &dst,\n       const BlockVector<double> &src) const\n     {\n       Vector<double> utmp(src.block(0));\n```\n\nFirst solve with the approximation for S\n\n```\n       {\n         SolverControl solver_control(1000, 1e-6 * src.block(1).l2_norm());\n         SolverCG<Vector<double>> cg(solver_control);\n   \n         dst.block(1) = 0.0;\n         cg.solve(schur_complement_matrix,\n                  dst.block(1),\n                  src.block(1),\n                  preconditioner_S);\n   \n         n_iterations_S += solver_control.last_step();\n         dst.block(1) *= -1.0;\n       }\n```\n\nSecond, apply the top right block (B^T)\n\n```\n       {\n         system_matrix.block(0, 1).vmult(utmp, dst.block(1));\n         utmp *= -1.0;\n         utmp += src.block(0);\n       }\n```\n\nFinally, either solve with the top left block or just apply one preconditioner sweep\n\n```\n       if (do_solve_A == true)\n         {\n           SolverControl            solver_control(10000, utmp.l2_norm() * 1e-4);\n           SolverCG<Vector<double>> cg(solver_control);\n   \n           dst.block(0) = 0.0;\n           cg.solve(system_matrix.block(0, 0),\n                    dst.block(0),\n                    utmp,\n                    preconditioner_A);\n   \n           n_iterations_A += solver_control.last_step();\n         }\n       else\n         {\n           preconditioner_A.vmult(dst.block(0), utmp);\n           n_iterations_A += 1;\n         }\n     }\n```\n\n### The StokesProblem class\n\nThis is the main class of the problem.\n\n```\n     template <int dim>\n     class StokesProblem\n     {\n     public:\n       StokesProblem(const unsigned int pressure_degree,\n                     const SolverType   solver_type);\n       void run();\n   \n     private:\n       void setup_dofs();\n       void assemble_system();\n       void assemble_multigrid();\n       void solve();\n       void compute_errors();\n       void output_results(const unsigned int refinement_cycle) const;\n   \n       const unsigned int pressure_degree;\n       const SolverType   solver_type;\n   \n       Triangulation<dim> triangulation;\n       const FESystem<dim> velocity_fe;\n       const FESystem<dim> fe;\n       DoFHandler<dim>     dof_handler;\n       DoFHandler<dim>     velocity_dof_handler;\n   \n       AffineConstraints<double> constraints;\n   \n       BlockSparsityPattern      sparsity_pattern;\n       BlockSparseMatrix<double> system_matrix;\n       SparseMatrix<double>      pressure_mass_matrix;\n   \n       BlockVector<double> solution;\n       BlockVector<double> system_rhs;\n   \n       MGLevelObject<SparsityPattern>      mg_sparsity_patterns;\n       MGLevelObject<SparseMatrix<double>> mg_matrices;\n       MGLevelObject<SparseMatrix<double>> mg_interface_matrices;\n       MGConstrainedDoFs                   mg_constrained_dofs;\n   \n       TimerOutput computing_timer;\n     };\n   \n   \n   \n     template <int dim>\n     StokesProblem<dim>::StokesProblem(const unsigned int pressure_degree,\n                                       const SolverType   solver_type)\n   \n       : pressure_degree(pressure_degree)\n       , solver_type(solver_type)\n       , triangulation(Triangulation<dim>::maximum_smoothing)\n       ,\n```\n\nFinite element for the velocity only:\n\n```\n       velocity_fe(FE_Q<dim>(pressure_degree + 1) ^ dim)\n       ,\n```\n\nFinite element for the whole system:\n\n```\n       fe(velocity_fe, FE_Q<dim>(pressure_degree))\n       , dof_handler(triangulation)\n       , velocity_dof_handler(triangulation)\n       , computing_timer(std::cout, TimerOutput::never, TimerOutput::wall_times)\n     {}\n```\n\n#### StokesProblem::setup\\_dofs\n\nThis function sets up the [DoFHandler](classDoFHandler.html), matrices, vectors, and [Multigrid](classMultigrid.html) structures (if needed).\n\n```\n     template <int dim>\n     void StokesProblem<dim>::setup_dofs()\n     {\n       TimerOutput::Scope scope(computing_timer, \"Setup\");\n   \n       system_matrix.clear();\n       pressure_mass_matrix.clear();\n```\n\nThe main [DoFHandler](classDoFHandler.html) only needs active DoFs, so we are not calling distribute\\_mg\\_dofs() here\n\n```\n       dof_handler.distribute_dofs(fe);\n```\n\nThis block structure separates the dim velocity components from the pressure component (used for reordering). Note that we have 2 instead of dim+1 blocks like in [step-22](step_22.html), because our [FESystem](classFESystem.html) is nested and the dim velocity components appear as one block.\n\n```\n       std::vector<unsigned int> block_component(2);\n       block_component[0] = 0;\n       block_component[1] = 1;\n```\n\nVelocities start at component 0:\n\n```\n       const FEValuesExtractors::Vector velocities(0);\n```\n\nILU behaves better if we apply a reordering to reduce fillin. There is no advantage in doing this for the other solvers.\n\n```\n       if (solver_type == SolverType::FGMRES_ILU)\n         {\n           TimerOutput::Scope ilu_specific(computing_timer, \"(ILU specific)\");\n           DoFRenumbering::Cuthill_McKee(dof_handler);\n         }\n```\n\nThis ensures that all velocities DoFs are enumerated before the pressure unknowns. This allows us to use blocks for vectors and matrices and allows us to get the same DoF numbering for dof\\_handler and velocity\\_dof\\_handler.\n\n```\n       DoFRenumbering::block_wise(dof_handler);\n   \n       if (solver_type == SolverType::FGMRES_GMG)\n         {\n           TimerOutput::Scope multigrid_specific(computing_timer,\n                                                 \"(Multigrid specific)\");\n           TimerOutput::Scope setup_multigrid(computing_timer,\n                                              \"Setup - Multigrid\");\n```\n\nThis distributes the active dofs and multigrid dofs for the velocity space in a separate [DoFHandler](classDoFHandler.html) as described in the introduction.\n\n```\n           velocity_dof_handler.distribute_dofs(velocity_fe);\n           velocity_dof_handler.distribute_mg_dofs();\n```\n\nThe following block of code initializes the MGConstrainedDofs (using the boundary conditions for the velocity), and the sparsity patterns and matrices for each level. The resize() function of MGLevelObject<T> will destroy all existing contained objects.\n\n```\n           const std::set<types::boundary_id> zero_boundary_ids = {0};\n   \n           mg_constrained_dofs.clear();\n           mg_constrained_dofs.initialize(velocity_dof_handler);\n           mg_constrained_dofs.make_zero_boundary_constraints(velocity_dof_handler,\n                                                              zero_boundary_ids);\n           const unsigned int n_levels = triangulation.n_levels();\n   \n           mg_interface_matrices.resize(0, n_levels - 1);\n           mg_matrices.resize(0, n_levels - 1);\n           mg_sparsity_patterns.resize(0, n_levels - 1);\n   \n           for (unsigned int level = 0; level < n_levels; ++level)\n             {\n               DynamicSparsityPattern csp(velocity_dof_handler.n_dofs(level),\n                                          velocity_dof_handler.n_dofs(level));\n               MGTools::make_sparsity_pattern(velocity_dof_handler, csp, level);\n               mg_sparsity_patterns[level].copy_from(csp);\n   \n               mg_matrices[level].reinit(mg_sparsity_patterns[level]);\n               mg_interface_matrices[level].reinit(mg_sparsity_patterns[level]);\n             }\n         }\n   \n       const std::vector<types::global_dof_index> dofs_per_block =\n         DoFTools::count_dofs_per_fe_block(dof_handler, block_component);\n       const unsigned int n_u = dofs_per_block[0];\n       const unsigned int n_p = dofs_per_block[1];\n   \n       {\n         constraints.clear();\n```\n\nThe following makes use of a component mask for interpolation of the boundary values for the velocity only, which is further explained in the vector valued dealii [step-20](step_20.html) tutorial.\n\n```\n         DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n         VectorTools::interpolate_boundary_values(dof_handler,\n                                                  0,\n                                                  Solution<dim>(),\n                                                  constraints,\n                                                  fe.component_mask(velocities));\n```\n\nAs discussed in the introduction, we need to fix one degree of freedom of the pressure variable to ensure solvability of the problem. We do this here by marking the first pressure dof, which has index n\\_u as a constrained dof.\n\n```\n         if (solver_type == SolverType::UMFPACK)\n           constraints.constrain_dof_to_zero(n_u);\n   \n         constraints.close();\n       }\n   \n       std::cout << \"\\tNumber of active cells: \" << triangulation.n_active_cells()\n                 << std::endl\n                 << \"\\tNumber of degrees of freedom: \" << dof_handler.n_dofs()\n                 << \" (\" << n_u << '+' << n_p << ')' << std::endl;\n   \n       {\n         BlockDynamicSparsityPattern csp(dofs_per_block, dofs_per_block);\n         DoFTools::make_sparsity_pattern(dof_handler, csp, constraints, false);\n         sparsity_pattern.copy_from(csp);\n       }\n       system_matrix.reinit(sparsity_pattern);\n   \n       solution.reinit(dofs_per_block);\n       system_rhs.reinit(dofs_per_block);\n     }\n```\n\n#### StokesProblem::assemble\\_system\n\nIn this function, the system matrix is assembled. We assemble the pressure [mass matrix](DEALGlossary.html#GlossMassMatrix) in the (1,1) block (if needed) and move it out of this location at the end of this function.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::assemble_system()\n     {\n       TimerOutput::Scope assemble(computing_timer, \"Assemble\");\n       system_matrix = 0;\n       system_rhs    = 0;\n```\n\nIf true, we will assemble the pressure mass matrix in the (1,1) block:\n\n```\n       const bool assemble_pressure_mass_matrix =\n         (solver_type == SolverType::UMFPACK) ? false : true;\n   \n       const QGauss<dim> quadrature_formula(pressure_degree + 2);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values | update_gradients);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n   \n       const unsigned int n_q_points = quadrature_formula.size();\n   \n       FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<double>     local_rhs(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       const RightHandSide<dim>    right_hand_side;\n       std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim + 1));\n   \n       const FEValuesExtractors::Vector velocities(0);\n       const FEValuesExtractors::Scalar pressure(dim);\n   \n       std::vector<SymmetricTensor<2, dim>> symgrad_phi_u(dofs_per_cell);\n       std::vector<double>                  div_phi_u(dofs_per_cell);\n       std::vector<double>                  phi_p(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           fe_values.reinit(cell);\n           local_matrix = 0;\n           local_rhs    = 0;\n   \n           right_hand_side.vector_value_list(fe_values.get_quadrature_points(),\n                                             rhs_values);\n   \n           for (unsigned int q = 0; q < n_q_points; ++q)\n             {\n               for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                 {\n                   symgrad_phi_u[k] =\n                     fe_values[velocities].symmetric_gradient(k, q);\n                   div_phi_u[k] = fe_values[velocities].divergence(k, q);\n                   phi_p[k]     = fe_values[pressure].value(k, q);\n                 }\n   \n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 {\n                   for (unsigned int j = 0; j <= i; ++j)\n                     {\n                       local_matrix(i, j) +=\n                         (2 * (symgrad_phi_u[i] * symgrad_phi_u[j]) -\n                          div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j] +\n                          (assemble_pressure_mass_matrix ? phi_p[i] * phi_p[j] :\n                                                           0)) *\n                         fe_values.JxW(q);\n                     }\n   \n                   const unsigned int component_i =\n                     fe.system_to_component_index(i).first;\n                   local_rhs(i) += fe_values.shape_value(i, q) *\n                                   rhs_values[q](component_i) * fe_values.JxW(q);\n                 }\n             }\n   \n           for (unsigned int i = 0; i < dofs_per_cell; ++i)\n             for (unsigned int j = i + 1; j < dofs_per_cell; ++j)\n               local_matrix(i, j) = local_matrix(j, i);\n   \n           cell->get_dof_indices(local_dof_indices);\n           constraints.distribute_local_to_global(local_matrix,\n                                                  local_rhs,\n                                                  local_dof_indices,\n                                                  system_matrix,\n                                                  system_rhs);\n         }\n   \n       if (solver_type != SolverType::UMFPACK)\n         {\n           pressure_mass_matrix.reinit(sparsity_pattern.block(1, 1));\n           pressure_mass_matrix.copy_from(system_matrix.block(1, 1));\n           system_matrix.block(1, 1) = 0;\n         }\n     }\n```\n\n#### StokesProblem::assemble\\_multigrid\n\nHere, like in [step-16](step_16.html), we have a function that assembles the level and interface matrices necessary for the multigrid preconditioner.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::assemble_multigrid()\n     {\n       TimerOutput::Scope multigrid_specific(computing_timer,\n                                             \"(Multigrid specific)\");\n       TimerOutput::Scope assemble_multigrid(computing_timer,\n                                             \"Assemble Multigrid\");\n   \n       mg_matrices = 0.;\n   \n       const QGauss<dim> quadrature_formula(pressure_degree + 2);\n   \n       FEValues<dim> fe_values(velocity_fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values | update_gradients);\n   \n       const unsigned int dofs_per_cell = velocity_fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       const FEValuesExtractors::Vector velocities(0);\n   \n       std::vector<SymmetricTensor<2, dim>> symgrad_phi_u(dofs_per_cell);\n   \n       std::vector<AffineConstraints<double>> boundary_constraints(\n         triangulation.n_levels());\n       std::vector<AffineConstraints<double>> boundary_interface_constraints(\n         triangulation.n_levels());\n       for (unsigned int level = 0; level < triangulation.n_levels(); ++level)\n         {\n           for (const types::global_dof_index dof_index :\n                mg_constrained_dofs.get_refinement_edge_indices(level))\n             boundary_constraints[level].constrain_dof_to_zero(dof_index);\n           for (const types::global_dof_index dof_index :\n                mg_constrained_dofs.get_boundary_indices(level))\n             boundary_constraints[level].constrain_dof_to_zero(dof_index);\n           boundary_constraints[level].close();\n   \n           const IndexSet idx =\n             mg_constrained_dofs.get_refinement_edge_indices(level) &\n             mg_constrained_dofs.get_boundary_indices(level);\n   \n           for (const types::global_dof_index dof_index : idx)\n             boundary_interface_constraints[level].add_constraint(dof_index,\n                                                                  {},\n                                                                  0.);\n           boundary_interface_constraints[level].close();\n         }\n```\n\nThis iterator goes over all cells (not just active)\n\n```\n       for (const auto &cell : velocity_dof_handler.cell_iterators())\n         {\n           fe_values.reinit(cell);\n           cell_matrix = 0;\n   \n           for (unsigned int q = 0; q < n_q_points; ++q)\n             {\n               for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                 symgrad_phi_u[k] = fe_values[velocities].symmetric_gradient(k, q);\n   \n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 for (unsigned int j = 0; j <= i; ++j)\n                   {\n                     cell_matrix(i, j) +=\n                       (symgrad_phi_u[i] * symgrad_phi_u[j]) * fe_values.JxW(q);\n                   }\n             }\n   \n           for (unsigned int i = 0; i < dofs_per_cell; ++i)\n             for (unsigned int j = i + 1; j < dofs_per_cell; ++j)\n               cell_matrix(i, j) = cell_matrix(j, i);\n   \n           cell->get_mg_dof_indices(local_dof_indices);\n   \n           boundary_constraints[cell->level()].distribute_local_to_global(\n             cell_matrix, local_dof_indices, mg_matrices[cell->level()]);\n   \n           for (unsigned int i = 0; i < dofs_per_cell; ++i)\n             for (unsigned int j = 0; j < dofs_per_cell; ++j)\n               if (!mg_constrained_dofs.at_refinement_edge(cell->level(),\n                                                           local_dof_indices[i]) ||\n                   mg_constrained_dofs.at_refinement_edge(cell->level(),\n                                                          local_dof_indices[j]))\n                 cell_matrix(i, j) = 0;\n   \n           boundary_interface_constraints[cell->level()]\n             .distribute_local_to_global(cell_matrix,\n                                         local_dof_indices,\n                                         mg_interface_matrices[cell->level()]);\n         }\n     }\n```\n\n#### StokesProblem::solve\n\nThis function sets up things differently based on if you want to use ILU or GMG as a preconditioner. Both methods share the same solver (FGMRES) but require a different preconditioner to be initialized. Here we time not only the entire solve function, but we separately time the setup of the preconditioner as well as the solve itself.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::solve()\n     {\n       TimerOutput::Scope solve(computing_timer, \"Solve\");\n       constraints.set_zero(solution);\n   \n       if (solver_type == SolverType::UMFPACK)\n         {\n           computing_timer.enter_subsection(\"(UMFPACK specific)\");\n           computing_timer.enter_subsection(\"Solve - Initialize\");\n   \n           SparseDirectUMFPACK A_direct;\n           A_direct.initialize(system_matrix);\n   \n           computing_timer.leave_subsection();\n           computing_timer.leave_subsection();\n   \n           {\n             TimerOutput::Scope solve_backslash(computing_timer,\n                                                \"Solve - Backslash\");\n             A_direct.vmult(solution, system_rhs);\n           }\n   \n           constraints.distribute(solution);\n           return;\n         }\n```\n\nHere we must make sure to solve for the residual with \"good enough\" accuracy\n\n```\n       SolverControl solver_control(system_matrix.m(),\n                                    1e-10 * system_rhs.l2_norm());\n       unsigned int  n_iterations_A;\n       unsigned int  n_iterations_S;\n```\n\nThis is used to pass whether or not we want to solve for A inside the preconditioner. One could change this to false to see if there is still convergence and if so does the program then run faster or slower\n\n```\n       const bool use_expensive = true;\n   \n       SolverFGMRES<BlockVector<double>> solver(solver_control);\n   \n       if (solver_type == SolverType::FGMRES_ILU)\n         {\n           computing_timer.enter_subsection(\"(ILU specific)\");\n           computing_timer.enter_subsection(\"Solve - Set-up Preconditioner\");\n   \n           std::cout << \"   Computing preconditioner...\" << std::endl\n                     << std::flush;\n   \n           SparseILU<double> A_preconditioner;\n           A_preconditioner.initialize(system_matrix.block(0, 0));\n   \n           SparseILU<double> S_preconditioner;\n           S_preconditioner.initialize(pressure_mass_matrix);\n   \n           const BlockSchurPreconditioner<SparseILU<double>, SparseILU<double>>\n             preconditioner(system_matrix,\n                            pressure_mass_matrix,\n                            A_preconditioner,\n                            S_preconditioner,\n                            use_expensive);\n   \n           computing_timer.leave_subsection();\n           computing_timer.leave_subsection();\n   \n           {\n             TimerOutput::Scope solve_fmgres(computing_timer, \"Solve - FGMRES\");\n   \n             solver.solve(system_matrix, solution, system_rhs, preconditioner);\n             n_iterations_A = preconditioner.n_iterations_A;\n             n_iterations_S = preconditioner.n_iterations_S;\n           }\n         }\n       else\n         {\n           computing_timer.enter_subsection(\"(Multigrid specific)\");\n           computing_timer.enter_subsection(\"Solve - Set-up Preconditioner\");\n```\n\nTransfer operators between levels\n\n```\n           MGTransferPrebuilt<Vector<double>> mg_transfer(mg_constrained_dofs);\n           mg_transfer.build(velocity_dof_handler);\n```\n\nSetup coarse grid solver\n\n```\n           FullMatrix<double> coarse_matrix;\n           coarse_matrix.copy_from(mg_matrices[0]);\n           MGCoarseGridHouseholder<double, Vector<double>> coarse_grid_solver;\n           coarse_grid_solver.initialize(coarse_matrix);\n   \n           using Smoother = PreconditionSOR<SparseMatrix<double>>;\n           mg::SmootherRelaxation<Smoother, Vector<double>> mg_smoother;\n           mg_smoother.initialize(mg_matrices);\n           mg_smoother.set_steps(2);\n```\n\n[Multigrid](classMultigrid.html), when used as a preconditioner for CG, needs to be a symmetric operator, so the smoother must be symmetric\n\n```\n           mg_smoother.set_symmetric(true);\n   \n           mg::Matrix<Vector<double>> mg_matrix(mg_matrices);\n           mg::Matrix<Vector<double>> mg_interface_up(mg_interface_matrices);\n           mg::Matrix<Vector<double>> mg_interface_down(mg_interface_matrices);\n```\n\nNow, we are ready to set up the V-cycle operator and the multilevel preconditioner.\n\n```\n           Multigrid<Vector<double>> mg(\n             mg_matrix, coarse_grid_solver, mg_transfer, mg_smoother, mg_smoother);\n           mg.set_edge_matrices(mg_interface_down, mg_interface_up);\n   \n           PreconditionMG<dim, Vector<double>, MGTransferPrebuilt<Vector<double>>>\n             A_Multigrid(velocity_dof_handler, mg, mg_transfer);\n   \n           SparseILU<double> S_preconditioner;\n           S_preconditioner.initialize(pressure_mass_matrix,\n                                       SparseILU<double>::AdditionalData());\n   \n           const BlockSchurPreconditioner<\n             PreconditionMG<dim,\n                            Vector<double>,\n                            MGTransferPrebuilt<Vector<double>>>,\n             SparseILU<double>>\n             preconditioner(system_matrix,\n                            pressure_mass_matrix,\n                            A_Multigrid,\n                            S_preconditioner,\n                            use_expensive);\n   \n           computing_timer.leave_subsection();\n           computing_timer.leave_subsection();\n   \n           {\n             TimerOutput::Scope solve_fmgres(computing_timer, \"Solve - FGMRES\");\n             solver.solve(system_matrix, solution, system_rhs, preconditioner);\n             n_iterations_A = preconditioner.n_iterations_A;\n             n_iterations_S = preconditioner.n_iterations_S;\n           }\n         }\n   \n       constraints.distribute(solution);\n   \n       std::cout\n         << std::endl\n         << \"\\tNumber of FGMRES iterations: \" << solver_control.last_step()\n         << std::endl\n         << \"\\tTotal number of iterations used for approximation of A inverse: \"\n         << n_iterations_A << std::endl\n         << \"\\tTotal number of iterations used for approximation of S inverse: \"\n         << n_iterations_S << std::endl\n         << std::endl;\n     }\n```\n\n#### StokesProblem::process\\_solution\n\nThis function computes the L2 and H1 errors of the solution. For this, we need to make sure the pressure has mean zero.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::compute_errors()\n     {\n```\n\nCompute the mean pressure \\(\\frac{1}{\\Omega} \\int\\_{\\Omega} p(x) dx \\) and then subtract it from each pressure coefficient. This will result in a pressure with mean value zero. Here we make use of the fact that the pressure is component \\(dim\\) and that the finite element space is nodal.\n\n```\n       const double mean_pressure = VectorTools::compute_mean_value(\n         dof_handler, QGauss<dim>(pressure_degree + 2), solution, dim);\n       solution.block(1).add(-mean_pressure);\n       std::cout << \"   Note: The mean value was adjusted by \" << -mean_pressure\n                 << std::endl;\n   \n       const ComponentSelectFunction<dim> pressure_mask(dim, dim + 1);\n       const ComponentSelectFunction<dim> velocity_mask(std::make_pair(0, dim),\n                                                        dim + 1);\n   \n       Vector<float> difference_per_cell(triangulation.n_active_cells());\n       VectorTools::integrate_difference(dof_handler,\n                                         solution,\n                                         Solution<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(pressure_degree + 2),\n                                         VectorTools::L2_norm,\n                                         &velocity_mask);\n   \n       const double Velocity_L2_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::L2_norm);\n   \n       VectorTools::integrate_difference(dof_handler,\n                                         solution,\n                                         Solution<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(pressure_degree + 2),\n                                         VectorTools::L2_norm,\n                                         &pressure_mask);\n   \n       const double Pressure_L2_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::L2_norm);\n   \n       VectorTools::integrate_difference(dof_handler,\n                                         solution,\n                                         Solution<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(pressure_degree + 2),\n                                         VectorTools::H1_norm,\n                                         &velocity_mask);\n   \n       const double Velocity_H1_error =\n         VectorTools::compute_global_error(triangulation,\n                                           difference_per_cell,\n                                           VectorTools::H1_norm);\n   \n       std::cout << std::endl\n                 << \"   Velocity L2 Error: \" << Velocity_L2_error << std::endl\n                 << \"   Pressure L2 Error: \" << Pressure_L2_error << std::endl\n                 << \"   Velocity H1 Error: \" << Velocity_H1_error << std::endl;\n     }\n```\n\n#### StokesProblem::output\\_results\n\nThis function generates graphical output like it is done in [step-22](step_22.html).\n\n```\n     template <int dim>\n     void\n     StokesProblem<dim>::output_results(const unsigned int refinement_cycle) const\n     {\n       std::vector<std::string> solution_names(dim, \"velocity\");\n       solution_names.emplace_back(\"pressure\");\n   \n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           dim, DataComponentInterpretation::component_is_part_of_vector);\n       data_component_interpretation.push_back(\n         DataComponentInterpretation::component_is_scalar);\n   \n       DataOut<dim> data_out;\n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(solution,\n                                solution_names,\n                                DataOut<dim>::type_dof_data,\n                                data_component_interpretation);\n       data_out.build_patches();\n   \n       std::ofstream output(\n         \"solution-\" + Utilities::int_to_string(refinement_cycle, 2) + \".vtk\");\n       data_out.write_vtk(output);\n     }\n```\n\n#### StokesProblem::run\n\nThe last step in the Stokes class is, as usual, the function that generates the initial grid and calls the other functions in the respective order.\n\n```\n     template <int dim>\n     void StokesProblem<dim>::run()\n     {\n       GridGenerator::hyper_cube(triangulation);\n       triangulation.refine_global(6 - dim);\n   \n       if (solver_type == SolverType::FGMRES_ILU)\n         std::cout << \"Now running with ILU\" << std::endl;\n       else if (solver_type == SolverType::FGMRES_GMG)\n         std::cout << \"Now running with Multigrid\" << std::endl;\n       else\n         std::cout << \"Now running with UMFPACK\" << std::endl;\n   \n   \n       for (unsigned int refinement_cycle = 0; refinement_cycle < 3;\n            ++refinement_cycle)\n         {\n           std::cout << \"Refinement cycle \" << refinement_cycle << std::endl;\n   \n           if (refinement_cycle > 0)\n             triangulation.refine_global(1);\n   \n           std::cout << \"   Set-up...\" << std::endl;\n           setup_dofs();\n   \n           std::cout << \"   Assembling...\" << std::endl;\n           assemble_system();\n   \n           if (solver_type == SolverType::FGMRES_GMG)\n             {\n               std::cout << \"   Assembling Multigrid...\" << std::endl;\n   \n               assemble_multigrid();\n             }\n   \n           std::cout << \"   Solving...\" << std::flush;\n           solve();\n   \n           compute_errors();\n   \n           output_results(refinement_cycle);\n   \n           Utilities::System::MemoryStats mem;\n           Utilities::System::get_memory_stats(mem);\n           std::cout << \"   VM Peak: \" << mem.VmPeak << std::endl;\n   \n           computing_timer.print_summary();\n           computing_timer.reset();\n         }\n     }\n   } // namespace Step56\n```\n\n### The main function\n\n```\n   int main()\n   {\n     try\n       {\n         using namespace Step56;\n   \n         const int degree = 1;\n         const int dim    = 3;\n```\n\noptions for SolverType: UMFPACK FGMRES\\_ILU FGMRES\\_GMG\n\n```\n         StokesProblem<dim> flow_problem(degree, SolverType::FGMRES_GMG);\n   \n         flow_problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### Errors\n\nWe first run the code and confirm that the finite element solution converges with the correct rates as predicted by the error analysis of mixed finite element problems. Given sufficiently smooth exact solutions \\(u\\) and \\(p\\), the errors of the Taylor-Hood element \\(Q\\_k \\times Q\\_{k-1}\\) should be\n\n\\[\n\\| u -u\\_h \\|\\_0 + h ( \\| u- u\\_h\\|\\_1 + \\|p - p\\_h \\|\\_0)\n\\leq C h^{k+1} ( \\|u \\|\\_{k+1} + \\| p \\|\\_k )\n\\]\n\nsee for example Ern/Guermond \"Theory and Practice of Finite Elements\", Section 4.2.5 p195. This is indeed what we observe, using the \\(Q\\_2 \\times Q\\_1\\) element as an example (this is what is done in the code, but is easily changed in `main()`):\n\n|  | L2 Velocity | Reduction | L2 Pressure | Reduction | H1 Velocity | Reduction |\n| --- | --- | --- | --- | --- | --- | --- |\n| 3D, 3 global refinements | 0.000670888 | - | 0.0036533 | - | 0.0414704 | - |\n| 3D, 4 global refinements | 8.38E-005 | 8.0 | 0.00088494 | 4.1 | 0.0103781 | 4.0 |\n| 3D, 5 global refinements | 1.05E-005 | 8.0 | 0.000220253 | 4.0 | 0.00259519 | 4.0 |\n\n### Timing Results\n\nLet us compare the direct solver approach using UMFPACK to the two methods in which we choose \\(\\widetilde {A^{-1}}=A^{-1}\\) and \\(\\widetilde{S^{-1}}=S^{-1}\\) by solving linear systems with \\(A,S\\) using CG. The preconditioner for CG is then either ILU or GMG. The following table summarizes solver iterations, timings, and virtual memory (VM) peak usage:\n\n|  | General | | | GMG | | | | | | ILU | | | | | | UMFPACK | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  |  | Timings | | Timings | | Iterations | | |  | Timings | | Iterations | | |  | Timings | |  |\n| Cycle | DoFs | Setup | Assembly | Setup | Solve | Outer | Inner (A) | Inner (S) | VM Peak | Setup | Solve | Outer | Inner (A) | Inner (S) | VM Peak | Setup | Solve | VM Peak |\n| 0 | 15468 | 0.1s | 0.3s | 0.3s | 1.3s | 21 | 67 | 22 | 4805 | 0.3s | 0.6s | 21 | 180 | 22 | 4783 | 2.65s | 2.8s | 5054 |\n| 1 | 112724 | 1.0s | 2.4s | 2.6s | 14s | 21 | 67 | 22 | 5441 | 2.8s | 15.8s | 21 | 320 | 22 | 5125 | 236s | 237s | 11288 |\n| 2 | 859812 | 9.0s | 20s | 20s | 101s | 20 | 65 | 21 | 10641 | 27s | 268s | 21 | 592 | 22 | 8307 | - | - | - |\n\nAs can be seen from the table:\n\n1. UMFPACK uses large amounts of memory, especially in 3d. Also, UMFPACK timings do not scale favorably with problem size.\n2. Because we are using inner solvers for \\(A\\) and \\(S\\), ILU and GMG require the same number of outer iterations.\n3. The number of (inner) iterations for \\(A\\) increases for ILU with refinement, leading to worse than linear scaling in solve time. In contrast, the number of inner iterations for \\(A\\) stays constant with GMG leading to nearly perfect scaling in solve time.\n4. GMG needs slightly more memory than ILU to store the level and interface matrices.\n\n### Possibilities for extensions\n\n#### Check higher order discretizations\n\nExperiment with higher order stable FE pairs and check that you observe the correct convergence rates.\n\n#### Compare with cheap preconditioner\n\nThe introduction also outlined another option to precondition the overall system, namely one in which we do not choose \\(\\widetilde\n{A^{-1}}=A^{-1}\\) as in the table above, but in which \\(\\widetilde{A^{-1}}\\) is only a single preconditioner application with GMG or ILU, respectively.\n\nThis is in fact implemented in the code: Currently, the boolean `use_expensive` in `solve()` is set to `true`. The option mentioned above is obtained by setting it to `false`.\n\nWhat you will find is that the number of FGMRES iterations stays constant under refinement if you use GMG this way. This means that the [Multigrid](classMultigrid.html) is optimal and independent of \\(h\\).\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2016 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n \n * Authors: Ryan Grove, Clemson University\n *          Timo Heister, Clemson University\n */\n \n \n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/utilities.h>\n \n#include <deal.II/lac/block_vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/block_sparse_matrix.h>\n#include <deal.II/lac/block_sparsity_pattern.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/solver_gmres.h>\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_tools.h>\n#include <deal.II/grid/grid_refinement.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n \n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n \n#include <deal.II/lac/sparse_direct.h>\n \n#include <deal.II/lac/sparse_ilu.h>\n#include <deal.II/grid/grid_out.h>\n \n#include <deal.II/base/timer.h>\n \n#include <deal.II/multigrid/multigrid.h>\n#include <deal.II/multigrid/mg_transfer.h>\n#include <deal.II/multigrid/mg_tools.h>\n#include <deal.II/multigrid/mg_coarse.h>\n#include <deal.II/multigrid/mg_smoother.h>\n#include <deal.II/multigrid/mg_matrix.h>\n \n#include <iostream>\n#include <fstream>\n \nnamespace Step56\n{\n using namespace dealii;\n \n enum class SolverType\n  {\n    FGMRES_ILU,\n    FGMRES_GMG,\n    UMFPACK\n  };\n \n template <int dim>\n class Solution : public Function<dim>\n  {\n public:\n    Solution()\n      : Function<dim>(dim + 1)\n    {}\n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n virtual Tensor<1, dim>\n gradient(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n template <>\n double Solution<2>::value(const Point<2>    &p,\n const unsigned int component) const\n {\n Assert(component <= 2 + 1, ExcIndexRange(component, 0, 2 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n \n if (component == 0)\n return sin(PI * x);\n if (component == 1)\n return -PI * y * cos(PI * x);\n if (component == 2)\n return sin(PI * x) * cos(PI * y);\n \n return 0;\n  }\n \n template <>\n double Solution<3>::value(const Point<3>    &p,\n const unsigned int component) const\n {\n Assert(component <= 3 + 1, ExcIndexRange(component, 0, 3 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n const double z = p[2];\n \n if (component == 0)\n return 2.0 * sin(PI * x);\n if (component == 1)\n return -PI * y * cos(PI * x);\n if (component == 2)\n return -PI * z * cos(PI * x);\n if (component == 3)\n return sin(PI * x) * cos(PI * y) * sin(PI * z);\n \n return 0;\n  }\n \n template <>\n Tensor<1, 2> Solution<2>::gradient(const Point<2>    &p,\n const unsigned int component) const\n {\n Assert(component <= 2, ExcIndexRange(component, 0, 2 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n \n Tensor<1, 2> return_value;\n if (component == 0)\n      {\n        return_value[0] = PI * cos(PI * x);\n        return_value[1] = 0.0;\n      }\n else if (component == 1)\n      {\n        return_value[0] = y * PI * PI * sin(PI * x);\n        return_value[1] = -PI * cos(PI * x);\n      }\n else if (component == 2)\n      {\n        return_value[0] = PI * cos(PI * x) * cos(PI * y);\n        return_value[1] = -PI * sin(PI * x) * sin(PI * y);\n      }\n \n return return_value;\n  }\n \n template <>\n Tensor<1, 3> Solution<3>::gradient(const Point<3>    &p,\n const unsigned int component) const\n {\n Assert(component <= 3, ExcIndexRange(component, 0, 3 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n const double z = p[2];\n \n Tensor<1, 3> return_value;\n if (component == 0)\n      {\n        return_value[0] = 2 * PI * cos(PI * x);\n        return_value[1] = 0.0;\n        return_value[2] = 0.0;\n      }\n else if (component == 1)\n      {\n        return_value[0] = y * PI * PI * sin(PI * x);\n        return_value[1] = -PI * cos(PI * x);\n        return_value[2] = 0.0;\n      }\n else if (component == 2)\n      {\n        return_value[0] = z * PI * PI * sin(PI * x);\n        return_value[1] = 0.0;\n        return_value[2] = -PI * cos(PI * x);\n      }\n else if (component == 3)\n      {\n        return_value[0] = PI * cos(PI * x) * cos(PI * y) * sin(PI * z);\n        return_value[1] = -PI * sin(PI * x) * sin(PI * y) * sin(PI * z);\n        return_value[2] = PI * sin(PI * x) * cos(PI * y) * cos(PI * z);\n      }\n \n return return_value;\n  }\n \n template <int dim>\n class RightHandSide : public Function<dim>\n  {\n public:\n    RightHandSide()\n      : Function<dim>(dim + 1)\n    {}\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n template <>\n double RightHandSide<2>::value(const Point<2>    &p,\n const unsigned int component) const\n {\n Assert(component <= 2, ExcIndexRange(component, 0, 2 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n if (component == 0)\n return PI * PI * sin(PI * x) + PI * cos(PI * x) * cos(PI * y);\n if (component == 1)\n return -PI * PI * PI * y * cos(PI * x) - PI * sin(PI * y) * sin(PI * x);\n if (component == 2)\n return 0;\n \n return 0;\n  }\n \n template <>\n double RightHandSide<3>::value(const Point<3>    &p,\n const unsigned int component) const\n {\n Assert(component <= 3, ExcIndexRange(component, 0, 3 + 1));\n \n using numbers::PI;\n const double x = p[0];\n const double y = p[1];\n const double z = p[2];\n if (component == 0)\n return 2 * PI * PI * sin(PI * x) +\n             PI * cos(PI * x) * cos(PI * y) * sin(PI * z);\n if (component == 1)\n return -PI * PI * PI * y * cos(PI * x) +\n             PI * (-1) * sin(PI * y) * sin(PI * x) * sin(PI * z);\n if (component == 2)\n return -PI * PI * PI * z * cos(PI * x) +\n             PI * cos(PI * z) * sin(PI * x) * cos(PI * y);\n if (component == 3)\n return 0;\n \n return 0;\n  }\n \n \n \n \n template <class PreconditionerAType, class PreconditionerSType>\n class BlockSchurPreconditioner : public Subscriptor\n  {\n public:\n    BlockSchurPreconditioner(\n const BlockSparseMatrix<double> &system_matrix,\n const SparseMatrix<double>      &schur_complement_matrix,\n const PreconditionerAType       &preconditioner_A,\n const PreconditionerSType       &preconditioner_S,\n const bool                       do_solve_A);\n \n void vmult(BlockVector<double> &dst, const BlockVector<double> &src) const;\n \n mutable unsigned int n_iterations_A;\n mutable unsigned int n_iterations_S;\n \n private:\n const BlockSparseMatrix<double> &system_matrix;\n const SparseMatrix<double>      &schur_complement_matrix;\n const PreconditionerAType       &preconditioner_A;\n const PreconditionerSType       &preconditioner_S;\n \n const bool do_solve_A;\n  };\n \n template <class PreconditionerAType, class PreconditionerSType>\n  BlockSchurPreconditioner<PreconditionerAType, PreconditionerSType>::\n    BlockSchurPreconditioner(\n const BlockSparseMatrix<double> &system_matrix,\n const SparseMatrix<double>      &schur_complement_matrix,\n const PreconditionerAType       &preconditioner_A,\n const PreconditionerSType       &preconditioner_S,\n const bool                       do_solve_A)\n    : n_iterations_A(0)\n    , n_iterations_S(0)\n    , system_matrix(system_matrix)\n    , schur_complement_matrix(schur_complement_matrix)\n    , preconditioner_A(preconditioner_A)\n    , preconditioner_S(preconditioner_S)\n    , do_solve_A(do_solve_A)\n  {}\n \n \n \n template <class PreconditionerAType, class PreconditionerSType>\n void\n  BlockSchurPreconditioner<PreconditionerAType, PreconditionerSType>::vmult(\n BlockVector<double>       &dst,\n const BlockVector<double> &src) const\n {\n Vector<double> utmp(src.block(0));\n \n    {\n SolverControl solver_control(1000, 1e-6 * src.block(1).l2_norm());\n SolverCG<Vector<double>> cg(solver_control);\n \n      dst.block(1) = 0.0;\n      cg.solve(schur_complement_matrix,\n               dst.block(1),\n               src.block(1),\n               preconditioner_S);\n \n      n_iterations_S += solver_control.last_step();\n      dst.block(1) *= -1.0;\n    }\n \n    {\n      system_matrix.block(0, 1).vmult(utmp, dst.block(1));\n      utmp *= -1.0;\n      utmp += src.block(0);\n    }\n \n if (do_solve_A == true)\n      {\n SolverControl            solver_control(10000, utmp.l2_norm() * 1e-4);\n SolverCG<Vector<double>> cg(solver_control);\n \n        dst.block(0) = 0.0;\n        cg.solve(system_matrix.block(0, 0),\n                 dst.block(0),\n                 utmp,\n                 preconditioner_A);\n \n        n_iterations_A += solver_control.last_step();\n      }\n else\n      {\n        preconditioner_A.vmult(dst.block(0), utmp);\n        n_iterations_A += 1;\n      }\n  }\n \n template <int dim>\n class StokesProblem\n  {\n public:\n    StokesProblem(const unsigned int pressure_degree,\n const SolverType   solver_type);\n void run();\n \n private:\n void setup_dofs();\n void assemble_system();\n void assemble_multigrid();\n void solve();\n void compute_errors();\n void output_results(const unsigned int refinement_cycle) const;\n \n const unsigned int pressure_degree;\n const SolverType   solver_type;\n \n Triangulation<dim> triangulation;\n const FESystem<dim> velocity_fe;\n const FESystem<dim> fe;\n DoFHandler<dim>     dof_handler;\n DoFHandler<dim>     velocity_dof_handler;\n \n AffineConstraints<double> constraints;\n \n BlockSparsityPattern      sparsity_pattern;\n BlockSparseMatrix<double> system_matrix;\n SparseMatrix<double>      pressure_mass_matrix;\n \n BlockVector<double> solution;\n BlockVector<double> system_rhs;\n \n MGLevelObject<SparsityPattern>      mg_sparsity_patterns;\n MGLevelObject<SparseMatrix<double>> mg_matrices;\n MGLevelObject<SparseMatrix<double>> mg_interface_matrices;\n MGConstrainedDoFs                   mg_constrained_dofs;\n \n TimerOutput computing_timer;\n  };\n \n \n \n template <int dim>\n  StokesProblem<dim>::StokesProblem(const unsigned int pressure_degree,\n const SolverType   solver_type)\n \n    : pressure_degree(pressure_degree)\n    , solver_type(solver_type)\n    , triangulation(Triangulation<dim>::maximum_smoothing)\n    ,\n    velocity_fe(FE_Q<dim>(pressure_degree + 1) ^ dim)\n    ,\n    fe(velocity_fe, FE_Q<dim>(pressure_degree))\n    , dof_handler(triangulation)\n    , velocity_dof_handler(triangulation)\n    , computing_timer(std::cout, TimerOutput::never, TimerOutput::wall_times)\n  {}\n \n \n \n \n template <int dim>\n void StokesProblem<dim>::setup_dofs()\n  {\n TimerOutput::Scope scope(computing_timer, \"Setup\");\n \n    system_matrix.clear();\n    pressure_mass_matrix.clear();\n \n    dof_handler.distribute_dofs(fe);\n \n    std::vector<unsigned int> block_component(2);\n    block_component[0] = 0;\n    block_component[1] = 1;\n \n const FEValuesExtractors::Vector velocities(0);\n \n if (solver_type == SolverType::FGMRES_ILU)\n      {\n TimerOutput::Scope ilu_specific(computing_timer, \"(ILU specific)\");\n DoFRenumbering::Cuthill_McKee(dof_handler);\n      }\n \n DoFRenumbering::block_wise(dof_handler);\n \n if (solver_type == SolverType::FGMRES_GMG)\n      {\n TimerOutput::Scope multigrid_specific(computing_timer,\n \"(Multigrid specific)\");\n TimerOutput::Scope setup_multigrid(computing_timer,\n \"Setup - Multigrid\");\n \n        velocity_dof_handler.distribute_dofs(velocity_fe);\n        velocity_dof_handler.distribute_mg_dofs();\n \n const std::set<types::boundary_id> zero_boundary_ids = {0};\n \n        mg_constrained_dofs.clear();\n        mg_constrained_dofs.initialize(velocity_dof_handler);\n        mg_constrained_dofs.make_zero_boundary_constraints(velocity_dof_handler,\n                                                           zero_boundary_ids);\n const unsigned int n_levels = triangulation.n_levels();\n \n        mg_interface_matrices.resize(0, n_levels - 1);\n        mg_matrices.resize(0, n_levels - 1);\n        mg_sparsity_patterns.resize(0, n_levels - 1);\n \n for (unsigned int level = 0; level < n_levels; ++level)\n          {\n DynamicSparsityPattern csp(velocity_dof_handler.n_dofs(level),\n                                       velocity_dof_handler.n_dofs(level));\n MGTools::make_sparsity_pattern(velocity_dof_handler, csp, level);\n            mg_sparsity_patterns[level].copy_from(csp);\n \n            mg_matrices[level].reinit(mg_sparsity_patterns[level]);\n            mg_interface_matrices[level].reinit(mg_sparsity_patterns[level]);\n          }\n      }\n \n const std::vector<types::global_dof_index> dofs_per_block =\n DoFTools::count_dofs_per_fe_block(dof_handler, block_component);\n const unsigned int n_u = dofs_per_block[0];\n const unsigned int n_p = dofs_per_block[1];\n \n    {\n      constraints.clear();\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                               0,\n                                               Solution<dim>(),\n                                               constraints,\n                                               fe.component_mask(velocities));\n \n if (solver_type == SolverType::UMFPACK)\n        constraints.constrain_dof_to_zero(n_u);\n \n      constraints.close();\n    }\n \n    std::cout << \"\\tNumber of active cells: \" << triangulation.n_active_cells()\n              << std::endl\n              << \"\\tNumber of degrees of freedom: \" << dof_handler.n_dofs()\n              << \" (\" << n_u << '+' << n_p << ')' << std::endl;\n \n    {\n BlockDynamicSparsityPattern csp(dofs_per_block, dofs_per_block);\n DoFTools::make_sparsity_pattern(dof_handler, csp, constraints, false);\n      sparsity_pattern.copy_from(csp);\n    }\n    system_matrix.reinit(sparsity_pattern);\n \n    solution.reinit(dofs_per_block);\n    system_rhs.reinit(dofs_per_block);\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::assemble_system()\n  {\n TimerOutput::Scope assemble(computing_timer, \"Assemble\");\n    system_matrix = 0;\n    system_rhs    = 0;\n \n const bool assemble_pressure_mass_matrix =\n      (solver_type == SolverType::UMFPACK) ? false : true;\n \n const QGauss<dim> quadrature_formula(pressure_degree + 2);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values | update_gradients);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n \n const unsigned int n_q_points = quadrature_formula.size();\n \n FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n Vector<double>     local_rhs(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n const RightHandSide<dim>    right_hand_side;\n    std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim + 1));\n \n const FEValuesExtractors::Vector velocities(0);\n const FEValuesExtractors::Scalar pressure(dim);\n \n    std::vector<SymmetricTensor<2, dim>> symgrad_phi_u(dofs_per_cell);\n    std::vector<double>                  div_phi_u(dofs_per_cell);\n    std::vector<double>                  phi_p(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        fe_values.reinit(cell);\n        local_matrix = 0;\n        local_rhs    = 0;\n \n        right_hand_side.vector_value_list(fe_values.get_quadrature_points(),\n                                          rhs_values);\n \n for (unsigned int q = 0; q < n_q_points; ++q)\n          {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n              {\n                symgrad_phi_u[k] =\n                  fe_values[velocities].symmetric_gradient(k, q);\n                div_phi_u[k] = fe_values[velocities].divergence(k, q);\n                phi_p[k]     = fe_values[pressure].value(k, q);\n              }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              {\n for (unsigned int j = 0; j <= i; ++j)\n                  {\n                    local_matrix(i, j) +=\n                      (2 * (symgrad_phi_u[i] * symgrad_phi_u[j]) -\n                       div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j] +\n                       (assemble_pressure_mass_matrix ? phi_p[i] * phi_p[j] :\n                                                        0)) *\n                      fe_values.JxW(q);\n                  }\n \n const unsigned int component_i =\n                  fe.system_to_component_index(i).first;\n                local_rhs(i) += fe_values.shape_value(i, q) *\n                                rhs_values[q](component_i) * fe_values.JxW(q);\n              }\n          }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = i + 1; j < dofs_per_cell; ++j)\n            local_matrix(i, j) = local_matrix(j, i);\n \n        cell->get_dof_indices(local_dof_indices);\n        constraints.distribute_local_to_global(local_matrix,\n                                               local_rhs,\n                                               local_dof_indices,\n                                               system_matrix,\n                                               system_rhs);\n      }\n \n if (solver_type != SolverType::UMFPACK)\n      {\n        pressure_mass_matrix.reinit(sparsity_pattern.block(1, 1));\n        pressure_mass_matrix.copy_from(system_matrix.block(1, 1));\n        system_matrix.block(1, 1) = 0;\n      }\n  }\n \n \n template <int dim>\n void StokesProblem<dim>::assemble_multigrid()\n  {\n TimerOutput::Scope multigrid_specific(computing_timer,\n \"(Multigrid specific)\");\n TimerOutput::Scope assemble_multigrid(computing_timer,\n \"Assemble Multigrid\");\n \n    mg_matrices = 0.;\n \n const QGauss<dim> quadrature_formula(pressure_degree + 2);\n \n FEValues<dim> fe_values(velocity_fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values | update_gradients);\n \n const unsigned int dofs_per_cell = velocity_fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n const FEValuesExtractors::Vector velocities(0);\n \n    std::vector<SymmetricTensor<2, dim>> symgrad_phi_u(dofs_per_cell);\n \n    std::vector<AffineConstraints<double>> boundary_constraints(\n triangulation.n_levels());\n    std::vector<AffineConstraints<double>> boundary_interface_constraints(\n triangulation.n_levels());\n for (unsigned int level = 0; level < triangulation.n_levels(); ++level)\n      {\n for (const types::global_dof_index dof_index :\n             mg_constrained_dofs.get_refinement_edge_indices(level))\n          boundary_constraints[level].constrain_dof_to_zero(dof_index);\n for (const types::global_dof_index dof_index :\n             mg_constrained_dofs.get_boundary_indices(level))\n          boundary_constraints[level].constrain_dof_to_zero(dof_index);\n        boundary_constraints[level].close();\n \n const IndexSet idx =\n          mg_constrained_dofs.get_refinement_edge_indices(level) &\n          mg_constrained_dofs.get_boundary_indices(level);\n \n for (const types::global_dof_index dof_index : idx)\n          boundary_interface_constraints[level].add_constraint(dof_index,\n                                                               {},\n                                                               0.);\n        boundary_interface_constraints[level].close();\n      }\n \n for (const auto &cell : velocity_dof_handler.cell_iterators())\n      {\n        fe_values.reinit(cell);\n cell_matrix = 0;\n \n for (unsigned int q = 0; q < n_q_points; ++q)\n          {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n              symgrad_phi_u[k] = fe_values[velocities].symmetric_gradient(k, q);\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = 0; j <= i; ++j)\n                {\n cell_matrix(i, j) +=\n                    (symgrad_phi_u[i] * symgrad_phi_u[j]) * fe_values.JxW(q);\n                }\n          }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = i + 1; j < dofs_per_cell; ++j)\n cell_matrix(i, j) = cell_matrix(j, i);\n \n        cell->get_mg_dof_indices(local_dof_indices);\n \n        boundary_constraints[cell->level()].distribute_local_to_global(\n          cell_matrix, local_dof_indices, mg_matrices[cell->level()]);\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n if (!mg_constrained_dofs.at_refinement_edge(cell->level(),\n                                                        local_dof_indices[i]) ||\n                mg_constrained_dofs.at_refinement_edge(cell->level(),\n                                                       local_dof_indices[j]))\n cell_matrix(i, j) = 0;\n \n        boundary_interface_constraints[cell->level()]\n          .distribute_local_to_global(cell_matrix,\n                                      local_dof_indices,\n                                      mg_interface_matrices[cell->level()]);\n      }\n  }\n \n \n template <int dim>\n void StokesProblem<dim>::solve()\n  {\n TimerOutput::Scope solve(computing_timer, \"Solve\");\n    constraints.set_zero(solution);\n \n if (solver_type == SolverType::UMFPACK)\n      {\n        computing_timer.enter_subsection(\"(UMFPACK specific)\");\n        computing_timer.enter_subsection(\"Solve - Initialize\");\n \n SparseDirectUMFPACK A_direct;\n        A_direct.initialize(system_matrix);\n \n        computing_timer.leave_subsection();\n        computing_timer.leave_subsection();\n \n        {\n TimerOutput::Scope solve_backslash(computing_timer,\n \"Solve - Backslash\");\n          A_direct.vmult(solution, system_rhs);\n        }\n \n        constraints.distribute(solution);\n return;\n      }\n \n SolverControl solver_control(system_matrix.m(),\n                                 1e-10 * system_rhs.l2_norm());\n unsigned int  n_iterations_A;\n unsigned int  n_iterations_S;\n \n const bool use_expensive = true;\n \n SolverFGMRES<BlockVector<double>> solver(solver_control);\n \n if (solver_type == SolverType::FGMRES_ILU)\n      {\n        computing_timer.enter_subsection(\"(ILU specific)\");\n        computing_timer.enter_subsection(\"Solve - Set-up Preconditioner\");\n \n        std::cout << \"   Computing preconditioner...\" << std::endl\n                  << std::flush;\n \n SparseILU<double> A_preconditioner;\n        A_preconditioner.initialize(system_matrix.block(0, 0));\n \n SparseILU<double> S_preconditioner;\n        S_preconditioner.initialize(pressure_mass_matrix);\n \n const BlockSchurPreconditioner<SparseILU<double>, SparseILU<double>>\n          preconditioner(system_matrix,\n                         pressure_mass_matrix,\n                         A_preconditioner,\n                         S_preconditioner,\n                         use_expensive);\n \n        computing_timer.leave_subsection();\n        computing_timer.leave_subsection();\n \n        {\n TimerOutput::Scope solve_fmgres(computing_timer, \"Solve - FGMRES\");\n \n          solver.solve(system_matrix, solution, system_rhs, preconditioner);\n          n_iterations_A = preconditioner.n_iterations_A;\n          n_iterations_S = preconditioner.n_iterations_S;\n        }\n      }\n else\n      {\n        computing_timer.enter_subsection(\"(Multigrid specific)\");\n        computing_timer.enter_subsection(\"Solve - Set-up Preconditioner\");\n \n MGTransferPrebuilt<Vector<double>> mg_transfer(mg_constrained_dofs);\n        mg_transfer.build(velocity_dof_handler);\n \n FullMatrix<double> coarse_matrix;\n        coarse_matrix.copy_from(mg_matrices[0]);\n MGCoarseGridHouseholder<double, Vector<double>> coarse_grid_solver;\n        coarse_grid_solver.initialize(coarse_matrix);\n \n using Smoother = PreconditionSOR<SparseMatrix<double>>;\n mg::SmootherRelaxation<Smoother, Vector<double>> mg_smoother;\n        mg_smoother.initialize(mg_matrices);\n        mg_smoother.set_steps(2);\n \n        mg_smoother.set_symmetric(true);\n \n mg::Matrix<Vector<double>> mg_matrix(mg_matrices);\n mg::Matrix<Vector<double>> mg_interface_up(mg_interface_matrices);\n mg::Matrix<Vector<double>> mg_interface_down(mg_interface_matrices);\n \n Multigrid<Vector<double>> mg(\n          mg_matrix, coarse_grid_solver, mg_transfer, mg_smoother, mg_smoother);\n mg.set_edge_matrices(mg_interface_down, mg_interface_up);\n \n PreconditionMG<dim, Vector<double>, MGTransferPrebuilt<Vector<double>>>\n          A_Multigrid(velocity_dof_handler, mg, mg_transfer);\n \n SparseILU<double> S_preconditioner;\n        S_preconditioner.initialize(pressure_mass_matrix,\n SparseILU<double>::AdditionalData());\n \n const BlockSchurPreconditioner<\n PreconditionMG<dim,\n Vector<double>,\n MGTransferPrebuilt<Vector<double>>>,\n SparseILU<double>>\n          preconditioner(system_matrix,\n                         pressure_mass_matrix,\n                         A_Multigrid,\n                         S_preconditioner,\n                         use_expensive);\n \n        computing_timer.leave_subsection();\n        computing_timer.leave_subsection();\n \n        {\n TimerOutput::Scope solve_fmgres(computing_timer, \"Solve - FGMRES\");\n          solver.solve(system_matrix, solution, system_rhs, preconditioner);\n          n_iterations_A = preconditioner.n_iterations_A;\n          n_iterations_S = preconditioner.n_iterations_S;\n        }\n      }\n \n    constraints.distribute(solution);\n \n    std::cout\n      << std::endl\n      << \"\\tNumber of FGMRES iterations: \" << solver_control.last_step()\n      << std::endl\n      << \"\\tTotal number of iterations used for approximation of A inverse: \"\n      << n_iterations_A << std::endl\n      << \"\\tTotal number of iterations used for approximation of S inverse: \"\n      << n_iterations_S << std::endl\n      << std::endl;\n  }\n \n \n \n template <int dim>\n void StokesProblem<dim>::compute_errors()\n  {\n const double mean_pressure = VectorTools::compute_mean_value(\n      dof_handler, QGauss<dim>(pressure_degree + 2), solution, dim);\n    solution.block(1).add(-mean_pressure);\n    std::cout << \"   Note: The mean value was adjusted by \" << -mean_pressure\n              << std::endl;\n \n const ComponentSelectFunction<dim> pressure_mask(dim, dim + 1);\n const ComponentSelectFunction<dim> velocity_mask(std::make_pair(0, dim),\n                                                     dim + 1);\n \n Vector<float> difference_per_cell(triangulation.n_active_cells());\n VectorTools::integrate_difference(dof_handler,\n                                      solution,\n                                      Solution<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(pressure_degree + 2),\n VectorTools::L2_norm,\n                                      &velocity_mask);\n \n const double Velocity_L2_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::L2_norm);\n \n VectorTools::integrate_difference(dof_handler,\n                                      solution,\n                                      Solution<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(pressure_degree + 2),\n VectorTools::L2_norm,\n                                      &pressure_mask);\n \n const double Pressure_L2_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::L2_norm);\n \n VectorTools::integrate_difference(dof_handler,\n                                      solution,\n                                      Solution<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(pressure_degree + 2),\n VectorTools::H1_norm,\n                                      &velocity_mask);\n \n const double Velocity_H1_error =\n VectorTools::compute_global_error(triangulation,\n                                        difference_per_cell,\n VectorTools::H1_norm);\n \n    std::cout << std::endl\n              << \"   Velocity L2 Error: \" << Velocity_L2_error << std::endl\n              << \"   Pressure L2 Error: \" << Pressure_L2_error << std::endl\n              << \"   Velocity H1 Error: \" << Velocity_H1_error << std::endl;\n  }\n \n \n \n template <int dim>\n void\n  StokesProblem<dim>::output_results(const unsigned int refinement_cycle) const\n {\n    std::vector<std::string> solution_names(dim, \"velocity\");\n    solution_names.emplace_back(\"pressure\");\n \n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        dim, DataComponentInterpretation::component_is_part_of_vector);\n    data_component_interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n DataOut<dim> data_out;\n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(solution,\n                             solution_names,\n DataOut<dim>::type_dof_data,\n                             data_component_interpretation);\n    data_out.build_patches();\n \n    std::ofstream output(\n \"solution-\" + Utilities::int_to_string(refinement_cycle, 2) + \".vtk\");\n    data_out.write_vtk(output);\n  }\n \n \n \n \n template <int dim>\n void StokesProblem<dim>::run()\n  {\n GridGenerator::hyper_cube(triangulation);\n triangulation.refine_global(6 - dim);\n \n if (solver_type == SolverType::FGMRES_ILU)\n      std::cout << \"Now running with ILU\" << std::endl;\n else if (solver_type == SolverType::FGMRES_GMG)\n      std::cout << \"Now running with Multigrid\" << std::endl;\n else\n      std::cout << \"Now running with UMFPACK\" << std::endl;\n \n \n for (unsigned int refinement_cycle = 0; refinement_cycle < 3;\n         ++refinement_cycle)\n      {\n        std::cout << \"Refinement cycle \" << refinement_cycle << std::endl;\n \n if (refinement_cycle > 0)\n triangulation.refine_global(1);\n \n        std::cout << \"   Set-up...\" << std::endl;\n        setup_dofs();\n \n        std::cout << \"   Assembling...\" << std::endl;\n        assemble_system();\n \n if (solver_type == SolverType::FGMRES_GMG)\n          {\n            std::cout << \"   Assembling Multigrid...\" << std::endl;\n \n            assemble_multigrid();\n          }\n \n        std::cout << \"   Solving...\" << std::flush;\n        solve();\n \n        compute_errors();\n \n        output_results(refinement_cycle);\n \n Utilities::System::MemoryStats mem;\n Utilities::System::get_memory_stats(mem);\n        std::cout << \"   VM Peak: \" << mem.VmPeak << std::endl;\n \n        computing_timer.print_summary();\n        computing_timer.reset();\n      }\n  }\n} // namespace Step56\n \nint main()\n{\n try\n    {\n using namespace Step56;\n \n const int degree = 1;\n const int dim    = 3;\n      StokesProblem<dim> flow_problem(degree, SolverType::FGMRES_GMG);\n \n      flow_problem.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_57.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nIncompressible, stationary Navier Stokes equations.\nTutorial content :\nThis tutorial depends on [step-15](step_15.html), [step-22](step_22.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_57-Intro)    * [Navier Stokes Equations](#step_57-NavierStokesEquations) * [Linearization of Navier-Stokes Equations](#step_57-LinearizationofNavierStokesEquations) * [Finding an Initial Guess](#step_57-FindinganInitialGuess) * [The Solver and Preconditioner](#step_57-TheSolverandPreconditioner) * [Test Case](#step_57-TestCase)- [The commented program](#step_57-CommProg)      * [Include files](#step_57-Includefiles)* [The `NavierStokesProblem` class template](#step_57-ThecodeNavierStokesProblemcodeclasstemplate)* [Boundary values and right hand side](#step_57-Boundaryvaluesandrighthandside)* [BlockSchurPreconditioner for Navier Stokes equations](#step_57-BlockSchurPreconditionerforNavierStokesequations)* [StationaryNavierStokes class implementation](#step_57-StationaryNavierStokesclassimplementation)                + [StationaryNavierStokes::StationaryNavierStokes](#step_57-StationaryNavierStokesStationaryNavierStokes)+ [StationaryNavierStokes::setup\\_dofs](#step_57-StationaryNavierStokessetup_dofs)+ [StationaryNavierStokes::initialize\\_system](#step_57-StationaryNavierStokesinitialize_system)+ [StationaryNavierStokes::assemble](#step_57-StationaryNavierStokesassemble)+ [StationaryNavierStokes::solve](#step_57-StationaryNavierStokessolve)+ [StationaryNavierStokes::refine\\_mesh](#step_57-StationaryNavierStokesrefine_mesh)+ [StationaryNavierStokes::newton\\_iteration](#step_57-StationaryNavierStokesdimnewton_iteration)+ [StationaryNavierStokes::compute\\_initial\\_guess](#step_57-StationaryNavierStokescompute_initial_guess)+ [StationaryNavierStokes::output\\_results](#step_57-StationaryNavierStokesoutput_results)+ [StationaryNavierStokes::process\\_solution](#step_57-StationaryNavierStokesprocess_solution)+ [StationaryNavierStokes::run](#step_57-StationaryNavierStokesrun) | 1. [Results](#step_57-Results)    * [Test case 1: Low Reynolds Number](#step_57-Testcase1LowReynoldsNumber) * [Test case 2: High Reynolds Number](#step_57-Testcase2HighReynoldsNumber) * [Possibilities for extensions](#step_57-Possibilitiesforextensions)          + [Compare to other solvers](#step_57-Comparetoothersolvers)+ [3d computations](#step_57-3dcomputations)+ [Parallelization](#step_57-Parallelization)- [The plain program](#step_57-PlainProg) |\n\n*This program was contributed by Liang Zhao and Timo Heister.*\n\n*This material is based upon work partially supported by National Science Foundation grant DMS1522191 and the Computational Infrastructure in Geodynamics initiative (CIG), through the National Science Foundation under Award No. EAR-0949446 and The University of California-Davis.*\n\nNote\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.484156](https://zenodo.org/badge/DOI/10.5281/zenodo.484156.svg)](https://doi.org/10.5281/zenodo.484156)\n\nIntroduction\n============\n\n### Navier Stokes Equations\n\nIn this tutorial we show how to solve the incompressible Navier Stokes equations (NSE) with Newton's method. The flow we consider here is assumed to be steady. In a domain \\(\\Omega \\subset\n\\mathbb{R}^{d}\\), \\(d=2,3\\), with a piecewise smooth boundary \\(\\partial \\Omega\\), and a given force field \\(\\textbf{f}\\), we seek a velocity field \\(\\textbf{u}\\) and a pressure field \\(\\textbf{p}\\) satisfying\n\n\\begin{eqnarray\\*}\n- \\nu \\Delta\\textbf{u} + (\\textbf{u} \\cdot \\nabla)\\textbf{u} + \\nabla p &=& \\textbf{f}\\\\\n- \\nabla \\cdot \\textbf{u} &=& 0.\n\\end{eqnarray\\*}\n\nUnlike the Stokes equations as discussed in [step-22](step_22.html), the NSE are a nonlinear system of equations because of the convective term \\((\\textbf{u} \\cdot\n\\nabla)\\textbf{u}\\). The first step of computing a numerical solution is to linearize the system and this will be done using Newton's method. A time-dependent problem is discussed in [step-35](step_35.html), where the system is linearized using the solution from the last time step and no nonlinear solve is necessary.\n\n### Linearization of Navier-Stokes Equations\n\nWe define a nonlinear function whose root is a solution to the NSE by\n\n\\begin{eqnarray\\*}\nF(\\mathbf{u}, p) =\n\\begin{pmatrix}\n- \\nu \\Delta\\mathbf{u} + (\\mathbf{u} \\cdot \\nabla)\\mathbf{u} + \\nabla p - \\mathbf{f} \\\\\n- \\nabla \\cdot \\mathbf{u}\n\\end{pmatrix}.\n\\end{eqnarray\\*}\n\nAssuming the initial guess is good enough to guarantee the convergence of Newton's iteration and denoting \\(\\textbf{x} = (\\textbf{u}, p)\\), Newton's iteration on a vector function can be defined as\n\n\\begin{eqnarray\\*}\n\\textbf{x}^{k+1} = \\textbf{x}^{k} - (\\nabla F(\\textbf{x}^{k}))^{-1} F(\\textbf{x}^{k}),\n\\end{eqnarray\\*}\n\nwhere \\(\\textbf{x}^{k+1}\\) is the approximate solution in step \\(k+1\\), \\(\\textbf{x}^{k}\\) represents the solution from the previous step, and \\(\\nabla\nF(\\textbf{x}^{k})\\) is the Jacobian matrix evaluated at \\(\\textbf{x}^{k}\\). A similar iteration can be found in [step-15](step_15.html).\n\nThe Newton iteration formula implies the new solution is obtained by adding an update term to the old solution. Instead of evaluating the Jacobian matrix and taking its inverse, we consider the update term as a whole, that is\n\n\\begin{eqnarray\\*}\n\\delta \\textbf{x}^{k} = - (\\nabla F(\\textbf{x}^{k}))^{-1} F(\\textbf{x}^{k}),\n\\end{eqnarray\\*}\n\nwhere \\(\\textbf{x}^{k+1}=\\textbf{x}^{k}+\\delta \\textbf{x}^{k}\\).\n\nWe can find the update term by solving the system\n\n\\begin{eqnarray\\*}\n\\nabla F(\\textbf{x}^{k}) \\delta \\textbf{x}^{k} = -F(\\textbf{x}^{k}).\n\\end{eqnarray\\*}\n\nHere, the left of the previous equation represents the directional gradient of \\(F(\\textbf{x})\\) along \\(\\delta\n\\textbf{x}^{k}\\) at \\(\\textbf{x}^{k}\\). By definition, the directional gradient is given by\n\n\\begin{eqnarray\\*}\n& &\\nabla F(\\mathbf{u}^{k}, p^{k}) (\\delta \\mathbf{u}^{k}, \\delta p^{k}) \\\\\n\\\\\n&=& \\lim\\_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n\\left(\nF(\\mathbf{u}^{k} + \\epsilon \\delta \\mathbf{u}^{k},\np^{k} + \\epsilon \\nabla \\delta p^{k})\n- F(\\mathbf{u}^{k}, p^{k})\n\\right)\\\\\n\\\\\n&=& \\lim\\_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n\\begin{pmatrix}\n- \\epsilon \\nu \\Delta \\delta \\mathbf{u}^{k}\n+ \\epsilon \\mathbf{u}^{k} \\cdot \\nabla \\delta \\mathbf{u}^{k}\n+ \\epsilon \\delta \\mathbf{u}^{k} \\cdot \\nabla \\mathbf{u}^{k}\n+ \\epsilon^{2} \\delta \\mathbf{u}^{k} \\cdot \\nabla \\delta \\mathbf{u}^{k}\n+ \\epsilon \\nabla \\delta p^{k}\\\\\n- \\epsilon \\nabla \\cdot \\delta \\mathbf{u}^{k}\n\\end{pmatrix} \\\\\n\\\\\n&=& \\begin{pmatrix}\n- \\nu \\Delta \\delta \\mathbf{u}^{k}\n+ \\mathbf{u}^{k} \\cdot \\nabla \\delta \\mathbf{u}^{k}\n+ \\delta \\mathbf{u}^{k} \\cdot \\nabla \\mathbf{u}^{k}\n+ \\nabla \\delta p^{k}\\\\\n- \\nabla \\cdot \\delta \\mathbf{u}^{k}\n\\end{pmatrix}.\n\\end{eqnarray\\*}\n\nTherefore, we arrive at the linearized system:\n\n\\begin{eqnarray\\*}\n-\\nu \\Delta \\delta \\mathbf{u}^{k}\n+ \\mathbf{u}^{k} \\cdot \\nabla \\delta \\mathbf{u}^{k}\n+ \\delta \\mathbf{u}^{k} \\cdot \\nabla \\mathbf{u}^{k}\n+ \\nabla \\delta p^{k}\n= -F(\\mathbf{x}^k), \\\\\n-\\nabla \\cdot\\delta \\mathbf{u}^{k}\n= \\nabla \\cdot \\mathbf{u}^{k},\n\\end{eqnarray\\*}\n\nwhere \\(\\textbf{u}^k\\) and \\(p^k\\) are the solutions from the previous iteration. Additionally, the right hand side of the second equation is not zero since the discrete solution is not exactly divergence free (divergence free for the continuous solution). The right hand side here acts as a correction which leads the discrete solution of the velocity to be divergence free along Newton's iteration. In this linear system, the only unknowns are the update terms \\(\\delta \\textbf{u}^{k}\\) and \\(\\delta p^{k}\\), and we can use a similar strategy to the one used in [step-22](step_22.html) (and derive the weak form in the same way).\n\nNow, Newton's iteration can be used to solve for the update terms:\n\n1. Initialization: Initial guess \\(u\\_0\\) and \\(p\\_0\\), tolerance \\(\\tau\\);\n2. Linear solve to compute update term \\(\\delta\\textbf{u}^{k}\\) and \\(\\delta p^k\\);\n3. Update the approximation: \\(\\textbf{u}^{k+1} = \\textbf{u}^{k} + \\delta\\textbf{u}^{k}\\) and \\(p^{k+1} = p^{k} + \\delta p^{k}\\);\n4. Check residual norm: \\(E^{k+1} = \\|F(\\mathbf{u}^{k+1}, p^{k+1})\\|\\):\n   * If \\(E^{k+1} \\leq \\tau\\), STOP.\n   * If \\(E^{k+1} > \\tau\\), back to step 2.\n\n### Finding an Initial Guess\n\nThe initial guess needs to be close enough to the solution for Newton's method to converge; hence, finding a good starting value is crucial to the nonlinear solver.\n\nWhen the viscosity \\(\\nu\\) is large, a good initial guess can be obtained by solving the Stokes equation with viscosity \\(\\nu\\). While problem dependent, this works for \\(\\nu \\geq 1/400\\) for the test problem considered here.\n\nHowever, the convective term \\((\\mathbf{u}\\cdot\\nabla)\\mathbf{u}\\) will be dominant if the viscosity is small, like \\(1/7500\\) in test case 2. In this situation, we use a continuation method to set up a series of auxiliary NSEs with viscosity approaching the one in the target NSE. Correspondingly, we create a sequence \\(\\{\\nu\\_{i}\\}\\) with \\(\\nu\\_{n}= \\nu\\), and accept that the solutions to two NSE with viscosity \\(\\nu\\_{i}\\) and \\(\\nu\\_{i+1}\\) are close if \\(|\\nu\\_{i} -\n\\nu\\_{i+1}|\\) is small. Then we use the solution to the NSE with viscosity \\(\\nu\\_{i}\\) as the initial guess of the NSE with \\(\\nu\\_{i+1}\\). This can be thought of as a staircase from the Stokes equations to the NSE we want to solve.\n\nThat is, we first solve a Stokes problem\n\n\\begin{eqnarray\\*}\n-\\nu\\_{1} \\Delta \\textbf{u} + \\nabla p &=& \\textbf{f}\\\\\n-\\nabla \\cdot \\textbf{u} &=& 0\n\\end{eqnarray\\*}\n\nto get the initial guess for\n\n\\begin{eqnarray\\*}\n-\\nu\\_{1} \\Delta \\textbf{u} + (\\textbf{u} \\cdot \\nabla)\\textbf{u} + \\nabla p &=& \\textbf{f},\\\\\n-\\nabla \\cdot \\textbf{u} &=& 0,\n\\end{eqnarray\\*}\n\nwhich also acts as the initial guess of the continuation method. Here \\(\\nu\\_{1}\\) is relatively large so that the solution to the Stokes problem with viscosity \\(\\nu\\_{1}\\) can be used as an initial guess for the NSE in Newton's iteration.\n\nThen the solution to\n\n\\begin{eqnarray\\*}\n-\\nu\\_{i} \\Delta \\textbf{u} + (\\textbf{u} \\cdot \\nabla)\\textbf{u} + \\nabla p &=& \\textbf{f},\\\\\n-\\nabla \\cdot \\textbf{u} &=& 0.\n\\end{eqnarray\\*}\n\nacts as the initial guess for\n\n\\begin{eqnarray\\*}\n-\\nu\\_{i+1} \\Delta \\textbf{u} + (\\textbf{u} \\cdot \\nabla)\\textbf{u} + \\nabla p &=& \\textbf{f},\\\\\n-\\nabla \\cdot \\textbf{u} &=& 0.\n\\end{eqnarray\\*}\n\nThis process is repeated with a sequence of viscosities \\(\\{\\nu\\_i\\}\\) that is determined experimentally so that the final solution can used as a starting guess for the Newton iteration.\n\n### The Solver and Preconditioner\n\nAt each step of Newton's iteration, the problem results in solving a saddle point systems of the form\n\n\\begin{eqnarray\\*}\n\\begin{pmatrix}\nA & B^{T} \\\\\nB & 0\n\\end{pmatrix}\n\\begin{pmatrix}\nU \\\\\nP\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nF \\\\\n0\n\\end{pmatrix}.\n\\end{eqnarray\\*}\n\nThis system matrix has the same block structure as the one in [step-22](step_22.html). However, the matrix \\(A\\) at the top left corner is not symmetric because of the nonlinear term. Instead of solving the above system, we can solve the equivalent system\n\n\\begin{eqnarray\\*}\n\\begin{pmatrix}\nA + \\gamma B^TW^{-1}B & B^{T} \\\\\nB & 0\n\\end{pmatrix}\n\\begin{pmatrix}\nU \\\\\nP\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nF \\\\\n0\n\\end{pmatrix}\n\\end{eqnarray\\*}\n\nwith a parameter \\(\\gamma\\) and an invertible matrix \\(W\\). Here \\(\\gamma B^TW^{-1}B\\) is the Augmented Lagrangian term; see [[26]](citelist.html#CITEREF_Benzi2006) for details.\n\nDenoting the system matrix of the new system by \\(G\\) and the right-hand side by \\(b\\), we solve it iteratively with right preconditioning \\(P^{-1}\\) as \\(GP^{-1}y = b\\), where\n\n\\begin{eqnarray\\*}\nP^{-1} =\n\\begin{pmatrix}\n\\tilde{A} & B^T \\\\\n0 & \\tilde{S}\n\\end{pmatrix}^{-1}\n\\end{eqnarray\\*}\n\nwith \\(\\tilde{A} = A + \\gamma B^TW^{-1}B\\) and \\(\\tilde{S}\\) is the corresponding Schur complement \\(\\tilde{S} = B^T \\tilde{A}^{-1} B\\). We let \\(W = M\\_p\\) where \\(M\\_p\\) is the pressure [mass matrix](DEALGlossary.html#GlossMassMatrix), then \\(\\tilde{S}^{-1}\\) can be approximated by\n\n\\begin{eqnarray\\*}\n\\tilde{S}^{-1} \\approx -(\\nu+\\gamma)M\\_p^{-1}.\n\\end{eqnarray\\*}\n\nSee [[26]](citelist.html#CITEREF_Benzi2006) for details.\n\nWe decompose \\(P^{-1}\\) as\n\n\\begin{eqnarray\\*}\nP^{-1} =\n\\begin{pmatrix}\n\\tilde{A}^{-1} & 0 \\\\\n0 & I\n\\end{pmatrix}\n\\begin{pmatrix}\nI & -B^T \\\\\n0 & I\n\\end{pmatrix}\n\\begin{pmatrix}\nI & 0 \\\\\n0 & \\tilde{S}^{-1}\n\\end{pmatrix}.\n\\end{eqnarray\\*}\n\nHere two inexact solvers will be needed for \\(\\tilde{A}^{-1}\\) and \\(\\tilde{S}^{-1}\\), respectively (see [[26]](citelist.html#CITEREF_Benzi2006)). Since the pressure mass matrix is symmetric and positive definite, CG with ILU as a preconditioner is appropriate to use for \\(\\tilde{S}^{-1}\\). For simplicity, we use the direct solver UMFPACK for \\(\\tilde{A}^{-1}\\). The last ingredient is a sparse matrix-vector product with \\(B^T\\). Instead of computing the matrix product in the augmented Lagrangian term in \\(\\tilde{A}\\), we assemble Grad-Div stabilization \\((\\nabla \\cdot \\phi \\_{i}, \\nabla \\cdot \\phi \\_{j}) \\approx (B^T\nM\\_p^{-1}B)\\_{ij}\\), as explained in [[113]](citelist.html#CITEREF_HeisterRapin2013).\n\n### Test Case\n\nWe use the lid driven cavity flow as our test case; see [this page](http://www.cfd-online.com/Wiki/Lid-driven_cavity_problem) for details. The computational domain is the unit square and the right-hand side is \\(f=0\\). The boundary condition is\n\n\\begin{eqnarray\\*}\n(u(x, y), v(x,y)) &=& (1,0) \\qquad\\qquad \\textrm{if}\\ y = 1 \\\\\n(u(x, y), v(x,y)) &=& (0,0) \\qquad\\qquad \\textrm{otherwise}.\n\\end{eqnarray\\*}\n\nWhen solving this problem, the error consists of the nonlinear error (from Newton's iteration) and the discretization error (dependent on mesh size). The nonlinear part decreases with each Newton iteration and the discretization error reduces with mesh refinement. In this example, the solution from the coarse mesh is transferred to successively finer meshes and used as an initial guess. Therefore, the nonlinear error is always brought below the tolerance of Newton's iteration and the discretization error is reduced with each mesh refinement.\n\nInside the loop, we involve three solvers: one for \\(\\tilde{A}^{-1}\\), one for \\(M\\_p^{-1}\\) and one for \\(Gx=b\\). The first two solvers are invoked in the preconditioner and the outer solver gives us the update term. Overall convergence is controlled by the nonlinear residual; as Newton's method does not require an exact Jacobian, we employ FGMRES with a relative tolerance of only 1e-4 for the outer linear solver. In fact, we use the truncated Newton solve for this system. As described in [step-22](step_22.html), the inner linear solves are also not required to be done very accurately. Here we use CG with a relative tolerance of 1e-6 for the pressure mass matrix. As expected, we still see convergence of the nonlinear residual down to 1e-14. Also, we use a simple line search algorithm for globalization of the Newton method.\n\nThe cavity reference values for \\(\\mathrm{Re}=400\\) and \\(\\mathrm{Re}=7500\\) are from [[97]](citelist.html#CITEREF_Ghia1982) and [[83]](citelist.html#CITEREF_Erturk2005), respectively, where \\(\\mathrm{Re}\\) is the [Reynolds number](https://en.wikipedia.org/wiki/Reynolds_number). Here the viscosity is defined by \\(1/\\mathrm{Re}\\). Even though we can still find a solution for \\(\\mathrm{Re}=10000\\) and the papers cited throughout this introduction contain results for comparison, we limit our discussion here to \\(\\mathrm{Re}=7500\\). This is because the solution is no longer stationary starting around \\(\\mathrm{Re}=8000\\) but instead becomes periodic, see [[47]](citelist.html#CITEREF_Bruneau2006) for details.\n\nThe commented program\n=====================\n\n### Include files\n\nAs usual, we start by including some well-known files:\n\n```\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/utilities.h>\n   #include <deal.II/base/tensor.h>\n   \n   #include <deal.II/lac/block_vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/block_sparse_matrix.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/solver_gmres.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/affine_constraints.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   #include <deal.II/grid/grid_tools.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   \n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n```\n\nTo transfer solutions between meshes, this file is included:\n\n```\n   #include <deal.II/numerics/solution_transfer.h>\n```\n\nThis file includes UMFPACK: the direct solver:\n\n```\n   #include <deal.II/lac/sparse_direct.h>\n```\n\nAnd the one for ILU preconditioner:\n\n```\n   #include <deal.II/lac/sparse_ilu.h>\n   \n   \n   #include <fstream>\n   #include <iostream>\n   \n   namespace Step57\n   {\n     using namespace dealii;\n```\n\n### The `NavierStokesProblem` class template\n\nThis class manages the matrices and vectors described in the introduction: in particular, we store a [BlockVector](classBlockVector.html) for the current solution, current Newton update, and the line search update. We also store two [AffineConstraints](classAffineConstraints.html) objects: one which enforces the Dirichlet boundary conditions and one that sets all boundary values to zero. The first constrains the solution vector while the second constraints the updates (i.e., we never update boundary values, so we force the relevant update vector values to be zero).\n\n```\n     template <int dim>\n     class StationaryNavierStokes\n     {\n     public:\n       StationaryNavierStokes(const unsigned int degree);\n       void run(const unsigned int refinement);\n   \n     private:\n       void setup_dofs();\n   \n       void initialize_system();\n   \n       void assemble(const bool initial_step, const bool assemble_matrix);\n   \n       void assemble_system(const bool initial_step);\n   \n       void assemble_rhs(const bool initial_step);\n   \n       void solve(const bool initial_step);\n   \n       void refine_mesh();\n   \n       void process_solution(unsigned int refinement);\n   \n       void output_results(const unsigned int refinement_cycle) const;\n   \n       void newton_iteration(const double       tolerance,\n                             const unsigned int max_n_line_searches,\n                             const unsigned int max_n_refinements,\n                             const bool         is_initial_step,\n                             const bool         output_result);\n   \n       void compute_initial_guess(double step_size);\n   \n       double                               viscosity;\n       double                               gamma;\n       const unsigned int                   degree;\n       std::vector<types::global_dof_index> dofs_per_block;\n   \n       Triangulation<dim> triangulation;\n       const FESystem<dim> fe;\n       DoFHandler<dim>     dof_handler;\n   \n       AffineConstraints<double> zero_constraints;\n       AffineConstraints<double> nonzero_constraints;\n   \n       BlockSparsityPattern      sparsity_pattern;\n       BlockSparseMatrix<double> system_matrix;\n       SparseMatrix<double>      pressure_mass_matrix;\n   \n       BlockVector<double> present_solution;\n       BlockVector<double> newton_update;\n       BlockVector<double> system_rhs;\n       BlockVector<double> evaluation_point;\n     };\n```\n\n### Boundary values and right hand side\n\nIn this problem we set the velocity along the upper surface of the cavity to be one and zero on the other three walls. The right hand side function is zero so we do not need to set the right hand side function in this tutorial. The number of components of the boundary function is `dim+1`. We will ultimately use [VectorTools::interpolate\\_boundary\\_values](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) to set boundary values, which requires the boundary value functions to have the same number of components as the solution, even if all are not used. Put another way: to make this function happy we define boundary values for the pressure even though we will never actually use them.\n\n```\n     template <int dim>\n     class BoundaryValues : public Function<dim>\n     {\n     public:\n       BoundaryValues()\n         : Function<dim>(dim + 1)\n       {}\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component) const override;\n     };\n   \n     template <int dim>\n     double BoundaryValues<dim>::value(const Point<dim>  &p,\n                                       const unsigned int component) const\n     {\n       Assert(component < this->n_components,\n              ExcIndexRange(component, 0, this->n_components));\n       if (component == 0 && std::abs(p[dim - 1] - 1.0) < 1e-10)\n         return 1.0;\n   \n       return 0;\n     }\n```\n\n### BlockSchurPreconditioner for Navier Stokes equations\n\nAs discussed in the introduction, the preconditioner in Krylov iterative methods is implemented as a matrix-vector product operator. In practice, the Schur complement preconditioner is decomposed as a product of three matrices (as presented in the first section). The \\(\\tilde{A}^{-1}\\) in the first factor involves a solve for the linear system \\(\\tilde{A}x=b\\). Here we solve this system via a direct solver for simplicity. The computation involved in the second factor is a simple matrix-vector multiplication. The Schur complement \\(\\tilde{S}\\) can be well approximated by the pressure [mass matrix](DEALGlossary.html#GlossMassMatrix) and its inverse can be obtained through an inexact solver. Because the pressure mass matrix is symmetric and positive definite, we can use CG to solve the corresponding linear system.\n\n```\n     template <class PreconditionerMp>\n     class BlockSchurPreconditioner : public Subscriptor\n     {\n     public:\n       BlockSchurPreconditioner(double                           gamma,\n                                double                           viscosity,\n                                const BlockSparseMatrix<double> &S,\n                                const SparseMatrix<double>      &P,\n                                const PreconditionerMp          &Mppreconditioner);\n   \n       void vmult(BlockVector<double> &dst, const BlockVector<double> &src) const;\n   \n     private:\n       const double                     gamma;\n       const double                     viscosity;\n       const BlockSparseMatrix<double> &stokes_matrix;\n       const SparseMatrix<double>      &pressure_mass_matrix;\n       const PreconditionerMp          &mp_preconditioner;\n       SparseDirectUMFPACK              A_inverse;\n     };\n```\n\nWe can notice that the initialization of the inverse of the matrix at the top left corner is completed in the constructor. If so, every application of the preconditioner then no longer requires the computation of the matrix factors.\n\n```\n     template <class PreconditionerMp>\n     BlockSchurPreconditioner<PreconditionerMp>::BlockSchurPreconditioner(\n       double                           gamma,\n       double                           viscosity,\n       const BlockSparseMatrix<double> &S,\n       const SparseMatrix<double>      &P,\n       const PreconditionerMp          &Mppreconditioner)\n       : gamma(gamma)\n       , viscosity(viscosity)\n       , stokes_matrix(S)\n       , pressure_mass_matrix(P)\n       , mp_preconditioner(Mppreconditioner)\n     {\n       A_inverse.initialize(stokes_matrix.block(0, 0));\n     }\n   \n     template <class PreconditionerMp>\n     void BlockSchurPreconditioner<PreconditionerMp>::vmult(\n       BlockVector<double>       &dst,\n       const BlockVector<double> &src) const\n     {\n       Vector<double> utmp(src.block(0));\n   \n       {\n         SolverControl solver_control(1000, 1e-6 * src.block(1).l2_norm());\n         SolverCG<Vector<double>> cg(solver_control);\n   \n         dst.block(1) = 0.0;\n         cg.solve(pressure_mass_matrix,\n                  dst.block(1),\n                  src.block(1),\n                  mp_preconditioner);\n         dst.block(1) *= -(viscosity + gamma);\n       }\n   \n       {\n         stokes_matrix.block(0, 1).vmult(utmp, dst.block(1));\n         utmp *= -1.0;\n         utmp += src.block(0);\n       }\n   \n       A_inverse.vmult(dst.block(0), utmp);\n     }\n```\n\n### StationaryNavierStokes class implementation\n\n#### StationaryNavierStokes::StationaryNavierStokes\n\nThe constructor of this class looks very similar to the one in [step-22](step_22.html). The only difference is the viscosity and the Augmented Lagrangian coefficient `gamma`.\n\n```\n     template <int dim>\n     StationaryNavierStokes<dim>::StationaryNavierStokes(const unsigned int degree)\n       : viscosity(1.0 / 7500.0)\n       , gamma(1.0)\n       , degree(degree)\n       , triangulation(Triangulation<dim>::maximum_smoothing)\n       , fe(FE_Q<dim>(degree + 1) ^ dim, FE_Q<dim>(degree))\n       , dof_handler(triangulation)\n     {}\n```\n\n#### StationaryNavierStokes::setup\\_dofs\n\nThis function initializes the [DoFHandler](classDoFHandler.html) enumerating the degrees of freedom and constraints on the current mesh.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::setup_dofs()\n     {\n       system_matrix.clear();\n       pressure_mass_matrix.clear();\n```\n\nThe first step is to associate DoFs with a given mesh.\n\n```\n       dof_handler.distribute_dofs(fe);\n```\n\nWe renumber the components to have all velocity DoFs come before the pressure DoFs to be able to split the solution vector in two blocks which are separately accessed in the block preconditioner.\n\n```\n       std::vector<unsigned int> block_component(dim + 1, 0);\n       block_component[dim] = 1;\n       DoFRenumbering::component_wise(dof_handler, block_component);\n   \n       dofs_per_block =\n         DoFTools::count_dofs_per_fe_block(dof_handler, block_component);\n       unsigned int dof_u = dofs_per_block[0];\n       unsigned int dof_p = dofs_per_block[1];\n```\n\nIn Newton's scheme, we first apply the boundary condition on the solution obtained from the initial step. To make sure the boundary conditions remain satisfied during Newton's iteration, zero boundary conditions are used for the update \\(\\delta u^k\\). Therefore we set up two different constraint objects.\n\n```\n       const FEValuesExtractors::Vector velocities(0);\n       {\n         nonzero_constraints.clear();\n   \n         DoFTools::make_hanging_node_constraints(dof_handler, nonzero_constraints);\n         VectorTools::interpolate_boundary_values(dof_handler,\n                                                  0,\n                                                  BoundaryValues<dim>(),\n                                                  nonzero_constraints,\n                                                  fe.component_mask(velocities));\n       }\n       nonzero_constraints.close();\n   \n       {\n         zero_constraints.clear();\n   \n         DoFTools::make_hanging_node_constraints(dof_handler, zero_constraints);\n         VectorTools::interpolate_boundary_values(dof_handler,\n                                                  0,\n                                                  Functions::ZeroFunction<dim>(\n                                                    dim + 1),\n                                                  zero_constraints,\n                                                  fe.component_mask(velocities));\n       }\n       zero_constraints.close();\n   \n       std::cout << \"Number of active cells: \" << triangulation.n_active_cells()\n                 << std::endl\n                 << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n                 << \" (\" << dof_u << \" + \" << dof_p << ')' << std::endl;\n     }\n```\n\n#### StationaryNavierStokes::initialize\\_system\n\nOn each mesh the [SparsityPattern](classSparsityPattern.html) and the size of the linear system are different. This function initializes them after mesh refinement.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::initialize_system()\n     {\n       {\n         BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n         DoFTools::make_sparsity_pattern(dof_handler, dsp, nonzero_constraints);\n         sparsity_pattern.copy_from(dsp);\n       }\n   \n       system_matrix.reinit(sparsity_pattern);\n   \n       present_solution.reinit(dofs_per_block);\n       newton_update.reinit(dofs_per_block);\n       system_rhs.reinit(dofs_per_block);\n     }\n```\n\n#### StationaryNavierStokes::assemble\n\nThis function builds the system matrix and right hand side that we currently work on. The `initial_step` argument is used to determine which set of constraints we apply (nonzero for the initial step and zero for the others). The `assemble_matrix` argument determines whether to assemble the whole system or only the right hand side vector, respectively.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::assemble(const bool initial_step,\n                                                const bool assemble_matrix)\n     {\n       if (assemble_matrix)\n         system_matrix = 0;\n   \n       system_rhs = 0;\n   \n       const QGauss<dim> quadrature_formula(degree + 2);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values | update_gradients);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       const FEValuesExtractors::Vector velocities(0);\n       const FEValuesExtractors::Scalar pressure(dim);\n   \n       FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<double>     local_rhs(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n```\n\nFor the linearized system, we create temporary storage for present velocity and gradient, and present pressure. In practice, they are all obtained through their shape functions at quadrature points.\n\n```\n       std::vector<Tensor<1, dim>> present_velocity_values(n_q_points);\n       std::vector<Tensor<2, dim>> present_velocity_gradients(n_q_points);\n       std::vector<double>         present_pressure_values(n_q_points);\n   \n       std::vector<double>         div_phi_u(dofs_per_cell);\n       std::vector<Tensor<1, dim>> phi_u(dofs_per_cell);\n       std::vector<Tensor<2, dim>> grad_phi_u(dofs_per_cell);\n       std::vector<double>         phi_p(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           fe_values.reinit(cell);\n   \n           local_matrix = 0;\n           local_rhs    = 0;\n   \n           fe_values[velocities].get_function_values(evaluation_point,\n                                                     present_velocity_values);\n   \n           fe_values[velocities].get_function_gradients(\n             evaluation_point, present_velocity_gradients);\n   \n           fe_values[pressure].get_function_values(evaluation_point,\n                                                   present_pressure_values);\n```\n\nThe assembly is similar to [step-22](step_22.html). An additional term with gamma as a coefficient is the Augmented Lagrangian (AL), which is assembled via grad-div stabilization. As we discussed in the introduction, the bottom right block of the system matrix should be zero. Since the pressure mass matrix is used while creating the preconditioner, we assemble it here and then move it into a separate [SparseMatrix](classSparseMatrix.html) at the end (same as in [step-22](step_22.html)).\n\n```\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             {\n               for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                 {\n                   div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                   grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                   phi_u[k]      = fe_values[velocities].value(k, q);\n                   phi_p[k]      = fe_values[pressure].value(k, q);\n                 }\n   \n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 {\n                   if (assemble_matrix)\n                     {\n                       for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                         {\n                           local_matrix(i, j) +=\n                             (viscosity *\n                                scalar_product(grad_phi_u[i], grad_phi_u[j]) +\n                              phi_u[i] *\n                                (present_velocity_gradients[q] * phi_u[j]) +\n                              phi_u[i] *\n                                (grad_phi_u[j] * present_velocity_values[q]) -\n                              div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j] +\n                              gamma * div_phi_u[i] * div_phi_u[j] +\n                              phi_p[i] * phi_p[j]) *\n                             fe_values.JxW(q);\n                         }\n                     }\n   \n                   double present_velocity_divergence =\n                     trace(present_velocity_gradients[q]);\n                   local_rhs(i) +=\n                     (-viscosity * scalar_product(grad_phi_u[i],\n                                                  present_velocity_gradients[q]) -\n                      phi_u[i] * (present_velocity_gradients[q] *\n                                  present_velocity_values[q]) +\n                      div_phi_u[i] * present_pressure_values[q] +\n                      phi_p[i] * present_velocity_divergence -\n                      gamma * div_phi_u[i] * present_velocity_divergence) *\n                     fe_values.JxW(q);\n                 }\n             }\n   \n           cell->get_dof_indices(local_dof_indices);\n   \n           const AffineConstraints<double> &constraints_used =\n             initial_step ? nonzero_constraints : zero_constraints;\n   \n           if (assemble_matrix)\n             {\n               constraints_used.distribute_local_to_global(local_matrix,\n                                                           local_rhs,\n                                                           local_dof_indices,\n                                                           system_matrix,\n                                                           system_rhs);\n             }\n           else\n             {\n               constraints_used.distribute_local_to_global(local_rhs,\n                                                           local_dof_indices,\n                                                           system_rhs);\n             }\n         }\n```\n\nIf we were asked to assemble the Newton matrix, then we also built a pressure mass matrix in the bottom right block of the matrix. We only need this for the preconditioner, so we need to copy it in into a separate matrix object, followed by zeroing out this block in the Newton matrix.\n\nNote that settings this bottom right block to zero is not identical to not assembling anything in this block, because applying boundary values and hanging node constraints (in the `constraints_used.distribute_local_to_global()` call above) puts entries into this block. As a consequence, setting the \\((1,1)\\) block to zero below does not result in what would have happened if we had just not assembled a pressure mass matrix in that block to begin with.\n\nThe difference is that if we had not assembled anything in this block, dealing with constraint degrees of freedom would have put entries on the diagonal of the \\((1,1)\\) block whereas the last operation below, zeroing out the entire block, results in a system matrix with rows and columns that are completely empty. In other words, the linear problem is singular. Luckily, however, the FGMRES solver we use appears to handle these rows and columns without any problem.\n\n```\n       if (assemble_matrix)\n         {\n           pressure_mass_matrix.reinit(sparsity_pattern.block(1, 1));\n           pressure_mass_matrix.copy_from(system_matrix.block(1, 1));\n   \n           system_matrix.block(1, 1) = 0;\n         }\n     }\n   \n     template <int dim>\n     void StationaryNavierStokes<dim>::assemble_system(const bool initial_step)\n     {\n       assemble(initial_step, true);\n     }\n   \n     template <int dim>\n     void StationaryNavierStokes<dim>::assemble_rhs(const bool initial_step)\n     {\n       assemble(initial_step, false);\n     }\n```\n\n#### StationaryNavierStokes::solve\n\nIn this function, we use FGMRES together with the block preconditioner, which is defined at the beginning of the program, to solve the linear system. What we obtain at this step is the solution vector. If this is the initial step, the solution vector gives us an initial guess for the Navier Stokes equations. For the initial step, nonzero constraints are applied in order to make sure boundary conditions are satisfied. In the following steps, we will solve for the Newton update so zero constraints are used.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::solve(const bool initial_step)\n     {\n       const AffineConstraints<double> &constraints_used =\n         initial_step ? nonzero_constraints : zero_constraints;\n   \n       SolverControl solver_control(system_matrix.m(),\n                                    1e-4 * system_rhs.l2_norm(),\n                                    true);\n   \n       SolverFGMRES<BlockVector<double>> gmres(solver_control);\n       SparseILU<double>                 pmass_preconditioner;\n       pmass_preconditioner.initialize(pressure_mass_matrix,\n                                       SparseILU<double>::AdditionalData());\n   \n       const BlockSchurPreconditioner<SparseILU<double>> preconditioner(\n         gamma,\n         viscosity,\n         system_matrix,\n         pressure_mass_matrix,\n         pmass_preconditioner);\n   \n       gmres.solve(system_matrix, newton_update, system_rhs, preconditioner);\n       std::cout << \"FGMRES steps: \" << solver_control.last_step() << std::endl;\n   \n       constraints_used.distribute(newton_update);\n     }\n```\n\n#### StationaryNavierStokes::refine\\_mesh\n\nAfter finding a good initial guess on the coarse mesh, we hope to decrease the error through refining the mesh. Here we do adaptive refinement similar to [step-15](step_15.html) except that we use the Kelly estimator on the velocity only. We also need to transfer the current solution to the next mesh using the [SolutionTransfer](classSolutionTransfer.html) class.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::refine_mesh()\n     {\n       Vector<float> estimated_error_per_cell(triangulation.n_active_cells());\n       const FEValuesExtractors::Vector velocity(0);\n       KellyErrorEstimator<dim>::estimate(\n         dof_handler,\n         QGauss<dim - 1>(degree + 1),\n         std::map<types::boundary_id, const Function<dim> *>(),\n         present_solution,\n         estimated_error_per_cell,\n         fe.component_mask(velocity));\n   \n       GridRefinement::refine_and_coarsen_fixed_number(triangulation,\n                                                       estimated_error_per_cell,\n                                                       0.3,\n                                                       0.0);\n   \n       triangulation.prepare_coarsening_and_refinement();\n       SolutionTransfer<dim, BlockVector<double>> solution_transfer(dof_handler);\n       solution_transfer.prepare_for_coarsening_and_refinement(present_solution);\n       triangulation.execute_coarsening_and_refinement();\n```\n\nFirst the [DoFHandler](classDoFHandler.html) is set up and constraints are generated. Then we create a temporary [BlockVector](classBlockVector.html) `tmp`, whose size is according with the solution on the new mesh.\n\n```\n       setup_dofs();\n   \n       BlockVector<double> tmp(dofs_per_block);\n```\n\nTransfer solution from coarse to fine mesh and apply boundary value constraints to the new transferred solution. Note that present\\_solution is still a vector corresponding to the old mesh.\n\n```\n       solution_transfer.interpolate(present_solution, tmp);\n       nonzero_constraints.distribute(tmp);\n```\n\nFinally set up matrix and vectors and set the present\\_solution to the interpolated data.\n\n```\n       initialize_system();\n       present_solution = tmp;\n     }\n```\n\n#### StationaryNavierStokes<dim>::newton\\_iteration\n\nThis function implements the Newton iteration with given tolerance, maximum number of iterations, and the number of mesh refinements to do.\n\nThe argument `is_initial_step` tells us whether `setup_system` is necessary, and which part, system matrix or right hand side vector, should be assembled. If we do a line search, the right hand side is already assembled while checking the residual norm in the last iteration. Therefore, we just need to assemble the system matrix at the current iteration. The last argument `output_result` determines whether or not graphical output should be produced.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::newton_iteration(\n       const double       tolerance,\n       const unsigned int max_n_line_searches,\n       const unsigned int max_n_refinements,\n       const bool         is_initial_step,\n       const bool         output_result)\n     {\n       bool first_step = is_initial_step;\n   \n       for (unsigned int refinement_n = 0; refinement_n < max_n_refinements + 1;\n            ++refinement_n)\n         {\n           unsigned int line_search_n = 0;\n           double       last_res      = 1.0;\n           double       current_res   = 1.0;\n           std::cout << \"grid refinements: \" << refinement_n << std::endl\n                     << \"viscosity: \" << viscosity << std::endl;\n   \n           while ((first_step || (current_res > tolerance)) &&\n                  line_search_n < max_n_line_searches)\n             {\n               if (first_step)\n                 {\n                   setup_dofs();\n                   initialize_system();\n                   evaluation_point = present_solution;\n                   assemble_system(first_step);\n                   solve(first_step);\n                   present_solution = newton_update;\n                   nonzero_constraints.distribute(present_solution);\n                   first_step       = false;\n                   evaluation_point = present_solution;\n                   assemble_rhs(first_step);\n                   current_res = system_rhs.l2_norm();\n                   std::cout << \"The residual of initial guess is \" << current_res\n                             << std::endl;\n                   last_res = current_res;\n                 }\n               else\n                 {\n                   evaluation_point = present_solution;\n                   assemble_system(first_step);\n                   solve(first_step);\n```\n\nTo make sure our solution is getting close to the exact solution, we let the solution be updated with a weight `alpha` such that the new residual is smaller than the one of last step, which is done in the following loop. This is the same line search algorithm used in [step-15](step_15.html).\n\n```\n                   for (double alpha = 1.0; alpha > 1e-5; alpha *= 0.5)\n                     {\n                       evaluation_point = present_solution;\n                       evaluation_point.add(alpha, newton_update);\n                       nonzero_constraints.distribute(evaluation_point);\n                       assemble_rhs(first_step);\n                       current_res = system_rhs.l2_norm();\n                       std::cout << \"  alpha: \" << std::setw(10) << alpha\n                                 << std::setw(0) << \"  residual: \" << current_res\n                                 << std::endl;\n                       if (current_res < last_res)\n                         break;\n                     }\n                   {\n                     present_solution = evaluation_point;\n                     std::cout << \"  number of line searches: \" << line_search_n\n                               << \"  residual: \" << current_res << std::endl;\n                     last_res = current_res;\n                   }\n                   ++line_search_n;\n                 }\n   \n               if (output_result)\n                 {\n                   output_results(max_n_line_searches * refinement_n +\n                                  line_search_n);\n   \n                   if (current_res <= tolerance)\n                     process_solution(refinement_n);\n                 }\n             }\n   \n           if (refinement_n < max_n_refinements)\n             {\n               refine_mesh();\n             }\n         }\n     }\n```\n\n#### StationaryNavierStokes::compute\\_initial\\_guess\n\nThis function will provide us with an initial guess by using a continuation method as we discussed in the introduction. The Reynolds number is increased step-by-step until we reach the target value. By experiment, the solution to Stokes is good enough to be the initial guess of NSE with Reynolds number 1000 so we start there. To make sure the solution from previous problem is close enough to the next one, the step size must be small enough.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::compute_initial_guess(double step_size)\n     {\n       const double target_Re = 1.0 / viscosity;\n   \n       bool is_initial_step = true;\n   \n       for (double Re = 1000.0; Re < target_Re;\n            Re        = std::min(Re + step_size, target_Re))\n         {\n           viscosity = 1.0 / Re;\n           std::cout << \"Searching for initial guess with Re = \" << Re\n                     << std::endl;\n           newton_iteration(1e-12, 50, 0, is_initial_step, false);\n           is_initial_step = false;\n         }\n     }\n```\n\n#### StationaryNavierStokes::output\\_results\n\nThis function is the same as in [step-22](step_22.html) except that we choose a name for the output file that also contains the Reynolds number (i.e., the inverse of the viscosity in the current context).\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::output_results(\n       const unsigned int output_index) const\n     {\n       std::vector<std::string> solution_names(dim, \"velocity\");\n       solution_names.emplace_back(\"pressure\");\n   \n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           dim, DataComponentInterpretation::component_is_part_of_vector);\n       data_component_interpretation.push_back(\n         DataComponentInterpretation::component_is_scalar);\n       DataOut<dim> data_out;\n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(present_solution,\n                                solution_names,\n                                DataOut<dim>::type_dof_data,\n                                data_component_interpretation);\n       data_out.build_patches();\n   \n       std::ofstream output(std::to_string(1.0 / viscosity) + \"-solution-\" +\n                            Utilities::int_to_string(output_index, 4) + \".vtk\");\n       data_out.write_vtk(output);\n     }\n```\n\n#### StationaryNavierStokes::process\\_solution\n\nIn our test case, we do not know the analytical solution. This function outputs the velocity components along \\(x=0.5\\) and \\(0 \\leq y \\leq 1\\) so they can be compared with data from the literature.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::process_solution(unsigned int refinement)\n     {\n       std::ofstream f(std::to_string(1.0 / viscosity) + \"-line-\" +\n                       std::to_string(refinement) + \".txt\");\n       f << \"# y u_x u_y\" << std::endl;\n   \n       Point<dim> p;\n       p[0] = 0.5;\n       p[1] = 0.5;\n   \n       f << std::scientific;\n   \n       for (unsigned int i = 0; i <= 100; ++i)\n         {\n           p[dim - 1] = i / 100.0;\n   \n           Vector<double> tmp_vector(dim + 1);\n           VectorTools::point_value(dof_handler, present_solution, p, tmp_vector);\n           f << p[dim - 1];\n   \n           for (int j = 0; j < dim; ++j)\n             f << ' ' << tmp_vector(j);\n           f << std::endl;\n         }\n     }\n```\n\n#### StationaryNavierStokes::run\n\nThis is the last step of this program. In this part, we generate the grid and run the other functions respectively. The max refinement can be set by the argument.\n\n```\n     template <int dim>\n     void StationaryNavierStokes<dim>::run(const unsigned int refinement)\n     {\n       GridGenerator::hyper_cube(triangulation);\n       triangulation.refine_global(5);\n   \n       const double Re = 1.0 / viscosity;\n```\n\nIf the viscosity is smaller than \\(1/1000\\), we have to first search for an initial guess via a continuation method. What we should notice is the search is always on the initial mesh, that is the \\(8 \\times 8\\) mesh in this program. After that, we just do the same as we did when viscosity is larger than \\(1/1000\\): run Newton's iteration, refine the mesh, transfer solutions, and repeat.\n\n```\n       if (Re > 1000.0)\n         {\n           std::cout << \"Searching for initial guess ...\" << std::endl;\n           const double step_size = 2000.0;\n           compute_initial_guess(step_size);\n           std::cout << \"Found initial guess.\" << std::endl;\n           std::cout << \"Computing solution with target Re = \" << Re << std::endl;\n           viscosity = 1.0 / Re;\n           newton_iteration(1e-12, 50, refinement, false, true);\n         }\n       else\n         {\n```\n\nWhen the viscosity is larger than 1/1000, the solution to Stokes equations is good enough as an initial guess. If so, we do not need to search for the initial guess using a continuation method. Newton's iteration can be started directly.\n\n```\n           newton_iteration(1e-12, 50, refinement, true, true);\n         }\n     }\n   } // namespace Step57\n   \n   int main()\n   {\n     try\n       {\n         using namespace Step57;\n   \n         StationaryNavierStokes<2> flow(/* degree = */ 1);\n         flow.run(4);\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     return 0;\n   }\n```\n\nResults\n=======\n\nNow we use the method we discussed above to solve Navier Stokes equations with viscosity \\(1/400\\) and \\(1/7500\\).\n\n### Test case 1: Low Reynolds Number\n\nIn the first test case the viscosity is set to be \\(1/400\\). As we discussed in the introduction, the initial guess is the solution to the corresponding Stokes problem. In the following table, the residuals at each Newton's iteration on every mesh is shown. The data in the table shows that Newton's iteration converges quadratically.\n\n| \\(\\mathrm{Re}=400\\) | Mesh0 | | Mesh1 | | Mesh2 | | Mesh3 | | Mesh4 | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Newton iter | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES |\n| 1 | 3.7112e-03 | 5 | 6.4189e-03 | 3 | 2.4338e-03 | 3 | 1.0570e-03 | 3 | 4.9499e-04 | 3 |\n| 2 | 7.0849e-04 | 5 | 9.9458e-04 | 5 | 1.1409e-04 | 6 | 1.3544e-05 | 6 | 1.4171e-06 | 6 |\n| 3 | 1.9980e-05 | 5 | 4.5007e-05 | 5 | 2.9020e-08 | 5 | 4.4021e-10 | 6 | 6.3435e-11 | 6 |\n| 4 | 2.3165e-09 | 6 | 1.6891e-07 | 5 | 1.2338e-14 | 7 | 1.8506e-14 | 8 | 8.8563e-15 | 8 |\n| 5 | 1.2585e-13 | 7 | 1.4520e-11 | 6 | 1.9044e-13 | 8 |  |  |  |  |\n| 6 |  |  | 1.3998e-15 | 8 |  |  |  |  |  |  |\n\nThe following figures show the sequence of generated grids. For the case of \\(\\mathrm{Re}=400\\), the initial guess is obtained by solving Stokes on an \\(8 \\times 8\\) mesh, and the mesh is refined adaptively. Between meshes, the solution from the coarse mesh is interpolated to the fine mesh to be used as an initial guess.\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |\n\nThis picture is the graphical streamline result of lid-driven cavity with \\(\\mathrm{Re}=400\\). ![](images/steps/developer/step-57.Re400_Streamline.png)\n\nThen the solution is compared with a reference solution from [[97]](citelist.html#CITEREF_Ghia1982) and the reference solution data can be found in the file \"ref\\_2d\\_ghia\\_u.txt\".\n\n![](images/steps/developer/step-57.compare-Re400.svg)\n\n### Test case 2: High Reynolds Number\n\nNewton's iteration requires a good initial guess. However, the nonlinear term dominates when the Reynolds number is large, so that the solution to the Stokes equations may be far away from the exact solution. If the Stokes solution acts as the initial guess, the convergence will be lost. The following picture shows that the nonlinear iteration gets stuck and the residual no longer decreases in further iterations.\n\n![](images/steps/developer/step-57.Re7500_loss_convergence.svg)\n\nThe initial guess, therefore, has to be obtained via a continuation method which has been discussed in the introduction. Here the step size in the continuation method, that is \\(|\\nu\\_{i}-\\nu\\_{i+1}|\\), is 2000 and the initial mesh is of size \\(32 \\times 32\\). After obtaining an initial guess, the mesh is refined as in the previous test case. The following picture shows that at each refinement Newton's iteration has quadratic convergence. 52 steps of Newton's iterations are executed for solving this test case.\n\n![](images/steps/developer/step-57.Re7500_get_convergence.svg)\n\nWe also show the residual from each step of Newton's iteration on every mesh. The quadratic convergence is clearly visible in the table.\n\n| \\(\\mathrm{Re}=7500\\) | Mesh0 | | Mesh1 | | Mesh2 | | Mesh3 | | Mesh4 | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Newton iter | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES | Residual | FGMRES |\n| 1 | 1.8922e-06 | 6 | 4.2506e-03 | 3 | 1.4299e-03 | 3 | 4.8793e-04 | 2 | 1.8998e-04 | 2 |\n| 2 | 3.1644e-09 | 8 | 1.3732e-03 | 7 | 4.1506e-04 | 7 | 9.1119e-05 | 8 | 1.3555e-05 | 8 |\n| 3 | 1.7611e-14 | 9 | 2.1946e-04 | 6 | 1.7881e-05 | 6 | 5.2678e-07 | 7 | 9.3739e-09 | 7 |\n| 4 |  |  | 8.8269e-06 | 6 | 6.8210e-09 | 7 | 2.2770e-11 | 8 | 1.2588e-13 | 9 |\n| 5 |  |  | 1.2974e-07 | 7 | 1.2515e-13 | 9 | 1.7801e-14 | 1 |  |  |\n| 6 |  |  | 4.4352e-11 | 7 |  |  |  |  |  |  |\n| 7 |  |  | 6.2863e-15 | 9 |  |  |  |  |  |  |\n\nThe sequence of generated grids looks like this:\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |\n\nWe compare our solution with the reference solution from [[83]](citelist.html#CITEREF_Erturk2005) . ![](images/steps/developer/step-57.compare-Re7500.svg) The following picture presents the graphical result. ![](images/steps/developer/step-57.Re7500_Streamline.png)\n\nFurthermore, the error consists of the nonlinear error, which decreases as we perform Newton iterations, and the discretization error, which depends on the mesh size. That is why we have to refine the mesh and repeat Newton's iteration on the next finer mesh. From the table above, we can see that the final residual (nonlinear error) is below \\(10^{-12}\\) on each mesh, but the following picture shows us the difference between solutions on subsequently finer meshes:\n\n![](images/steps/developer/step-57.converge-Re7500.svg)\n\n### Possibilities for extensions\n\n#### Compare to other solvers\n\nIt is easy to compare the currently implemented linear solver to just using UMFPACK for the whole linear system. You need to remove the nullspace containing the constant pressures and it is done in [step-56](step_56.html). More interesting is the comparison to other state of the art preconditioners like PCD. It turns out that the preconditioner here is very competitive, as can be seen in the paper [[113]](citelist.html#CITEREF_HeisterRapin2013).\n\nThe following table shows the timing results between our iterative approach (FGMRES) compared to a direct solver (UMFPACK) for the whole system with viscosity set to 1/400. Even though we use the same direct solver for the velocity block in the iterative solver, it is considerably faster and consumes less memory. This will be even more pronounced in 3d.\n\n| Refinement Cycle | DoFs | Iterative: Total/s (Setup/s) | Direct: Total/s (Setup/s) |\n| --- | --- | --- | --- |\n| 5 | 9539 | 0.10 (0.06) | 0.13 (0.12) |\n| 6 | 37507 | 0.58 (0.37) | 1.03 (0.97) |\n| 7 | 148739 | 3.59 (2.73) | 7.78 (7.53) |\n| 8 | 592387 | 29.17 (24.94) | (>4GB RAM) |\n\n#### 3d computations\n\nThe code is set up to also run in 3d. Of course the reference values are different, see [[210]](citelist.html#CITEREF_Yang1998) for example. High resolution computations are not doable with this example as is, because a direct solver for the velocity block does not work well in 3d. Rather, a parallel solver based on algebraic or geometric multigrid is needed – see below.\n\n#### Parallelization\n\nFor larger computations, especially in 3d, it is necessary to implement MPI parallel solvers and preconditioners. A good starting point would be [step-55](step_55.html), which uses algebraic multigrid for the velocity block for the Stokes equations. Another option would be to take a look at the list of codes in the [deal.II code gallery](https://www.dealii.org/code-gallery.html), which already contains parallel Navier-Stokes solvers.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2017 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Liang Zhao and Timo Heister, Clemson University, 2016\n */\n \n \n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/utilities.h>\n#include <deal.II/base/tensor.h>\n \n#include <deal.II/lac/block_vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/block_sparse_matrix.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/solver_gmres.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/affine_constraints.h>\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n#include <deal.II/grid/grid_tools.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n \n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n \n#include <deal.II/numerics/solution_transfer.h>\n \n#include <deal.II/lac/sparse_direct.h>\n \n#include <deal.II/lac/sparse_ilu.h>\n \n \n#include <fstream>\n#include <iostream>\n \nnamespace Step57\n{\n using namespace dealii;\n \n \n template <int dim>\n class StationaryNavierStokes\n  {\n public:\n    StationaryNavierStokes(const unsigned int degree);\n void run(const unsigned int refinement);\n \n private:\n void setup_dofs();\n \n void initialize_system();\n \n void assemble(const bool initial_step, const bool assemble_matrix);\n \n void assemble_system(const bool initial_step);\n \n void assemble_rhs(const bool initial_step);\n \n void solve(const bool initial_step);\n \n void refine_mesh();\n \n void process_solution(unsigned int refinement);\n \n void output_results(const unsigned int refinement_cycle) const;\n \n void newton_iteration(const double       tolerance,\n const unsigned int max_n_line_searches,\n const unsigned int max_n_refinements,\n const bool         is_initial_step,\n const bool         output_result);\n \n void compute_initial_guess(double step_size);\n \n double                               viscosity;\n double                               gamma;\n const unsigned int                   degree;\n    std::vector<types::global_dof_index> dofs_per_block;\n \n Triangulation<dim> triangulation;\n const FESystem<dim> fe;\n DoFHandler<dim>     dof_handler;\n \n AffineConstraints<double> zero_constraints;\n AffineConstraints<double> nonzero_constraints;\n \n BlockSparsityPattern      sparsity_pattern;\n BlockSparseMatrix<double> system_matrix;\n SparseMatrix<double>      pressure_mass_matrix;\n \n BlockVector<double> present_solution;\n BlockVector<double> newton_update;\n BlockVector<double> system_rhs;\n BlockVector<double> evaluation_point;\n  };\n \n \n template <int dim>\n class BoundaryValues : public Function<dim>\n  {\n public:\n    BoundaryValues()\n      : Function<dim>(dim + 1)\n    {}\n virtual double value(const Point<dim>  &p,\n const unsigned int component) const override;\n  };\n \n template <int dim>\n double BoundaryValues<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n Assert(component < this->n_components,\n           ExcIndexRange(component, 0, this->n_components));\n if (component == 0 && std::abs(p[dim - 1] - 1.0) < 1e-10)\n return 1.0;\n \n return 0;\n  }\n \n template <class PreconditionerMp>\n class BlockSchurPreconditioner : public Subscriptor\n  {\n public:\n    BlockSchurPreconditioner(double                           gamma,\n double                           viscosity,\n const BlockSparseMatrix<double> &S,\n const SparseMatrix<double>      &P,\n const PreconditionerMp          &Mppreconditioner);\n \n void vmult(BlockVector<double> &dst, const BlockVector<double> &src) const;\n \n private:\n const double gamma;\n const double                     viscosity;\n const BlockSparseMatrix<double> &stokes_matrix;\n const SparseMatrix<double>      &pressure_mass_matrix;\n const PreconditionerMp          &mp_preconditioner;\n SparseDirectUMFPACK              A_inverse;\n  };\n \n \n template <class PreconditionerMp>\n  BlockSchurPreconditioner<PreconditionerMp>::BlockSchurPreconditioner(\n double                           gamma,\n double                           viscosity,\n const BlockSparseMatrix<double> &S,\n const SparseMatrix<double>      &P,\n const PreconditionerMp          &Mppreconditioner)\n    : gamma(gamma)\n    , viscosity(viscosity)\n    , stokes_matrix(S)\n    , pressure_mass_matrix(P)\n    , mp_preconditioner(Mppreconditioner)\n  {\n    A_inverse.initialize(stokes_matrix.block(0, 0));\n  }\n \n template <class PreconditionerMp>\n void BlockSchurPreconditioner<PreconditionerMp>::vmult(\n BlockVector<double>       &dst,\n const BlockVector<double> &src) const\n {\n Vector<double> utmp(src.block(0));\n \n    {\n SolverControl solver_control(1000, 1e-6 * src.block(1).l2_norm());\n SolverCG<Vector<double>> cg(solver_control);\n \n      dst.block(1) = 0.0;\n      cg.solve(pressure_mass_matrix,\n               dst.block(1),\n               src.block(1),\n               mp_preconditioner);\n      dst.block(1) *= -(viscosity + gamma);\n    }\n \n    {\n      stokes_matrix.block(0, 1).vmult(utmp, dst.block(1));\n      utmp *= -1.0;\n      utmp += src.block(0);\n    }\n \n    A_inverse.vmult(dst.block(0), utmp);\n  }\n \n template <int dim>\n  StationaryNavierStokes<dim>::StationaryNavierStokes(const unsigned int degree)\n    : viscosity(1.0 / 7500.0)\n    , gamma(1.0)\n    , degree(degree)\n    , triangulation(Triangulation<dim>::maximum_smoothing)\n    , fe(FE_Q<dim>(degree + 1) ^ dim, FE_Q<dim>(degree))\n    , dof_handler(triangulation)\n  {}\n \n template <int dim>\n void StationaryNavierStokes<dim>::setup_dofs()\n  {\n    system_matrix.clear();\n    pressure_mass_matrix.clear();\n \n    dof_handler.distribute_dofs(fe);\n \n    std::vector<unsigned int> block_component(dim + 1, 0);\n    block_component[dim] = 1;\n DoFRenumbering::component_wise(dof_handler, block_component);\n \n    dofs_per_block =\n DoFTools::count_dofs_per_fe_block(dof_handler, block_component);\n unsigned int dof_u = dofs_per_block[0];\n unsigned int dof_p = dofs_per_block[1];\n \n const FEValuesExtractors::Vector velocities(0);\n    {\n      nonzero_constraints.clear();\n \n DoFTools::make_hanging_node_constraints(dof_handler, nonzero_constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                               0,\n                                               BoundaryValues<dim>(),\n                                               nonzero_constraints,\n                                               fe.component_mask(velocities));\n    }\n    nonzero_constraints.close();\n \n    {\n      zero_constraints.clear();\n \n DoFTools::make_hanging_node_constraints(dof_handler, zero_constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                               0,\n Functions::ZeroFunction<dim>(\n                                                 dim + 1),\n                                               zero_constraints,\n                                               fe.component_mask(velocities));\n    }\n    zero_constraints.close();\n \n    std::cout << \"Number of active cells: \" << triangulation.n_active_cells()\n              << std::endl\n              << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n              << \" (\" << dof_u << \" + \" << dof_p << ')' << std::endl;\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::initialize_system()\n  {\n    {\n BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n DoFTools::make_sparsity_pattern(dof_handler, dsp, nonzero_constraints);\n      sparsity_pattern.copy_from(dsp);\n    }\n \n    system_matrix.reinit(sparsity_pattern);\n \n    present_solution.reinit(dofs_per_block);\n    newton_update.reinit(dofs_per_block);\n    system_rhs.reinit(dofs_per_block);\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::assemble(const bool initial_step,\n const bool assemble_matrix)\n  {\n if (assemble_matrix)\n      system_matrix = 0;\n \n    system_rhs = 0;\n \n const QGauss<dim> quadrature_formula(degree + 2);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values | update_gradients);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n const FEValuesExtractors::Vector velocities(0);\n const FEValuesExtractors::Scalar pressure(dim);\n \n FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n Vector<double>     local_rhs(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n \n    std::vector<Tensor<1, dim>> present_velocity_values(n_q_points);\n    std::vector<Tensor<2, dim>> present_velocity_gradients(n_q_points);\n    std::vector<double>         present_pressure_values(n_q_points);\n \n    std::vector<double>         div_phi_u(dofs_per_cell);\n    std::vector<Tensor<1, dim>> phi_u(dofs_per_cell);\n    std::vector<Tensor<2, dim>> grad_phi_u(dofs_per_cell);\n    std::vector<double>         phi_p(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        fe_values.reinit(cell);\n \n        local_matrix = 0;\n        local_rhs    = 0;\n \n        fe_values[velocities].get_function_values(evaluation_point,\n                                                  present_velocity_values);\n \n        fe_values[velocities].get_function_gradients(\n          evaluation_point, present_velocity_gradients);\n \n        fe_values[pressure].get_function_values(evaluation_point,\n                                                present_pressure_values);\n \n for (unsigned int q = 0; q < n_q_points; ++q)\n          {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n              {\n                div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                phi_u[k]      = fe_values[velocities].value(k, q);\n                phi_p[k]      = fe_values[pressure].value(k, q);\n              }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              {\n if (assemble_matrix)\n                  {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                      {\n                        local_matrix(i, j) +=\n                          (viscosity *\n                             scalar_product(grad_phi_u[i], grad_phi_u[j]) +\n                           phi_u[i] *\n                             (present_velocity_gradients[q] * phi_u[j]) +\n                           phi_u[i] *\n                             (grad_phi_u[j] * present_velocity_values[q]) -\n                           div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j] +\n gamma * div_phi_u[i] * div_phi_u[j] +\n                           phi_p[i] * phi_p[j]) *\n                          fe_values.JxW(q);\n                      }\n                  }\n \n double present_velocity_divergence =\n trace(present_velocity_gradients[q]);\n                local_rhs(i) +=\n                  (-viscosity * scalar_product(grad_phi_u[i],\n                                               present_velocity_gradients[q]) -\n                   phi_u[i] * (present_velocity_gradients[q] *\n                               present_velocity_values[q]) +\n                   div_phi_u[i] * present_pressure_values[q] +\n                   phi_p[i] * present_velocity_divergence -\n                   gamma * div_phi_u[i] * present_velocity_divergence) *\n                  fe_values.JxW(q);\n              }\n          }\n \n        cell->get_dof_indices(local_dof_indices);\n \n const AffineConstraints<double> &constraints_used =\n          initial_step ? nonzero_constraints : zero_constraints;\n \n if (assemble_matrix)\n          {\n            constraints_used.distribute_local_to_global(local_matrix,\n                                                        local_rhs,\n                                                        local_dof_indices,\n                                                        system_matrix,\n                                                        system_rhs);\n          }\n else\n          {\n            constraints_used.distribute_local_to_global(local_rhs,\n                                                        local_dof_indices,\n                                                        system_rhs);\n          }\n      }\n \n if (assemble_matrix)\n      {\n        pressure_mass_matrix.reinit(sparsity_pattern.block(1, 1));\n        pressure_mass_matrix.copy_from(system_matrix.block(1, 1));\n \n        system_matrix.block(1, 1) = 0;\n      }\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::assemble_system(const bool initial_step)\n  {\n assemble(initial_step, true);\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::assemble_rhs(const bool initial_step)\n  {\n assemble(initial_step, false);\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::solve(const bool initial_step)\n  {\n const AffineConstraints<double> &constraints_used =\n      initial_step ? nonzero_constraints : zero_constraints;\n \n SolverControl solver_control(system_matrix.m(),\n                                 1e-4 * system_rhs.l2_norm(),\n true);\n \n SolverFGMRES<BlockVector<double>> gmres(solver_control);\n SparseILU<double>                 pmass_preconditioner;\n    pmass_preconditioner.initialize(pressure_mass_matrix,\n SparseILU<double>::AdditionalData());\n \n const BlockSchurPreconditioner<SparseILU<double>> preconditioner(\n      gamma,\n      viscosity,\n      system_matrix,\n      pressure_mass_matrix,\n      pmass_preconditioner);\n \n    gmres.solve(system_matrix, newton_update, system_rhs, preconditioner);\n    std::cout << \"FGMRES steps: \" << solver_control.last_step() << std::endl;\n \n    constraints_used.distribute(newton_update);\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::refine_mesh()\n  {\n Vector<float> estimated_error_per_cell(triangulation.n_active_cells());\n const FEValuesExtractors::Vector velocity(0);\n KellyErrorEstimator<dim>::estimate(\n      dof_handler,\n QGauss<dim - 1>(degree + 1),\n      std::map<types::boundary_id, const Function<dim> *>(),\n      present_solution,\n      estimated_error_per_cell,\n      fe.component_mask(velocity));\n \n GridRefinement::refine_and_coarsen_fixed_number(triangulation,\n                                                    estimated_error_per_cell,\n                                                    0.3,\n                                                    0.0);\n \n triangulation.prepare_coarsening_and_refinement();\n SolutionTransfer<dim, BlockVector<double>> solution_transfer(dof_handler);\n    solution_transfer.prepare_for_coarsening_and_refinement(present_solution);\n triangulation.execute_coarsening_and_refinement();\n \n    setup_dofs();\n \n BlockVector<double> tmp(dofs_per_block);\n \n    solution_transfer.interpolate(present_solution, tmp);\n    nonzero_constraints.distribute(tmp);\n \n    initialize_system();\n    present_solution = tmp;\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::newton_iteration(\n const double       tolerance,\n const unsigned int max_n_line_searches,\n const unsigned int max_n_refinements,\n const bool         is_initial_step,\n const bool         output_result)\n  {\n bool first_step = is_initial_step;\n \n for (unsigned int refinement_n = 0; refinement_n < max_n_refinements + 1;\n         ++refinement_n)\n      {\n unsigned int line_search_n = 0;\n double       last_res      = 1.0;\n double       current_res   = 1.0;\n        std::cout << \"grid refinements: \" << refinement_n << std::endl\n                  << \"viscosity: \" << viscosity << std::endl;\n \n while ((first_step || (current_res > tolerance)) &&\n               line_search_n < max_n_line_searches)\n          {\n if (first_step)\n              {\n                setup_dofs();\n                initialize_system();\n                evaluation_point = present_solution;\n                assemble_system(first_step);\n                solve(first_step);\n                present_solution = newton_update;\n                nonzero_constraints.distribute(present_solution);\n                first_step       = false;\n                evaluation_point = present_solution;\n                assemble_rhs(first_step);\n                current_res = system_rhs.l2_norm();\n                std::cout << \"The residual of initial guess is \" << current_res\n                          << std::endl;\n                last_res = current_res;\n              }\n else\n              {\n                evaluation_point = present_solution;\n                assemble_system(first_step);\n                solve(first_step);\n \n for (double alpha = 1.0; alpha > 1e-5; alpha *= 0.5)\n                  {\n                    evaluation_point = present_solution;\n                    evaluation_point.add(alpha, newton_update);\n                    nonzero_constraints.distribute(evaluation_point);\n                    assemble_rhs(first_step);\n                    current_res = system_rhs.l2_norm();\n                    std::cout << \"  alpha: \" << std::setw(10) << alpha\n                              << std::setw(0) << \"  residual: \" << current_res\n                              << std::endl;\n if (current_res < last_res)\n break;\n                  }\n                {\n                  present_solution = evaluation_point;\n                  std::cout << \"  number of line searches: \" << line_search_n\n                            << \"  residual: \" << current_res << std::endl;\n                  last_res = current_res;\n                }\n                ++line_search_n;\n              }\n \n if (output_result)\n              {\n                output_results(max_n_line_searches * refinement_n +\n                               line_search_n);\n \n if (current_res <= tolerance)\n                  process_solution(refinement_n);\n              }\n          }\n \n if (refinement_n < max_n_refinements)\n          {\n            refine_mesh();\n          }\n      }\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::compute_initial_guess(double step_size)\n  {\n const double target_Re = 1.0 / viscosity;\n \n bool is_initial_step = true;\n \n for (double Re = 1000.0; Re < target_Re;\n         Re        = std::min(Re + step_size, target_Re))\n      {\n        viscosity = 1.0 / Re;\n        std::cout << \"Searching for initial guess with Re = \" << Re\n                  << std::endl;\n        newton_iteration(1e-12, 50, 0, is_initial_step, false);\n        is_initial_step = false;\n      }\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::output_results(\n const unsigned int output_index) const\n {\n    std::vector<std::string> solution_names(dim, \"velocity\");\n    solution_names.emplace_back(\"pressure\");\n \n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        dim, DataComponentInterpretation::component_is_part_of_vector);\n    data_component_interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n DataOut<dim> data_out;\n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(present_solution,\n                             solution_names,\n DataOut<dim>::type_dof_data,\n                             data_component_interpretation);\n    data_out.build_patches();\n \n    std::ofstream output(std::to_string(1.0 / viscosity) + \"-solution-\" +\n Utilities::int_to_string(output_index, 4) + \".vtk\");\n    data_out.write_vtk(output);\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::process_solution(unsigned int refinement)\n  {\n    std::ofstream f(std::to_string(1.0 / viscosity) + \"-line-\" +\n                    std::to_string(refinement) + \".txt\");\n    f << \"# y u_x u_y\" << std::endl;\n \n Point<dim> p;\n    p[0] = 0.5;\n    p[1] = 0.5;\n \n    f << std::scientific;\n \n for (unsigned int i = 0; i <= 100; ++i)\n      {\n        p[dim - 1] = i / 100.0;\n \n Vector<double> tmp_vector(dim + 1);\n VectorTools::point_value(dof_handler, present_solution, p, tmp_vector);\n        f << p[dim - 1];\n \n for (int j = 0; j < dim; ++j)\n          f << ' ' << tmp_vector(j);\n        f << std::endl;\n      }\n  }\n \n template <int dim>\n void StationaryNavierStokes<dim>::run(const unsigned int refinement)\n  {\n GridGenerator::hyper_cube(triangulation);\n triangulation.refine_global(5);\n \n const double Re = 1.0 / viscosity;\n \n if (Re > 1000.0)\n      {\n        std::cout << \"Searching for initial guess ...\" << std::endl;\n const double step_size = 2000.0;\n        compute_initial_guess(step_size);\n        std::cout << \"Found initial guess.\" << std::endl;\n        std::cout << \"Computing solution with target Re = \" << Re << std::endl;\n        viscosity = 1.0 / Re;\n        newton_iteration(1e-12, 50, refinement, false, true);\n      }\n else\n      {\n \n        newton_iteration(1e-12, 50, refinement, true, true);\n      }\n  }\n} // namespace Step57\n \nint main()\n{\n try\n    {\n using namespace Step57;\n \n      StationaryNavierStokes<2> flow(/* degree = */ 1);\n      flow.run(4);\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_58.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nThe nonlinear Schrödinger equation.\nTutorial content :\nThis tutorial depends on [step-26](step_26.html), [step-29](step_29.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_58-Intro)    * [A note about the character of the equations](#step_58-Anoteaboutthecharacteroftheequations)* [The general idea of operator splitting](#step_58-Thegeneralideaofoperatorsplitting)* [Operator splitting: the \"Lie splitting\" approach](#step_58-OperatorsplittingtheLiesplittingapproach)* [Operator splitting: the \"Strang splitting\" approach](#step_58-OperatorsplittingtheStrangsplittingapproach)* [Time discretization](#step_58-Timediscretization)* [Spatial discretization and dealing with complex variables](#step_58-Spatialdiscretizationanddealingwithcomplexvariables)* [Linear solvers](#step_58-Linearsolvers)* [Definition of the test case](#step_58-Definitionofthetestcase)- [The commented program](#step_58-CommProg)      * [Include files](#step_58-Includefiles)* [The `NonlinearSchroedingerEquation` class](#step_58-ThecodeNonlinearSchroedingerEquationcodeclass)* [Equation data](#step_58-Equationdata)* [Implementation of the `NonlinearSchroedingerEquation` class](#step_58-ImplementationofthecodeNonlinearSchroedingerEquationcodeclass)              + [Setting up data structures and assembling matrices](#step_58-Settingupdatastructuresandassemblingmatrices)+ [Implementing the Strang splitting steps](#step_58-ImplementingtheStrangsplittingsteps)+ [Creating graphical output](#step_58-Creatinggraphicaloutput)+ [Running the simulation](#step_58-Runningthesimulation)+ [The main() function](#step_58-Themainfunction) | 1. [Results](#step_58-Results)    * [Visualizing the solution](#step_58-Visualizingthesolution)* [Possibilities for extensions](#step_58-Possibilitiesforextensions)        + [Better linear solvers](#step_58-Betterlinearsolvers) + [Boundary conditions](#step_58-Boundaryconditions) + [Adaptive meshes](#step_58-Adaptivemeshes)- [The plain program](#step_58-PlainProg) |\n\n*This program was contributed by Wolfgang Bangerth (Colorado State University) and Yong-Yong Cai ([Beijing Computational Science Research Center](http://www.csrc.ac.cn/en/), CSRC) and is the result of the first author's time as a visitor at CSRC.*\n\n*This material is based upon work partially supported by National Science Foundation grants OCI-1148116, OAC-1835673, DMS-1821210, and EAR-1925595; and by the Computational Infrastructure in Geodynamics initiative (CIG), through the National Science Foundation under Award No. EAR-1550901 and The University of California-Davis.*\n\nIntroduction\n============\n\nThe [Nonlinear Schrödinger Equation (NLSE)](https://en.wikipedia.org/wiki/Nonlinear_Schr%C3%B6dinger_equation) for a function \\(\\psi=\\psi(\\mathbf\nx,t)\\) and a potential \\(V=V(\\mathbf x)\\) is a model often used in quantum mechanics and nonlinear optics. If one measures in appropriate quantities (so that \\(\\hbar=1\\)), then it reads as follows:\n\n\\begin{align\\*}\n- i \\frac{\\partial \\psi}{\\partial t}\n- \\frac 12 \\Delta \\psi\n+ V \\psi\n+ \\kappa |\\psi|^2 \\psi\n&= 0\n\\qquad\\qquad\n&\n\\text{in}\\; \\Omega\\times (0,T),\n\\\\\n\\psi(\\mathbf x,0) &= \\psi\\_0(\\mathbf x)\n&\n\\text{in}\\; \\Omega,\n\\\\\n\\psi(\\mathbf x,t) &= 0\n&\n\\text{on}\\; \\partial\\Omega\\times (0,T).\n\\end{align\\*}\n\nIf there is no potential, i.e. \\(V(\\mathbf x)=0\\), then it can be used to describe the propagation of light in optical fibers. If \\(V(\\mathbf\nx)\\neq 0\\), the equation is also sometimes called the [Gross-Pitaevskii equation](https://en.wikipedia.org/wiki/Gross%E2%80%93Pitaevskii_equation) and can be used to model the time dependent behavior of [Bose-Einstein condensates](https://en.wikipedia.org/wiki/Bose%E2%80%93Einstein_condensate).\n\nFor this particular tutorial program, the physical interpretation of the equation is not of much concern to us. Rather, we want to use it as a model that allows us to explain two aspects:\n\n* It is a **complex-valued equation** for \\(\\psi \\in H^1(\\Omega,{\\mathbb\n  C})\\). We have previously seen complex-valued equations in [step-29](step_29.html), but there have opted to split the equations into real and imaginary parts and consequently ended up solving a system of two real-valued equations. In contrast, the goal here is to show how to solve problems in which we keep everything as complex numbers.\n* The equation is a nice model problem to explain how **operator splitting methods** work. This is because it has terms with fundamentally different character: on the one hand, \\(- \\frac 12\n  \\Delta \\psi\\) is a regular spatial operator in the way we have seen many times before; on the other hand, \\(\\kappa |\\psi(\\mathbf x,t)|^2\n  \\psi\\) has no spatial or temporal derivatives, i.e., it is a purely local operator. It turns out that we have efficient methods for each of these terms (in particular, we have analytic solutions for the latter), and that we may be better off treating these terms differently and separately. We will explain this in more detail below.\n\n### A note about the character of the equations\n\nAt first glance, the equations appear to be parabolic and similar to the heat equation (see [step-26](step_26.html)) as there is only a single time derivative and two spatial derivatives. But this is misleading. Indeed, that this is not the correct interpretation is more easily seen if we assume for a moment that the potential \\(V=0\\) and \\(\\kappa=0\\). Then we have the equation\n\n\\begin{align\\*}\n- i \\frac{\\partial \\psi}{\\partial t}\n- \\frac 12 \\Delta \\psi\n&= 0.\n\\end{align\\*}\n\nIf we separate the solution into real and imaginary parts, \\(\\psi=v+iw\\), with \\(v=\\textrm{Re}\\;\\psi,\\; w=\\textrm{Im}\\;\\psi\\), then we can split the one equation into its real and imaginary parts in the same way as we did in [step-29](step_29.html):\n\n\\begin{align\\*}\n\\frac{\\partial w}{\\partial t}\n- \\frac 12 \\Delta v\n&= 0,\n\\\\\n-\\frac{\\partial v}{\\partial t}\n- \\frac 12 \\Delta w\n&= 0.\n\\end{align\\*}\n\nNot surprisingly, the factor \\(i\\) in front of the time derivative couples the real and imaginary parts of the equation. If we want to understand this equation further, take the time derivative of one of the equations, say\n\n\\begin{align\\*}\n\\frac{\\partial^2 w}{\\partial t^2}\n- \\frac 12 \\Delta \\frac{\\partial v}{\\partial t}\n&= 0,\n\\end{align\\*}\n\n(where we have assumed that, at least in some formal sense, we can commute the spatial and temporal derivatives), and then insert the other equation into it:\n\n\\begin{align\\*}\n\\frac{\\partial^2 w}{\\partial t^2}\n+ \\frac 14 \\Delta^2 w\n&= 0.\n\\end{align\\*}\n\nThis equation is hyperbolic and similar in character to the wave equation. (This will also be obvious if you look at the video in the \"Results\" section of this program.) Furthermore, we could have arrived at the same equation for \\(v\\) as well. Consequently, a better assumption for the NLSE is to think of it as a hyperbolic, wave-propagation equation than as a diffusion equation such as the heat equation. (You may wonder whether it is correct that the operator \\(\\Delta^2\\) appears with a positive sign whereas in the wave equation, \\(\\Delta\\) has a negative sign. This is indeed correct: After multiplying by a test function and integrating by parts, we want to come out with a positive (semi-)definite form. So, from \\(-\\Delta u\\) we obtain \\(+(\\nabla v,\\nabla u)\\). Likewise, after integrating by parts twice, we obtain from \\(+\\Delta^2 u\\) the form \\(+(\\Delta v,\\Delta u)\\). In both cases do we get the desired positive sign.)\n\nThe real NLSE, of course, also has the terms \\(V\\psi\\) and \\(\\kappa|\\psi|^2\\psi\\). However, these are of lower order in the spatial derivatives, and while they are obviously important, they do not change the character of the equation.\n\nIn any case, the purpose of this discussion is to figure out what time stepping scheme might be appropriate for the equation. The conclusions is that, as a hyperbolic-kind of equation, we need to choose a time step that satisfies a CFL-type condition. If we were to use an explicit method (which we will not), we would have to investigate the eigenvalues of the matrix that corresponds to the spatial operator. If you followed the discussions of the video lectures (See also [video lecture 26](https://www.math.colostate.edu/~bangerth/videos.676.26.html), [video lecture 27](https://www.math.colostate.edu/~bangerth/videos.676.27.html), [video lecture 28](https://www.math.colostate.edu/~bangerth/videos.676.28.html).) then you will remember that the pattern is that one needs to make sure that \\(k^s \\propto h^t\\) where \\(k\\) is the time step, \\(h\\) the mesh width, and \\(s,t\\) are the orders of temporal and spatial derivatives. Whether you take the original equation ( \\(s=1,t=2\\)) or the reformulation for only the real or imaginary part, the outcome is that we would need to choose \\(k \\propto h^2\\) if we were to use an explicit time stepping method. This is not feasible for the same reasons as in [step-26](step_26.html) for the heat equation: It would yield impractically small time steps for even only modestly refined meshes. Rather, we have to use an implicit time stepping method and can then choose a more balanced \\(k \\propto h\\). Indeed, we will use the implicit Crank-Nicolson method as we have already done in [step-23](step_23.html) before for the regular wave equation.\n\n### The general idea of operator splitting\n\nNote\n:   The material presented here is also discussed in [video lecture 30.25](https://www.math.colostate.edu/~bangerth/videos.676.30.25.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\n\nIf one thought of the NLSE as an ordinary differential equation in which the right hand side happens to have spatial derivatives, i.e., write it as\n\n\\begin{align\\*}\n\\frac{d\\psi}{dt}\n&=\ni\\frac 12 \\Delta \\psi\n-i V \\psi\n-i\\kappa |\\psi|^2 \\psi,\n\\qquad\\qquad\n&\n\\text{for}\\; t \\in (0,T),\n\\\\\n\\psi(0) &= \\psi\\_0,\n\\end{align\\*}\n\none may be tempted to \"formally solve\" it by integrating both sides over a time interval \\([t\\_{n},t\\_{n+1}]\\) and obtain\n\n\\begin{align\\*}\n\\psi(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\ni\\frac 12 \\Delta \\psi(t)\n-i V \\psi(t)\n-i\\kappa |\\psi(t)|^2 \\psi(t)\n\\right)\n\\;\ndt.\n\\end{align\\*}\n\nOf course, it's not that simple: the \\(\\psi(t)\\) in the integrand is still changing over time in accordance with the differential equation, so we cannot just evaluate the integral (or approximate it easily via quadrature) because we don't know \\(\\psi(t)\\). But we can write this with separate contributions as follows, and this will allow us to deal with different terms separately:\n\n\\begin{align\\*}\n\\psi(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\ni\\frac 12 \\Delta \\psi(t)\n\\right)\n\\;\ndt\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i V \\psi(t)\n\\right)\n\\;\ndt\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i\\kappa |\\psi(t)|^2 \\,\\psi(t)\n\\right)\n\\;\ndt.\n\\end{align\\*}\n\nThe way this equation can now be read is as follows: For each time interval \\([t\\_{n},t\\_{n+1}]\\), the change \\(\\psi(t\\_{n+1})-\\psi(t\\_{n})\\) in the solution consists of three contributions:\n\n* The contribution of the Laplace operator.\n* The contribution of the potential \\(V\\).\n* The contribution of the \"phase\" term \\(-i\\kappa |\\psi(t)|^2\\,\\psi(t)\\).\n\n*Operator splitting* is now an approximation technique that allows us to treat each of these contributions separately. (If we want: In practice, we will treat the first two together, and the last one separate. But that is a detail, conceptually we could treat all of them differently.) To this end, let us introduce three separate \"solutions\":\n\n\\begin{align\\*}\n\\psi^{(1)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\ni\\frac 12 \\Delta \\psi^{(1)}(t)\n\\right)\n\\;\ndt,\n\\\\\n\\psi^{(2)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i V \\psi^{(2)}(t)\n\\right)\n\\;\ndt,\n\\\\\n\\psi^{(3)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i\\kappa |\\psi^{(3)}(t)|^2 \\,\\psi^{(3)}(t)\n\\right)\n\\;\ndt.\n\\end{align\\*}\n\nThese three \"solutions\" can be thought of as satisfying the following differential equations:\n\n\\begin{align\\*}\n\\frac{d\\psi^{(1)}}{dt}\n&=\ni\\frac 12 \\Delta \\psi^{(1)},\n\\qquad\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(1)}(t\\_n) &= \\psi(t\\_n),\n\\\\\n\\frac{d\\psi^{(2)}}{dt}\n&=\n-i V \\psi^{(2)},\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(2)}(t\\_n) &= \\psi(t\\_n),\n\\\\\n\\frac{d\\psi^{(3)}}{dt}\n&=\n-i\\kappa |\\psi^{(3)}|^2 \\,\\psi^{(3)},\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(3)}(t\\_n) &= \\psi(t\\_n).\n\\end{align\\*}\n\nIn other words, they are all trajectories \\(\\psi^{(k)}\\) that start at \\(\\psi(t\\_n)\\) and integrate up the effects of exactly one of the three terms. The increments resulting from each of these terms over our time interval are then \\(I^{(1)}=\\psi^{(1)}(t\\_{n+1})-\\psi(t\\_n)\\), \\(I^{(2)}=\\psi^{(2)}(t\\_{n+1})-\\psi(t\\_n)\\), and \\(I^{(3)}=\\psi^{(3)}(t\\_{n+1})-\\psi(t\\_n)\\).\n\nIt is now reasonable to assume (this is an approximation!) that the change due to all three of the effects in question is well approximated by the sum of the three separate increments:\n\n\\begin{align\\*}\n\\psi(t\\_{n+1})-\\psi(t\\_n)\n\\approx\nI^{(1)} + I^{(2)} + I^{(3)}.\n\\end{align\\*}\n\nThis intuition is indeed correct, though the approximation is not exact: the difference between the exact left hand side and the term \\(I^{(1)}+I^{(2)}+I^{(3)}\\) (i.e., the difference between the *exact* increment for the exact solution \\(\\psi(t)\\) when moving from \\(t\\_n\\) to \\(t\\_{n+1}\\), and the increment composed of the three parts on the right hand side), is proportional to \\(\\Delta t=t\\_{n+1}-t\\_{n}\\). In other words, this approach introduces an error of size \\({\\cal O}(\\Delta t)\\). Nothing we have done so far has discretized anything in time or space, so the *overall* error is going to be \\({\\cal O}(\\Delta t)\\) plus whatever error we commit when approximating the integrals (the temporal discretization error) plus whatever error we commit when approximating the spatial dependencies of \\(\\psi\\) (the spatial error).\n\nBefore we continue with discussions about operator splitting, let us talk about why one would even want to go this way? The answer is simple: For some of the separate equations for the \\(\\psi^{(k)}\\), we may have ways to solve them more efficiently than if we throw everything together and try to solve it at once. For example, and particularly pertinent in the current case: The equation for \\(\\psi^{(3)}\\), i.e.,\n\n\\begin{align\\*}\n\\frac{d\\psi^{(3)}}{dt}\n&=\n-i\\kappa |\\psi^{(3)}|^2 \\,\\psi^{(3)},\n\\qquad\\qquad\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(3)}(t\\_n) &= \\psi(t\\_n),\n\\end{align\\*}\n\nor equivalently,\n\n\\begin{align\\*}\n\\psi^{(3)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i\\kappa |\\psi^{(3)}(t)|^2 \\,\\psi^{(3)}(t)\n\\right)\n\\;\ndt,\n\\end{align\\*}\n\ncan be solved exactly: the equation is solved by\n\n\\begin{align\\*}\n\\psi^{(3)}(t) = e^{-i\\kappa|\\psi(t\\_n)|^2 (t-t\\_{n})} \\psi(t\\_n).\n\\end{align\\*}\n\nThis is easy to see if (i) you plug this solution into the differential equation, and (ii) realize that the magnitude \\(|\\psi^{(3)}|\\) is constant, i.e., the term \\(|\\psi(t\\_n)|^2\\) in the exponent is in fact equal to \\(|\\psi^{(3)}(t)|^2\\). In other words, the solution of the ODE for \\(\\psi^{(3)}(t)\\) only changes its *phase*, but the *magnitude* of the complex-valued function \\(\\psi^{(3)}(t)\\) remains constant. This makes computing \\(I^{(3)}\\) particularly convenient: we don't actually need to solve any ODE, we can write the solution down by hand. Using the operator splitting approach, none of the methods to compute \\(I^{(1)},I^{(2)}\\) therefore have to deal with the nonlinear term and all of the associated unpleasantries: we can get away with solving only *linear* problems, as long as we allow ourselves the luxury of using an operator splitting approach.\n\nSecondly, one often uses operator splitting if the different physical effects described by the different terms have different time scales. Imagine, for example, a case where we really did have some sort of diffusion equation. Diffusion acts slowly, but if \\(\\kappa\\) is large, then the \"phase rotation\" by the term \\(-i\\kappa\n|\\psi^{(3)}(t)|^2 \\,\\psi^{(3)}(t)\\) acts quickly. If we treated everything together, this would imply having to take rather small time steps. But with operator splitting, we can take large time steps \\(\\Delta t=t\\_{n+1}-t\\_{n}\\) for the diffusion, and (assuming we didn't have an analytic solution) use an ODE solver with many small time steps to integrate the \"phase rotation\" equation for \\(\\psi^{(3)}\\) from \\(t\\_n\\) to \\(t\\_{n+1}\\). In other words, operator splitting allows us to decouple slow and fast time scales and treat them differently, with methods adjusted to each case.\n\n### Operator splitting: the \"Lie splitting\" approach\n\nWhile the method above allows to compute the three contributions \\(I^{(k)}\\) in parallel, if we want, the method can be made slightly more accurate and easy to implement if we don't let the trajectories for the \\(\\psi^{(k)}\\) start all at \\(\\psi(t\\_n)\\), but instead let the trajectory for \\(\\psi^{(2)}\\) start at the *end point* of the trajectory for \\(\\psi^{(1)}\\), namely \\(\\psi^{(1)}(t\\_{n+1})\\); similarly, we will start the trajectory for \\(\\psi^{(3)}\\) start at the end point of the trajectory for \\(\\psi^{(2)}\\), namely \\(\\psi^{(2)}(t\\_{n+1})\\). This method is then called \"Lie splitting\" and has the same order of error as the method above, i.e., the splitting error is \\({\\cal O}(\\Delta\nt)\\).\n\nThis variation of operator splitting can be written as follows (carefully compare the initial conditions to the ones above):\n\n\\begin{align\\*}\n\\frac{d\\psi^{(1)}}{dt}\n&=\ni\\frac 12 \\Delta \\psi^{(1)},\n\\qquad\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(1)}(t\\_n) &= \\psi(t\\_n),\n\\\\\n\\frac{d\\psi^{(2)}}{dt}\n&=\n-i V \\psi^{(2)},\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(2)}(t\\_n) &= \\psi^{(1)}(t\\_{n+1}),\n\\\\\n\\frac{d\\psi^{(3)}}{dt}\n&=\n-i\\kappa |\\psi^{(3)}|^2 \\,\\psi^{(3)},\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(3)}(t\\_n) &= \\psi^{(2)}(t\\_{n+1}).\n\\end{align\\*}\n\n(Obviously, while the formulas above imply that we should solve these problems in this particular order, it is equally valid to first solve for trajectory 3, then 2, then 1, or any other permutation.)\n\nThe integrated forms of these equations are then\n\n\\begin{align\\*}\n\\psi^{(1)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\ni\\frac 12 \\Delta \\psi^{(1)}(t)\n\\right)\n\\;\ndt,\n\\\\\n\\psi^{(2)}(t\\_{n+1})\n&=\n\\psi^{(1)}(t\\_{n+1})\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i V \\psi^{(2)}(t)\n\\right)\n\\;\ndt,\n\\\\\n\\psi^{(3)}(t\\_{n+1})\n&=\n\\psi^{(2)}(t\\_{n+1})\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i\\kappa |\\psi^{(3)}(t)|^2 \\,\\psi^{(3)}(t)\n\\right)\n\\;\ndt.\n\\end{align\\*}\n\nFrom a practical perspective, this has the advantage that we need to keep around fewer solution vectors: Once \\(\\psi^{(1)}(t\\_n)\\) has been computed, we don't need \\(\\psi(t\\_n)\\) any more; once \\(\\psi^{(2)}(t\\_n)\\) has been computed, we don't need \\(\\psi^{(1)}(t\\_n)\\) any more. And once \\(\\psi^{(3)}(t\\_n)\\) has been computed, we can just call it \\(\\psi(t\\_{n+1})\\) because, if you insert the first into the second, and then into the third equation, you see that the right hand side of \\(\\psi^{(3)}(t\\_n)\\) now contains the contributions of all three physical effects:\n\n\\begin{align\\*}\n\\psi^{(3)}(t\\_{n+1})\n&=\n\\psi(t\\_n)\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\ni\\frac 12 \\Delta \\psi^{(1)}(t)\n\\right)\n\\;\ndt\n+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i V \\psi^{(2)}(t)\n\\right)\n\\;\ndt+\n\\int\\_{t\\_n}^{t\\_{n+1}}\n\\left(\n-i\\kappa |\\psi^{(3)}(t)|^2 \\,\\psi^{(3)}(t)\n\\right)\n\\;\ndt.\n\\end{align\\*}\n\n(Compare this again with the \"exact\" computation of \\(\\psi(t\\_{n+1})\\): It only differs in how we approximate \\(\\psi(t)\\) in each of the three integrals.) In other words, Lie splitting is a lot simpler to implement that the original method outlined above because data handling is so much simpler.\n\n### Operator splitting: the \"Strang splitting\" approach\n\nAs mentioned above, Lie splitting is only \\({\\cal O}(\\Delta t)\\) accurate. This is acceptable if we were to use a first order time discretization, for example using the explicit or implicit Euler methods to solve the differential equations for \\(\\psi^{(k)}\\). This is because these time integration methods introduce an error proportional to \\(\\Delta t\\) themselves, and so the splitting error is proportional to an error that we would introduce anyway, and does not diminish the overall convergence order.\n\nBut we typically want to use something higher order – say, a [Crank-Nicolson](https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method) or [BDF2](https://en.wikipedia.org/wiki/Backward_differentiation_formula) method – since these are often not more expensive than a simple Euler method. It would be a shame if we were to use a time stepping method that is \\({\\cal O}(\\Delta t^2)\\), but then lose the accuracy again through the operator splitting.\n\nThis is where the [Strang splitting](https://en.wikipedia.org/wiki/Strang_splitting) method comes in. It is easier to explain if we had only two parts, and so let us combine the effects of the Laplace operator and of the potential into one, and the phase rotation into a second effect. (Indeed, this is what we will do in the code since solving the equation with the Laplace equation with or without the potential costs the same – so we merge these two steps.) The Lie splitting method from above would then do the following: It computes solutions of the following two ODEs,\n\n\\begin{align\\*}\n\\frac{d\\psi^{(1)}}{dt}\n&=\ni\\frac 12 \\Delta \\psi^{(1)} -i V \\psi^{(1)},\n\\qquad\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(1)}(t\\_n) &= \\psi(t\\_n),\n\\\\\n\\frac{d\\psi^{(2)}}{dt}\n&=\n-i\\kappa |\\psi^{(2)}|^2 \\,\\psi^{(2)},\n&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad\\text{with initial condition}\\;\n\\psi^{(2)}(t\\_n) &= \\psi^{(1)}(t\\_{n+1}),\n\\end{align\\*}\n\nand then uses the approximation \\(\\psi(t\\_{n+1}) \\approx\n\\psi^{(2)}(t\\_{n+1})\\). In other words, we first make one full time step for physical effect one, then one full time step for physical effect two. The solution at the end of the time step is simply the sum of the increments due to each of these physical effects separately.\n\nIn contrast, [Gil Strang](https://en.wikipedia.org/wiki/Gilbert_Strang) (one of the titans of numerical analysis starting in the mid-20th century) figured out that it is more accurate to first do one half-step for one physical effect, then a full time step for the other physical effect, and then another half step for the first. Which one is which does not matter, but because it is so simple to do the phase rotation, we will use this effect for the half steps and then only need to do one spatial solve with the Laplace operator plus potential. This operator splitting method is now \\({\\cal O}(\\Delta\nt^2)\\) accurate. Written in formulas, this yields the following sequence of steps:\n\n\\begin{align\\*}\n\\frac{d\\psi^{(1)}}{dt}\n&=\n-i\\kappa |\\psi^{(1)}|^2 \\,\\psi^{(1)},\n&&\n\\text{for}\\; t \\in (t\\_n,t\\_n+\\tfrac 12\\Delta t),\n\\qquad\\qquad&\\text{with initial condition}\\;\n\\psi^{(1)}(t\\_n) &= \\psi(t\\_n),\n\\\\\n\\frac{d\\psi^{(2)}}{dt}\n&=\ni\\frac 12 \\Delta \\psi^{(2)} -i V \\psi^{(2)},\n\\qquad\n&&\n\\text{for}\\; t \\in (t\\_n,t\\_{n+1}),\n\\qquad\\qquad&\\text{with initial condition}\\;\n\\psi^{(2)}(t\\_n) &= \\psi^{(1)}(t\\_n+\\tfrac 12\\Delta t),\n\\\\\n\\frac{d\\psi^{(3)}}{dt}\n&=\n-i\\kappa |\\psi^{(3)}|^2 \\,\\psi^{(3)},\n&&\n\\text{for}\\; t \\in (t\\_n+\\tfrac 12\\Delta t,t\\_{n+1}),\n\\qquad\\qquad&\\text{with initial condition}\\;\n\\psi^{(3)}(t\\_n) &= \\psi^{(2)}(t\\_{n+1}).\n\\end{align\\*}\n\nAs before, the first and third step can be computed exactly for this particular equation, yielding\n\n\\begin{align\\*}\n\\psi^{(1)}(t\\_n+\\tfrac 12\\Delta t) &= e^{-i\\kappa|\\psi(t\\_n)|^2 \\tfrac\n12\\Delta t} \\; \\psi(t\\_n),\n\\\\\n\\psi^{(3)}(t\\_{n+1}) &= e^{-i\\kappa|\\psi^{(2)}(t\\_{n+1})|^2 \\tfrac\n12\\Delta t} \\; \\psi^{(2)}(t\\_{n+1}).\n\\end{align\\*}\n\nThis is then how we are going to implement things in this program: In each time step, we execute three steps, namely\n\n* Update the solution value at each node by analytically integrating the phase rotation equation by one half time step;\n* Solving the space-time equation that corresponds to the full step for \\(\\psi^{(2)}\\), namely \\(-i\\frac{\\partial\\psi^{(2)}}{\\partial t}\n  -\n  \\frac 12 \\Delta \\psi^{(2)} + V \\psi^{(2)} = 0\\), with initial conditions equal to the solution of the first half step above.\n* Update the solution value at each node by analytically integrating the phase rotation equation by another half time step.\n\nThis structure will be reflected in an obvious way in the main time loop of the program.\n\n### Time discretization\n\nFrom the discussion above, it should have become clear that the only partial differential equation we have to solve in each time step is\n\n\\begin{align\\*}\n-i\\frac{\\partial\\psi^{(2)}}{\\partial t}\n-\n\\frac 12 \\Delta \\psi^{(2)} + V \\psi^{(2)} = 0.\n\\end{align\\*}\n\nThis equation is linear. Furthermore, we only have to solve it from \\(t\\_n\\) to \\(t\\_{n+1}\\), i.e., for exactly one time step.\n\nTo do this, we will apply the second order accurate Crank-Nicolson scheme that we have already used in some of the other time dependent codes (specifically: [step-23](step_23.html) and [step-26](step_26.html)). It reads as follows:\n\n\\begin{align\\*}\n-i\\frac{\\psi^{(n,2)}-\\psi^{(n,1)}}{k\\_{n+1}}\n-\n\\frac 12 \\Delta \\left[\\frac 12\n\\left(\\psi^{(n,2)}+\\psi^{(n,1)}\\right)\\right]\n+\nV \\left[\\frac 12 \\left(\\psi^{(n,2)}+\\psi^{(n,1)}\\right)\\right] = 0.\n\\end{align\\*}\n\nHere, the \"previous\" solution \\(\\psi^{(n,1)}\\) (or the \"initial\ncondition\" for this part of the time step) is the output of the first phase rotation half-step; the output of the current step will be denoted by \\(\\psi^{(n,2)}\\). \\(k\\_{n+1}=t\\_{n+1}-t\\_n\\) is the length of the time step. (One could argue whether \\(\\psi^{(n,1)}\\) and \\(\\psi^{(n,1)}\\) live at time step \\(n\\) or \\(n+1\\) and what their upper indices should be. This is a philosophical discussion without practical impact, and one might think of \\(\\psi^{(n,1)}\\) as something like \\(\\psi^{(n+\\tfrac 13)}\\), and \\(\\psi^{(n,2)}\\) as \\(\\psi^{(n+\\tfrac 23)}\\) if that helps clarify things – though, again \\(n+\\frac 13\\) is not to be understood as \"one third time step after\n\\\\_form#339\" but more like \"we've already done one third of the work necessary\nfor time step \\\\_form#3447\".)\n\nIf we multiply the whole equation with \\(k\\_{n+1}\\) and sort terms with the unknown \\(\\psi^{(n+1,2)}\\) to the left and those with the known \\(\\psi^{(n,2)}\\) to the right, then we obtain the following (spatial) partial differential equation that needs to be solved in each time step:\n\n\\begin{align\\*}\n-i\\psi^{(n,2)}\n-\n\\frac 14 k\\_{n+1} \\Delta \\psi^{(n,2)}\n+\n\\frac 12 k\\_{n+1} V \\psi^{(n,2)}\n=\n-i\\psi^{(n,1)}\n+\n\\frac 14 k\\_{n+1} \\Delta \\psi^{(n,1)}\n-\n\\frac 12 k\\_{n+1} V \\psi^{(n,1)}.\n\\end{align\\*}\n\n### Spatial discretization and dealing with complex variables\n\nAs mentioned above, the previous tutorial program dealing with complex-valued solutions (namely, [step-29](step_29.html)) separated real and imaginary parts of the solution. It thus reduced everything to real arithmetic. In contrast, we here want to keep things complex-valued.\n\nThe first part of this is that we need to define the discretized solution as \\(\\psi\\_h^n(\\mathbf x)=\\sum\\_j \\Psi^n\\_j \\varphi\\_j(\\mathbf\nx) \\approx \\psi(\\mathbf x,t\\_n)\\) where the \\(\\varphi\\_j\\) are the usual shape functions (which are real valued) but the expansion coefficients \\(\\Psi^n\\_j\\) at time step \\(n\\) are now complex-valued. This is easily done in deal.II: We just have to use Vector<std::complex<double>> instead of [Vector<double>](classVector.html) to store these coefficients.\n\nOf more interest is how to build and solve the linear system. Obviously, this will only be necessary for the second step of the Strang splitting discussed above, with the time discretization of the previous subsection. We obtain the fully discrete version through straightforward substitution of \\(\\psi^n\\) by \\(\\psi^n\\_h\\) and multiplication by a test function:\n\n\\begin{align\\*}\n-iM\\Psi^{(n,2)}\n+\n\\frac 14 k\\_{n+1} A \\Psi^{(n,2)}\n+\n\\frac 12 k\\_{n+1} W \\Psi^{(n,2)}\n=\n-iM\\Psi^{(n+1,1)}\n-\n\\frac 14 k\\_{n+1} A \\Psi^{(n,1)}\n-\n\\frac 12 k\\_{n+1} W \\Psi^{(n,1)},\n\\end{align\\*}\n\nor written in a more compact way:\n\n\\begin{align\\*}\n\\left[\n-iM\n+\n\\frac 14 k\\_{n+1} A\n+\n\\frac 12 k\\_{n+1} W\n\\right] \\Psi^{(n,2)}\n=\n\\left[\n-iM\n-\n\\frac 14 k\\_{n+1} A\n-\n\\frac 12 k\\_{n+1} W\n\\right] \\Psi^{(n,1)}.\n\\end{align\\*}\n\nHere, the matrices are defined in their obvious ways:\n\n\\begin{align\\*}\nM\\_{ij} &= (\\varphi\\_i,\\varphi\\_j), \\\\\nA\\_{ij} &= (\\nabla\\varphi\\_i,\\nabla\\varphi\\_j), \\\\\nW\\_{ij} &= (\\varphi\\_i,V \\varphi\\_j).\n\\end{align\\*}\n\nNote that all matrices individually are in fact symmetric, real-valued, and at least positive semidefinite, though the same is obviously not true for the system matrix \\(C = -iM + \\frac 14 k\\_{n+1} A + \\frac 12 k\\_{n+1} W\\) and the corresponding matrix \\(R = -iM - \\frac 14 k\\_{n+1} A - \\frac 12 k\\_{n+1} W\\) on the right hand side.\n\n### Linear solvers\n\nNote\n:   The material presented here is also discussed in [video lecture 34](https://www.math.colostate.edu/~bangerth/videos.676.34.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\n\nThe only remaining important question about the solution procedure is how to solve the complex-valued linear system\n\n\\begin{align\\*}\nC \\Psi^{(n+1,2)}\n=\nR \\Psi^{(n+1,1)},\n\\end{align\\*}\n\nwith the matrix \\(C = -iM + \\frac 14 k\\_{n+1} A + \\frac 12 k\\_{n+1}\nW\\) and a right hand side that is easily computed as the product of a known matrix and the previous part-step's solution. As usual, this comes down to the question of what properties the matrix \\(C\\) has. If it is symmetric and positive definite, then we can for example use the Conjugate Gradient method.\n\nUnfortunately, the matrix's only useful property is that it is complex symmetric, i.e., \\(C\\_{ij}=C\\_{ji}\\), as is easy to see by recalling that \\(M,A,W\\) are all symmetric. It is not, however, [Hermitian](https://en.wikipedia.org/wiki/Hermitian_matrix), which would require that \\(C\\_{ij}=\\bar C\\_{ji}\\) where the bar indicates complex conjugation.\n\nComplex symmetry can be exploited for iterative solvers as a quick literature search indicates. We will here not try to become too sophisticated (and indeed leave this to the [Possibilities for extensions](#extensions) section below) and instead simply go with the good old standby for problems without properties: A direct solver. That's not optimal, especially for large problems, but it shall suffice for the purposes of a tutorial program. Fortunately, the [SparseDirectUMFPACK](classSparseDirectUMFPACK.html) class allows solving complex-valued problems.\n\n### Definition of the test case\n\nInitial conditions for the NLSE are typically chosen to represent particular physical situations. This is beyond the scope of this program, but suffice it to say that these initial conditions are (i) often superpositions of the wave functions of particles located at different points, and that (ii) because \\(|\\psi(\\mathbf x,t)|^2\\) corresponds to a particle density function, the integral\n\n\\[\nN(t) = \\int\\_\\Omega |\\psi(\\mathbf x,t)|^2\n\\]\n\ncorresponds to the number of particles in the system. (Clearly, if one were to be physically correct, \\(N(t)\\) better be a constant if the system is closed, or \\(\\frac{dN}{dt}<0\\) if one has absorbing boundary conditions.) The important point is that one should choose initial conditions so that\n\n\\[\nN(0) = \\int\\_\\Omega |\\psi\\_0(\\mathbf x)|^2\n\\]\n\nmakes sense.\n\nWhat we will use here, primarily because it makes for good graphics, is the following:\n\n\\[\n\\psi\\_0(\\mathbf x) = \\sqrt{\\sum\\_{k=1}^4 \\alpha\\_k e^{-\\frac{r\\_k^2}{R^2}}},\n\\]\n\nwhere \\(r\\_k = |\\mathbf x-\\mathbf x\\_k|\\) is the distance from the (fixed) locations \\(\\mathbf x\\_k\\), and \\(\\alpha\\_k\\) are chosen so that each of the Gaussians that we are adding up adds an integer number of particles to \\(N(0)\\). We achieve this by making sure that\n\n\\[\n\\int\\_\\Omega \\alpha\\_k e^{-\\frac{r\\_k^2}{R^2}}\n\\]\n\nis a positive integer. In other words, we need to choose \\(\\alpha\\) as an integer multiple of\n\n\\[\n\\left(\\int\\_\\Omega e^{-\\frac{r\\_k^2}{R^2}}\\right)^{-1}\n=\n\\left(R^d\\sqrt{\\pi^d}\\right)^{-1},\n\\]\n\nassuming for the moment that \\(\\Omega={\\mathbb R}^d\\) – which is of course not the case, but we'll ignore the small difference in integral.\n\nThus, we choose \\(\\alpha\\_k=\\left(R^d\\sqrt{\\pi^d}\\right)^{-1}\\) for all, and \\(R=0.1\\). This \\(R\\) is small enough that the difference between the exact (infinite) integral and the integral over \\(\\Omega\\) should not be too concerning. We choose the four points \\(\\mathbf x\\_k\\) as \\((\\pm 0.3, 0), (0, \\pm\n0.3)\\) – also far enough away from the boundary of \\(\\Omega\\) to keep ourselves on the safe side.\n\nFor simplicity, we pose the problem on the square \\([-1,1]^2\\). For boundary conditions, we will use time-independent Neumann conditions of the form\n\n\\[\n\\nabla\\psi(\\mathbf x,t)\\cdot \\mathbf n=0 \\qquad\\qquad \\forall \\mathbf x\\in\\partial\\Omega.\n\\]\n\nThis is not a realistic choice of boundary conditions but sufficient for what we want to demonstrate here. We will comment further on this in the [Possibilities for extensions](#extensions) section below.\n\nFinally, we choose \\(\\kappa=1\\), and the potential as\n\n\\[\nV(\\mathbf x)\n=\n\\begin{cases} 0 & \\text{if}\\; |\\mathbf x|<0.7\n\\\\\n1000 & \\text{otherwise}.\n\\end{cases}\n\\]\n\nUsing a large potential makes sure that the wave function \\(\\psi\\) remains small outside the circle of radius 0.7. All of the Gaussians that make up the initial conditions are within this circle, and the solution will mostly oscillate within it, with a small amount of energy radiating into the outside. The use of a large potential also makes sure that the nonphysical boundary condition does not have too large an effect.\n\nThe commented program\n=====================\n\n### Include files\n\nThe program starts with the usual include files, all of which you should have seen before by now:\n\n```\n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/block_sparse_matrix.h>\n   #include <deal.II/lac/block_vector.h>\n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/sparse_direct.h>\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/error_estimator.h>\n   \n   #include <fstream>\n   #include <iostream>\n```\n\nThen the usual placing of all content of this program into a namespace and the importation of the deal.II namespace into the one we will work in:\n\n```\n   namespace Step58\n   {\n     using namespace dealii;\n```\n\n### The `NonlinearSchroedingerEquation` class\n\nThen the main class. It looks very much like the corresponding classes in [step-4](step_4.html) or [step-6](step_6.html), with the only exception that the matrices and vectors and everything else related to the linear system are now storing elements of type `std::complex<double>` instead of just `double`.\n\n```\n     template <int dim>\n     class NonlinearSchroedingerEquation\n     {\n     public:\n       NonlinearSchroedingerEquation();\n       void run();\n   \n     private:\n       void setup_system();\n       void assemble_matrices();\n       void do_half_phase_step();\n       void do_full_spatial_step();\n       void output_results() const;\n   \n   \n       Triangulation<dim> triangulation;\n       const FE_Q<dim>    fe;\n       DoFHandler<dim>    dof_handler;\n   \n       AffineConstraints<std::complex<double>> constraints;\n   \n       SparsityPattern                    sparsity_pattern;\n       SparseMatrix<std::complex<double>> system_matrix;\n       SparseMatrix<std::complex<double>> rhs_matrix;\n   \n       Vector<std::complex<double>> solution;\n       Vector<std::complex<double>> system_rhs;\n   \n       double       time;\n       double       time_step;\n       unsigned int timestep_number;\n   \n       double kappa;\n     };\n```\n\n### Equation data\n\nBefore we go on filling in the details of the main class, let us define the equation data corresponding to the problem, i.e. initial values, as well as a right hand side class. (We will reuse the initial conditions also for the boundary values, which we simply keep constant.) We do so using classes derived from the [Function](classFunction.html) class template that has been used many times before, so the following should not look surprising. The only point of interest is that we here have a complex-valued problem, so we have to provide the second template argument of the [Function](classFunction.html) class (which would otherwise default to `double`). Furthermore, the return type of the `value()` functions is then of course also complex.\n\nWhat precisely these functions return has been discussed at the end of the Introduction section.\n\n```\n     template <int dim>\n     class InitialValues : public Function<dim, std::complex<double>>\n     {\n     public:\n       InitialValues()\n         : Function<dim, std::complex<double>>(1)\n       {}\n   \n       virtual std::complex<double>\n       value(const Point<dim> &p, const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     std::complex<double>\n     InitialValues<dim>::value(const Point<dim>  &p,\n                               const unsigned int component) const\n     {\n       static_assert(dim == 2, \"This initial condition only works in 2d.\");\n   \n       (void)component;\n       Assert(component == 0, ExcIndexRange(component, 0, 1));\n   \n       const std::vector<Point<dim>> vortex_centers = {{0, -0.3},\n                                                       {0, +0.3},\n                                                       {+0.3, 0},\n                                                       {-0.3, 0}};\n   \n       const double R = 0.1;\n       const double alpha =\n         1. / (std::pow(R, dim) * std::pow(numbers::PI, dim / 2.));\n   \n       double sum = 0;\n       for (const auto &vortex_center : vortex_centers)\n         {\n           const Tensor<1, dim> distance = p - vortex_center;\n           const double         r        = distance.norm();\n   \n           sum += alpha * std::exp(-(r * r) / (R * R));\n         }\n   \n       return {std::sqrt(sum), 0.};\n     }\n   \n   \n   \n     template <int dim>\n     class Potential : public Function<dim>\n     {\n     public:\n       Potential() = default;\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double Potential<dim>::value(const Point<dim>  &p,\n                                  const unsigned int component) const\n     {\n       (void)component;\n       Assert(component == 0, ExcIndexRange(component, 0, 1));\n   \n       return (Point<dim>().distance(p) > 0.7 ? 1000 : 0);\n     }\n```\n\n### Implementation of the `NonlinearSchroedingerEquation` class\n\nWe start by specifying the implementation of the constructor of the class. There is nothing of surprise to see here except perhaps that we choose quadratic ( \\(Q\\_2\\)) Lagrange elements – the solution is expected to be smooth, so we choose a higher polynomial degree than the bare minimum.\n\n```\n     template <int dim>\n     NonlinearSchroedingerEquation<dim>::NonlinearSchroedingerEquation()\n       : fe(2)\n       , dof_handler(triangulation)\n       , time(0)\n       , time_step(1. / 128)\n       , timestep_number(0)\n       , kappa(1)\n     {}\n```\n\n#### Setting up data structures and assembling matrices\n\nThe next function is the one that sets up the mesh, [DoFHandler](classDoFHandler.html), and matrices and vectors at the beginning of the program, i.e. before the first time step. The first few lines are pretty much standard if you've read through the tutorial programs at least up to [step-6](step_6.html):\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::setup_system()\n     {\n       GridGenerator::hyper_cube(triangulation, -1, 1);\n       triangulation.refine_global(6);\n   \n       std::cout << \"Number of active cells: \" << triangulation.n_active_cells()\n                 << std::endl;\n   \n       dof_handler.distribute_dofs(fe);\n   \n       std::cout << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n                 << std::endl\n                 << std::endl;\n   \n       DynamicSparsityPattern dsp(dof_handler.n_dofs(), dof_handler.n_dofs());\n       DoFTools::make_sparsity_pattern(dof_handler, dsp);\n       sparsity_pattern.copy_from(dsp);\n   \n       system_matrix.reinit(sparsity_pattern);\n       rhs_matrix.reinit(sparsity_pattern);\n   \n       solution.reinit(dof_handler.n_dofs());\n       system_rhs.reinit(dof_handler.n_dofs());\n   \n       constraints.close();\n     }\n```\n\nNext, we assemble the relevant matrices. The way we have written the Crank-Nicolson discretization of the spatial step of the Strang splitting (i.e., the second of the three partial steps in each time step), we were led to the linear system \\(\\left[ -iM + \\frac 14 k\\_{n+1} A + \\frac 12 k\\_{n+1} W \\right]\n\\Psi^{(n,2)}\n=\n\\left[ -iM - \\frac 14 k\\_{n+1} A - \\frac 12 k\\_{n+1} W \\right]\n\\Psi^{(n,1)}\\). In other words, there are two matrices in play here – one for the left and one for the right hand side. We build these matrices separately. (One could avoid building the right hand side matrix and instead just form the *action* of the matrix on \\(\\Psi^{(n,1)}\\) in each time step. This may or may not be more efficient, but efficiency is not foremost on our minds for this program.)\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::assemble_matrices()\n     {\n       const QGauss<dim> quadrature_formula(fe.degree + 1);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_gradients |\n                                 update_quadrature_points | update_JxW_values);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<std::complex<double>> cell_matrix_lhs(dofs_per_cell,\n                                                        dofs_per_cell);\n       FullMatrix<std::complex<double>> cell_matrix_rhs(dofs_per_cell,\n                                                        dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n       std::vector<double>                  potential_values(n_q_points);\n       const Potential<dim>                 potential;\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           cell_matrix_lhs = std::complex<double>(0.);\n           cell_matrix_rhs = std::complex<double>(0.);\n   \n           fe_values.reinit(cell);\n   \n           potential.value_list(fe_values.get_quadrature_points(),\n                                potential_values);\n   \n           for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n             {\n               for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                 {\n                   for (unsigned int l = 0; l < dofs_per_cell; ++l)\n                     {\n                       const std::complex<double> i = {0, 1};\n   \n                       cell_matrix_lhs(k, l) +=\n                         (-i * fe_values.shape_value(k, q_index) *\n                            fe_values.shape_value(l, q_index) +\n                          time_step / 4 * fe_values.shape_grad(k, q_index) *\n                            fe_values.shape_grad(l, q_index) +\n                          time_step / 2 * potential_values[q_index] *\n                            fe_values.shape_value(k, q_index) *\n                            fe_values.shape_value(l, q_index)) *\n                         fe_values.JxW(q_index);\n   \n                       cell_matrix_rhs(k, l) +=\n                         (-i * fe_values.shape_value(k, q_index) *\n                            fe_values.shape_value(l, q_index) -\n                          time_step / 4 * fe_values.shape_grad(k, q_index) *\n                            fe_values.shape_grad(l, q_index) -\n                          time_step / 2 * potential_values[q_index] *\n                            fe_values.shape_value(k, q_index) *\n                            fe_values.shape_value(l, q_index)) *\n                         fe_values.JxW(q_index);\n                     }\n                 }\n             }\n   \n           cell->get_dof_indices(local_dof_indices);\n           constraints.distribute_local_to_global(cell_matrix_lhs,\n                                                  local_dof_indices,\n                                                  system_matrix);\n           constraints.distribute_local_to_global(cell_matrix_rhs,\n                                                  local_dof_indices,\n                                                  rhs_matrix);\n         }\n     }\n```\n\n#### Implementing the Strang splitting steps\n\nHaving set up all data structures above, we are now in a position to implement the partial steps that form the Strang splitting scheme. We start with the half-step to advance the phase, and that is used as the first and last part of each time step.\n\nTo this end, recall that for the first half step, we needed to compute \\(\\psi^{(n,1)} = e^{-i\\kappa|\\psi^{(n,0)}|^2 \\tfrac\n12\\Delta t} \\; \\psi^{(n,0)}\\). Here, \\(\\psi^{(n,0)}=\\psi^{(n)}\\) and \\(\\psi^{(n,1)}\\) are functions of space and correspond to the output of the previous complete time step and the result of the first of the three part steps, respectively. A corresponding solution must be computed for the third of the part steps, i.e. \\(\\psi^{(n,3)} = e^{-i\\kappa|\\psi^{(n,2)}|^2 \\tfrac\n12\\Delta t} \\; \\psi^{(n,2)}\\), where \\(\\psi^{(n,3)}=\\psi^{(n+1)}\\) is the result of the time step as a whole, and its input \\(\\psi^{(n,2)}\\) is the result of the spatial step of the Strang splitting.\n\nAn important realization is that while \\(\\psi^{(n,0)}(\\mathbf x)\\) may be a finite element function (i.e., is piecewise polynomial), this may not necessarily be the case for the \"rotated\" function in which we have updated the phase using the exponential factor (recall that the amplitude of that function remains constant as part of that step). In other words, we could *compute* \\(\\psi^{(n,1)}(\\mathbf x)\\) at every point \\(\\mathbf x\\in\\Omega\\), but we can't represent it on a mesh because it is not a piecewise polynomial function. The best we can do in a discrete setting is to compute a projection or interpolation. In other words, we can compute \\(\\psi\\_h^{(n,1)}(\\mathbf x) = \\Pi\\_h\n\\left(e^{-i\\kappa|\\psi\\_h^{(n,0)}(\\mathbf x)|^2 \\tfrac 12\\Delta t}\n\\; \\psi\\_h^{(n,0)}(\\mathbf x) \\right)\\) where \\(\\Pi\\_h\\) is a projection or interpolation operator. The situation is particularly simple if we choose the interpolation: Then, all we need to compute is the value of the right hand side *at the node points* and use these as nodal values for the vector \\(\\Psi^{(n,1)}\\) of degrees of freedom. This is easily done because evaluating the right hand side at node points for a Lagrange finite element as used here requires us to only look at a single (complex-valued) entry of the node vector. In other words, what we need to do is to compute \\(\\Psi^{(n,1)}\\_j = e^{-i\\kappa|\\Psi^{(n,0)}\\_j|^2 \\tfrac\n12\\Delta t} \\; \\Psi^{(n,0)}\\_j\\) where \\(j\\) loops over all of the entries of our solution vector. This is what the function below does – in fact, it doesn't even use separate vectors for \\(\\Psi^{(n,0)}\\) and \\(\\Psi^{(n,1)}\\), but just updates the same vector as appropriate.\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::do_half_phase_step()\n     {\n       for (auto &value : solution)\n         {\n           const std::complex<double> i         = {0, 1};\n           const double               magnitude = std::abs(value);\n   \n           value = std::exp(-i * kappa * magnitude * magnitude * (time_step / 2)) *\n                   value;\n         }\n     }\n```\n\nThe next step is to solve for the linear system in each time step, i.e., the second half step of the Strang splitting we use. Recall that it had the form \\(C\\Psi^{(n,2)} = R\\Psi^{(n,1)}\\) where \\(C\\) and \\(R\\) are the matrices we assembled earlier.\n\nThe way we solve this here is using a direct solver. We first form the right hand side \\(r=R\\Psi^{(n,1)}\\) using the [SparseMatrix::vmult()](classSparseMatrix.html#a7706b5f721efc5ea1966f5a5cdaad0e6) function and put the result into the `system_rhs` variable. We then call SparseDirectUMFPACK::solver() which takes as argument the matrix \\(C\\) and the right hand side vector and returns the solution in the same vector `system_rhs`. The final step is then to put the solution so computed back into the `solution` variable.\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::do_full_spatial_step()\n     {\n       rhs_matrix.vmult(system_rhs, solution);\n   \n       SparseDirectUMFPACK direct_solver;\n       direct_solver.solve(system_matrix, system_rhs);\n   \n       solution = system_rhs;\n     }\n```\n\n#### Creating graphical output\n\nThe last of the helper functions and classes we ought to discuss are the ones that create graphical output. The result of running the half and full steps for the local and spatial parts of the Strang splitting is that we have updated the `solution` vector \\(\\Psi^n\\) to the correct value at the end of each time step. Its entries contain complex numbers for the solution at the nodes of the finite element mesh.\n\nComplex numbers are not easily visualized. We can output their real and imaginary parts, i.e., the fields \\(\\text{Re}(\\psi\\_h^{(n)}(\\mathbf x))\\) and \\(\\text{Im}(\\psi\\_h^{(n)}(\\mathbf x))\\), and that is exactly what the [DataOut](classDataOut.html) class does when one attaches as complex-valued vector via [DataOut::add\\_data\\_vector()](classDataOut__DoFData.html#ac43d3b1f6e67424f36e474627fe8e401) and then calls [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646). That is indeed what we do below.\n\nBut oftentimes we are not particularly interested in real and imaginary parts of the solution vector, but instead in derived quantities such as the magnitude \\(|\\psi|\\) and phase angle \\(\\text{arg}(\\psi)\\) of the solution. In the context of quantum systems such as here, the magnitude itself is not so interesting, but instead it is the \"amplitude\", \\(|\\psi|^2\\) that is a physical property: it corresponds to the probability density of finding a particle in a particular place of state. The way to put computed quantities into output files for visualization – as used in numerous previous tutorial programs – is to use the facilities of the [DataPostprocessor](classDataPostprocessor.html) and derived classes. Specifically, both the amplitude of a complex number and its phase angles are scalar quantities, and so the [DataPostprocessorScalar](classDataPostprocessorScalar.html) class is the right tool to base what we want to do on.\n\nConsequently, what we do here is to implement two classes `ComplexAmplitude` and `ComplexPhase` that compute for each point at which [DataOut](classDataOut.html) decides to generate output, the amplitudes \\(|\\psi\\_h|^2\\) and phases \\(\\text{arg}(\\psi\\_h)\\) of the solution for visualization. There is a fair amount of boiler-plate code below, with the only interesting parts of the first of these two classes being how its `evaluate_vector_field()` function computes the `computed_quantities` object.\n\n(There is also the rather awkward fact that the [std::norm()](https://en.cppreference.com/w/cpp/numeric/complex/norm) function does not compute what one would naively imagine, namely \\(|\\psi|\\), but returns \\(|\\psi|^2\\) instead. It's certainly quite confusing to have a standard function mis-named in such a way...)\n\n```\n     namespace DataPostprocessors\n     {\n       template <int dim>\n       class ComplexAmplitude : public DataPostprocessorScalar<dim>\n       {\n       public:\n         ComplexAmplitude();\n   \n         virtual void evaluate_vector_field(\n           const DataPostprocessorInputs::Vector<dim> &inputs,\n           std::vector<Vector<double>> &computed_quantities) const override;\n       };\n   \n   \n       template <int dim>\n       ComplexAmplitude<dim>::ComplexAmplitude()\n         : DataPostprocessorScalar<dim>(\"Amplitude\", update_values)\n       {}\n   \n   \n       template <int dim>\n       void ComplexAmplitude<dim>::evaluate_vector_field(\n         const DataPostprocessorInputs::Vector<dim> &inputs,\n         std::vector<Vector<double>>                &computed_quantities) const\n       {\n         AssertDimension(computed_quantities.size(),\n                         inputs.solution_values.size());\n   \n         for (unsigned int p = 0; p < computed_quantities.size(); ++p)\n           {\n             AssertDimension(computed_quantities[p].size(), 1);\n             AssertDimension(inputs.solution_values[p].size(), 2);\n   \n             const std::complex<double> psi(inputs.solution_values[p](0),\n                                            inputs.solution_values[p](1));\n             computed_quantities[p](0) = std::norm(psi);\n           }\n       }\n```\n\nThe second of these postprocessor classes computes the phase angle of the complex-valued solution at each point. In other words, if we represent \\(\\psi(\\mathbf x,t)=r(\\mathbf x,t) e^{i\\varphi(\\mathbf x,t)}\\), then this class computes \\(\\varphi(\\mathbf x,t)\\). The function [std::arg](https://en.cppreference.com/w/cpp/numeric/complex/arg) does this for us, and returns the angle as a real number between \\(-\\pi\\) and \\(+\\pi\\).\n\nFor reasons that we will explain in detail in the results section, we do not actually output this value at each location where output is generated. Rather, we take the maximum over all evaluation points of the phase and then fill each evaluation point's output field with this maximum – in essence, we output the phase angle as a piecewise constant field, where each cell has its own constant value. The reasons for this will become clear once you read through the discussion further down below.\n\n```\n       template <int dim>\n       class ComplexPhase : public DataPostprocessorScalar<dim>\n       {\n       public:\n         ComplexPhase();\n   \n         virtual void evaluate_vector_field(\n           const DataPostprocessorInputs::Vector<dim> &inputs,\n           std::vector<Vector<double>> &computed_quantities) const override;\n       };\n   \n   \n       template <int dim>\n       ComplexPhase<dim>::ComplexPhase()\n         : DataPostprocessorScalar<dim>(\"Phase\", update_values)\n       {}\n   \n   \n       template <int dim>\n       void ComplexPhase<dim>::evaluate_vector_field(\n         const DataPostprocessorInputs::Vector<dim> &inputs,\n         std::vector<Vector<double>>                &computed_quantities) const\n       {\n         AssertDimension(computed_quantities.size(),\n                         inputs.solution_values.size());\n   \n         double max_phase = -numbers::PI;\n         for (unsigned int p = 0; p < computed_quantities.size(); ++p)\n           {\n             AssertDimension(computed_quantities[p].size(), 1);\n             AssertDimension(inputs.solution_values[p].size(), 2);\n   \n             max_phase =\n               std::max(max_phase,\n                        std::arg(\n                          std::complex<double>(inputs.solution_values[p](0),\n                                               inputs.solution_values[p](1))));\n           }\n   \n         for (auto &output : computed_quantities)\n           output(0) = max_phase;\n       }\n   \n     } // namespace DataPostprocessors\n```\n\nHaving so implemented these post-processors, we create output as we always do. As in many other time-dependent tutorial programs, we attach flags to [DataOut](classDataOut.html) that indicate the number of the time step and the current simulation time.\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::output_results() const\n     {\n       const DataPostprocessors::ComplexAmplitude<dim> complex_magnitude;\n       const DataPostprocessors::ComplexPhase<dim>     complex_phase;\n   \n       DataOut<dim> data_out;\n   \n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(solution, \"Psi\");\n       data_out.add_data_vector(solution, complex_magnitude);\n       data_out.add_data_vector(solution, complex_phase);\n       data_out.build_patches();\n   \n       data_out.set_flags(DataOutBase::VtkFlags(time, timestep_number));\n   \n       const std::string filename =\n         \"solution-\" + Utilities::int_to_string(timestep_number, 3) + \".vtu\";\n       std::ofstream output(filename);\n       data_out.write_vtu(output);\n     }\n```\n\n#### Running the simulation\n\nThe remaining step is how we set up the overall logic for this program. It's really relatively simple: Set up the data structures; interpolate the initial conditions onto finite element space; then iterate over all time steps, and on each time step perform the three parts of the Strang splitting method. Every tenth time step, we generate graphical output. That's it.\n\n```\n     template <int dim>\n     void NonlinearSchroedingerEquation<dim>::run()\n     {\n       setup_system();\n       assemble_matrices();\n   \n       time = 0;\n       VectorTools::interpolate(dof_handler, InitialValues<dim>(), solution);\n       output_results();\n   \n       const double end_time = 1;\n       for (; time <= end_time; time += time_step)\n         {\n           ++timestep_number;\n   \n           std::cout << \"Time step \" << timestep_number << \" at t=\" << time\n                     << std::endl;\n   \n           do_half_phase_step();\n           do_full_spatial_step();\n           do_half_phase_step();\n   \n           if (timestep_number % 1 == 0)\n             output_results();\n         }\n     }\n   } // namespace Step58\n```\n\n#### The main() function\n\nThe rest is again boiler plate and exactly as in almost all of the previous tutorial programs:\n\n```\n   int main()\n   {\n     try\n       {\n         using namespace Step58;\n   \n         NonlinearSchroedingerEquation<2> nse;\n         nse.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     return 0;\n   }\n```\n\nResults\n=======\n\nRunning the code results in screen output like the following:\n\n```\nNumber of active cells: 4096\nNumber of degrees of freedom: 16641\n \nTime step 1 at t=0\nTime step 2 at t=0.00390625\nTime step 3 at t=0.0078125\nTime step 4 at t=0.0117188\n[...]\n```\n\nRunning the program also yields a good number of output files that we will visualize in the following.\n\n### Visualizing the solution\n\nThe `output_results()` function of this program generates output files that consist of a number of variables: The solution (split into its real and imaginary parts), the amplitude, and the phase. If we visualize these four fields, we get images like the following after a few time steps (at time \\(t=0.242\\), to be precise:\n\n![Real part of the solution at t=0.242](images/steps/developer/step-58.re.png)\n\n![Imaginary part of the solution at t=0.242](images/steps/developer/step-58.im.png)\n\n![Amplitude of the solution at t=0.242](images/steps/developer/step-58.magnitude.png)\n\n![Phase of the solution at t=0.242](images/steps/developer/step-58.phase.png)\n\nWhile the real and imaginary parts of the solution shown above are not particularly interesting (because, from a physical perspective, the global offset of the phase and therefore the balance between real and imaginary components, is meaningless), it is much more interesting to visualize the amplitude \\(|\\psi(\\mathbf x,t)|^2\\) and phase \\(\\text{arg}(\\psi(\\mathbf x,t))\\) of the solution and, in particular, their evolution. This leads to pictures like the following:\n\nThe phase picture shown here clearly has some flaws:\n\n* First, phase is a \"cyclic quantity\", but the color scale uses a fundamentally different color for values close to \\(-\\pi\\) than for values close to \\(+\\pi\\). This is a nuisance – what we need is a \"cyclic color map\" that uses the same colors for the two extremes of the range of the phase. Such color maps exist, see [this blog post of NicolÃ¡s GuarÃ­n-Zapata](https://nicoguaro.github.io/posts/cyclic_colormaps/) or [this StackExchange post](https://stackoverflow.com/questions/23712207/cyclic-colormap-without-visual-distortions-for-use-in-phase-angle-plots), for example. The problem is that the author's favorite one of the two big visualization packages, VisIt, does not have any of these color maps built in. In an act of desperation, I therefore had to resort to using Paraview given that it has several of the color maps mentioned in the post above implemented. The picture below uses the `nic_Edge` map in which both of the extreme values are shown as black.\n* There is a problem on cells in which the phase wraps around. If at some evaluation point of the cell the phase value is close to \\(-\\pi\\) and at another evaluation point it is close to \\(+\\pi\\), then what we would really like to happen is for the entire cell to have a color close to the extremes. But, instead, visualization programs produce a linear interpolation in which the values within the cell, i.e., between the evaluation points, is linearly interpolated between these two values, covering essentially the entire range of possible phase values and, consequently, cycling through the entire rainbow of colors from dark red to dark green over the course of one cell. The solution to this problem is to just output the phase value on each cell as a piecewise constant. Because averaging values close to the \\(-\\pi\\) and \\(+\\pi\\) is going to result in an average that has nothing to do with the actual phase angle, the `ComplexPhase` class just uses the *maximal* phase angle encountered on each cell.\n\nWith these modifications, the phase plot now looks as follows:\n\n![Phase of the solution at t=0.242, with a cyclic color map](images/steps/developer/step-58.phase-cyclic.png)\n\nFinally, we can generate a movie out of this. (To be precise, the video uses two more global refinement cycles and a time step half the size of what is used in the program above.) The author of these lines made the movie with VisIt, because that's what he's more familiar with, and using a hacked color map that is also cyclic – though this color map lacks all of the skill employed by the people who wrote the posts mentioned in the links above. It does, however, show the character of the solution as a wave equation if you look at the shaded part of the domain outside the circle of radius 0.7 in which the potential is zero – you can see how every time one of the bumps (showing the amplitude \\(|\\psi\\_h(\\mathbf x,t)|^2\\)) bumps into the area where the potential is large: a wave travels outbound from there. Take a look at the video:\n\nSo why did I end up shading the area where the potential \\(V(\\mathbf x)\\) is large? In that outside region, the solution is relatively small. It is also relatively smooth. As a consequence, to some approximate degree, the equation in that region simplifies to\n\n\\[\n- i \\frac{\\partial \\psi}{\\partial t}\n+ V \\psi\n\\approx 0,\n\\]\n\nor maybe easier to read:\n\n\\[\n\\frac{\\partial \\psi}{\\partial t}\n\\approx - i V \\psi.\n\\]\n\nTo the degree to which this approximation is valid (which, among other things, eliminates the traveling waves you can see in the video), this equation has a solution\n\n\\[\n\\psi(\\mathbf x, t) = \\psi(\\mathbf x, 0) e^{-i V t}.\n\\]\n\nBecause \\(V\\) is large, this means that the phase *rotates quite rapidly*. If you focus on the semi-transparent outer part of the domain, you can see that. If one colors this region in the same way as the inner part of the domain, this rapidly flashing outer part may be psychedelic, but is also distracting of what's happening on the inside; it's also quite hard to actually see the radiating waves that are easy to see at the beginning of the video.\n\n### Possibilities for extensions\n\n#### Better linear solvers\n\nThe solver chosen here is just too simple. It is also not efficient. What we do here is give the matrix to a sparse direct solver in every time step and let it find the solution of the linear system. But we know that we could do far better:\n\n* First, we should make use of the fact that the matrix doesn't actually change from time step to time step. This is an artifact of the fact that we here have constant boundary values and that we don't change the time step size – two assumptions that might not be true in actual applications. But at least in cases where this does happen to be the case, it would make sense to only factorize the matrix once (i.e., compute \\(L\\) and \\(U\\) factors once) and then use these factors for all following time steps until the matrix \\(C\\) changes and requires a new factorization. The interface of the [SparseDirectUMFPACK](classSparseDirectUMFPACK.html) class allows for this.\n* Ultimately, however, sparse direct solvers are only efficient for relatively small problems, say up to a few 100,000 unknowns. Beyond this, one needs iterative solvers such as the Conjugate Gradient method (for symmetric and positive definite problems) or GMRES. We have used many of these in other tutorial programs. In all cases, they need to be accompanied by good preconditioners. For the current case, one could in principle use GMRES – a method that does not require any specific properties of the matrix – as the outer solver but at least at the time of writing this sentence (in 2022), the [SolverGMRES](classSolverGMRES.html) class can only handle real-valued linear systems. This can be overcome by implementing a variation of GMRES that can deal with complex-valued matrices and vectors, see for example [[89]](citelist.html#CITEREF_Fraysse2005) . Even better would be to implement an iterative scheme that exploits the one structural feature we know is true for this problem: That the matrix is complex-symmetric (albeit not Hermitian), for which a literature search would probably find schemes as well.\n* A different strategy towards iterative solvers would be to break the linear system into a \\(2\\times 2\\) block system of real and imaginary components, like we did in [step-29](step_29.html). This would then enable using real-valued iterative solvers on the outer level (e.g., the existing GMRES implementation), but one would have to come up with preconditioners that exploit the block structure. There is, again, literature on the topic, of which we simply point out a non-representative sample: [[7]](citelist.html#CITEREF_Axelsson2014) , [[71]](citelist.html#CITEREF_Day2001) , [[143]](citelist.html#CITEREF_Liao2016) .\n\n#### Boundary conditions\n\nIn order to be usable for actual, realistic problems, solvers for the nonlinear Schrödinger equation need to utilize boundary conditions that make sense for the problem at hand. We have here restricted ourselves to simple Neumann boundary conditions – but these do not actually make sense for the problem. Indeed, the equations are generally posed on an infinite domain. But, since we can't compute on infinite domains, we need to truncate it somewhere and instead pose boundary conditions that make sense for this artificially small domain. The approach widely used is to use the [Perfectly Matched Layer](https://en.wikipedia.org/wiki/Perfectly_matched_layer) method that corresponds to a particular kind of attenuation. It is, in a different context, also used in [step-62](step_62.html).\n\n#### Adaptive meshes\n\nFinally, we know from experience and many other tutorial programs that it is worthwhile to use adaptively refined meshes, rather than the uniform meshes used here. It would, in fact, not be very difficult to add this here: It just requires periodic remeshing and transfer of the solution from one mesh to the next. [step-26](step_26.html) will be a good guide for how this could be implemented.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2020 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Wolfgang Bangerth, Colorado State University\n *          Yong-Yong Cai, Beijing Computational Science Research Center\n */\n \n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/block_sparse_matrix.h>\n#include <deal.II/lac/block_vector.h>\n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/sparse_direct.h>\n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/error_estimator.h>\n \n#include <fstream>\n#include <iostream>\n \n \nnamespace Step58\n{\n using namespace dealii;\n \n template <int dim>\n class NonlinearSchroedingerEquation\n  {\n public:\n    NonlinearSchroedingerEquation();\n void run();\n \n private:\n void setup_system();\n void assemble_matrices();\n void do_half_phase_step();\n void do_full_spatial_step();\n void output_results() const;\n \n \n Triangulation<dim> triangulation;\n const FE_Q<dim>    fe;\n DoFHandler<dim>    dof_handler;\n \n AffineConstraints<std::complex<double>> constraints;\n \n SparsityPattern                    sparsity_pattern;\n SparseMatrix<std::complex<double>> system_matrix;\n SparseMatrix<std::complex<double>> rhs_matrix;\n \n Vector<std::complex<double>> solution;\n Vector<std::complex<double>> system_rhs;\n \n double       time;\n double       time_step;\n unsigned int timestep_number;\n \n double kappa;\n  };\n \n \n \n \n template <int dim>\n class InitialValues : public Function<dim, std::complex<double>>\n  {\n public:\n    InitialValues()\n      : Function<dim, std::complex<double>>(1)\n    {}\n \n virtual std::complex<double>\n value(const Point<dim> &p, const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n  std::complex<double>\n  InitialValues<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n static_assert(dim == 2, \"This initial condition only works in 2d.\");\n \n    (void)component;\n Assert(component == 0, ExcIndexRange(component, 0, 1));\n \n const std::vector<Point<dim>> vortex_centers = {{0, -0.3},\n                                                    {0, +0.3},\n                                                    {+0.3, 0},\n                                                    {-0.3, 0}};\n \n const double R = 0.1;\n const double alpha =\n      1. / (std::pow(R, dim) * std::pow(numbers::PI, dim / 2.));\n \n double sum = 0;\n for (const auto &vortex_center : vortex_centers)\n      {\n const Tensor<1, dim> distance = p - vortex_center;\n const double         r        = distance.norm();\n \n sum += alpha * std::exp(-(r * r) / (R * R));\n      }\n \n return {std::sqrt(sum), 0.};\n  }\n \n \n \n template <int dim>\n class Potential : public Function<dim>\n  {\n public:\n    Potential() = default;\n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double Potential<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n    (void)component;\n Assert(component == 0, ExcIndexRange(component, 0, 1));\n \n return (Point<dim>().distance(p) > 0.7 ? 1000 : 0);\n  }\n \n \n \n \n template <int dim>\n  NonlinearSchroedingerEquation<dim>::NonlinearSchroedingerEquation()\n    : fe(2)\n    , dof_handler(triangulation)\n    , time(0)\n    , time_step(1. / 128)\n    , timestep_number(0)\n    , kappa(1)\n  {}\n \n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::setup_system()\n  {\n GridGenerator::hyper_cube(triangulation, -1, 1);\n triangulation.refine_global(6);\n \n    std::cout << \"Number of active cells: \" << triangulation.n_active_cells()\n              << std::endl;\n \n    dof_handler.distribute_dofs(fe);\n \n    std::cout << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n              << std::endl\n              << std::endl;\n \n DynamicSparsityPattern dsp(dof_handler.n_dofs(), dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler, dsp);\n    sparsity_pattern.copy_from(dsp);\n \n    system_matrix.reinit(sparsity_pattern);\n    rhs_matrix.reinit(sparsity_pattern);\n \n    solution.reinit(dof_handler.n_dofs());\n    system_rhs.reinit(dof_handler.n_dofs());\n \n    constraints.close();\n  }\n \n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::assemble_matrices()\n  {\n const QGauss<dim> quadrature_formula(fe.degree + 1);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points | update_JxW_values);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<std::complex<double>> cell_matrix_lhs(dofs_per_cell,\n                                                     dofs_per_cell);\n FullMatrix<std::complex<double>> cell_matrix_rhs(dofs_per_cell,\n                                                     dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n    std::vector<double>                  potential_values(n_q_points);\n const Potential<dim>                 potential;\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        cell_matrix_lhs = std::complex<double>(0.);\n        cell_matrix_rhs = std::complex<double>(0.);\n \n        fe_values.reinit(cell);\n \n        potential.value_list(fe_values.get_quadrature_points(),\n                             potential_values);\n \n for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n          {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n              {\n for (unsigned int l = 0; l < dofs_per_cell; ++l)\n                  {\n const std::complex<double> i = {0, 1};\n \n                    cell_matrix_lhs(k, l) +=\n                      (-i * fe_values.shape_value(k, q_index) *\n                         fe_values.shape_value(l, q_index) +\n                       time_step / 4 * fe_values.shape_grad(k, q_index) *\n                         fe_values.shape_grad(l, q_index) +\n                       time_step / 2 * potential_values[q_index] *\n                         fe_values.shape_value(k, q_index) *\n                         fe_values.shape_value(l, q_index)) *\n                      fe_values.JxW(q_index);\n \n                    cell_matrix_rhs(k, l) +=\n                      (-i * fe_values.shape_value(k, q_index) *\n                         fe_values.shape_value(l, q_index) -\n                       time_step / 4 * fe_values.shape_grad(k, q_index) *\n                         fe_values.shape_grad(l, q_index) -\n                       time_step / 2 * potential_values[q_index] *\n                         fe_values.shape_value(k, q_index) *\n                         fe_values.shape_value(l, q_index)) *\n                      fe_values.JxW(q_index);\n                  }\n              }\n          }\n \n        cell->get_dof_indices(local_dof_indices);\n        constraints.distribute_local_to_global(cell_matrix_lhs,\n                                               local_dof_indices,\n                                               system_matrix);\n        constraints.distribute_local_to_global(cell_matrix_rhs,\n                                               local_dof_indices,\n                                               rhs_matrix);\n      }\n  }\n \n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::do_half_phase_step()\n  {\n for (auto &value : solution)\n      {\n const std::complex<double> i         = {0, 1};\n const double               magnitude = std::abs(value);\n \n value = std::exp(-i * kappa * magnitude * magnitude * (time_step / 2)) *\n value;\n      }\n  }\n \n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::do_full_spatial_step()\n  {\n    rhs_matrix.vmult(system_rhs, solution);\n \n SparseDirectUMFPACK direct_solver;\n    direct_solver.solve(system_matrix, system_rhs);\n \n    solution = system_rhs;\n  }\n \n \n \n \n \n namespace DataPostprocessors\n  {\n template <int dim>\n class ComplexAmplitude : public DataPostprocessorScalar<dim>\n    {\n public:\n      ComplexAmplitude();\n \n virtual void evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n        std::vector<Vector<double>> &computed_quantities) const override;\n    };\n \n \n template <int dim>\n    ComplexAmplitude<dim>::ComplexAmplitude()\n      : DataPostprocessorScalar<dim>(\"Amplitude\", update_values)\n    {}\n \n \n template <int dim>\n void ComplexAmplitude<dim>::evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n      std::vector<Vector<double>>                &computed_quantities) const\n {\n AssertDimension(computed_quantities.size(),\n                      inputs.solution_values.size());\n \n for (unsigned int p = 0; p < computed_quantities.size(); ++p)\n        {\n AssertDimension(computed_quantities[p].size(), 1);\n AssertDimension(inputs.solution_values[p].size(), 2);\n \n const std::complex<double> psi(inputs.solution_values[p](0),\n                                         inputs.solution_values[p](1));\n          computed_quantities[p](0) = std::norm(psi);\n        }\n    }\n \n \n \n template <int dim>\n class ComplexPhase : public DataPostprocessorScalar<dim>\n    {\n public:\n      ComplexPhase();\n \n virtual void evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n        std::vector<Vector<double>> &computed_quantities) const override;\n    };\n \n \n template <int dim>\n    ComplexPhase<dim>::ComplexPhase()\n      : DataPostprocessorScalar<dim>(\"Phase\", update_values)\n    {}\n \n \n template <int dim>\n void ComplexPhase<dim>::evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n      std::vector<Vector<double>>                &computed_quantities) const\n {\n AssertDimension(computed_quantities.size(),\n                      inputs.solution_values.size());\n \n double max_phase = -numbers::PI;\n for (unsigned int p = 0; p < computed_quantities.size(); ++p)\n        {\n AssertDimension(computed_quantities[p].size(), 1);\n AssertDimension(inputs.solution_values[p].size(), 2);\n \n          max_phase =\n std::max(max_phase,\n                     std::arg(\n                       std::complex<double>(inputs.solution_values[p](0),\n                                            inputs.solution_values[p](1))));\n        }\n \n for (auto &output : computed_quantities)\n        output(0) = max_phase;\n    }\n \n  } // namespace DataPostprocessors\n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::output_results() const\n {\n const DataPostprocessors::ComplexAmplitude<dim> complex_magnitude;\n const DataPostprocessors::ComplexPhase<dim>     complex_phase;\n \n DataOut<dim> data_out;\n \n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(solution, \"Psi\");\n    data_out.add_data_vector(solution, complex_magnitude);\n    data_out.add_data_vector(solution, complex_phase);\n    data_out.build_patches();\n \n    data_out.set_flags(DataOutBase::VtkFlags(time, timestep_number));\n \n const std::string filename =\n \"solution-\" + Utilities::int_to_string(timestep_number, 3) + \".vtu\";\n    std::ofstream output(filename);\n    data_out.write_vtu(output);\n  }\n \n \n \n \n template <int dim>\n void NonlinearSchroedingerEquation<dim>::run()\n  {\n    setup_system();\n    assemble_matrices();\n \n    time = 0;\n VectorTools::interpolate(dof_handler, InitialValues<dim>(), solution);\n    output_results();\n \n const double end_time = 1;\n for (; time <= end_time; time += time_step)\n      {\n        ++timestep_number;\n \n        std::cout << \"Time step \" << timestep_number << \" at t=\" << time\n                  << std::endl;\n \n        do_half_phase_step();\n        do_full_spatial_step();\n        do_half_phase_step();\n \n if (timestep_number % 1 == 0)\n          output_results();\n      }\n  }\n} // namespace Step58\n \n \n \nint main()\n{\n try\n    {\n using namespace Step58;\n \n      NonlinearSchroedingerEquation<2> nse;\n      nse.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_59.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving a Poisson problem discretized with an interior penalty DG method and a multilevel preconditioner in a matrix-free fashion using a massively parallel implementation.\nTutorial content :\nThis tutorial depends on [step-37](step_37.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_59-Intro)    * [The symmetric interior penalty formulation for the Laplacian](#step_59-ThesymmetricinteriorpenaltyformulationfortheLaplacian)* [Face integration support in MatrixFree and FEFaceEvaluation](#step_59-FaceintegrationsupportinMatrixFreeandFEFaceEvaluation)* [The FE\\_DGQHermite element](#step_59-TheFE_DGQHermiteelement)* [An approximate block-Jacobi smoother using the fast diagonalization method](#step_59-AnapproximateblockJacobismootherusingthefastdiagonalizationmethod)- [The commented program](#step_59-CommProg)      * [Equation data](#step_59-Equationdata)* [Matrix-free implementation](#step_59-Matrixfreeimplementation) | 1. [Results](#step_59-Results)    * [Program output](#step_59-Programoutput)* [Comparison of efficiency at different polynomial degrees](#step_59-Comparisonofefficiencyatdifferentpolynomialdegrees)* [Evaluation of efficiency of ingredients](#step_59-Evaluationofefficiencyofingredients)* [Possibilities for extension](#step_59-Possibilitiesforextension)- [The plain program](#step_59-PlainProg) |\n\n*This program was contributed by Katharina Kormann and Martin Kronbichler.*\n\n*This work was partly supported by the German Research Foundation (DFG) through the project \"High-order discontinuous Galerkin for the exa-scale\" (ExaDG) within the priority program \"Software for Exascale Computing\" (SPPEXA).*\n\nIntroduction\n============\n\nMatrix-free operator evaluation enables very efficient implementations of discretization with high-order polynomial bases due to a method called sum factorization. This concept has been introduced in the [step-37](step_37.html) and [step-48](step_48.html) tutorial programs. In this tutorial program, we extend those concepts to discontinuous Galerkin (DG) schemes that include face integrals, a class of methods where high orders are particularly widespread.\n\nThe underlying idea of the matrix-free evaluation is the same as for continuous elements: The matrix-vector product that appears in an iterative solver or multigrid smoother is not implemented by a classical sparse matrix kernel, but instead applied implicitly by the evaluation of the underlying integrals on the fly. For tensor product shape functions that are integrated with a tensor product quadrature rule, this evaluation is particularly efficient by using the sum-factorization technique, which decomposes the initially \\((k+1)^{2d}\\) operations for interpolation involving \\((k+1)^d\\) vector entries with associated shape functions at degree \\(k\\) in \\(d\\) dimensions to \\((k+1)^d\\) quadrature points into \\(d\\) one-dimensional operations of cost \\((k+1)^{d+1}\\) each. In 3D, this reduces the order of complexity by two powers in \\(k\\). When measured as the complexity per degree of freedom, the complexity is \\(\\mathcal O(k)\\) in the polynomial degree. Due to the presence of face integrals in DG, and due to the fact that operations on quadrature points involve more memory transfer, which both scale as \\(\\mathcal O(1)\\), the observed complexity is often constant for moderate \\(k\\leq 10\\). This means that a high order method can be evaluated with the same throughput in terms of degrees of freedom per second as a low-order method.\n\nMore information on the algorithms are available in the preprint   \n[Fast matrix-free evaluation of discontinuous Galerkin finite element operators](https://arxiv.org/abs/1711.03590) by Martin Kronbichler and Katharina Kormann, arXiv:1711.03590.\n\n### The symmetric interior penalty formulation for the Laplacian\n\nFor this tutorial program, we exemplify the matrix-free DG framework for the interior penalty discretization of the Laplacian, i.e., the same scheme as the one used for the [step-39](step_39.html) tutorial program. The discretization of the Laplacian is given by the following weak form\n\n\\begin{align\\*}\n&\\sum\\_{K\\in\\text{cells}} \\left(\\nabla v\\_h, \\nabla u\\_h\\right)\\_{K}+\\\\\n&\\sum\\_{F\\in\\text{faces}}\\Big(-\\left<\\jump{v\\_h}, \\average{\\nabla u\\_h}\\right>\\_{F} - \\left<\\average{\\nabla v\\_h}, \\jump{u\\_h}\\right>\\_{F} + \\left<\\jump{v\\_h}, \\sigma \\jump{u\\_h}\\right>\\_{F}\\Big) \\\\\n&= \\sum\\_{K\\in\\text{cells}}\\left(v\\_h, f\\right)\\_{K},\n\\end{align\\*}\n\nwhere \\(\\jump{v} = v^- \\mathbf{n}^- + v^+ \\mathbf{n}^+ = \\mathbf n^{-}\n\\left(v^- - v^+\\right)\\) denotes the directed jump of the quantity \\(v\\) from the two associated cells \\(K^-\\) and \\(K^+\\), and \\(\\average{v}=\\frac{v^- + v^+}{2}\\) is the average from both sides.\n\nThe terms in the equation represent the cell integral after integration by parts, the primal consistency term that arises at the element interfaces due to integration by parts and insertion of an average flux, the adjoint consistency term that is added for restoring symmetry of the underlying matrix, and a penalty term with factor \\(\\sigma\\), whose magnitude is equal the length of the cells in direction normal to face multiplied by \\(k(k+1)\\), see [step-39](step_39.html). The penalty term is chosen such that an inverse estimate holds and the final weak form is coercive, i.e., positive definite in the discrete setting. The adjoint consistency term and the penalty term involve the jump \\(\\jump{u\\_h}\\) at the element interfaces, which disappears for the analytic solution \\(u\\). Thus, these terms are consistent with the original PDE, ensuring that the method can retain optimal orders of convergence.\n\nIn the implementation below, we implement the weak form above by moving the normal vector \\(\\mathbf{n}^-\\) from the jump terms to the derivatives to form a *normal* derivative of the form \\(\\mathbf{n}^-\\cdot \\nabla u\\_h\\). This makes the implementation on quadrature points slightly more efficient because we only need to work with scalar terms rather than tensors, and is mathematically equivalent.\n\nFor boundary conditions, we use the so-called mirror principle that defines *artificial* exterior values \\(u^+\\) by extrapolation from the interior solution \\(u^-\\) combined with the given boundary data, setting \\(u^+ = -u^- + 2\ng\\_\\text{D}\\) and \\(\\mathbf{n}^-\\cdot \\nabla u^+ = \\mathbf{n}^-\\cdot \\nabla u^-\\) on Dirichlet boundaries and \\(u^+=u^-\\) and \\(\\mathbf{n}^-\\cdot \\nabla u^+ =\n-\\mathbf{n}^-\\cdot \\nabla u^- + 2 g\\_\\text{N}\\) on Neumann boundaries, for given Dirichlet values \\(g\\_\\text{D}\\) and Neumann values \\(g\\_\\text{N}\\). These expressions are then inserted in the above weak form. Contributions involving the known quantities \\(g\\_\\text{D}\\) and \\(g\\_\\text{N}\\) are eventually moved to the right hand side, whereas the unknown value \\(u^-\\) is retained on the left hand side and contributes to the matrix terms similarly as interior faces. Upon these manipulations, the same weak form as in [step-39](step_39.html) is obtained.\n\n### Face integration support in [MatrixFree](classMatrixFree.html) and [FEFaceEvaluation](classFEFaceEvaluation.html)\n\nThe matrix-free framework of deal.II provides the necessary infrastructure to implement the action of the discretized equation above. As opposed to the [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) that we used in [step-37](step_37.html) and [step-48](step_48.html), we now build a code in terms of [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) that takes three function pointers, one for the cell integrals, one for the inner face integrals, and one for the boundary face integrals (in analogy to the design of [MeshWorker](namespaceMeshWorker.html) used in the [step-39](step_39.html) tutorial program). In each of these three functions, we then implement the respective terms on the quadrature points. For interpolation between the vector entries and the values and gradients on quadrature points, we use the class [FEEvaluation](classFEEvaluation.html) for cell contributions and [FEFaceEvaluation](classFEFaceEvaluation.html) for face contributions. The basic usage of these functions has been discussed extensively in the [step-37](step_37.html) tutorial program.\n\nIn [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf), all interior faces are visited exactly once, so one must make sure to compute the contributions from both the test functions \\(v\\_h^-\\) and \\(v\\_h^+\\). Given the fact that the test functions on both sides are indeed independent, the weak form above effectively means that we submit the same contribution to both an [FEFaceEvaluation](classFEFaceEvaluation.html) object called `phi_inner` and `phi_outer` for testing with the normal derivative of the test function, and values with opposite sign for testing with the values of the test function, because the latter involves opposite signs due to the jump term. For faces between cells of different refinement level, the integration is done from the refined side, and [FEFaceEvaluation](classFEFaceEvaluation.html) automatically performs interpolation to a subface on the coarse side. Thus, a hanging node never appears explicitly in a user implementation of a weak form.\n\nThe fact that each face is visited exactly once also applies to those faces at subdomain boundaries between different processors when parallelized with MPI, where one cell belongs to one processor and one to the other. The setup in [MatrixFree::reinit()](classMatrixFree.html#adb324d469b296f2a6921b41208732ddf) splits the faces between the two sides, and eventually only reports the faces actually handled locally in [MatrixFree::n\\_inner\\_face\\_batches()](classMatrixFree.html#a1d24c18bcde8d09a2a7847f0f7f96d19) and [MatrixFree::n\\_boundary\\_face\\_batches()](classMatrixFree.html#aa787165092c1949ce2128ca63799abc1), respectively. Note that, in analogy to the cell integrals discussed in [step-37](step_37.html), deal.II applies vectorization over several faces to use SIMD, working on something we call a *batch of faces* with a single instruction. The face batches are independent from the cell batches, even though the time at which face integrals are processed is kept close to the time when the cell integrals of the respective cells are processed, in order to increase the data locality.\n\nAnother thing that is new in this program is the fact that we no longer split the vector access like [FEEvaluation::read\\_dof\\_values()](classFEEvaluationBase.html#aff4ac5c0f5afb445a2a5cf9a0715a2fe) or [FEEvaluation::distribute\\_local\\_to\\_global()](classFEEvaluationBase.html#a4aaf3e9004fbaf810655f4e0962a015e) from the evaluation and integration steps, but call combined functions [FEEvaluation::gather\\_evaluate()](classFEEvaluation.html#ab53d5c08f460cfe6c9830ac14a427115) and [FEEvaluation::integrate\\_scatter()](classFEEvaluation.html#a52265fb3ecb2b63388e1708ef395418f), respectively. This is useful for face integrals because, depending on what gets evaluated on the faces, not all vector entries of a cell must be touched in the first place. Think for example of the case of the nodal element [FE\\_DGQ](classFE__DGQ.html) with node points on the element surface: If we are interested in the shape function values on a face, only \\((k+ 1)^{d-1}\\) degrees of freedom contribute to them in a non-trivial way (in a more technical way of speaking, only \\((k+1)^{d-1}\\) shape functions have a nonzero support on the face and return true for [FiniteElement::has\\_support\\_on\\_face()](classFiniteElement.html#a68dc9f085edbcd92f8d0703d3e5fce6f)). When compared to the \\((k+1)^d\\) degrees of freedom of a cell, this is one power less.\n\nNow of course we are not interested in only the function values, but also the derivatives on the cell. Fortunately, there is an element in deal.II that extends this property of reduced access also for derivatives on faces, the [FE\\_DGQHermite](classFE__DGQHermite.html) element.\n\n### The [FE\\_DGQHermite](classFE__DGQHermite.html) element\n\nThe element [FE\\_DGQHermite](classFE__DGQHermite.html) belongs to the family of [FE\\_DGQ](classFE__DGQ.html) elements, i.e., its shape functions are a tensor product of 1D polynomials and the element is fully discontinuous. As opposed to the nodal character in the usual [FE\\_DGQ](classFE__DGQ.html) element, the [FE\\_DGQHermite](classFE__DGQHermite.html) element is a mixture of nodal contributions and derivative contributions based on a Hermite-like concept. The underlying polynomial class is [Polynomials::HermiteLikeInterpolation](classPolynomials_1_1HermiteLikeInterpolation.html) and can be summarized as follows: For cubic polynomials, we use two polynomials to represent the function value and first derivative at the left end of the unit interval, \\(x=0\\), and two polynomials to represent the function value and first derivative and the right end of the unit interval, \\(x=1\\). At the opposite ends, both the value and first derivative of the shape functions are zero, ensuring that only two out of the four basis functions contribute to values and derivative on the respective end. However, we deviate from the classical Hermite interpolation in not strictly assigning one degree of freedom for the value and one for the first derivative, but rather allow the first derivative to be a linear combination of the first and the second shape function. This is done to improve the conditioning of the interpolation. Also, when going to degrees beyond three, we add node points in the element interior in a Lagrange-like fashion, combined with double zeros in the points \\(x=0\\) and \\(x=1\\). The position of these extra nodes is determined by the zeros of some Jacobi polynomials as explained in the description of the class [Polynomials::HermiteLikeInterpolation](classPolynomials_1_1HermiteLikeInterpolation.html).\n\nUsing this element, we only need to access \\(2(k+1)^{d-1}\\) degrees of freedom for computing both values and derivatives on a face. The check whether the Hermite property is fulfilled is done transparently inside [FEFaceEvaluation::gather\\_evaluate()](classFEFaceEvaluation.html#a4ac53fde2eab227ef45c7d29a5ed33fe) and [FEFaceEvaluation::integrate\\_scatter()](classFEFaceEvaluation.html#a21c3b33147e4abc2b0ae787b6510ec04) that check the type of the basis and reduce the access to data if possible. Obviously, this would not be possible if we had separated [FEFaceEvaluation::read\\_dof\\_values()](classFEEvaluationBase.html#aff4ac5c0f5afb445a2a5cf9a0715a2fe) from [FEFaceEvaluation::evaluate()](classFEFaceEvaluation.html#a92f84b8ad276ca9866f30c6f789cf3a4), because the amount of entries we need to read depends on the type of the derivative (only values, first derivative, etc.) and thus must be given to `read_dof_values()`.\n\nThis optimization is not only useful for computing the face integrals, but also for the MPI ghost layer exchange: In a naive exchange, we would need to send all degrees of freedom of a cell to another processor if the other processor is responsible for computing the face's contribution. Since we know that only some of the degrees of freedom in the evaluation with [FEFaceEvaluation](classFEFaceEvaluation.html) are touched, it is natural to only exchange the relevant ones. The [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) function has support for a selected data exchange when combined with [LinearAlgebra::distributed::Vector](classLinearAlgebra_1_1distributed_1_1Vector.html). To make this happen, we need to tell the loop what kind of evaluation on faces we are going to do, using an argument of type [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15), as can be seen in the implementation of `LaplaceOperator::vmult()` below. The way data is exchanged in that case is as follows: The ghost layer data in the vector still pretends to represent all degrees of freedom, such that [FEFaceEvaluation](classFEFaceEvaluation.html) can continue to read the values as if the cell were a locally owned one. The data exchange routines take care of the task for packing and unpacking the data into this format. While this sounds pretty complicated, we will show in the results section below that this really pays off by comparing the performance to a baseline code that does not specify the data access on faces.\n\n### An approximate block-Jacobi smoother using the fast diagonalization method\n\nIn the tradition of the [step-37](step_37.html) program, we again solve a Poisson problem with a geometric multigrid preconditioner inside a conjugate gradient solver. Instead of computing the diagonal and use the basic [PreconditionChebyshev](classPreconditionChebyshev.html) as a smoother, we choose a different strategy in this tutorial program. We implement a block-Jacobi preconditioner, where a block refers to all degrees of freedom on a cell. Rather than building the full cell matrix and applying its LU factorization (or inverse) in the preconditioner — an operation that would be heavily memory bandwidth bound and thus pretty slow — we approximate the inverse of the block by a special technique called fast diagonalization method.\n\nThe idea of the method is to take use of the structure of the cell matrix. In case of the Laplacian with constant coefficients discretized on a Cartesian mesh, the cell matrix \\(L\\) can be written as\n\n\\begin{align\\*}\nL &= A\\_1 \\otimes M\\_0 + M\\_1 \\otimes A\\_0\n\\end{align\\*}\n\nin 2D and\n\n\\begin{align\\*}\nL &= A\\_2 \\otimes M\\_1 \\otimes M\\_0 + M\\_2 \\otimes A\\_1 \\otimes M\\_0 + M\\_2 \\otimes M\\_1 \\otimes A\\_0\n\\end{align\\*}\n\nin 3D. The matrices \\(A\\_0\\) and \\(A\\_1\\) denote the 1D Laplace matrix (including the cell and face term associated to the current cell values \\(u^-\\_h\\) and \\(v^-\\_h\\)) and \\(M\\_0\\) and \\(M\\_1\\) are the mass matrices. Note that this simple tensor product structure is lost once there are non-constant coefficients on the cell or the geometry is not constant any more. We mention that a similar setup could also be used to replace the computed integrals with this final tensor product form of the matrices, which would cut the operations for the operator evaluation into less than half. However, given the fact that this only holds for Cartesian cells and constant coefficients, which is a pretty narrow case, we refrain from pursuing this idea.\n\nInterestingly, the exact inverse of the matrix \\(L\\) can be found through tensor products due to a method introduced by Lynch et al. [[149]](citelist.html#CITEREF_Lynch1964) in 1964,\n\n\\begin{align\\*}\nL^{-1} &= S\\_1 \\otimes S\\_0 (\\Lambda\\_1 \\otimes I + I \\otimes \\Lambda\\_0)^{-1}\nS\\_1^\\mathrm T \\otimes S\\_0^\\mathrm T,\n\\end{align\\*}\n\nwhere \\(S\\_d\\) is the matrix of eigenvectors to the generalized eigenvalue problem in the given tensor direction \\(d\\):\n\n\\begin{align\\*}\nA\\_d s &= \\lambda M\\_d s, \\quad d = 0, \\ldots,\\mathrm{dim-1},\n\\end{align\\*}\n\nand \\(\\Lambda\\_d\\) is the diagonal matrix representing the generalized eigenvalues \\(\\lambda\\). Note that the vectors \\(s\\) are such that they simultaneously diagonalize \\(A\\_d\\) and \\(M\\_d\\), i.e. \\(S\\_d^{\\mathrm T} A\\_d S\\_d =\n\\Lambda\\_d\\) and \\(S\\_d^{\\mathrm T} M\\_d S\\_d = I\\).\n\nThe deal.II library implements a class using this concept, called [TensorProductMatrixSymmetricSum](classTensorProductMatrixSymmetricSum.html).\n\nFor the sake of this program, we stick with constant coefficients and Cartesian meshes, even though an approximate version based on tensor products would still be possible for a more general mesh, and the operator evaluation itself is of course generic. Also, we do not bother with adaptive meshes where the multigrid algorithm would need to get access to flux matrices over the edges of different refinement, as explained in [step-39](step_39.html). One thing we do, however, is to still wrap our block-Jacobi preconditioner inside [PreconditionChebyshev](classPreconditionChebyshev.html). That class relieves us from finding an appropriate relaxation parameter (which would be around 0.7 in 2D and 0.5 in 3D for the block-Jacobi smoother), and often increases smoothing efficiency somewhat over plain Jacobi smoothing, especially when using several iterations.\n\nNote that the block-Jacobi smoother has an additional benefit: The fast diagonalization method can also be interpreted as a change from the Hermite-like polynomials underlying [FE\\_DGQHermite](classFE__DGQHermite.html) to a basis where the cell Laplacian is diagonal. Thus, it cancels the effect of the basis, and we get the same iteration counts irrespective of whether we use [FE\\_DGQHermite](classFE__DGQHermite.html) or [FE\\_DGQ](classFE__DGQ.html). This is in contrast to using the [PreconditionChebyshev](classPreconditionChebyshev.html) class with only the diagonal (a point-Jacobi scheme), where [FE\\_DGQ](classFE__DGQ.html) and [FE\\_DGQHermite](classFE__DGQHermite.html) do indeed behave differently and [FE\\_DGQ](classFE__DGQ.html) needs fewer iterations than [FE\\_DGQHermite](classFE__DGQHermite.html), despite the modification made to the Hermite-like shape functions to ensure a good conditioning.\n\nThe commented program\n=====================\n\nThe include files are essentially the same as in [step-37](step_37.html), with the exception of the finite element class [FE\\_DGQHermite](classFE__DGQHermite.html) instead of [FE\\_Q](classFE__Q.html). All functionality for matrix-free computations on face integrals is already contained in `fe_evaluation.h`.\n\n```\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/timer.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/la_parallel_vector.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/tensor_product_matrix.h>\n   \n   #include <deal.II/fe/fe_dgq.h>\n   #include <deal.II/fe/fe_tools.h>\n   #include <deal.II/fe/mapping_q1.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_tools.h>\n   \n   #include <deal.II/multigrid/multigrid.h>\n   #include <deal.II/multigrid/mg_transfer_matrix_free.h>\n   #include <deal.II/multigrid/mg_tools.h>\n   #include <deal.II/multigrid/mg_coarse.h>\n   #include <deal.II/multigrid/mg_smoother.h>\n   #include <deal.II/multigrid/mg_matrix.h>\n   \n   #include <deal.II/numerics/vector_tools.h>\n   \n   #include <deal.II/matrix_free/matrix_free.h>\n   #include <deal.II/matrix_free/fe_evaluation.h>\n   \n   #include <iostream>\n   #include <fstream>\n   \n   \n   namespace Step59\n   {\n     using namespace dealii;\n```\n\nAs in [step-37](step_37.html), we collect the dimension and polynomial degree as constants here at the top of the program for simplicity. As opposed to [step-37](step_37.html), we choose a really high order method this time with degree 8 where any implementation not using sum factorization would become prohibitively slow compared to the implementation with [MatrixFree](classMatrixFree.html) which provides an efficiency that is essentially the same as at degrees two or three. Furthermore, all classes in this tutorial program are templated, so it would be easy to select the degree at run time from an input file or a command-line argument by adding instantiations of the appropriate degrees in the `main()` function.\n\n```\n     const unsigned int degree_finite_element = 8;\n     const unsigned int dimension             = 3;\n```\n\n### Equation data\n\nIn analogy to [step-7](step_7.html), we define an analytic solution that we try to reproduce with our discretization. Since the aim of this tutorial is to show matrix-free methods, we choose one of the simplest possibilities, namely a cosine function whose derivatives are simple enough for us to compute analytically. Further down, the wave number 2.4 we select here will be matched with the domain extent in \\(x\\)-direction that is 2.5, such that we obtain a periodic solution at \\(x = 2.5\\) including \\(6pi\\) or three full wave revolutions in the cosine. The first function defines the solution and its gradient for expressing the analytic solution for the Dirichlet and Neumann boundary conditions, respectively. Furthermore, a class representing the negative Laplacian of the solution is used to represent the right hand side (forcing) function that we use to match the given analytic solution in the discretized version (manufactured solution).\n\n```\n     template <int dim>\n     class Solution : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim> &p,\n                            const unsigned int = 0) const override final\n       {\n         double val = 1.;\n         for (unsigned int d = 0; d < dim; ++d)\n           val *= std::cos(numbers::PI * 2.4 * p[d]);\n         return val;\n       }\n   \n       virtual Tensor<1, dim> gradient(const Point<dim> &p,\n                                       const unsigned int = 0) const override final\n       {\n         const double   arg = numbers::PI * 2.4;\n         Tensor<1, dim> grad;\n         for (unsigned int d = 0; d < dim; ++d)\n           {\n             grad[d] = 1.;\n             for (unsigned int e = 0; e < dim; ++e)\n               if (d == e)\n                 grad[d] *= -arg * std::sin(arg * p[e]);\n               else\n                 grad[d] *= std::cos(arg * p[e]);\n           }\n         return grad;\n       }\n     };\n   \n   \n   \n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim> &p,\n                            const unsigned int = 0) const override final\n       {\n         const double arg = numbers::PI * 2.4;\n         double       val = 1.;\n         for (unsigned int d = 0; d < dim; ++d)\n           val *= std::cos(arg * p[d]);\n         return dim * arg * arg * val;\n       }\n     };\n```\n\n### Matrix-free implementation\n\nThe `LaplaceOperator` class is similar to the respective class in [step-37](step_37.html). A significant difference is that we do not derive the class from [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html) because we want to present some additional features of [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) that are not available in the general-purpose class [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html). We derive the class from the [Subscriptor](classSubscriptor.html) class to be able to use the operator within the Chebyshev preconditioner because that preconditioner stores the underlying matrix via a [SmartPointer](classSmartPointer.html).\n\nGiven that we implement a complete matrix interface by hand, we need to add an `initialize()` function, an `m()` function, a `vmult()` function, and a `Tvmult()` function that were previously provided by [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html). Our LaplaceOperator also contains a member function `get_penalty_factor()` that centralizes the selection of the penalty parameter in the symmetric interior penalty method according to [step-39](step_39.html).\n\n```\n     template <int dim, int fe_degree, typename number>\n     class LaplaceOperator : public Subscriptor\n     {\n     public:\n       using value_type = number;\n   \n       LaplaceOperator() = default;\n   \n       void initialize(std::shared_ptr<const MatrixFree<dim, number>> data);\n   \n       void clear();\n   \n       types::global_dof_index m() const;\n   \n       void initialize_dof_vector(\n         LinearAlgebra::distributed::Vector<number> &vec) const;\n   \n       std::shared_ptr<const MatrixFree<dim, number>> get_matrix_free() const;\n   \n       void vmult(LinearAlgebra::distributed::Vector<number>       &dst,\n                  const LinearAlgebra::distributed::Vector<number> &src) const;\n   \n       void Tvmult(LinearAlgebra::distributed::Vector<number>       &dst,\n                   const LinearAlgebra::distributed::Vector<number> &src) const;\n   \n       number get_penalty_factor() const\n       {\n         return 1.0 * fe_degree * (fe_degree + 1);\n       }\n   \n     private:\n       void\n       apply_cell(const MatrixFree<dim, number>                    &data,\n                  LinearAlgebra::distributed::Vector<number>       &dst,\n                  const LinearAlgebra::distributed::Vector<number> &src,\n                  const std::pair<unsigned int, unsigned int> &cell_range) const;\n   \n       void\n       apply_face(const MatrixFree<dim, number>                    &data,\n                  LinearAlgebra::distributed::Vector<number>       &dst,\n                  const LinearAlgebra::distributed::Vector<number> &src,\n                  const std::pair<unsigned int, unsigned int> &face_range) const;\n   \n       void apply_boundary(\n         const MatrixFree<dim, number>                    &data,\n         LinearAlgebra::distributed::Vector<number>       &dst,\n         const LinearAlgebra::distributed::Vector<number> &src,\n         const std::pair<unsigned int, unsigned int>      &face_range) const;\n   \n       std::shared_ptr<const MatrixFree<dim, number>> data;\n     };\n```\n\nThe `PreconditionBlockJacobi` class defines our custom preconditioner for this problem. As opposed to [step-37](step_37.html) which was based on the matrix diagonal, we here compute an approximate inversion of the diagonal blocks in the discontinuous Galerkin method by using the so-called fast diagonalization method discussed in the introduction.\n\n```\n     template <int dim, int fe_degree, typename number>\n     class PreconditionBlockJacobi\n     {\n     public:\n       using value_type = number;\n   \n       void clear()\n       {\n         cell_matrices.clear();\n       }\n   \n       void initialize(const LaplaceOperator<dim, fe_degree, number> &op);\n   \n       void vmult(LinearAlgebra::distributed::Vector<number>       &dst,\n                  const LinearAlgebra::distributed::Vector<number> &src) const;\n   \n       void Tvmult(LinearAlgebra::distributed::Vector<number>       &dst,\n                   const LinearAlgebra::distributed::Vector<number> &src) const\n       {\n         vmult(dst, src);\n       }\n   \n     private:\n       std::shared_ptr<const MatrixFree<dim, number>> data;\n       std::vector<TensorProductMatrixSymmetricSum<dim,\n                                                   VectorizedArray<number>,\n                                                   fe_degree + 1>>\n         cell_matrices;\n     };\n```\n\nThis free-standing function is used in both the `LaplaceOperator` and `PreconditionBlockJacobi` classes to adjust the ghost range. This function is necessary because some of the vectors that the `vmult()` functions are supplied with are not initialized properly with `LaplaceOperator::initialize_dof_vector` that includes the correct layout of ghost entries, but instead comes from the [MGTransferMatrixFree](classMGTransferMatrixFree.html) class that has no notion on the ghost selection of the matrix-free classes. To avoid index confusion, we must adjust the ghost range before actually doing something with these vectors. Since the vectors are kept around in the multigrid smoother and transfer classes, a vector whose ghost range has once been adjusted will remain in this state throughout the lifetime of the object, so we can use a shortcut at the start of the function to see whether the partitioner object of the distributed vector, which is stored as a shared pointer, is the same as the layout expected by [MatrixFree](classMatrixFree.html), which is stored in a data structure accessed by MatrixFree::get\\_dof\\_info(0), where the 0 indicates the [DoFHandler](classDoFHandler.html) number from which this was extracted; we only use a single [DoFHandler](classDoFHandler.html) in [MatrixFree](classMatrixFree.html), so the only valid number is 0 here.\n\n```\n     template <int dim, typename number>\n     void adjust_ghost_range_if_necessary(\n       const MatrixFree<dim, number>                    &data,\n       const LinearAlgebra::distributed::Vector<number> &vec)\n     {\n       if (vec.get_partitioner().get() ==\n           data.get_dof_info(0).vector_partitioner.get())\n         return;\n   \n       LinearAlgebra::distributed::Vector<number> copy_vec(vec);\n       const_cast<LinearAlgebra::distributed::Vector<number> &>(vec).reinit(\n         data.get_dof_info(0).vector_partitioner);\n       const_cast<LinearAlgebra::distributed::Vector<number> &>(vec)\n         .copy_locally_owned_data_from(copy_vec);\n     }\n```\n\nThe next five functions to clear and initialize the `LaplaceOperator` class, to return the shared pointer holding the [MatrixFree](classMatrixFree.html) data container, as well as the correct initialization of the vector and operator sizes are the same as in [step-37](step_37.html) or rather [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html).\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::clear()\n     {\n       data.reset();\n     }\n   \n   \n   \n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::initialize(\n       std::shared_ptr<const MatrixFree<dim, number>> data)\n     {\n       this->data = data;\n     }\n   \n   \n   \n     template <int dim, int fe_degree, typename number>\n     std::shared_ptr<const MatrixFree<dim, number>>\n     LaplaceOperator<dim, fe_degree, number>::get_matrix_free() const\n     {\n       return data;\n     }\n   \n   \n   \n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::initialize_dof_vector(\n       LinearAlgebra::distributed::Vector<number> &vec) const\n     {\n       data->initialize_dof_vector(vec);\n     }\n   \n   \n   \n     template <int dim, int fe_degree, typename number>\n     types::global_dof_index LaplaceOperator<dim, fe_degree, number>::m() const\n     {\n       Assert(data.get() != nullptr, ExcNotInitialized());\n       return data->get_dof_handler().n_dofs();\n     }\n```\n\nThis function implements the action of the LaplaceOperator on a vector `src` and stores the result in the vector `dst`. When compared to [step-37](step_37.html), there are four new features present in this call.\n\nThe first new feature is the `adjust_ghost_range_if_necessary` function mentioned above that is needed to fit the vectors to the layout expected by [FEEvaluation](classFEEvaluation.html) and [FEFaceEvaluation](classFEFaceEvaluation.html) in the cell and face functions.\n\nThe second new feature is the fact that we do not implement a `vmult_add()` function as we did in [step-37](step_37.html) (through the virtual function [MatrixFreeOperators::Base::vmult\\_add()](classMatrixFreeOperators_1_1Base.html#a1e60046e128b7bf9a8f8c6d12fca25d5)), but directly implement a `vmult()` functionality. Since both cell and face integrals will sum into the destination vector, we must of course zero the vector somewhere. For DG elements, we are given two options – one is to use [FEEvaluation::set\\_dof\\_values()](classFEEvaluationBase.html#aea17b9ce958683ef4a01401d2cc9fcfd) instead of [FEEvaluation::distribute\\_local\\_to\\_global()](classFEEvaluationBase.html#a4aaf3e9004fbaf810655f4e0962a015e) in the `apply_cell` function below. This works because the loop layout in [MatrixFree](classMatrixFree.html) is such that cell integrals always touch a given vector entry before the face integrals. However, this really only works for fully discontinuous bases where every cell has its own degrees of freedom, without any sharing with neighboring results. An alternative setup, the one chosen here, is to let the [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) take care of zeroing the vector. This can be thought of as simply calling `dst = 0;` somewhere in the code. The implementation is more involved for supported vectors such as `LinearAlgebra::distributed::Vector`, because we aim to not zero the whole vector at once. Doing the zero operation on a small enough pieces of a few thousands of vector entries has the advantage that the vector entries that get zeroed remain in caches before they are accessed again in [FEEvaluation::distribute\\_local\\_to\\_global()](classFEEvaluationBase.html#a4aaf3e9004fbaf810655f4e0962a015e) and [FEFaceEvaluation::distribute\\_local\\_to\\_global()](classFEEvaluationBase.html#a4aaf3e9004fbaf810655f4e0962a015e). Since matrix-free operator evaluation is really fast, just zeroing a large vector can amount to up to a 25% of the operator evaluation time, and we obviously want to avoid this cost. This option of zeroing the vector is also available for [MatrixFree::cell\\_loop](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) and for continuous bases, even though it was not used in the [step-37](step_37.html) or [step-48](step_48.html) tutorial programs.\n\nThe third new feature is the way we provide the functions to compute on cells, inner faces, and boundary faces: The class [MatrixFree](classMatrixFree.html) has a function called `loop` that takes three function pointers to the three cases, allowing to separate the implementations of different things. As explained in [step-37](step_37.html), these function pointers can be `std::function` objects or member functions of a class. In this case, we use pointers to member functions.\n\nThe final new feature are the last two arguments of type [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15) that can be given to [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf). This class passes the type of data access for face integrals to the MPI data exchange routines [LinearAlgebra::distributed::Vector::update\\_ghost\\_values()](classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878) and [LinearAlgebra::distributed::Vector::compress()](classLinearAlgebra_1_1distributed_1_1Vector.html#a7109b4722d532dbca2ad52f953d22c40) of the parallel vectors. The purpose is to not send all degrees of freedom of a neighboring element, but to reduce the amount of data to what is really needed for the computations at hand. The data exchange is a real bottleneck in particular for high-degree DG methods, therefore a more restrictive way of exchange is often beneficial. The enum field [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15) can take the value `none`, which means that no face integrals at all are done, which would be analogous to [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7), the value `values` meaning that only shape function values (but no derivatives) are used on faces, and the value `gradients` when also first derivatives on faces are accessed besides the values. A value `unspecified` means that all degrees of freedom will be exchanged for the faces that are located at the processor boundaries and designated to be worked on at the local processor.\n\nTo see how the data can be reduced, think of the case of the nodal element [FE\\_DGQ](classFE__DGQ.html) with node points on the element surface, where only \\((k+1)^{d-1}\\) degrees of freedom contribute to the values on a face for polynomial degree \\(k\\) in \\(d\\) space dimensions, out of the \\((k+1)^d\\) degrees of freedom of a cell. A similar reduction is also possible for the interior penalty method that evaluates values and first derivatives on the faces. When using a Hermite-like basis in 1d, only up to two basis functions contribute to the value and derivative. The class [FE\\_DGQHermite](classFE__DGQHermite.html) implements a tensor product of this concept, as discussed in the introduction. Thus, only \\(2(k+1)^{d-1}\\) degrees of freedom must be exchanged for each face, which is a clear win once \\(k\\) gets larger than four or five. Note that this reduced exchange of [FE\\_DGQHermite](classFE__DGQHermite.html) is valid also on meshes with curved boundaries, as the derivatives are taken on the reference element, whereas the geometry only mixes them on the inside. Thus, this is different from the attempt to obtain \\(C^1\\) continuity with continuous Hermite-type shape functions where the non-Cartesian case changes the picture significantly. Obviously, on non-Cartesian meshes the derivatives also include tangential derivatives of shape functions beyond the normal derivative, but those only need the function values on the element surface, too. Should the element not provide any compression, the loop automatically exchanges all entries for the affected cells.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::vmult(\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src) const\n     {\n       adjust_ghost_range_if_necessary(*data, dst);\n       adjust_ghost_range_if_necessary(*data, src);\n       data->loop(&LaplaceOperator::apply_cell,\n                  &LaplaceOperator::apply_face,\n                  &LaplaceOperator::apply_boundary,\n                  this,\n                  dst,\n                  src,\n                  /*zero_dst =*/true,\n                  MatrixFree<dim, number>::DataAccessOnFaces::gradients,\n                  MatrixFree<dim, number>::DataAccessOnFaces::gradients);\n     }\n```\n\nSince the Laplacian is symmetric, the `Tvmult()` (needed by the multigrid smoother interfaces) operation is simply forwarded to the `vmult()` case.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::Tvmult(\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src) const\n     {\n       vmult(dst, src);\n     }\n```\n\nThe cell operation is very similar to [step-37](step_37.html). We do not use a coefficient here, though. The second difference is that we replaced the two steps of [FEEvaluation::read\\_dof\\_values()](classFEEvaluationBase.html#aff4ac5c0f5afb445a2a5cf9a0715a2fe) followed by [FEEvaluation::evaluate()](classFEEvaluation.html#a710c252e9dccc0c4ce07044cac3bdd9b) by a single function call [FEEvaluation::gather\\_evaluate()](classFEEvaluation.html#ab53d5c08f460cfe6c9830ac14a427115) which internally calls the sequence of the two individual methods. Likewise, [FEEvaluation::integrate\\_scatter()](classFEEvaluation.html#a52265fb3ecb2b63388e1708ef395418f) implements the sequence of [FEEvaluation::integrate()](classFEEvaluation.html#ad61cbe0d7d6138be040d46ae06a268f1) followed by [FEEvaluation::distribute\\_local\\_to\\_global()](classFEEvaluationBase.html#a4aaf3e9004fbaf810655f4e0962a015e). In this case, these new functions merely save two lines of code. However, we use them for the analogy with [FEFaceEvaluation](classFEFaceEvaluation.html) where they are more important as explained below.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::apply_cell(\n       const MatrixFree<dim, number>                    &data,\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src,\n       const std::pair<unsigned int, unsigned int>      &cell_range) const\n     {\n       FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(data);\n       for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n         {\n           phi.reinit(cell);\n           phi.gather_evaluate(src, EvaluationFlags::gradients);\n           for (const unsigned int q : phi.quadrature_point_indices())\n             phi.submit_gradient(phi.get_gradient(q), q);\n           phi.integrate_scatter(EvaluationFlags::gradients, dst);\n         }\n     }\n```\n\nThe face operation implements the terms of the interior penalty method in analogy to [step-39](step_39.html), as explained in the introduction. We need two evaluator objects for this task, one for handling the solution that comes from the cell on one of the two sides of an interior face, and one for handling the solution from the other side. The evaluators for face integrals are called [FEFaceEvaluation](classFEFaceEvaluation.html) and take a boolean argument in the second slot of the constructor to indicate which of the two sides the evaluator should belong two. In [FEFaceEvaluation](classFEFaceEvaluation.html) and [MatrixFree](classMatrixFree.html), we call one of the two sides the `interior` one and the other the `exterior` one. The name `exterior` refers to the fact that the evaluator from both sides will return the same normal vector. For the `interior` side, the normal vector points outwards, whereas it points inwards on the other side, and is opposed to the outer normal vector of that cell. Apart from the new class name, we again get a range of items to work with in analogy to what was discussed in [step-37](step_37.html), but for the interior faces in this case. Note that the data structure of [MatrixFree](classMatrixFree.html) forms batches of faces that are analogous to the batches of cells for the cell integrals. All faces within a batch involve different cell numbers but have the face number within the reference cell, have the same refinement configuration (no refinement or the same subface), and the same orientation, to keep SIMD operations simple and efficient.\n\nNote that there is no implied meaning in interior versus exterior except the logic decision of the orientation of the normal, which is pretty random internally. One can in no way rely on a certain pattern of assigning interior versus exterior flags, as the decision is made for the sake of access regularity and uniformity in the [MatrixFree](classMatrixFree.html) setup routines. Since most sane DG methods are conservative, i.e., fluxes look the same from both sides of an interface, the mathematics are unaltered if the interior/exterior flags are switched and normal vectors get the opposite sign.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::apply_face(\n       const MatrixFree<dim, number>                    &data,\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src,\n       const std::pair<unsigned int, unsigned int>      &face_range) const\n     {\n       FEFaceEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi_inner(data,\n                                                                            true);\n       FEFaceEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi_outer(data,\n                                                                            false);\n       for (unsigned int face = face_range.first; face < face_range.second; ++face)\n         {\n```\n\nOn a given batch of faces, we first update the pointers to the current face and then access the vector. As mentioned above, we combine the vector access with the evaluation. In the case of face integrals, the data access into the vector can be reduced for the special case of an [FE\\_DGQHermite](classFE__DGQHermite.html) basis as explained for the data exchange above: Since only \\(2(k+1)^{d-1}\\) out of the \\((k+1)^d\\) cell degrees of freedom get multiplied by a non-zero value or derivative of a shape function, this structure can be utilized for the evaluation, significantly reducing the data access. The reduction of the data access is not only beneficial because it reduces the data in flight and thus helps caching, but also because the data access to faces is often more irregular than for cell integrals when gathering values from cells that are farther apart in the index list of cells.\n\n```\n           phi_inner.reinit(face);\n           phi_inner.gather_evaluate(src,\n                                     EvaluationFlags::values |\n                                       EvaluationFlags::gradients);\n           phi_outer.reinit(face);\n           phi_outer.gather_evaluate(src,\n                                     EvaluationFlags::values |\n                                       EvaluationFlags::gradients);\n```\n\nThe next two statements compute the penalty parameter for the interior penalty method. As explained in the introduction, we would like to have a scaling like \\(\\frac{1}{h\\_\\text{i}}\\) of the length \\(h\\_\\text{i}\\) normal to the face. For a general non-Cartesian mesh, this length must be computed by the product of the inverse Jacobian times the normal vector in real coordinates. From this vector of `dim` components, we must finally pick the component that is oriented normal to the reference cell. In the geometry data stored in [MatrixFree](classMatrixFree.html), a permutation of the components in the Jacobian is applied such that this latter direction is always the last component `dim-1` (this is beneficial because reference-cell derivative sorting can be made agnostic of the direction of the face). This means that we can simply access the last entry `dim-1` and must not look up the local face number in `data.get_face_info(face).interior_face_no` and `data.get_face_info(face).exterior_face_no`. Finally, we must also take the absolute value of these factors as the normal could point into either positive or negative direction.\n\n```\n           const VectorizedArray<number> inverse_length_normal_to_face =\n             0.5 * (std::abs((phi_inner.normal_vector(0) *\n                              phi_inner.inverse_jacobian(0))[dim - 1]) +\n                    std::abs((phi_outer.normal_vector(0) *\n                              phi_outer.inverse_jacobian(0))[dim - 1]));\n           const VectorizedArray<number> sigma =\n             inverse_length_normal_to_face * get_penalty_factor();\n```\n\nIn the loop over the quadrature points, we eventually compute all contributions to the interior penalty scheme. According to the formulas in the introduction, the value of the test function gets multiplied by the difference of the jump in the solution times the penalty parameter and the average of the normal derivative in real space. Since the two evaluators for interior and exterior sides get different signs due to the jump, we pass the result with a different sign here. The normal derivative of the test function gets multiplied by the negative jump in the solution between the interior and exterior side. This term, coined adjoint consistency term, must also include the factor of \\(\\frac{1}{2}\\) in the code in accordance with its relation to the primal consistency term that gets the factor of one half due to the average in the test function slot.\n\n```\n           for (const unsigned int q : phi_inner.quadrature_point_indices())\n             {\n               const VectorizedArray<number> solution_jump =\n                 (phi_inner.get_value(q) - phi_outer.get_value(q));\n               const VectorizedArray<number> average_normal_derivative =\n                 (phi_inner.get_normal_derivative(q) +\n                  phi_outer.get_normal_derivative(q)) *\n                 number(0.5);\n               const VectorizedArray<number> test_by_value =\n                 solution_jump * sigma - average_normal_derivative;\n   \n               phi_inner.submit_value(test_by_value, q);\n               phi_outer.submit_value(-test_by_value, q);\n   \n               phi_inner.submit_normal_derivative(-solution_jump * number(0.5), q);\n               phi_outer.submit_normal_derivative(-solution_jump * number(0.5), q);\n             }\n```\n\nOnce we are done with the loop over quadrature points, we can do the sum factorization operations for the integration loops on faces and sum the results into the result vector, using the `integrate_scatter` function. The name `scatter` reflects the distribution of the vector data into scattered positions in the vector using the same pattern as in `gather_evaluate`. Like before, the combined integrate + write operation allows us to reduce the data access.\n\n```\n           phi_inner.integrate_scatter(EvaluationFlags::values |\n                                         EvaluationFlags::gradients,\n                                       dst);\n           phi_outer.integrate_scatter(EvaluationFlags::values |\n                                         EvaluationFlags::gradients,\n                                       dst);\n         }\n     }\n```\n\nThe boundary face function follows by and large the interior face function. The only difference is the fact that we do not have a separate [FEFaceEvaluation](classFEFaceEvaluation.html) object that provides us with exterior values \\(u^+\\), but we must define them from the boundary conditions and interior values \\(u^-\\). As explained in the introduction, we use \\(u^+ = -u^- + 2\ng\\_\\text{D}\\) and \\(\\mathbf{n}^-\\cdot \\nabla u^+ = \\mathbf{n}^-\\cdot \\nabla\nu^-\\) on Dirichlet boundaries and \\(u^+=u^-\\) and \\(\\mathbf{n}^-\\cdot \\nabla\nu^+ = -\\mathbf{n}^-\\cdot \\nabla u^- + 2 g\\_\\text{N}\\) on Neumann boundaries. Since this operation implements the homogeneous part, i.e., the matrix-vector product, we must neglect the boundary functions \\(g\\_\\text{D}\\) and \\(g\\_\\text{N}\\) here, and added them to the right hand side in `LaplaceProblem::compute_rhs()`. Note that due to extension of the solution \\(u^-\\) to the exterior via \\(u^+\\), we can keep all factors \\(0.5\\) the same as in the inner face function, see also the discussion in [step-39](step_39.html).\n\nThere is one catch at this point: The implementation below uses a boolean variable `is_dirichlet` to switch between the Dirichlet and the Neumann cases. However, we solve a problem where we also want to impose periodic boundary conditions on some boundaries, namely along those in the \\(x\\) direction. One might wonder how those conditions should be handled here. The answer is that [MatrixFree](classMatrixFree.html) automatically treats periodic boundaries as what they are technically, namely an inner face where the solution values of two adjacent cells meet and must be treated by proper numerical fluxes. Thus, all the faces on the periodic boundaries will appear in the `apply_face()` function and not in this one.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void LaplaceOperator<dim, fe_degree, number>::apply_boundary(\n       const MatrixFree<dim, number>                    &data,\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src,\n       const std::pair<unsigned int, unsigned int>      &face_range) const\n     {\n       FEFaceEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi_inner(data,\n                                                                            true);\n       for (unsigned int face = face_range.first; face < face_range.second; ++face)\n         {\n           phi_inner.reinit(face);\n           phi_inner.gather_evaluate(src,\n                                     EvaluationFlags::values |\n                                       EvaluationFlags::gradients);\n   \n           const VectorizedArray<number> inverse_length_normal_to_face = std::abs((\n             phi_inner.normal_vector(0) * phi_inner.inverse_jacobian(0))[dim - 1]);\n           const VectorizedArray<number> sigma =\n             inverse_length_normal_to_face * get_penalty_factor();\n   \n           const bool is_dirichlet = (data.get_boundary_id(face) == 0);\n   \n           for (const unsigned int q : phi_inner.quadrature_point_indices())\n             {\n               const VectorizedArray<number> u_inner = phi_inner.get_value(q);\n               const VectorizedArray<number> u_outer =\n                 is_dirichlet ? -u_inner : u_inner;\n               const VectorizedArray<number> normal_derivative_inner =\n                 phi_inner.get_normal_derivative(q);\n               const VectorizedArray<number> normal_derivative_outer =\n                 is_dirichlet ? normal_derivative_inner : -normal_derivative_inner;\n               const VectorizedArray<number> solution_jump = (u_inner - u_outer);\n               const VectorizedArray<number> average_normal_derivative =\n                 (normal_derivative_inner + normal_derivative_outer) * number(0.5);\n               const VectorizedArray<number> test_by_value =\n                 solution_jump * sigma - average_normal_derivative;\n               phi_inner.submit_normal_derivative(-solution_jump * number(0.5), q);\n               phi_inner.submit_value(test_by_value, q);\n             }\n           phi_inner.integrate_scatter(EvaluationFlags::values |\n                                         EvaluationFlags::gradients,\n                                       dst);\n         }\n     }\n```\n\nNext we turn to the preconditioner initialization. As explained in the introduction, we want to construct an (approximate) inverse of the cell matrices from a product of 1d mass and Laplace matrices. Our first task is to compute the 1d matrices, which we do by first creating a 1d finite element. Instead of anticipating FE\\_DGQHermite<1> here, we get the finite element's name from [DoFHandler](classDoFHandler.html), replace the `dim` argument (2 or 3) by 1 to create a 1d name, and construct the 1d element by using [FETools](namespaceFETools.html).\n\n```\n     template <int dim, int fe_degree, typename number>\n     void PreconditionBlockJacobi<dim, fe_degree, number>::initialize(\n       const LaplaceOperator<dim, fe_degree, number> &op)\n     {\n       data = op.get_matrix_free();\n   \n       std::string name = data->get_dof_handler().get_fe().get_name();\n       name.replace(name.find('<') + 1, 1, \"1\");\n       std::unique_ptr<FiniteElement<1>> fe_1d = FETools::get_fe_by_name<1>(name);\n```\n\nAs for computing the 1d matrices on the unit element, we simply write down what a typical assembly procedure over rows and columns of the matrix as well as the quadrature points would do. We select the same Laplace matrices once and for all using the coefficients 0.5 for interior faces (but possibly scaled differently in different directions as a result of the mesh). Thus, we make a slight mistake at the Dirichlet boundary (where the correct factor would be 1 for the derivative terms and 2 for the penalty term, see [step-39](step_39.html)) or at the Neumann boundary where the factor should be zero. Since we only use this class as a smoother inside a multigrid scheme, this error is not going to have any significant effect and merely affects smoothing quality.\n\n```\n       const unsigned int                                 N = fe_degree + 1;\n       FullMatrix<double>                                 laplace_unscaled(N, N);\n       std::array<Table<2, VectorizedArray<number>>, dim> mass_matrices;\n       std::array<Table<2, VectorizedArray<number>>, dim> laplace_matrices;\n       for (unsigned int d = 0; d < dim; ++d)\n         {\n           mass_matrices[d].reinit(N, N);\n           laplace_matrices[d].reinit(N, N);\n         }\n   \n       const QGauss<1> quadrature(N);\n       for (unsigned int i = 0; i < N; ++i)\n         for (unsigned int j = 0; j < N; ++j)\n           {\n             double sum_mass = 0, sum_laplace = 0;\n             for (unsigned int q = 0; q < quadrature.size(); ++q)\n               {\n                 sum_mass += (fe_1d->shape_value(i, quadrature.point(q)) *\n                              fe_1d->shape_value(j, quadrature.point(q))) *\n                             quadrature.weight(q);\n                 sum_laplace += (fe_1d->shape_grad(i, quadrature.point(q))[0] *\n                                 fe_1d->shape_grad(j, quadrature.point(q))[0]) *\n                                quadrature.weight(q);\n               }\n             for (unsigned int d = 0; d < dim; ++d)\n               mass_matrices[d](i, j) = sum_mass;\n```\n\nThe left and right boundary terms assembled by the next two statements appear to have somewhat arbitrary signs, but those are correct as can be verified by looking at [step-39](step_39.html) and inserting the value -1 and 1 for the normal vector in the 1d case.\n\n```\n             sum_laplace +=\n               (1. * fe_1d->shape_value(i, Point<1>()) *\n                  fe_1d->shape_value(j, Point<1>()) * op.get_penalty_factor() +\n                0.5 * fe_1d->shape_grad(i, Point<1>())[0] *\n                  fe_1d->shape_value(j, Point<1>()) +\n                0.5 * fe_1d->shape_grad(j, Point<1>())[0] *\n                  fe_1d->shape_value(i, Point<1>()));\n   \n             sum_laplace +=\n               (1. * fe_1d->shape_value(i, Point<1>(1.0)) *\n                  fe_1d->shape_value(j, Point<1>(1.0)) * op.get_penalty_factor() -\n                0.5 * fe_1d->shape_grad(i, Point<1>(1.0))[0] *\n                  fe_1d->shape_value(j, Point<1>(1.0)) -\n                0.5 * fe_1d->shape_grad(j, Point<1>(1.0))[0] *\n                  fe_1d->shape_value(i, Point<1>(1.0)));\n   \n             laplace_unscaled(i, j) = sum_laplace;\n           }\n```\n\nNext, we go through the cells and pass the scaled matrices to [TensorProductMatrixSymmetricSum](classTensorProductMatrixSymmetricSum.html) to actually compute the generalized eigenvalue problem for representing the inverse: Since the matrix approximation is constructed as \\(A\\otimes M + M\\otimes A\\) and the weights are constant for each element, we can apply all weights on the Laplace matrix and simply keep the mass matrices unscaled. In the loop over cells, we want to make use of the geometry compression provided by the [MatrixFree](classMatrixFree.html) class and check if the current geometry is the same as on the last cell batch, in which case there is nothing to do. This compression can be accessed by [FEEvaluation::get\\_mapping\\_data\\_index\\_offset()](classFEEvaluationData.html#a5ede471687176952195e63708cf699ca) once `reinit()` has been called.\n\nOnce we have accessed the inverse Jacobian through the [FEEvaluation](classFEEvaluation.html) access function (we take the one for the zeroth quadrature point as they should be the same on all quadrature points for a Cartesian cell), we check that it is diagonal and then extract the determinant of the original Jacobian, i.e., the inverse of the determinant of the inverse Jacobian, and set the weight as \\(\\text{det}(J) / h\\_d^2\\) according to the 1d Laplacian times \\(d-1\\) copies of the [mass matrix](DEALGlossary.html#GlossMassMatrix).\n\n```\n       cell_matrices.clear();\n       FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*data);\n       unsigned int old_mapping_data_index = numbers::invalid_unsigned_int;\n       for (unsigned int cell = 0; cell < data->n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n   \n           if (phi.get_mapping_data_index_offset() == old_mapping_data_index)\n             continue;\n   \n           Tensor<2, dim, VectorizedArray<number>> inverse_jacobian =\n             phi.inverse_jacobian(0);\n   \n           for (unsigned int d = 0; d < dim; ++d)\n             for (unsigned int e = 0; e < dim; ++e)\n               if (d != e)\n                 for (unsigned int v = 0; v < VectorizedArray<number>::size(); ++v)\n                   AssertThrow(inverse_jacobian[d][e][v] == 0.,\n                               ExcNotImplemented());\n   \n           VectorizedArray<number> jacobian_determinant = inverse_jacobian[0][0];\n           for (unsigned int e = 1; e < dim; ++e)\n             jacobian_determinant *= inverse_jacobian[e][e];\n           jacobian_determinant = 1. / jacobian_determinant;\n   \n           for (unsigned int d = 0; d < dim; ++d)\n             {\n               const VectorizedArray<number> scaling_factor =\n                 inverse_jacobian[d][d] * inverse_jacobian[d][d] *\n                 jacobian_determinant;\n```\n\nOnce we know the factor by which we should scale the Laplace matrix, we apply this weight to the unscaled DG Laplace matrix and send the array to the class [TensorProductMatrixSymmetricSum](classTensorProductMatrixSymmetricSum.html) for computing the generalized eigenvalue problem mentioned in the introduction.\n\n```\n               for (unsigned int i = 0; i < N; ++i)\n                 for (unsigned int j = 0; j < N; ++j)\n                   laplace_matrices[d](i, j) =\n                     scaling_factor * laplace_unscaled(i, j);\n             }\n           if (cell_matrices.size() <= phi.get_mapping_data_index_offset())\n             cell_matrices.resize(phi.get_mapping_data_index_offset() + 1);\n           cell_matrices[phi.get_mapping_data_index_offset()].reinit(\n             mass_matrices, laplace_matrices);\n         }\n     }\n```\n\nThe vmult function for the approximate block-Jacobi preconditioner is very simple in the DG context: We simply need to read the values of the current cell batch, apply the inverse for the given entry in the array of tensor product matrix, and write the result back. In this loop, we overwrite the content in `dst` rather than first setting the entries to zero. This is legitimate for a DG method because every cell has independent degrees of freedom. Furthermore, we manually write out the loop over all cell batches, rather than going through [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7). We do this because we know that we are not going to need data exchange over the MPI network here as all computations are done on the cells held locally on each processor.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void PreconditionBlockJacobi<dim, fe_degree, number>::vmult(\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src) const\n     {\n       adjust_ghost_range_if_necessary(*data, dst);\n       adjust_ghost_range_if_necessary(*data, src);\n   \n       FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*data);\n       for (unsigned int cell = 0; cell < data->n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n           phi.read_dof_values(src);\n           cell_matrices[phi.get_mapping_data_index_offset()].apply_inverse(\n             ArrayView<VectorizedArray<number>>(phi.begin_dof_values(),\n                                                phi.dofs_per_cell),\n             ArrayView<const VectorizedArray<number>>(phi.begin_dof_values(),\n                                                      phi.dofs_per_cell));\n           phi.set_dof_values(dst);\n         }\n     }\n```\n\nThe definition of the LaplaceProblem class is very similar to [step-37](step_37.html). One difference is the fact that we add the element degree as a template argument to the class, which would allow us to more easily include more than one degree in the same program by creating different instances in the `main()` function. The second difference is the selection of the element, [FE\\_DGQHermite](classFE__DGQHermite.html), which is specialized for this kind of equations.\n\n```\n     template <int dim, int fe_degree>\n     class LaplaceProblem\n     {\n     public:\n       LaplaceProblem();\n       void run();\n   \n     private:\n       void setup_system();\n       void compute_rhs();\n       void solve();\n       void analyze_results() const;\n   \n   #ifdef DEAL_II_WITH_P4EST\n       parallel::distributed::Triangulation<dim> triangulation;\n   #else\n       Triangulation<dim> triangulation;\n   #endif\n   \n       const FE_DGQHermite<dim> fe;\n       DoFHandler<dim>          dof_handler;\n   \n       MappingQ1<dim> mapping;\n   \n       using SystemMatrixType = LaplaceOperator<dim, fe_degree, double>;\n       SystemMatrixType system_matrix;\n   \n       using LevelMatrixType = LaplaceOperator<dim, fe_degree, float>;\n       MGLevelObject<LevelMatrixType> mg_matrices;\n   \n       LinearAlgebra::distributed::Vector<double> solution;\n       LinearAlgebra::distributed::Vector<double> system_rhs;\n   \n       double             setup_time;\n       ConditionalOStream pcout;\n       ConditionalOStream time_details;\n     };\n   \n   \n   \n     template <int dim, int fe_degree>\n     LaplaceProblem<dim, fe_degree>::LaplaceProblem()\n   #ifdef DEAL_II_WITH_P4EST\n       : triangulation(MPI_COMM_WORLD,\n                       Triangulation<dim>::limit_level_difference_at_vertices,\n                       parallel::distributed::Triangulation<\n                         dim>::construct_multigrid_hierarchy)\n   #else\n       : triangulation(Triangulation<dim>::limit_level_difference_at_vertices)\n   #endif\n       , fe(fe_degree)\n       , dof_handler(triangulation)\n       , setup_time(0.)\n       , pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n       , time_details(std::cout,\n                      false &&\n                        Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n     {}\n```\n\nThe setup function differs in two aspects from [step-37](step_37.html). The first is that we do not need to interpolate any constraints for the discontinuous ansatz space, and simply pass a dummy [AffineConstraints](classAffineConstraints.html) object into Matrixfree::reinit(). The second change arises because we need to tell [MatrixFree](classMatrixFree.html) to also initialize the data structures for faces. We do this by setting update flags for the inner and boundary faces, respectively. On the boundary faces, we need both the function values, their gradients, JxW values (for integration), the normal vectors, and quadrature points (for the evaluation of the boundary conditions), whereas we only need shape function values, gradients, JxW values, and normal vectors for interior faces. The face data structures in [MatrixFree](classMatrixFree.html) are always built as soon as one of `mapping_update_flags_inner_faces` or `mapping_update_flags_boundary_faces` are different from the default value `update_default` of UpdateFlags.\n\n```\n     template <int dim, int fe_degree>\n     void LaplaceProblem<dim, fe_degree>::setup_system()\n     {\n       Timer time;\n       setup_time = 0;\n   \n       system_matrix.clear();\n       mg_matrices.clear_elements();\n   \n       dof_handler.distribute_dofs(fe);\n       dof_handler.distribute_mg_dofs();\n   \n       pcout << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n             << std::endl;\n   \n       setup_time += time.wall_time();\n       time_details << \"Distribute DoFs               \" << time.wall_time() << \" s\"\n                    << std::endl;\n       time.restart();\n   \n       AffineConstraints<double> dummy;\n       dummy.close();\n   \n       {\n         typename MatrixFree<dim, double>::AdditionalData additional_data;\n         additional_data.tasks_parallel_scheme =\n           MatrixFree<dim, double>::AdditionalData::none;\n         additional_data.mapping_update_flags =\n           (update_gradients | update_JxW_values | update_quadrature_points);\n         additional_data.mapping_update_flags_inner_faces =\n           (update_gradients | update_JxW_values | update_normal_vectors);\n         additional_data.mapping_update_flags_boundary_faces =\n           (update_gradients | update_JxW_values | update_normal_vectors |\n            update_quadrature_points);\n         const auto system_mf_storage =\n           std::make_shared<MatrixFree<dim, double>>();\n         system_mf_storage->reinit(\n           mapping, dof_handler, dummy, QGauss<1>(fe.degree + 1), additional_data);\n         system_matrix.initialize(system_mf_storage);\n       }\n   \n       system_matrix.initialize_dof_vector(solution);\n       system_matrix.initialize_dof_vector(system_rhs);\n   \n       setup_time += time.wall_time();\n       time_details << \"Setup matrix-free system      \" << time.wall_time() << \" s\"\n                    << std::endl;\n       time.restart();\n   \n       const unsigned int nlevels = triangulation.n_global_levels();\n       mg_matrices.resize(0, nlevels - 1);\n   \n       for (unsigned int level = 0; level < nlevels; ++level)\n         {\n           typename MatrixFree<dim, float>::AdditionalData additional_data;\n           additional_data.tasks_parallel_scheme =\n             MatrixFree<dim, float>::AdditionalData::none;\n           additional_data.mapping_update_flags =\n             (update_gradients | update_JxW_values);\n           additional_data.mapping_update_flags_inner_faces =\n             (update_gradients | update_JxW_values);\n           additional_data.mapping_update_flags_boundary_faces =\n             (update_gradients | update_JxW_values);\n           additional_data.mg_level = level;\n           const auto mg_mf_storage_level =\n             std::make_shared<MatrixFree<dim, float>>();\n           mg_mf_storage_level->reinit(mapping,\n                                       dof_handler,\n                                       dummy,\n                                       QGauss<1>(fe.degree + 1),\n                                       additional_data);\n   \n           mg_matrices[level].initialize(mg_mf_storage_level);\n         }\n       setup_time += time.wall_time();\n       time_details << \"Setup matrix-free levels      \" << time.wall_time() << \" s\"\n                    << std::endl;\n     }\n```\n\nThe computation of the right hand side is a bit more complicated than in [step-37](step_37.html). The cell term now consists of the negative Laplacian of the analytical solution, `RightHandSide`, for which we need to first split up the [Point](classPoint.html) of [VectorizedArray](classVectorizedArray.html) fields, i.e., a batch of points, into a single point by evaluating all lanes in the [VectorizedArray](classVectorizedArray.html) separately. Remember that the number of lanes depends on the hardware; it could be 1 for systems that do not offer vectorization (or where deal.II does not have intrinsics), but it could also be 8 or 16 on AVX-512 of recent Intel architectures.\n\n```\n     template <int dim, int fe_degree>\n     void LaplaceProblem<dim, fe_degree>::compute_rhs()\n     {\n       Timer time;\n       system_rhs                          = 0;\n       const MatrixFree<dim, double> &data = *system_matrix.get_matrix_free();\n       FEEvaluation<dim, fe_degree>   phi(data);\n       RightHandSide<dim>             rhs_func;\n       Solution<dim>                  exact_solution;\n       for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               VectorizedArray<double> rhs_val = VectorizedArray<double>();\n               Point<dim, VectorizedArray<double>> point_batch =\n                 phi.quadrature_point(q);\n               for (unsigned int v = 0; v < VectorizedArray<double>::size(); ++v)\n                 {\n                   Point<dim> single_point;\n                   for (unsigned int d = 0; d < dim; ++d)\n                     single_point[d] = point_batch[d][v];\n                   rhs_val[v] = rhs_func.value(single_point);\n                 }\n               phi.submit_value(rhs_val, q);\n             }\n           phi.integrate_scatter(EvaluationFlags::values, system_rhs);\n         }\n```\n\nSecondly, we also need to apply the Dirichlet and Neumann boundary conditions. This function is the missing part of to the function `LaplaceOperator::apply_boundary()` function once the exterior solution values \\(u^+ = -u^- + 2 g\\_\\text{D}\\) and \\(\\mathbf{n}^-\\cdot \\nabla u^+ =\n\\mathbf{n}^-\\cdot \\nabla u^-\\) on Dirichlet boundaries and \\(u^+=u^-\\) and \\(\\mathbf{n}^-\\cdot \\nabla u^+ = -\\mathbf{n}^-\\cdot \\nabla u^- + 2\ng\\_\\text{N}\\) on Neumann boundaries are inserted and expanded in terms of the boundary functions \\(g\\_\\text{D}\\) and \\(g\\_\\text{N}\\). One thing to remember is that we move the boundary conditions to the right hand side, so the sign is the opposite from what we imposed on the solution part.\n\nWe could have issued both the cell and the boundary part through a [MatrixFree::loop](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) part, but we choose to manually write the full loop over all faces to learn how the index layout of face indices is set up in [MatrixFree](classMatrixFree.html): Both the inner faces and the boundary faces share the index range, and all batches of inner faces have lower numbers than the batches of boundary cells. A single index for both variants allows us to easily use the same data structure [FEFaceEvaluation](classFEFaceEvaluation.html) for both cases that attaches to the same data field, just at different positions. The number of inner face batches (where a batch is due to the combination of several faces into one for vectorization) is given by [MatrixFree::n\\_inner\\_face\\_batches()](classMatrixFree.html#a1d24c18bcde8d09a2a7847f0f7f96d19), whereas the number of boundary face batches is given by [MatrixFree::n\\_boundary\\_face\\_batches()](classMatrixFree.html#aa787165092c1949ce2128ca63799abc1).\n\n```\n       FEFaceEvaluation<dim, fe_degree> phi_face(data, true);\n       for (unsigned int face = data.n_inner_face_batches();\n            face < data.n_inner_face_batches() + data.n_boundary_face_batches();\n            ++face)\n         {\n           phi_face.reinit(face);\n   \n           const VectorizedArray<double> inverse_length_normal_to_face = std::abs(\n             (phi_face.normal_vector(0) * phi_face.inverse_jacobian(0))[dim - 1]);\n           const VectorizedArray<double> sigma =\n             inverse_length_normal_to_face * system_matrix.get_penalty_factor();\n   \n           for (const unsigned int q : phi_face.quadrature_point_indices())\n             {\n               VectorizedArray<double> test_value = VectorizedArray<double>(),\n                                       test_normal_derivative =\n                                         VectorizedArray<double>();\n               Point<dim, VectorizedArray<double>> point_batch =\n                 phi_face.quadrature_point(q);\n   \n               for (unsigned int v = 0; v < VectorizedArray<double>::size(); ++v)\n                 {\n                   Point<dim> single_point;\n                   for (unsigned int d = 0; d < dim; ++d)\n                     single_point[d] = point_batch[d][v];\n```\n\nThe [MatrixFree](classMatrixFree.html) class lets us query the boundary\\_id of the current face batch. Remember that [MatrixFree](classMatrixFree.html) sets up the batches for vectorization such that all faces within a batch have the same properties, which includes their `boundary_id`. Thus, we can query that id here for the current face index `face` and either impose the Dirichlet case (where we add something to the function value) or the Neumann case (where we add something to the normal derivative).\n\n```\n                   if (data.get_boundary_id(face) == 0)\n                     test_value[v] = 2.0 * exact_solution.value(single_point);\n                   else\n                     {\n                       Tensor<1, dim> normal;\n                       for (unsigned int d = 0; d < dim; ++d)\n                         normal[d] = phi_face.normal_vector(q)[d][v];\n                       test_normal_derivative[v] =\n                         -normal * exact_solution.gradient(single_point);\n                     }\n                 }\n               phi_face.submit_value(test_value * sigma - test_normal_derivative,\n                                     q);\n               phi_face.submit_normal_derivative(-0.5 * test_value, q);\n             }\n           phi_face.integrate_scatter(EvaluationFlags::values |\n                                        EvaluationFlags::gradients,\n                                      system_rhs);\n         }\n```\n\nSince we have manually run the loop over cells rather than using [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf), we must not forget to perform the data exchange with MPI - or actually, we would not need that for DG elements here because each cell carries its own degrees of freedom and cell and boundary integrals only evaluate quantities on the locally owned cells. The coupling to neighboring subdomain only comes in by the inner face integrals, which we have not done here. That said, it does not hurt to call this function here, so we do it as a reminder of what happens inside [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf).\n\n```\n       system_rhs.compress(VectorOperation::add);\n       setup_time += time.wall_time();\n       time_details << \"Compute right hand side       \" << time.wall_time()\n                    << \" s\\n\";\n     }\n```\n\nThe `solve()` function is copied almost verbatim from [step-37](step_37.html). We set up the same multigrid ingredients, namely the level transfer, a smoother, and a coarse grid solver. The only difference is the fact that we do not use the diagonal of the Laplacian for the preconditioner of the Chebyshev iteration used for smoothing, but instead our newly resolved class `PreconditionBlockJacobi`. The mechanisms are the same, though.\n\n```\n     template <int dim, int fe_degree>\n     void LaplaceProblem<dim, fe_degree>::solve()\n     {\n       Timer                            time;\n       MGTransferMatrixFree<dim, float> mg_transfer;\n       mg_transfer.build(dof_handler);\n       setup_time += time.wall_time();\n       time_details << \"MG build transfer time        \" << time.wall_time()\n                    << \" s\\n\";\n       time.restart();\n   \n       using SmootherType =\n         PreconditionChebyshev<LevelMatrixType,\n                               LinearAlgebra::distributed::Vector<float>,\n                               PreconditionBlockJacobi<dim, fe_degree, float>>;\n       mg::SmootherRelaxation<SmootherType,\n                              LinearAlgebra::distributed::Vector<float>>\n                                                            mg_smoother;\n       MGLevelObject<typename SmootherType::AdditionalData> smoother_data;\n       smoother_data.resize(0, triangulation.n_global_levels() - 1);\n       for (unsigned int level = 0; level < triangulation.n_global_levels();\n            ++level)\n         {\n           if (level > 0)\n             {\n               smoother_data[level].smoothing_range     = 15.;\n               smoother_data[level].degree              = 3;\n               smoother_data[level].eig_cg_n_iterations = 10;\n             }\n           else\n             {\n               smoother_data[0].smoothing_range = 2e-2;\n               smoother_data[0].degree          = numbers::invalid_unsigned_int;\n               smoother_data[0].eig_cg_n_iterations = mg_matrices[0].m();\n             }\n           smoother_data[level].preconditioner =\n             std::make_shared<PreconditionBlockJacobi<dim, fe_degree, float>>();\n           smoother_data[level].preconditioner->initialize(mg_matrices[level]);\n         }\n       mg_smoother.initialize(mg_matrices, smoother_data);\n   \n       MGCoarseGridApplySmoother<LinearAlgebra::distributed::Vector<float>>\n         mg_coarse;\n       mg_coarse.initialize(mg_smoother);\n   \n       mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_matrix(\n         mg_matrices);\n   \n       Multigrid<LinearAlgebra::distributed::Vector<float>> mg(\n         mg_matrix, mg_coarse, mg_transfer, mg_smoother, mg_smoother);\n   \n       PreconditionMG<dim,\n                      LinearAlgebra::distributed::Vector<float>,\n                      MGTransferMatrixFree<dim, float>>\n         preconditioner(dof_handler, mg, mg_transfer);\n   \n       SolverControl solver_control(10000, 1e-12 * system_rhs.l2_norm());\n       SolverCG<LinearAlgebra::distributed::Vector<double>> cg(solver_control);\n       setup_time += time.wall_time();\n       time_details << \"MG build smoother time        \" << time.wall_time()\n                    << \"s\\n\";\n       pcout << \"Total setup time              \" << setup_time << \" s\\n\";\n   \n       time.reset();\n       time.start();\n       cg.solve(system_matrix, solution, system_rhs, preconditioner);\n   \n       pcout << \"Time solve (\" << solver_control.last_step() << \" iterations)    \"\n             << time.wall_time() << \" s\" << std::endl;\n     }\n```\n\nSince we have solved a problem with analytic solution, we want to verify the correctness of our implementation by computing the L2 error of the numerical result against the analytic solution.\n\n```\n     template <int dim, int fe_degree>\n     void LaplaceProblem<dim, fe_degree>::analyze_results() const\n     {\n       Vector<float> error_per_cell(triangulation.n_active_cells());\n       VectorTools::integrate_difference(mapping,\n                                         dof_handler,\n                                         solution,\n                                         Solution<dim>(),\n                                         error_per_cell,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::L2_norm);\n       pcout << \"Verification via L2 error:    \"\n             << std::sqrt(\n                  Utilities::MPI::sum(error_per_cell.norm_sqr(), MPI_COMM_WORLD))\n             << std::endl;\n     }\n```\n\nThe `run()` function sets up the initial grid and then runs the multigrid program in the usual way. As a domain, we choose a rectangle with periodic boundary conditions in the \\(x\\)-direction, a Dirichlet condition on the front face in \\(y\\) direction (i.e., the face with index number 2, with boundary id equal to 0), and Neumann conditions on the back face as well as the two faces in \\(z\\) direction for the 3d case (with boundary id equal to 1). The extent of the domain is a bit different in the \\(x\\) direction (where we want to achieve a periodic solution given the definition of `Solution`) as compared to the \\(y\\) and \\(z\\) directions.\n\n```\n     template <int dim, int fe_degree>\n     void LaplaceProblem<dim, fe_degree>::run()\n     {\n       const unsigned int n_ranks =\n         Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD);\n       pcout << \"Running with \" << n_ranks << \" MPI process\"\n             << (n_ranks > 1 ? \"es\" : \"\") << \", element \" << fe.get_name()\n             << std::endl\n             << std::endl;\n       for (unsigned int cycle = 0; cycle < 9 - dim; ++cycle)\n         {\n           pcout << \"Cycle \" << cycle << std::endl;\n   \n           if (cycle == 0)\n             {\n               Point<dim> upper_right;\n               upper_right[0] = 2.5;\n               for (unsigned int d = 1; d < dim; ++d)\n                 upper_right[d] = 2.8;\n               GridGenerator::hyper_rectangle(triangulation,\n                                              Point<dim>(),\n                                              upper_right);\n               triangulation.begin_active()->face(0)->set_boundary_id(10);\n               triangulation.begin_active()->face(1)->set_boundary_id(11);\n               triangulation.begin_active()->face(2)->set_boundary_id(0);\n               for (unsigned int f = 3;\n                    f < triangulation.begin_active()->n_faces();\n                    ++f)\n                 triangulation.begin_active()->face(f)->set_boundary_id(1);\n   \n               std::vector<GridTools::PeriodicFacePair<\n                 typename Triangulation<dim>::cell_iterator>>\n                 periodic_faces;\n               GridTools::collect_periodic_faces(\n                 triangulation, 10, 11, 0, periodic_faces);\n               triangulation.add_periodicity(periodic_faces);\n   \n               triangulation.refine_global(6 - 2 * dim);\n             }\n           triangulation.refine_global(1);\n           setup_system();\n           compute_rhs();\n           solve();\n           analyze_results();\n           pcout << std::endl;\n         };\n     }\n   } // namespace Step59\n```\n\nThere is nothing unexpected in the `main()` function. We call `MPI_Init()` through the `MPI_InitFinalize` class, pass on the two parameters on the dimension and the degree set at the top of the file, and run the Laplace problem.\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         using namespace Step59;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\n   \n         LaplaceProblem<dimension, degree_finite_element> laplace_problem;\n         laplace_problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### Program output\n\nLike in [step-37](step_37.html), we evaluate the multigrid solver in terms of run time. In two space dimensions with elements of degree 8, a possible output could look as follows:\n\n```\nRunning with 12 MPI processes, element FE_DGQHermite<2>(8)\n \nCycle 0\nNumber of degrees of freedom: 5184\nTotal setup time              0.0282445 s\nTime solve (14 iterations)    0.0110712 s\nVerification via L2 error:    1.66232e-07\n \nCycle 1\nNumber of degrees of freedom: 20736\nTotal setup time              0.0126282 s\nTime solve (14 iterations)    0.0157021 s\nVerification via L2 error:    2.91505e-10\n \nCycle 2\nNumber of degrees of freedom: 82944\nTotal setup time              0.0227573 s\nTime solve (14 iterations)    0.026568 s\nVerification via L2 error:    6.64514e-13\n \nCycle 3\nNumber of degrees of freedom: 331776\nTotal setup time              0.0604685 s\nTime solve (14 iterations)    0.0628356 s\nVerification via L2 error:    5.57513e-13\n \nCycle 4\nNumber of degrees of freedom: 1327104\nTotal setup time              0.154359 s\nTime solve (13 iterations)    0.219555 s\nVerification via L2 error:    3.08139e-12\n \nCycle 5\nNumber of degrees of freedom: 5308416\nTotal setup time              0.467764 s\nTime solve (13 iterations)    1.1821 s\nVerification via L2 error:    3.90334e-12\n \nCycle 6\nNumber of degrees of freedom: 21233664\nTotal setup time              1.73263 s\nTime solve (13 iterations)    5.21054 s\nVerification via L2 error:    4.94543e-12\n```\n\nLike in [step-37](step_37.html), the number of CG iterations remains constant with increasing problem size. The iteration counts are a bit higher, which is because we use a lower degree of the Chebyshev polynomial (2 vs 5 in [step-37](step_37.html)) and because the interior penalty discretization has a somewhat larger spread in eigenvalues. Nonetheless, 13 iterations to reduce the residual by 12 orders of magnitude, or almost a factor of 9 per iteration, indicates an overall very efficient method. In particular, we can solve a system with 21 million degrees of freedom in 5 seconds when using 12 cores, which is a very good efficiency. Of course, in 2D we are well inside the regime of roundoff for a polynomial degree of 8 – as a matter of fact, around 83k DoFs or 0.025s would have been enough to fully converge this (simple) analytic solution here.\n\nNot much changes if we run the program in three spatial dimensions, except for the fact that we now use do something more useful with the higher polynomial degree and increasing mesh sizes, as the roundoff errors are only obtained at the finest mesh. Still, it is remarkable that we can solve a 3D Laplace problem with a wave of three periods to roundoff accuracy on a twelve-core machine pretty easily - using about 3.5 GB of memory in total for the second to largest case with 24m DoFs, taking not more than eight seconds. The largest case uses 30GB of memory with 191m DoFs.\n\n```\nRunning with 12 MPI processes, element FE_DGQHermite<3>(8)\n \nCycle 0\nNumber of degrees of freedom: 5832\nTotal setup time              0.0210681 s\nTime solve (15 iterations)    0.0956945 s\nVerification via L2 error:    0.0297194\n \nCycle 1\nNumber of degrees of freedom: 46656\nTotal setup time              0.0452428 s\nTime solve (15 iterations)    0.113827 s\nVerification via L2 error:    9.55733e-05\n \nCycle 2\nNumber of degrees of freedom: 373248\nTotal setup time              0.190423 s\nTime solve (15 iterations)    0.218309 s\nVerification via L2 error:    2.6868e-07\n \nCycle 3\nNumber of degrees of freedom: 2985984\nTotal setup time              0.627914 s\nTime solve (15 iterations)    1.0595 s\nVerification via L2 error:    4.6918e-10\n \nCycle 4\nNumber of degrees of freedom: 23887872\nTotal setup time              2.85215 s\nTime solve (15 iterations)    8.30576 s\nVerification via L2 error:    9.38583e-13\n \nCycle 5\nNumber of degrees of freedom: 191102976\nTotal setup time              16.1324 s\nTime solve (15 iterations)    65.57 s\nVerification via L2 error:    3.17875e-13\n```\n\n### Comparison of efficiency at different polynomial degrees\n\nIn the introduction and in-code comments, it was mentioned several times that high orders are treated very efficiently with the [FEEvaluation](classFEEvaluation.html) and [FEFaceEvaluation](classFEFaceEvaluation.html) evaluators. Now, we want to substantiate these claims by looking at the throughput of the 3D multigrid solver for various polynomial degrees. We collect the times as follows: We first run a solver at problem size close to ten million, indicated in the first four table rows, and record the timings. Then, we normalize the throughput by recording the number of million degrees of freedom solved per second (MDoFs/s) to be able to compare the efficiency of the different degrees, which is computed by dividing the number of degrees of freedom by the solver time.\n\n| degree | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Number of DoFs | 2097152 | 7077888 | 16777216 | 32768000 | 7077888 | 11239424 | 16777216 | 23887872 | 32768000 | 43614208 | 7077888 | 8998912 |\n| Number of iterations | 13 | 12 | 12 | 12 | 13 | 13 | 15 | 15 | 17 | 19 | 18 | 18 |\n| Solver time [s] | 0.713 | 2.150 | 4.638 | 8.803 | 2.041 | 3.295 | 5.723 | 8.306 | 12.75 | 19.25 | 3.530 | 4.814 |\n| MDoFs/s | 2.94 | 3.29 | 3.62 | 3.72 | 3.47 | 3.41 | 2.93 | 2.88 | 2.57 | 2.27 | 2.01 | 1.87 |\n\nWe clearly see how the efficiency per DoF initially improves until it reaches a maximum for the polynomial degree \\(k=4\\). This effect is surprising, not only because higher polynomial degrees often yield a vastly better solution, but especially also when having matrix-based schemes in mind where the denser coupling at higher degree leads to a monotonously decreasing throughput (and a drastic one in 3D, with \\(k=4\\) being more than ten times slower than \\(k=1\\)!). For higher degrees, the throughput decreases a bit, which is both due to an increase in the number of iterations (going from 12 at \\(k=2,3,4\\) to 19 at \\(k=10\\)) and due to the \\(\\mathcal O(k)\\) complexity of operator evaluation. Nonetheless, efficiency as the time to solution would be still better for higher polynomial degrees because they have better convergence rates (at least for problems as simple as this one): For \\(k=12\\), we reach roundoff accuracy already with 1 million DoFs (solver time less than a second), whereas for \\(k=8\\) we need 24 million DoFs and 8 seconds. For \\(k=5\\), the error is around \\(10^{-9}\\) with 57m DoFs and thus still far away from roundoff, despite taking 16 seconds.\n\nNote that the above numbers are a bit pessimistic because they include the time it takes the Chebyshev smoother to compute an eigenvalue estimate, which is around 10 percent of the solver time. If the system is solved several times (as e.g. common in fluid dynamics), this eigenvalue cost is only paid once and faster times become available.\n\n### Evaluation of efficiency of ingredients\n\nFinally, we take a look at some of the special ingredients presented in this tutorial program, namely the [FE\\_DGQHermite](classFE__DGQHermite.html) basis in particular and the specification of [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15). In the following table, the third row shows the optimized solver above, the fourth row shows the timings with only the [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15) set to `unspecified` rather than the optimal `gradients`, and the last one with replacing [FE\\_DGQHermite](classFE__DGQHermite.html) by the basic [FE\\_DGQ](classFE__DGQ.html) elements where both the MPI exchange are more expensive and the operations done by [FEFaceEvaluation::gather\\_evaluate()](classFEFaceEvaluation.html#a4ac53fde2eab227ef45c7d29a5ed33fe) and [FEFaceEvaluation::integrate\\_scatter()](classFEFaceEvaluation.html#a21c3b33147e4abc2b0ae787b6510ec04).\n\n| degree | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Number of DoFs | 2097152 | 7077888 | 16777216 | 32768000 | 7077888 | 11239424 | 16777216 | 23887872 | 32768000 | 43614208 | 7077888 | 8998912 |\n| Solver time optimized as in tutorial [s] | 0.713 | 2.150 | 4.638 | 8.803 | 2.041 | 3.295 | 5.723 | 8.306 | 12.75 | 19.25 | 3.530 | 4.814 |\n| Solver time [MatrixFree::DataAccessOnFaces::unspecified](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15ad415f0e30c471dfdd9bc4f827329ef48) [s] | 0.711 | 2.151 | 4.675 | 8.968 | 2.243 | 3.655 | 6.277 | 9.082 | 13.50 | 20.05 | 3.817 | 5.178 |\n| Solver time [FE\\_DGQ](classFE__DGQ.html) [s] | 0.712 | 2.041 | 5.066 | 9.335 | 2.379 | 3.802 | 6.564 | 9.714 | 14.54 | 22.76 | 4.148 | 5.857 |\n\nThe data in the table shows that not using [MatrixFree::DataAccessOnFaces](classMatrixFree.html#a751b5f06534d52773eba384d2c866a15) increases costs by around 10% for higher polynomial degrees. For lower degrees, the difference is obviously less pronounced because the volume-to-surface ratio is more beneficial and less data needs to be exchanged. The difference is larger when looking at the matrix-vector product only, rather than the full multigrid solver shown here, with around 20% worse timings just because of the MPI communication.\n\nFor \\(k=1\\) and \\(k=2\\), the Hermite-like basis functions do obviously not really pay off (indeed, for \\(k=1\\) the polynomials are exactly the same as for [FE\\_DGQ](classFE__DGQ.html)) and the results are similar as with the [FE\\_DGQ](classFE__DGQ.html) basis. However, for degrees starting at three, we see an increasing advantage for [FE\\_DGQHermite](classFE__DGQHermite.html), showing the effectiveness of these basis functions.\n\n### Possibilities for extension\n\nAs mentioned in the introduction, the fast diagonalization method as realized here is tied to a Cartesian mesh with constant coefficients. When dealing with meshes that contain deformed cells or with variable coefficients, it is common to determine a nearby Cartesian mesh cell as an approximation. This can be done with the class [TensorProductMatrixSymmetricSumCollection](classTensorProductMatrixSymmetricSumCollection.html). Here, one can insert cell matrices similarly to the [PreconditionBlockJacobi::initialize()](classPreconditionBlock.html#a6c61513fe17633b8b4e1dd2d83b72e81) function of this tutorial program. The benefit of the collection class is that cells on which the coefficient of the PDE has the same value can re-use the same Laplacian matrix, which reduces the memory consumption for the inverse matrices. As compared to the algorithm implemented in this tutorial program, one would define the length scales as the distances between opposing faces. For continuous elements, the code project <a href=<https://github.com/peterrum/dealii-dd-and-schwarz>\">Cache-optimized and\nlow-overhead implementations of multigrid smoothers for high-order FEM\ncomputations</a> presents the computation for continuous elements. There is\ncurrently no infrastructure in deal.II to automatically generate the 1D\nmatrices for discontinuous elements with SIP-DG discretization, as opposed to\ncontinuous elements, where we provide\nTensorProductMatrixCreator::create\\_laplace\\_tensor\\_product\\_matrix().\nAnother way of extending the program would be to include support for adaptive\nmeshes. While the classical approach of defining interface operations at edges\nof different refinement level, as discussed in @ref step\\_39 \"step-39\", is one possibility,\nfor Poisson-type problems another option is typically more beneficial. Using\nthe class MGTransferGlobalCoarsening, which is explained in the @ref step\\_75 \"step-75\"\ntutorial program, one can deal with meshes of hanging nodes on all levels. An\nalgorithmic improvement can be obtained by combining the discontinuous\nfunction space with the auxiliary continuous finite element space of the same\npolynomial degree. This idea, introduced by Antonietti et al.\n@cite antonietti2016uniform in 2016, allows making the multigrid convergence\nindependent of the penalty parameter. As demonstrated by Fehn et al.\n@cite fehn2020hybrid, this also gives considerably lower iteration counts than\na multigrid solver directly working on levels with discontinuous function\nspaces. The latter work also proposes p-multigrid techniques and combination\nwith algebraic multigrid coarse spaces as a means to efficiently solve Poisson\nproblems with high-order discontinuous Galerkin discretizations on complicated\ngeometries, representing the current state-of-the-art for simple Poisson-type\nproblems. The class MGTransferGlobalCoarsening provides features for each of\nthese three coarsening variants, the discontinuous-continuous auxiliary\nfunction concept, p-multigrid, and traditional h-multigrid. The main\ningredient is to define an appropriate MGTwoLevelTransfer object and call\nMGTwoLevelTransfer::reinit\\_geometric\\_transfer() or\nMGTwoLevelTransfer::reinit\\_polynomial\\_transfer(), respectively.\n@anchor step\\_59-PlainProg <a></a>\n<h1> The plain program</h1>\n@include \"step-59.cc\"\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_60.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nDistributed Lagrange multipliers for the solution of Poisson problems in complex domains with constraints defined on non-matching grids.\nTutorial content :\nThis tutorial depends on [step-6](step_6.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_60-Intro)    * [Non-matching grid constraints through distributed Lagrange multipliers](#step_60-NonmatchinggridconstraintsthroughdistributedLagrangemultipliers)* [The testcase](#step_60-Thetestcase)* [References](#step_60-References)- [The commented program](#step_60-CommProg)      * [Include files](#step_60-Includefiles)* [DistributedLagrangeProblem](#step_60-DistributedLagrangeProblem)* [DistributedLagrangeProblem::Parameters](#step_60-DistributedLagrangeProblemParameters)* [Set up](#step_60-Setup)* [Assembly](#step_60-Assembly)* [Solve](#step_60-Solve) | 1. [Results](#step_60-Results)    * [Test case 1:](#step_60-Testcase1) * [Test case 2 and 3:](#step_60-Testcase2and3) * [Possibilities for extensions](#step_60-Possibilitiesforextensions)          + [Running with `spacedim` equal to three](#step_60-Runningwithspacedimequaltothree)+ [More general domains](#step_60-Moregeneraldomains) + [Preconditioner](#step_60-Preconditioner)+ [Parallel Code](#step_60-ParallelCode)- [The plain program](#step_60-PlainProg) |\n\n*This program was contributed by Luca Heltai and Giovanni Alzetta, SISSA, Trieste.*\n\nNote\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.1243280](https://zenodo.org/badge/DOI/10.5281/zenodo.1243280.svg)](https://doi.org/10.5281/zenodo.1243280)\n\nIntroduction\n============\n\n### Non-matching grid constraints through distributed Lagrange multipliers\n\nIn this tutorial we consider the case of two domains, \\(\\Omega\\) in \\(R^{\\text{spacedim}}\\) and \\(\\Gamma\\) in \\(R^{\\text{dim}}\\), where \\(\\Gamma\\) is embedded in \\(\\Omega\\) ( \\(\\Gamma \\subseteq \\Omega\\)). We want to solve a partial differential equation on \\(\\Omega\\), enforcing some conditions on the solution of the problem *on the embedded domain* \\(\\Gamma\\).\n\nThere are two interesting scenarios:\n\n* the geometrical dimension `dim` of the embedded domain \\(\\Gamma\\) is the same of the domain \\(\\Omega\\) (`spacedim`), that is, the spacedim-dimensional measure of \\(\\Gamma\\) is not zero, or\n* the embedded domain \\(\\Gamma\\) has an intrinsic dimension `dim` which is smaller than that of \\(\\Omega\\) (`spacedim`), thus its spacedim-dimensional measure is zero; for example it is a curve embedded in a two dimensional domain, or a surface embedded in a three-dimensional domain.\n\nIn both cases define the restriction operator \\(\\gamma\\) as the operator that, given a continuous function on \\(\\Omega\\), returns its (continuous) restriction on \\(\\Gamma\\), i.e.,\n\n\\[\n\\gamma : C^0(\\Omega) \\mapsto C^0(\\Gamma), \\quad \\text{ s.t. } \\gamma u = u|\\_{\\Gamma} \\in C^0(\\Gamma),\n\\quad \\forall u \\in C^0(\\Omega).\n\\]\n\nIt is well known that the operator \\(\\gamma\\) can be extended to a continuous operator on \\(H^1(\\Omega)\\), mapping functions in \\(H^1(\\Omega)\\) to functions in \\(H^1(\\Gamma)\\) when the intrinsic dimension of \\(\\Gamma\\) is the same of \\(\\Omega\\).\n\nThe same is true, with a less regular range space (namely \\(H^{1/2}(\\Gamma)\\)), when the dimension of \\(\\Gamma\\) is one less with respect to \\(\\Omega\\), and \\(\\Gamma\\) does not have a boundary. In this second case, the operator \\(\\gamma\\) is also known as the *trace* operator, and it is well defined for Lipschitz co-dimension one curves and surfaces \\(\\Gamma\\) embedded in \\(\\Omega\\) (read [this wikipedia article](https://en.wikipedia.org/wiki/Trace_operator) for further details on the trace operator).\n\nThe co-dimension two case is a little more complicated, and in general it is not possible to construct a continuous trace operator, not even from \\(H^1(\\Omega)\\) to \\(L^2(\\Gamma)\\), when the dimension of \\(\\Gamma\\) is zero or one respectively in two and three dimensions.\n\nIn this tutorial program we're not interested in further details on \\(\\gamma\\): we take the extension \\(\\gamma\\) for granted, assuming that the dimension of the embedded domain (`dim`) is always smaller by one or equal with respect to the dimension of the embedding domain \\(\\Omega\\) (`spacedim`).\n\nWe are going to solve the following differential problem: given a sufficiently regular function \\(g\\) on \\(\\Gamma\\), a forcing term \\(f \\in L^2(\\Omega)\\) and a Dirichlet boundary condition \\(u\\_D\\) on \\(\\partial \\Omega\\), find the solution \\(u\\) to\n\n\\begin{eqnarray\\*}\n- \\Delta u + \\gamma^T \\lambda &=& f \\text{ in } \\Omega\\\\\n\\gamma u &=& g \\text{ in } \\Gamma \\\\\nu & = & u\\_D \\text{ on } \\partial\\Omega.\n\\end{eqnarray\\*}\n\nThis is a constrained problem, where we are looking for a function \\(u\\) that solves the Poisson equation and that satisfies Dirichlet boundary conditions \\(u=u\\_D\\) on \\(\\partial \\Omega\\), subject to the constraint \\(\\gamma u = g\\) using a Lagrange multiplier.\n\nWhen \\(f=0\\) this problem has a physical interpretation: harmonic functions, i.e., functions that satisfy the Laplace equation, can be thought of as the displacements of a membrane whose boundary values are prescribed. The current situation then corresponds to finding the shape of a membrane for which not only the displacement at the boundary, but also on \\(\\Gamma\\) is prescribed. For example, if \\(\\Gamma\\) is a closed curve in 2d space, then that would model a soap film that is held in place by a wire loop along \\(\\partial \\Omega\\) as well as a second loop along \\(\\Gamma\\). In cases where \\(\\Gamma\\) is a whole area, you can think of this as a membrane that is stretched over an obstacle where \\(\\Gamma\\) is the contact area. (If the contact area is not known we have a different problem – called the \"obstacle problem\" – which is modeled in [step-41](step_41.html).)\n\nAs a first example we study the zero Dirichlet boundary condition on \\(\\partial\\Omega\\). The same equations apply if we apply zero Neumann boundary conditions on \\(\\partial\\Omega\\) or a mix of the two.\n\nThe variational formulation can be derived by introducing two infinite dimensional spaces \\(V(\\Omega)\\) and \\(Q^\\*(\\Gamma)\\), respectively for the solution \\(u\\) and for the Lagrange multiplier \\(\\lambda\\).\n\nMultiplying the first equation by \\(v \\in V(\\Omega)\\) and the second by \\(q \\in\nQ(\\Gamma)\\), integrating by parts when possible, and exploiting the boundary conditions on \\(\\partial\\Omega\\), we obtain the following variational problem:\n\nGiven a sufficiently regular function \\(g\\) on \\(\\Gamma\\), find the solution \\(u\\) to\n\n\\begin{eqnarray\\*}\n(\\nabla u, \\nabla v)\\_{\\Omega} + (\\lambda, \\gamma v)\\_{\\Gamma} &=& (f,v)\\_{\\Omega} \\qquad \\forall v \\in V(\\Omega) \\\\\n(\\gamma u, q)\\_{\\Gamma} &=& (g,q)\\_{\\Gamma} \\qquad \\forall q \\in Q(\\Gamma),\n\\end{eqnarray\\*}\n\nwhere \\((\\cdot, \\cdot)\\_{\\Omega}\\) and \\((\\cdot, \\cdot)\\_{\\Gamma}\\) represent, respectively, \\(L^2\\) scalar products in \\(\\Omega\\) and in \\(\\Gamma\\).\n\nInspection of the variational formulation tells us that the space \\(V(\\Omega)\\) can be taken to be \\(H^1\\_0(\\Omega)\\). The space \\(Q(\\Gamma)\\), in the co-dimension zero case, should be taken as \\(H^1(\\Gamma)\\), while in the co-dimension one case should be taken as \\(H^{1/2}(\\Gamma)\\).\n\nThe function \\(g\\) should therefore be either in \\(H^1(\\Gamma)\\) (for the co-dimension zero case) or \\(H^{1/2}(\\Gamma)\\) (for the co-dimension one case). This leaves us with a Lagrange multiplier \\(\\lambda\\) in \\(Q^\\*(\\Gamma)\\), which is either \\(H^{-1}(\\Gamma)\\) or \\(H^{-1/2}(\\Gamma)\\).\n\nThere are two options for the discretization of the problem above. One could choose matching discretizations, where the [Triangulation](classTriangulation.html) for \\(\\Gamma\\) is aligned with the [Triangulation](classTriangulation.html) for \\(\\Omega\\), or one could choose to discretize the two domains in a completely independent way.\n\nThe first option is clearly more indicated for the simple problem we proposed above: it is sufficient to use a single [Triangulation](classTriangulation.html) for \\(\\Omega\\) and then impose certain constraints depending \\(\\Gamma\\). An example of this approach is studied in [step-40](step_40.html), where the solution has to stay above an obstacle and this is achieved imposing constraints on \\(\\Omega\\).\n\nTo solve more complex problems, for example one where the domain \\(\\Gamma\\) is time dependent, the second option could be a more viable solution. Handling non aligned meshes is complex by itself: to illustrate how is done we study a simple problem.\n\nThe technique we describe here is presented in the literature using one of many names: the **immersed finite element method**, the **fictitious boundary method**, the **distributed Lagrange multiplier method**, and others. The main principle is that the discretization of the two grids and of the two finite element spaces are kept completely independent. This technique is particularly efficient for the simulation of fluid-structure interaction problems, where the configuration of the embedded structure is part of the problem itself, and one solves a (possibly non-linear) elastic problem to determine the (time dependent) configuration of \\(\\Gamma\\), and a (possibly non-linear) flow problem in \\(\\Omega\n\\setminus \\Gamma\\), plus coupling conditions on the interface between the fluid and the solid.\n\nIn this tutorial program we keep things a little simpler, and we assume that the configuration of the embedded domain is given in one of two possible ways:\n\n* as a deformation mapping \\(\\psi: \\Gamma\\_0 \\mapsto \\Gamma \\subseteq \\Omega\\), defined on a continuous finite dimensional space on \\(\\Gamma\\_0\\) and representing, for any point \\(x \\in \\Gamma\\_0\\), its coordinate \\(\\psi(x)\\) in \\(\\Omega\\);\n* as a displacement mapping \\(\\delta \\psi(x) = \\psi(x)-x\\) for \\(x\\in \\Gamma\\_0\\), representing for any point \\(x\\) the displacement vector applied in order to deform \\(x\\) to its actual configuration \\(\\psi(x) = x +\\delta\\psi(x)\\).\n\nWe define the embedded reference domain \\(\\Gamma\\_0\\) `embedded_grid`: on this triangulation we construct a finite dimensional space (`embedded_configuration_dh`) to describe either the deformation or the displacement through a [FiniteElement](classFiniteElement.html) system of [FE\\_Q](classFE__Q.html) objects (`embedded_configuration_fe`). This finite dimensional space is used only to interpolate a user supplied function (`embedded_configuration_function`) representing either \\(\\psi\\) (if the parameter `use_displacement` is set to `false`) or \\(\\delta\\psi\\) (if the parameter `use_displacement` is set to `true`).\n\nThe Lagrange multiplier \\(\\lambda\\) and the user supplied function \\(g\\) are defined through another finite dimensional space `embedded_dh`, and through another [FiniteElement](classFiniteElement.html) `embedded_fe`, using the same reference domain. In order to take into account the deformation of the domain, either a [MappingFEField](classMappingFEField.html) or a [MappingQEulerian](classMappingQEulerian.html) object are initialized with the `embedded_configuration` vector.\n\nIn the embedding space, a standard finite dimensional space `space_dh` is constructed on the embedding grid `space_grid`, using the [FiniteElement](classFiniteElement.html) `space_fe`, following almost verbatim the approach taken in [step-6](step_6.html).\n\nWe represent the discretizations of the spaces \\(V\\) and \\(Q\\) with\n\n\\[\nV\\_h(\\Omega) = \\text{span} \\{v\\_i\\}\\_{i=1}^n\n\\]\n\nand\n\n\\[\nQ\\_h(\\Gamma) = \\text{span} \\{q\\_i\\}\\_{i=1}^m\n\\]\n\nrespectively, where \\(n\\) is the dimension of `space_dh`, and \\(m\\) the dimension of `embedded_dh`.\n\nOnce all the finite dimensional spaces are defined, the variational formulation of the problem above leaves us with the following finite dimensional system of equations:\n\n\\[\n\\begin{pmatrix}\nK & C^T \\\\\nC & 0\n\\end{pmatrix}\n\\begin{pmatrix}\nu \\\\\n\\lambda\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nF \\\\\nG\n\\end{pmatrix}\n\\]\n\nwhere\n\n\\begin{eqnarray\\*}\nK\\_{ij} &\\dealcoloneq& (\\nabla v\\_j, \\nabla v\\_i)\\_\\Omega \\qquad i,j=1,\\dots,n \\\\\nC\\_{\\alpha j} &\\dealcoloneq& (v\\_j, q\\_\\alpha)\\_\\Gamma \\qquad j=1,\\dots,n, \\alpha = 1,\\dots, m \\\\\\\\\nF\\_{i} &\\dealcoloneq& (f, v\\_i)\\_\\Omega \\qquad i=1,\\dots,n \\\\\nG\\_{\\alpha} &\\dealcoloneq& (g, q\\_\\alpha)\\_\\Gamma \\qquad \\alpha = 1,\\dots, m.\n\\end{eqnarray\\*}\n\nWhile the matrix \\(K\\) is the standard [stiffness matrix](DEALGlossary.html#GlossStiffnessMatrix) for the Poisson problem on \\(\\Omega\\), and the vector \\(G\\) is a standard right-hand-side vector for a finite element problem with forcing term \\(g\\) on \\(\\Gamma\\), (see, for example, [step-3](step_3.html)), the matrix \\(C\\) or its transpose \\(C^T\\) are non-standard since they couple information on two non-matching grids.\n\nIn particular, the integral that appears in the computation of a single entry of \\(C\\), is computed on \\(\\Gamma\\). As usual in finite elements we split this integral into contributions from all cells of the triangulation used to discretize \\(\\Gamma\\), we transform the integral on \\(K\\) to an integral on the reference element \\(\\hat K\\), where \\(F\\_{K}\\) is the mapping from \\(\\hat K\\) to \\(K\\), and compute the integral on \\(\\hat K\\) using a quadrature formula:\n\n\\[\nC\\_{\\alpha j} \\dealcoloneq (v\\_j, q\\_\\alpha)\\_\\Gamma = \\sum\\_{K\\in \\Gamma} \\int\\_{\\hat K}\n\\hat q\\_\\alpha(\\hat x) (v\\_j \\circ F\\_{K}) (\\hat x) J\\_K (\\hat x) \\mathrm{d} \\hat x =\n\\sum\\_{K\\in \\Gamma} \\sum\\_{i=1}^{n\\_q} \\big(\\hat q\\_\\alpha(\\hat x\\_i) (v\\_j \\circ F\\_{K}) (\\hat x\\_i) J\\_K (\\hat x\\_i) w\\_i \\big)\n\\]\n\nComputing this sum is non-trivial because we have to evaluate \\((v\\_j \\circ F\\_{K})\n(\\hat x\\_i)\\). In general, if \\(\\Gamma\\) and \\(\\Omega\\) are not aligned, the point \\(F\\_{K}(\\hat x\\_i)\\) is completely arbitrary with respect to \\(\\Omega\\), and unless we figure out a way to interpolate all basis functions of \\(V\\_h(\\Omega)\\) on an arbitrary point on \\(\\Omega\\), we cannot compute the integral needed for an entry of the matrix \\(C\\).\n\nTo evaluate \\((v\\_j \\circ F\\_{K}) (\\hat x\\_i)\\) the following steps needs to be taken (as shown in the picture below):\n\n* For a given cell \\(K\\) in \\(\\Gamma\\) compute the real point \\(y\\_i \\dealcoloneq F\\_{K} (\\hat\n  x\\_i)\\), where \\(x\\_i\\) is one of the quadrature points used for the integral on \\(K\n  \\subseteq \\Gamma\\).\n* Find the cell of \\(\\Omega\\) in which \\(y\\_i\\) lies. We shall call this element \\(T\\).\n* To evaluate the basis function use the inverse of the mapping \\(G\\_T\\) that transforms the reference element \\(\\hat T\\) into the element \\(T\\): \\(v\\_j(y\\_i) = \\hat\n  v\\_j \\circ G^{-1}\\_{T} (y\\_i)\\).\n\n![](images/steps/developer/step-60.C_interpolation.png)\n\nThe three steps above can be computed by calling, in turn,\n\n* [GridTools::find\\_active\\_cell\\_around\\_point()](namespaceGridTools.html#a2e10aeb1c8e76110a84b6945eac3aaf0), followed by\n* [Mapping::transform\\_real\\_to\\_unit\\_cell()](classMapping.html#a7e322d14c2800734d071a48a95b00d35). We then\n* construct a custom [Quadrature](classQuadrature.html) formula, containing the point in the reference cell and then\n* construct an [FEValues](classFEValues.html) object, with the given quadrature formula, and initialized with the cell obtained in the first step.\n\nThis is what the deal.II function [VectorTools::point\\_value()](namespaceVectorTools.html#acd358e9b110ccbf4a7f76796d206b9c7) does when evaluating a finite element field (not just a single shape function) at an arbitrary point; but this would be inefficient in this case.\n\nA better solution is to use a convenient wrapper to perform the first three steps on a collection of points: [GridTools::compute\\_point\\_locations()](namespaceGridTools.html#a1da30ea67372da8ebd81de2becf06f1c). If one is actually interested in computing the full coupling matrix, then it is possible to call the method [NonMatching::create\\_coupling\\_mass\\_matrix()](namespaceNonMatching.html#a6e1f6762bf58daadf522cae5947050c3), that performs the above steps in an efficient way, reusing all possible data structures, and gathering expensive steps together. This is the function we'll be using later in this tutorial.\n\nWe solve the final saddle point problem by an iterative solver, applied to the Schur complement \\(S\\) (whose construction is described, for example, in [step-20](step_20.html)), and we construct \\(S\\) using [LinearOperator](classLinearOperator.html) classes.\n\n### The testcase\n\nThe problem we solve here is identical to [step-4](step_4.html), with the difference that we impose some constraints on an embedded domain \\(\\Gamma\\). The tutorial is written in a dimension independent way, and in the results section we show how to vary both `dim` and `spacedim`.\n\nThe tutorial is compiled for `dim` equal to one and `spacedim` equal to two. If you want to run the program in embedding dimension `spacedim` equal to three, you will most likely want to change the reference domain for \\(\\Gamma\\) to be, for example, something you read from file, or a closed sphere that you later deform to something more interesting.\n\nIn the default scenario, \\(\\Gamma\\) has co-dimension one, and this tutorial program implements the Fictitious Boundary Method. As it turns out, the same techniques are used in the Variational Immersed Finite Element Method, and the coupling operator \\(C\\) defined above is the same in almost all of these non-matching methods.\n\nThe embedded domain is assumed to be included in \\(\\Omega\\), which we take as the unit square \\([0,1]^2\\). The definition of the fictitious domain \\(\\Gamma\\) can be modified through the parameter file, and can be given as a mapping from the reference interval \\([0,1]\\) to a curve in \\(\\Omega\\).\n\nIf the curve is closed, then the results will be similar to running the same problem on a grid whose boundary is \\(\\Gamma\\). The program will happily run also with a non-closed \\(\\Gamma\\), although in those cases the mathematical formulation of the problem is more difficult, since \\(\\Gamma\\) will have a boundary by itself that has co-dimension two with respect to the domain \\(\\Omega\\).\n\n### References\n\n* Glowinski, R., T.-W. Pan, T.I. Hesla, and D.D. Joseph. 1999. âA Distributed Lagrange Multiplier/fictitious Domain Method for Particulate Flows.â International Journal of Multiphase Flow 25 (5). Pergamon: 755â94.\n* Boffi, D., L. Gastaldi, L. Heltai, and C.S. Peskin. 2008. âOn the Hyper-Elastic Formulation of the Immersed Boundary Method.â Computer Methods in Applied Mechanics and Engineering 197 (25â28).\n* Heltai, L., and F. Costanzo. 2012. âVariational Implementation of Immersed Finite Element Methods.â Computer Methods in Applied Mechanics and Engineering 229â232.\n\nThe commented program\n=====================\n\n### Include files\n\nMost of these have been introduced elsewhere, we'll comment only on the new ones.\n\n```\n   #include <deal.II/base/logstream.h>\n   #include <deal.II/base/utilities.h>\n   #include <deal.II/base/timer.h>\n```\n\nThe parameter acceptor class is the first novelty of this tutorial program: in general parameter files are used to steer the execution of a program at run time. While even a simple approach saves compile time, as the same executable can be run with different parameter settings, it can become difficult to handle hundreds of parameters simultaneously while maintaining compatibility between different programs. This is where the class [ParameterAcceptor](classParameterAcceptor.html) proves useful.\n\nThis class is used to define a public interface for classes that want to use a single global [ParameterHandler](classParameterHandler.html) to handle parameters. The class provides a static [ParameterHandler](classParameterHandler.html) member, namely [ParameterAcceptor::prm](classParameterAcceptor.html#a96081d4cc985b722c9841fcf0c0e54ec), and implements the \"Command design pattern\" (see, for example, E. Gamma, R. Helm, R. Johnson, J. Vlissides, Design [Patterns](namespacePatterns.html): Elements of Reusable Object-Oriented Software, Addison-Wesley Professional, 1994. <https://goo.gl/FNYByc>).\n\n[ParameterAcceptor](classParameterAcceptor.html) provides a global subscription mechanism. Whenever an object of a class derived from [ParameterAcceptor](classParameterAcceptor.html) is constructed, a pointer to that object-of-derived-type is registered, together with a section entry in the parameter file. Such registry is traversed upon invocation of the single function [ParameterAcceptor::initialize](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e)(\"file.prm\") which in turn makes sure that all classes stored in the global registry declare the parameters they will be using, and after having declared them, it reads the content of `file.prm` to parse the actual parameters.\n\nIf you call the method [ParameterHandler::add\\_parameter](classParameterHandler.html#a04b75c02037d19fd7fd781785fcefc79) for each of the parameters you want to use in your code, there is nothing else you need to do. If you are using an already existing class that provides the two functions `declare_parameters` and `parse_parameters`, you can still use [ParameterAcceptor](classParameterAcceptor.html), by encapsulating the existing class into a [ParameterAcceptorProxy](classParameterAcceptorProxy.html) class.\n\nIn this example, we'll use both strategies, using [ParameterAcceptorProxy](classParameterAcceptorProxy.html) for deal.II classes, and deriving our own parameter classes directly from [ParameterAcceptor](classParameterAcceptor.html).\n\n```\n   #include <deal.II/base/parameter_acceptor.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_tools.h>\n```\n\nThe other new include file is the one that contains the [GridTools::Cache](classGridTools_1_1Cache.html) class. The structure of deal.II, as many modern numerical libraries, is organized following a Directed Acyclic Graph (DAG). A DAG is a directed graph with topological ordering: each node structurally represents an object, and is connected to non-root nodes by one (or more) oriented edges, from the parent to the child. The most significant example of this structure is the [Triangulation](classTriangulation.html) and its [Triangulation::cell\\_iterator](group__Iterators.html#gafdac1d50b2c200f41f4cd2481ad9182b) structure. From a [Triangulation](classTriangulation.html) (the main node), we can access each cell (children nodes of the triangulation). From the cells themselves we can access over all vertices of the cell. In this simple example, the DAG structure can be represented as three node types (the triangulation, the cell iterator, and the vertex) connected by oriented edges from the triangulation to the cell iterators, and from the cell iterator to the vertices. This has several advantages, but it intrinsically creates âasymmetriesâ, making certain operations fast and their inverse very slow: finding the vertices of a cell has low computational cost, and can be done by simply traversing the DAG, while finding all the cells that share a vertex requires a non-trivial computation unless a new DAG data structure is added that represents the inverse search.\n\nSince inverse operations are usually not needed in a finite element code, these are implemented in [GridTools](namespaceGridTools.html) without the use of extra data structures related to the [Triangulation](classTriangulation.html) which would make them much faster. One such data structure, for example, is a map from the vertices of a [Triangulation](classTriangulation.html) to all cells that share those vertices, which would reduce the computations needed to answer to the previous question.\n\nSome methods, for example [GridTools::find\\_active\\_cell\\_around\\_point](namespaceGridTools.html#a2e10aeb1c8e76110a84b6945eac3aaf0), make heavy usage of these non-standard operations. If you need to call these methods more than once, it becomes convenient to store those data structures somewhere. [GridTools::Cache](classGridTools_1_1Cache.html) does exactly this, giving you access to previously computed objects, or computing them on the fly (and then storing them inside the class for later use), and making sure that whenever the [Triangulation](classTriangulation.html) is updated, also the relevant data structures are recomputed.\n\n```\n   #include <deal.II/grid/grid_tools_cache.h>\n   \n   #include <deal.II/fe/fe.h>\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n```\n\nIn this example, we will be using a reference domain to describe an embedded [Triangulation](classTriangulation.html), deformed through a finite element vector field.\n\nThe next two include files contain the definition of two classes that can be used in these cases. [MappingQEulerian](classMappingQEulerian.html) allows one to describe a domain through a *displacement* field, based on a [FESystem](classFESystem.html)[[FE\\_Q(p)](classFE__Q.html)^spacedim] finite element space. The second is a little more generic, and allows you to use arbitrary vector [FiniteElement](classFiniteElement.html) spaces, as long as they provide a *continuous* description of your domain. In this case, the description is done through the actual *deformation* field, rather than a *displacement* field.\n\nWhich one is used depends on how the user wants to specify the reference domain, and/or the actual configuration. We'll provide both options, and experiment a little in the results section of this tutorial program.\n\n```\n   #include <deal.II/fe/mapping_q_eulerian.h>\n   #include <deal.II/fe/mapping_fe_field.h>\n   \n   #include <deal.II/dofs/dof_tools.h>\n```\n\nThe parsed function class is another new entry. It allows one to create a [Function](classFunction.html) object, starting from a string in a parameter file which is parsed into an object that you can use anywhere deal.II accepts a [Function](classFunction.html) (for example, for interpolation, boundary conditions, etc.).\n\n```\n   #include <deal.II/base/parsed_function.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/matrix_tools.h>\n```\n\nThis is the last new entry for this tutorial program. The namespace [NonMatching](namespaceNonMatching.html) contains a few methods that are useful when performing computations on non-matching grids, or on curves that are not aligned with the underlying mesh.\n\nWe'll discuss its use in detail later on in the `setup_coupling` method.\n\n```\n   #include <deal.II/non_matching/coupling.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/sparse_direct.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/linear_operator.h>\n   #include <deal.II/lac/linear_operator_tools.h>\n   \n   #include <iostream>\n   #include <fstream>\n   \n   namespace Step60\n   {\n     using namespace dealii;\n```\n\n### DistributedLagrangeProblem\n\nIn the DistributedLagrangeProblem, we need two parameters describing the dimensions of the domain \\(\\Gamma\\) (`dim`) and of the domain \\(\\Omega\\) (`spacedim`).\n\nThese will be used to initialize a [Triangulation<dim,spacedim>](classTriangulation.html) (for \\(\\Gamma\\)) and a Triangulation<spacedim,spacedim> (for \\(\\Omega\\)).\n\nA novelty with respect to other tutorial programs is the heavy use of std::unique\\_ptr. These behave like classical pointers, with the advantage of doing automatic house-keeping: the contained object is automatically destroyed as soon as the unique\\_ptr goes out of scope, even if it is inside a container or there's an exception. Moreover it does not allow for duplicate pointers, which prevents ownership problems. We do this, because we want to be able to i) construct the problem, ii) read the parameters, and iii) initialize all objects according to what is specified in a parameter file.\n\nWe construct the parameters of our problem in the internal class `Parameters`, derived from [ParameterAcceptor](classParameterAcceptor.html). The `DistributedLagrangeProblem` class takes a const reference to a `Parameters` object, so that it is not possible to modify the parameters from within the DistributedLagrangeProblem class itself.\n\nWe could have initialized the parameters first, and then pass the parameters to the DistributedLagrangeProblem assuming all entries are set to the desired values, but this has two disadvantages:\n\n* We should not make assumptions on how the user initializes a class that is not under our direct control. If the user fails to initialize the class, we should notice and throw an exception;\n* Not all objects that need to read parameters from a parameter file may be available when we construct the Parameters; this is often the case for complex programs, with multiple physics, or where we reuse existing code in some external classes. We simulate this by keeping some \"complex\" objects, like ParsedFunction objects, inside the `DistributedLagrangeProblem` instead of inside the `Parameters`.\n\nHere we assume that upon construction, the classes that build up our problem are not usable yet. Parsing the parameter file is what ensures we have all ingredients to build up our classes, and we design them so that if parsing fails, or is not executed, the run is aborted.\n\n```\n     template <int dim, int spacedim = dim>\n     class DistributedLagrangeProblem\n     {\n     public:\n```\n\nThe `Parameters` class is derived from [ParameterAcceptor](classParameterAcceptor.html). This allows us to use the [ParameterAcceptor::add\\_parameter()](classParameterAcceptor.html#af2a534c7f1ea5bfa165fa8a469744a5d) method in its constructor.\n\nThe members of this function are all non-const, but the `DistributedLagrangeProblem` class takes a const reference to a `Parameters` object: this ensures that parameters are not modified from within the `DistributedLagrangeProblem` class.\n\n```\n       class Parameters : public ParameterAcceptor\n       {\n       public:\n         Parameters();\n```\n\nThe parameters now described can all be set externally using a parameter file: if no parameter file is present when running the executable, the program will create a \"parameters.prm\" file with the default values defined here, and then abort to give the user a chance to modify the parameters.prm file.\n\nInitial refinement for the embedding grid, corresponding to the domain \\(\\Omega\\).\n\n```\n         unsigned int initial_refinement = 4;\n```\n\nThe interaction between the embedded grid \\(\\Omega\\) and the embedding grid \\(\\Gamma\\) is handled through the computation of \\(C\\), which involves all cells of \\(\\Omega\\) overlapping with parts of \\(\\Gamma\\): a higher refinement of such cells might improve quality of our computations. For this reason we define `delta_refinement`: if it is greater than zero, then we mark each cell of the space grid that contains a vertex of the embedded grid and its neighbors, execute the refinement, and repeat this process `delta_refinement` times.\n\n```\n         unsigned int delta_refinement = 3;\n```\n\nStarting refinement of the embedded grid, corresponding to the domain \\(\\Gamma\\).\n\n```\n         unsigned int initial_embedded_refinement = 8;\n```\n\nThe list of boundary ids where we impose (possibly inhomogeneous) Dirichlet boundary conditions. On the remaining boundary ids (if any), we impose homogeneous Neumann boundary conditions. As a default problem we have zero Dirichlet boundary conditions on \\(\\partial \\Omega\\)\n\n```\n         std::list<types::boundary_id> dirichlet_ids{0, 1, 2, 3};\n```\n\n[FiniteElement](classFiniteElement.html) degree of the embedding space: \\(V\\_h(\\Omega)\\)\n\n```\n         unsigned int embedding_space_finite_element_degree = 1;\n```\n\n[FiniteElement](classFiniteElement.html) degree of the embedded space: \\(Q\\_h(\\Gamma)\\)\n\n```\n         unsigned int embedded_space_finite_element_degree = 1;\n```\n\n[FiniteElement](classFiniteElement.html) degree of the space used to describe the deformation of the embedded domain\n\n```\n         unsigned int embedded_configuration_finite_element_degree = 1;\n```\n\nOrder of the quadrature formula used to integrate the coupling\n\n```\n         unsigned int coupling_quadrature_order = 3;\n```\n\nIf set to true, then the embedded configuration function is interpreted as a displacement function\n\n```\n         bool use_displacement = false;\n```\n\nLevel of verbosity to use in the output\n\n```\n         unsigned int verbosity_level = 10;\n```\n\nA flag to keep track if we were initialized or not\n\n```\n         bool initialized = false;\n       };\n   \n       DistributedLagrangeProblem(const Parameters &parameters);\n```\n\nEntry point for the DistributedLagrangeProblem\n\n```\n       void run();\n   \n     private:\n```\n\nObject containing the actual parameters\n\n```\n       const Parameters &parameters;\n```\n\nThe following functions are similar to all other tutorial programs, with the exception that we now need to set up things for two different families of objects, namely the ones related to the *embedding* grids, and the ones related to the *embedded* one.\n\n```\n       void setup_grids_and_dofs();\n   \n       void setup_embedding_dofs();\n   \n       void setup_embedded_dofs();\n```\n\nThe only unconventional function we have here is the `setup_coupling()` method, used to generate the sparsity pattern for the coupling matrix \\(C\\).\n\n```\n       void setup_coupling();\n   \n       void assemble_system();\n   \n       void solve();\n   \n       void output_results();\n```\n\nfirst we gather all the objects related to the embedding space geometry\n\n```\n       std::unique_ptr<Triangulation<spacedim>> space_grid;\n       std::unique_ptr<GridTools::Cache<spacedim, spacedim>>\n                                                space_grid_tools_cache;\n       std::unique_ptr<FiniteElement<spacedim>> space_fe;\n       std::unique_ptr<DoFHandler<spacedim>>    space_dh;\n```\n\nThen the ones related to the embedded grid, with the [DoFHandler](classDoFHandler.html) associated to the Lagrange multiplier `lambda`\n\n```\n       std::unique_ptr<Triangulation<dim, spacedim>> embedded_grid;\n       std::unique_ptr<FiniteElement<dim, spacedim>> embedded_fe;\n       std::unique_ptr<DoFHandler<dim, spacedim>>    embedded_dh;\n```\n\nAnd finally, everything that is needed to *deform* the embedded triangulation\n\n```\n       std::unique_ptr<FiniteElement<dim, spacedim>> embedded_configuration_fe;\n       std::unique_ptr<DoFHandler<dim, spacedim>>    embedded_configuration_dh;\n       Vector<double>                                embedded_configuration;\n```\n\nThe [ParameterAcceptorProxy](classParameterAcceptorProxy.html) class is a \"transparent\" wrapper derived from both [ParameterAcceptor](classParameterAcceptor.html) and the type passed as its template parameter. At construction, the arguments are split into two parts: the first argument is an std::string, forwarded to the [ParameterAcceptor](classParameterAcceptor.html) class, and containing the name of the section that should be used for this class, while all the remaining arguments are forwarded to the constructor of the templated type, in this case, to the [Functions::ParsedFunction](classFunctions_1_1ParsedFunction.html) constructor.\n\nThis class allows you to use existing classes in conjunction with the [ParameterAcceptor](classParameterAcceptor.html) registration mechanism, provided that those classes have the members `declare_parameters()` and `parse_parameters()`.\n\nThis is the case here, making it fairly easy to exploit the [Functions::ParsedFunction](classFunctions_1_1ParsedFunction.html) class: instead of requiring users to create new [Function](classFunction.html) objects in their code for the RHS, boundary functions, etc., (like it is done in most of the other tutorials), here we allow the user to use deal.II interface to muParser (<http://muparser.beltoforion.de>), where the specification of the function is not done at compile time, but at run time, using a string that is parsed into an actual [Function](classFunction.html) object.\n\nIn this case, the `embedded_configuration_function` is a vector valued [Function](classFunction.html) that can be interpreted as either a *deformation* or a *displacement* according to the boolean value of `parameters.use_displacement`. The number of components is specified later on in the construction.\n\n```\n       ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n         embedded_configuration_function;\n   \n       std::unique_ptr<Mapping<dim, spacedim>> embedded_mapping;\n```\n\nWe do the same thing to specify the value of the forcing term \\(f\\). In this case the [Function](classFunction.html) is a scalar one.\n\n```\n       ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n         embedding_rhs_function;\n```\n\nThen, we specify the value of the function \\(g\\), which is what we want our solution to be in the embedded space. Again, in this case the [Function](classFunction.html) is a scalar one.\n\n```\n       ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n         embedded_value_function;\n```\n\nFinally, the value of the Dirichlet boundary conditions on \\(\\partial\n\\Omega\\) is specified.\n\n```\n       ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n         embedding_dirichlet_boundary_function;\n```\n\nSimilarly to what we have done with the [Functions::ParsedFunction](classFunctions_1_1ParsedFunction.html) class, we repeat the same for the [ReductionControl](classReductionControl.html) class, allowing us to specify all possible stopping criteria for the Schur complement iterative solver we'll use later on.\n\n```\n       ParameterAcceptorProxy<ReductionControl> schur_solver_control;\n```\n\nNext we gather all [SparsityPattern](classSparsityPattern.html), [SparseMatrix](classSparseMatrix.html), and [Vector](classVector.html) objects we'll need\n\n```\n       SparsityPattern stiffness_sparsity;\n       SparsityPattern coupling_sparsity;\n   \n       SparseMatrix<double> stiffness_matrix;\n       SparseMatrix<double> coupling_matrix;\n   \n       AffineConstraints<double> constraints;\n   \n       Vector<double> solution;\n       Vector<double> embedding_rhs;\n   \n       Vector<double> lambda;\n       Vector<double> embedded_rhs;\n       Vector<double> embedded_value;\n```\n\nThe [TimerOutput](classTimerOutput.html) class is used to provide some statistics on the performance of our program.\n\n```\n       TimerOutput monitor;\n     };\n```\n\n### DistributedLagrangeProblem::Parameters\n\nAt construction time, we initialize also the [ParameterAcceptor](classParameterAcceptor.html) class, with the section name we want our problem to use when parsing the parameter file.\n\nParameter files can be organized into section/subsection/etc.: this has the advantage that defined objects share parameters when sharing the same section/subsection/etc. [ParameterAcceptor](classParameterAcceptor.html) allows to specify the section name using Unix conventions on paths. If the section name starts with a slash (\"/\"), then the section is interpreted as an *absolute path*, [ParameterAcceptor](classParameterAcceptor.html) enters a subsection for each directory in the path, using the last name it encountered as the landing subsection for the current class.\n\nFor example, if you construct your class using `ParameterAcceptor(\"/first/second/third/My Class\")`, the parameters will be organized as follows:\n\n```\n# Example parameter file\nsubsection first\n  subsection second\n    subsection third\n      subsection My Class\n       ... # all the parameters\n      end\n    end\n  end\nend\n```\n\nInternally, the *current path* stored in [ParameterAcceptor](classParameterAcceptor.html) is now considered to be \"/first/second/third/\", i.e. when you specify an absolute path, [ParameterAcceptor](classParameterAcceptor.html) *changes* the current section to the current path, i.e. to the path of the section name until the *last* \"/\".\n\nYou can now construct another class derived from [ParameterAcceptor](classParameterAcceptor.html) using a relative path (e.g., `ParameterAcceptor(\"My Other Class\")`) instead of the absolute one (e.g. `ParameterAcceptor(\"/first/second/third/My Other\nClass\")`), obtaining:\n\n```\n# Example parameter file\nsubsection first\n  subsection second\n    subsection third\n      subsection My Class\n        ... # all the parameters\n      end\n      subsection My Other Class\n        ... # all the parameters of MyOtherClass\n      end\n    end\n  end\nend\n```\n\nIf the section name *ends* with a slash then subsequent classes will interpret this as a full path: for example, similar to the one above, if we have two classes, one initialized with `ParameterAcceptor(\"/first/second/third/My Class/\")` and the other with `ParameterAcceptor(\"My Other Class\")`, then the resulting parameter file will look like:\n\n```\n# Example parameter file\nsubsection first\n  subsection second\n    subsection third\n      subsection My Class\n        ... # all the parameters of MyClass\n        ... # notice My Class subsection does not end here\n        subsection My Other Class\n          ... # all the parameters of MyOtherClass\n        end # of subsection My Other Class\n      end # of subsection My Class\n    end\n  end\nend\n```\n\nWe are going to exploit this, by making our `Parameters` the *parent* of all subsequently constructed classes. Since most of the other classes are members of `DistributedLagrangeProblem` this allows, for example, to construct two `DistributedLagrangeProblem` for two different dimensions, without having conflicts in the parameters for the two problems.\n\n```\n     template <int dim, int spacedim>\n     DistributedLagrangeProblem<dim, spacedim>::Parameters::Parameters()\n       : ParameterAcceptor(\"/Distributed Lagrange<\" +\n                           Utilities::int_to_string(dim) + \",\" +\n                           Utilities::int_to_string(spacedim) + \">/\")\n     {\n```\n\nThe [ParameterAcceptor::add\\_parameter()](classParameterAcceptor.html#af2a534c7f1ea5bfa165fa8a469744a5d) function does a few things:\n\n* enters the subsection specified at construction time to [ParameterAcceptor](classParameterAcceptor.html)\n* calls the ParameterAcceptor::prm.add\\_parameter() function\n* calls any signal you may have attached to [ParameterAcceptor::declare\\_parameters\\_call\\_back](classParameterAcceptor.html#a1704a7098e692599c254a14c15ab05d2)\n* leaves the subsection\n\nIn turn, ParameterAcceptor::prm.add\\_parameter\n\n* declares an entry in the parameter handler for the given variable;\n* takes the current value of the variable\n* transforms it to a string, used as the default value for the parameter file\n* attaches an *action* to [ParameterAcceptor::prm](classParameterAcceptor.html#a96081d4cc985b722c9841fcf0c0e54ec) that monitors when a file is parsed, or when an entry is set, and when this happens, it updates the value of the variable passed to `add_parameter()` by setting it to whatever was specified in the input file (of course, after the input file has been parsed and the text representation converted to the type of the variable).\n\n```\n       add_parameter(\"Initial embedding space refinement\", initial_refinement);\n   \n       add_parameter(\"Initial embedded space refinement\",\n                     initial_embedded_refinement);\n   \n       add_parameter(\"Local refinements steps near embedded domain\",\n                     delta_refinement);\n   \n       add_parameter(\"Dirichlet boundary ids\", dirichlet_ids);\n   \n       add_parameter(\"Use displacement in embedded interface\", use_displacement);\n   \n       add_parameter(\"Embedding space finite element degree\",\n                     embedding_space_finite_element_degree);\n   \n       add_parameter(\"Embedded space finite element degree\",\n                     embedded_space_finite_element_degree);\n   \n       add_parameter(\"Embedded configuration finite element degree\",\n                     embedded_configuration_finite_element_degree);\n   \n       add_parameter(\"Coupling quadrature order\", coupling_quadrature_order);\n   \n       add_parameter(\"Verbosity level\", verbosity_level);\n```\n\nOnce the parameter file has been parsed, then the parameters are good to go. Set the internal variable `initialized` to true.\n\n```\n       parse_parameters_call_back.connect([&]() -> void { initialized = true; });\n     }\n```\n\nThe constructor is pretty standard, with the exception of the `ParameterAcceptorProxy` objects, as explained earlier.\n\n```\n     template <int dim, int spacedim>\n     DistributedLagrangeProblem<dim, spacedim>::DistributedLagrangeProblem(\n       const Parameters &parameters)\n       : parameters(parameters)\n       , embedded_configuration_function(\"Embedded configuration\", spacedim)\n       , embedding_rhs_function(\"Embedding rhs function\")\n       , embedded_value_function(\"Embedded value\")\n       , embedding_dirichlet_boundary_function(\n           \"Embedding Dirichlet boundary conditions\")\n       , schur_solver_control(\"Schur solver control\")\n       , monitor(std::cout, TimerOutput::summary, TimerOutput::cpu_and_wall_times)\n     {\n```\n\nHere is a way to set default values for a [ParameterAcceptor](classParameterAcceptor.html) class that was constructed using [ParameterAcceptorProxy](classParameterAcceptorProxy.html).\n\nIn this case, we set the default deformation of the embedded grid to be a circle with radius \\(R\\) and center \\((Cx, Cy)\\), we set the default value for the embedded\\_value\\_function to be the constant one, and specify some sensible values for the [SolverControl](classSolverControl.html) object.\n\nIt is fundamental for \\(\\Gamma\\) to be embedded: from the definition of \\(C\\_{\\alpha j}\\) is clear that, if \\(\\Gamma \\not\\subseteq \\Omega\\), certain rows of the matrix \\(C\\) will be zero. This would be a problem, as the Schur complement method requires \\(C\\) to have full column rank.\n\n```\n       embedded_configuration_function.declare_parameters_call_back.connect(\n         []() -> void {\n           ParameterAcceptor::prm.set(\"Function constants\", \"R=.3, Cx=.4, Cy=.4\");\n   \n   \n           ParameterAcceptor::prm.set(\"Function expression\",\n                                      \"R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy\");\n         });\n   \n       embedding_rhs_function.declare_parameters_call_back.connect(\n         []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"0\"); });\n   \n       embedded_value_function.declare_parameters_call_back.connect(\n         []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"1\"); });\n   \n       embedding_dirichlet_boundary_function.declare_parameters_call_back.connect(\n         []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"0\"); });\n   \n       schur_solver_control.declare_parameters_call_back.connect([]() -> void {\n         ParameterAcceptor::prm.set(\"Max steps\", \"1000\");\n         ParameterAcceptor::prm.set(\"Reduction\", \"1.e-12\");\n         ParameterAcceptor::prm.set(\"Tolerance\", \"1.e-12\");\n       });\n     }\n```\n\n### Set up\n\nThe function `DistributedLagrangeProblem::setup_grids_and_dofs()` is used to set up the finite element spaces. Notice how `std::make_unique` is used to create objects wrapped inside `std::unique_ptr` objects.\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::setup_grids_and_dofs()\n     {\n       TimerOutput::Scope timer_section(monitor, \"Setup grids and dofs\");\n```\n\nInitializing \\(\\Omega\\): constructing the [Triangulation](classTriangulation.html) and wrapping it into a `std::unique_ptr` object\n\n```\n       space_grid = std::make_unique<Triangulation<spacedim>>();\n```\n\nNext, we actually create the triangulation using [GridGenerator::hyper\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403). The last argument is set to true: this activates colorization (i.e., assigning different boundary indicators to different parts of the boundary), which we use to assign the Dirichlet and Neumann conditions.\n\n```\n       GridGenerator::hyper_cube(*space_grid, 0, 1, true);\n```\n\nOnce we constructed a [Triangulation](classTriangulation.html), we refine it globally according to the specifications in the parameter file, and construct a [GridTools::Cache](classGridTools_1_1Cache.html) with it.\n\n```\n       space_grid->refine_global(parameters.initial_refinement);\n       space_grid_tools_cache =\n         std::make_unique<GridTools::Cache<spacedim, spacedim>>(*space_grid);\n```\n\nThe same is done with the embedded grid. Since the embedded grid is deformed, we first need to set up the deformation mapping. We do so in the following few lines:\n\n```\n       embedded_grid = std::make_unique<Triangulation<dim, spacedim>>();\n       GridGenerator::hyper_cube(*embedded_grid);\n       embedded_grid->refine_global(parameters.initial_embedded_refinement);\n   \n       embedded_configuration_fe = std::make_unique<FESystem<dim, spacedim>>(\n         FE_Q<dim, spacedim>(\n           parameters.embedded_configuration_finite_element_degree) ^\n         spacedim);\n   \n       embedded_configuration_dh =\n         std::make_unique<DoFHandler<dim, spacedim>>(*embedded_grid);\n   \n       embedded_configuration_dh->distribute_dofs(*embedded_configuration_fe);\n       embedded_configuration.reinit(embedded_configuration_dh->n_dofs());\n```\n\nOnce we have defined a finite dimensional space for the deformation, we interpolate the `embedded_configuration_function` defined in the parameter file :\n\n```\n       VectorTools::interpolate(*embedded_configuration_dh,\n                                embedded_configuration_function,\n                                embedded_configuration);\n```\n\nNow we can interpret it according to what the user has specified in the parameter file: as a displacement, in which case we construct a mapping that *displaces* the position of each support point of our configuration finite element space by the specified amount on the corresponding configuration vector, or as an absolution position.\n\nIn the first case, the class [MappingQEulerian](classMappingQEulerian.html) offers its services, while in the second one, we'll use the class [MappingFEField](classMappingFEField.html). They are in fact very similar. [MappingQEulerian](classMappingQEulerian.html) will only work for systems of [FE\\_Q](classFE__Q.html) finite element spaces, where the displacement vector is stored in the first `spacedim` components of the [FESystem](classFESystem.html), and the degree given as a parameter at construction time, must match the degree of the first `spacedim` components.\n\nThe class [MappingFEField](classMappingFEField.html) is slightly more general, in that it allows you to select arbitrary [FiniteElement](classFiniteElement.html) types when constructing your approximation. Naturally some choices may (or may not) make sense, according to the type of [FiniteElement](classFiniteElement.html) you choose. [MappingFEField](classMappingFEField.html) implements the pure iso-parametric concept, and can be used, for example, to implement iso-geometric analysis codes in deal.II, by combining it with the [FE\\_Bernstein](classFE__Bernstein.html) finite element class. In this example, we'll use the two interchangeably, by taking into account the fact that one configuration will be a `displacement`, while the other will be an absolute `deformation` field.\n\n```\n       if (parameters.use_displacement == true)\n         embedded_mapping =\n           std::make_unique<MappingQEulerian<dim, Vector<double>, spacedim>>(\n             parameters.embedded_configuration_finite_element_degree,\n             *embedded_configuration_dh,\n             embedded_configuration);\n       else\n         embedded_mapping =\n           std::make_unique<MappingFEField<dim, spacedim, Vector<double>>>(\n             *embedded_configuration_dh, embedded_configuration);\n   \n       setup_embedded_dofs();\n```\n\nIn this tutorial program we not only refine \\(\\Omega\\) globally, but also allow a local refinement depending on the position of \\(\\Gamma\\), according to the value of `parameters.delta_refinement`, that we use to decide how many rounds of local refinement we should do on \\(\\Omega\\), corresponding to the position of \\(\\Gamma\\).\n\nWith the mapping in place, it is now possible to query what is the location of all support points associated with the `embedded_dh`, by calling the method [DoFTools::map\\_dofs\\_to\\_support\\_points()](namespaceDoFTools.html#a621c66a6f7e56cb56faac0e64014ece8).\n\nThis method has two variants. One that does *not* take a [Mapping](classMapping.html \"Abstract base class for mapping classes.\"), and one that takes a [Mapping](classMapping.html \"Abstract base class for mapping classes.\"). If you use the second type, like we are doing in this case, the support points are computed through the specified mapping, which can manipulate them accordingly.\n\nThis is precisely what the `embedded_mapping` is there for.\n\n```\n       std::vector<Point<spacedim>> support_points(embedded_dh->n_dofs());\n       if (parameters.delta_refinement != 0)\n         DoFTools::map_dofs_to_support_points(*embedded_mapping,\n                                              *embedded_dh,\n                                              support_points);\n```\n\nOnce we have the support points of the embedded finite element space, we would like to identify what cells of the embedding space contain what support point, to get a chance at refining the embedding grid where it is necessary, i.e., where the embedded grid is. This can be done manually, by looping over each support point, and then calling the method [Mapping::transform\\_real\\_to\\_unit\\_cell](classMapping.html#a7e322d14c2800734d071a48a95b00d35) for each cell of the embedding space, until we find one that returns points in the unit reference cell, or it can be done in a more intelligent way.\n\nThe [GridTools::find\\_active\\_cell\\_around\\_point](namespaceGridTools.html#a2e10aeb1c8e76110a84b6945eac3aaf0) is a possible option that performs the above task in a cheaper way, by first identifying the closest vertex of the embedding [Triangulation](classTriangulation.html) to the target point, and then by calling [Mapping::transform\\_real\\_to\\_unit\\_cell](classMapping.html#a7e322d14c2800734d071a48a95b00d35) only for those cells that share the found vertex.\n\nIn fact, there are algorithms in the [GridTools](namespaceGridTools.html) namespace that exploit a [GridTools::Cache](classGridTools_1_1Cache.html) object, and possibly a KDTree object to speed up these operations as much as possible.\n\nThe simplest way to exploit the maximum speed is by calling a specialized method, [GridTools::compute\\_point\\_locations](namespaceGridTools.html#a1da30ea67372da8ebd81de2becf06f1c), that will store a lot of useful information and data structures during the first point search, and then reuse all of this for subsequent points.\n\n[GridTools::compute\\_point\\_locations](namespaceGridTools.html#a1da30ea67372da8ebd81de2becf06f1c) returns a tuple where the first element is a vector of cells containing the input points, in this case support\\_points. For refinement, this is the only information we need, and this is exactly what happens now.\n\nWhen we need to assemble a coupling matrix, however, we'll also need the reference location of each point to evaluate the basis functions of the embedding space. The other elements of the tuple returned by [GridTools::compute\\_point\\_locations](namespaceGridTools.html#a1da30ea67372da8ebd81de2becf06f1c) allow you to reconstruct, for each point, what cell contains it, and what is the location in the reference cell of the given point. Since this information is better grouped into cells, then this is what the algorithm returns: a tuple, containing a vector of all cells that have at least one point in them, together with a list of all reference points and their corresponding index in the original vector.\n\nIn the following loop, we will be ignoring all returned objects except the first, identifying all cells contain at least one support point of the embedded space. This allows for a simple adaptive refinement strategy: refining these cells and their neighbors.\n\nNotice that we need to do some sanity checks, in the sense that we want to have an embedding grid which is well refined around the embedded grid, but where two consecutive support points lie either in the same cell, or in neighbor embedding cells.\n\nThis is only possible if we ensure that the smallest cell size of the embedding grid is nonetheless bigger than the largest cell size of the embedded grid. Since users can modify both levels of refinements, as well as the amount of local refinement they want around the embedded grid, we make sure that the resulting meshes satisfy our requirements, and if this is not the case, we bail out with an exception.\n\n```\n       for (unsigned int i = 0; i < parameters.delta_refinement; ++i)\n         {\n           const auto point_locations =\n             GridTools::compute_point_locations(*space_grid_tools_cache,\n                                                support_points);\n           const auto &cells = std::get<0>(point_locations);\n           for (auto &cell : cells)\n             {\n               cell->set_refine_flag();\n               for (const auto face_no : cell->face_indices())\n                 if (!cell->at_boundary(face_no))\n                   cell->neighbor(face_no)->set_refine_flag();\n             }\n           space_grid->execute_coarsening_and_refinement();\n         }\n```\n\nIn order to construct a well posed coupling interpolation operator \\(C\\), there are some constraints on the relative dimension of the grids between the embedding and the embedded domains. The coupling operator \\(C\\) and the spaces \\(V\\) and \\(Q\\) have to satisfy an inf-sup condition in order for the problem to have a solution. It turns out that the non-matching \\(L^2\\) projection satisfies such inf-sup, provided that the spaces \\(V\\) and \\(Q\\) are compatible between each other (for example, provided that they are chosen to be the ones described in the introduction).\n\nHowever, the *discrete* inf-sup condition must also hold. No complications arise here, but it turns out that the discrete inf-sup constant deteriorates when the non-matching grids have local diameters that are too far away from each other. In particular, it turns out that if you choose an embedding grid which is *finer* with respect to the embedded grid, the inf-sup constant deteriorates much more than if you let the embedded grid be finer.\n\nIn order to avoid issues, in this tutorial we will throw an exception if the parameters chosen by the user are such that the maximal diameter of the embedded grid is greater than the minimal diameter of the embedding grid.\n\nThis choice guarantees that almost every cell of the embedded grid spans no more than two cells of the embedding grid, with some rare exceptions, that are negligible in terms of the resulting inf-sup.\n\n```\n       const double embedded_space_maximal_diameter =\n         GridTools::maximal_cell_diameter(*embedded_grid, *embedded_mapping);\n       double embedding_space_minimal_diameter =\n         GridTools::minimal_cell_diameter(*space_grid);\n   \n       deallog << \"Embedding minimal diameter: \"\n               << embedding_space_minimal_diameter\n               << \", embedded maximal diameter: \"\n               << embedded_space_maximal_diameter << \", ratio: \"\n               << embedded_space_maximal_diameter /\n                    embedding_space_minimal_diameter\n               << std::endl;\n   \n       AssertThrow(embedded_space_maximal_diameter <\n                     embedding_space_minimal_diameter,\n                   ExcMessage(\n                     \"The embedding grid is too refined (or the embedded grid \"\n                     \"is too coarse). Adjust the parameters so that the minimal \"\n                     \"grid size of the embedding grid is larger \"\n                     \"than the maximal grid size of the embedded grid.\"));\n```\n\n\\(\\Omega\\) has been refined and we can now set up its DoFs\n\n```\n       setup_embedding_dofs();\n     }\n```\n\nWe now set up the DoFs of \\(\\Omega\\) and \\(\\Gamma\\): since they are fundamentally independent (except for the fact that \\(\\Omega\\)'s mesh is more refined \"around\" \\(\\Gamma\\)) the procedure is standard.\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::setup_embedding_dofs()\n     {\n       space_dh = std::make_unique<DoFHandler<spacedim>>(*space_grid);\n       space_fe = std::make_unique<FE_Q<spacedim>>(\n         parameters.embedding_space_finite_element_degree);\n       space_dh->distribute_dofs(*space_fe);\n   \n       DoFTools::make_hanging_node_constraints(*space_dh, constraints);\n       for (const types::boundary_id id : parameters.dirichlet_ids)\n         {\n           VectorTools::interpolate_boundary_values(\n             *space_dh, id, embedding_dirichlet_boundary_function, constraints);\n         }\n       constraints.close();\n```\n\nBy definition the stiffness matrix involves only \\(\\Omega\\)'s DoFs\n\n```\n       DynamicSparsityPattern dsp(space_dh->n_dofs(), space_dh->n_dofs());\n       DoFTools::make_sparsity_pattern(*space_dh, dsp, constraints);\n       stiffness_sparsity.copy_from(dsp);\n       stiffness_matrix.reinit(stiffness_sparsity);\n       solution.reinit(space_dh->n_dofs());\n       embedding_rhs.reinit(space_dh->n_dofs());\n   \n       deallog << \"Embedding dofs: \" << space_dh->n_dofs() << std::endl;\n     }\n   \n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::setup_embedded_dofs()\n     {\n       embedded_dh = std::make_unique<DoFHandler<dim, spacedim>>(*embedded_grid);\n       embedded_fe = std::make_unique<FE_Q<dim, spacedim>>(\n         parameters.embedded_space_finite_element_degree);\n       embedded_dh->distribute_dofs(*embedded_fe);\n```\n\nBy definition the rhs of the system we're solving involves only a zero vector and \\(G\\), which is computed using only \\(\\Gamma\\)'s DoFs\n\n```\n       lambda.reinit(embedded_dh->n_dofs());\n       embedded_rhs.reinit(embedded_dh->n_dofs());\n       embedded_value.reinit(embedded_dh->n_dofs());\n   \n       deallog << \"Embedded dofs: \" << embedded_dh->n_dofs() << std::endl;\n     }\n```\n\nCreating the coupling sparsity pattern is a complex operation, but it can be easily done using the [NonMatching::create\\_coupling\\_sparsity\\_pattern](namespaceNonMatching.html#a1203169e2ff87177be7c46ca849cf371), which requires the two [DoFHandler](classDoFHandler.html) objects, the quadrature points for the coupling, a [DynamicSparsityPattern](classDynamicSparsityPattern.html) (which then needs to be copied into the sparsity one, as usual), the component mask for the embedding and embedded [Triangulation](classTriangulation.html) (which we leave empty) and the mappings for both the embedding and the embedded [Triangulation](classTriangulation.html).\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::setup_coupling()\n     {\n       TimerOutput::Scope timer_section(monitor, \"Setup coupling\");\n   \n       const QGauss<dim> quad(parameters.coupling_quadrature_order);\n   \n       DynamicSparsityPattern dsp(space_dh->n_dofs(), embedded_dh->n_dofs());\n   \n       NonMatching::create_coupling_sparsity_pattern(*space_grid_tools_cache,\n                                                     *space_dh,\n                                                     *embedded_dh,\n                                                     quad,\n                                                     dsp,\n                                                     AffineConstraints<double>(),\n                                                     ComponentMask(),\n                                                     ComponentMask(),\n                                                     *embedded_mapping);\n       coupling_sparsity.copy_from(dsp);\n       coupling_matrix.reinit(coupling_sparsity);\n     }\n```\n\n### Assembly\n\nThe following function creates the matrices: as noted before computing the stiffness matrix and the rhs is a standard procedure.\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::assemble_system()\n     {\n       {\n         TimerOutput::Scope timer_section(monitor, \"Assemble system\");\n```\n\nEmbedding stiffness matrix \\(K\\) and right hand sides \\(F\\) and \\(G\\).\n\n```\n         MatrixTools::create_laplace_matrix(\n           *space_dh,\n           QGauss<spacedim>(2 * space_fe->degree + 1),\n           stiffness_matrix,\n           embedding_rhs_function,\n           embedding_rhs,\n           static_cast<const Function<spacedim> *>(nullptr),\n           constraints);\n   \n         VectorTools::create_right_hand_side(*embedded_mapping,\n                                             *embedded_dh,\n                                             QGauss<dim>(2 * embedded_fe->degree +\n                                                         1),\n                                             embedded_value_function,\n                                             embedded_rhs);\n       }\n       {\n         TimerOutput::Scope timer_section(monitor, \"Assemble coupling system\");\n```\n\nTo compute the coupling matrix we use the [NonMatching::create\\_coupling\\_mass\\_matrix](namespaceNonMatching.html#a6e1f6762bf58daadf522cae5947050c3) tool, which works similarly to [NonMatching::create\\_coupling\\_sparsity\\_pattern](namespaceNonMatching.html#a1203169e2ff87177be7c46ca849cf371).\n\n```\n         const QGauss<dim> quad(parameters.coupling_quadrature_order);\n         NonMatching::create_coupling_mass_matrix(*space_grid_tools_cache,\n                                                  *space_dh,\n                                                  *embedded_dh,\n                                                  quad,\n                                                  coupling_matrix,\n                                                  AffineConstraints<double>(),\n                                                  ComponentMask(),\n                                                  ComponentMask(),\n                                                  *embedded_mapping);\n   \n         VectorTools::interpolate(*embedded_mapping,\n                                  *embedded_dh,\n                                  embedded_value_function,\n                                  embedded_value);\n       }\n     }\n```\n\n### Solve\n\nAll parts have been assembled: we solve the system using the Schur complement method\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::solve()\n     {\n       TimerOutput::Scope timer_section(monitor, \"Solve system\");\n```\n\nStart by creating the inverse stiffness matrix\n\n```\n       SparseDirectUMFPACK K_inv_umfpack;\n       K_inv_umfpack.initialize(stiffness_matrix);\n```\n\nInitializing the operators, as described in the introduction\n\n```\n       auto K  = linear_operator(stiffness_matrix);\n       auto Ct = linear_operator(coupling_matrix);\n       auto C  = transpose_operator(Ct);\n   \n       auto K_inv = linear_operator(K, K_inv_umfpack);\n```\n\nUsing the Schur complement method\n\n```\n       auto                     S = C * K_inv * Ct;\n       SolverCG<Vector<double>> solver_cg(schur_solver_control);\n       auto S_inv = inverse_operator(S, solver_cg, PreconditionIdentity());\n   \n       lambda = S_inv * (C * K_inv * embedding_rhs - embedded_rhs);\n   \n       solution = K_inv * (embedding_rhs - Ct * lambda);\n   \n       constraints.distribute(solution);\n     }\n```\n\nThe following function simply generates standard result output on two separate files, one for each mesh.\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::output_results()\n     {\n       TimerOutput::Scope timer_section(monitor, \"Output results\");\n   \n       DataOut<spacedim> embedding_out;\n   \n       std::ofstream embedding_out_file(\"embedding.vtu\");\n   \n       embedding_out.attach_dof_handler(*space_dh);\n       embedding_out.add_data_vector(solution, \"solution\");\n       embedding_out.build_patches(\n         parameters.embedding_space_finite_element_degree);\n       embedding_out.write_vtu(embedding_out_file);\n```\n\nThe only difference between the two output routines is that in the second case, we want to output the data on the current configuration, and not on the reference one. This is possible by passing the actual embedded\\_mapping to the [DataOut::build\\_patches](classDataOut.html#a087f63e22f0614bca326dbdca288c646) function. The mapping will take care of outputting the result on the actual deformed configuration.\n\n```\n       DataOut<dim, spacedim> embedded_out;\n   \n       std::ofstream embedded_out_file(\"embedded.vtu\");\n   \n       embedded_out.attach_dof_handler(*embedded_dh);\n       embedded_out.add_data_vector(lambda, \"lambda\");\n       embedded_out.add_data_vector(embedded_value, \"g\");\n       embedded_out.build_patches(*embedded_mapping,\n                                  parameters.embedded_space_finite_element_degree);\n       embedded_out.write_vtu(embedded_out_file);\n     }\n```\n\nSimilar to all other tutorial programs, the `run()` function simply calls all other methods in the correct order. Nothing special to note, except that we check if parsing was done before we actually attempt to run our program.\n\n```\n     template <int dim, int spacedim>\n     void DistributedLagrangeProblem<dim, spacedim>::run()\n     {\n       AssertThrow(parameters.initialized, ExcNotInitialized());\n       deallog.depth_console(parameters.verbosity_level);\n   \n       setup_grids_and_dofs();\n       setup_coupling();\n       assemble_system();\n       solve();\n       output_results();\n     }\n   } // namespace Step60\n   \n   \n   \n   int main(int argc, char **argv)\n   {\n     try\n       {\n         using namespace dealii;\n         using namespace Step60;\n   \n         const unsigned int dim = 1, spacedim = 2;\n```\n\nDifferently to what happens in other tutorial programs, here we use [ParameterAcceptor](classParameterAcceptor.html) style of initialization, i.e., all objects are first constructed, and then a single call to the static method [ParameterAcceptor::initialize](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) is issued to fill all parameters of the classes that are derived from [ParameterAcceptor](classParameterAcceptor.html).\n\nWe check if the user has specified a parameter file name to use when the program was launched. If so, try to read that parameter file, otherwise, try to read the file \"parameters.prm\".\n\nIf the parameter file that was specified (implicitly or explicitly) does not exist, [ParameterAcceptor::initialize](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) will create one for you, and exit the program.\n\n```\n         DistributedLagrangeProblem<dim, spacedim>::Parameters parameters;\n         DistributedLagrangeProblem<dim, spacedim>             problem(parameters);\n   \n         std::string parameter_file;\n         if (argc > 1)\n           parameter_file = argv[1];\n         else\n           parameter_file = \"parameters.prm\";\n   \n         ParameterAcceptor::initialize(parameter_file, \"used_parameters.prm\");\n         problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     return 0;\n   }\n```\n\nResults\n=======\n\nThe directory in which this program is run does not contain a parameter file by default. On the other hand, this program wants to read its parameters from a file called parameters.prm – and so, when you execute it the first time, you will get an exception that no such file can be found:\n\n```\n----------------------------------------------------\nException on processing:\n \n--------------------------------------------------------\nAn error occurred in line <74> of file <../source/base/parameter_acceptor.cc> in function\n static void ::ParameterAcceptor::initialize(const std::string &, const std::string &, const ParameterHandler::OutputStyle, ::ParameterHandler &)\nThe violated condition was:\n false\nAdditional information:\n    You specified <parameters.prm> as input parameter file, but it does not exist. We created it for you.\n--------------------------------------------------------\n \nAborting!\n----------------------------------------------------\n```\n\nHowever, as the error message already states, the code that triggers the exception will also generate a parameters.prm file that simply contains the default values for all parameters this program cares about. By inspection of the parameter file, we see the following:\n\n```\n# Listing of Parameters\n# ---------------------\nsubsection Distributed Lagrange<1,2>\n  set Coupling quadrature order                    = 3\n  set Dirichlet boundary ids                       = 0, 1, 2, 3\n  set Embedded configuration finite element degree = 1\n  set Embedded space finite element degree         = 1\n  set Embedding space finite element degree        = 1\n  set Initial embedded space refinement            = 8\n  set Initial embedding space refinement           = 4\n  set Local refinements steps near embedded domain = 3\n  set Use displacement in embedded interface       = false\n  set Verbosity level                              = 10\n \n \n  subsection Embedded configuration\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  = R=.3, Cx=.4, Cy=.4                 # default:\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy # default: 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \n  subsection Embedded value\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  =\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = 1     # default: 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \n  subsection Embedding Dirichlet boundary conditions\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  =\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \n  subsection Embedding rhs function\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  =\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \n  subsection Schur solver control\n    set Log frequency = 1\n    set Log history   = false\n    set Log result    = true\n    set Max steps     = 1000   # default: 100\n    set Reduction     = 1.e-12 # default: 1.e-2\n    set Tolerance     = 1.e-12 # default: 1.e-10\n  end\n \nend\n```\n\nIf you now run the program, you will get a file called `used_parameters.prm`, containing a shorter version of the above parameters (without comments and documentation), documenting all parameters that were used to run your program:\n\n```\nsubsection Distributed Lagrange<1,2>\n  set Coupling quadrature order                    = 3\n  set Dirichlet boundary ids                       = 0, 1, 2, 3\n  set Embedded configuration finite element degree = 1\n  set Embedded space finite element degree         = 1\n  set Embedding space finite element degree        = 1\n  set Initial embedded space refinement            = 8\n  set Initial embedding space refinement           = 4\n  set Local refinements steps near embedded domain = 3\n  set Use displacement in embedded interface       = false\n  set Verbosity level                              = 10\n  subsection Embedded configuration\n    set Function constants  = R=.3, Cx=.4, Cy=.4\n    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy\n    set Variable names      = x,y,t\n  end\n  subsection Embedded value\n    set Function constants  =\n    set Function expression = 1\n    set Variable names      = x,y,t\n  end\n  subsection Embedding Dirichlet boundary conditions\n    set Function constants  =\n    set Function expression = 0\n    set Variable names      = x,y,t\n  end\n  subsection Embedding rhs function\n    set Function constants  =\n    set Function expression = 0\n    set Variable names      = x,y,t\n  end\n  subsection Schur solver control\n    set Log frequency = 1\n    set Log history   = false\n    set Log result    = true\n    set Max steps     = 1000\n    set Reduction     = 1.e-12\n    set Tolerance     = 1.e-12\n  end\nend\n```\n\nThe rationale behind creating first `parameters.prm` file (the first time the program is run) and then a `used_parameters.prm` (every other times you run the program), is because you may want to leave most parameters to their default values, and only modify a handful of them.\n\nFor example, you could use the following (perfectly valid) parameter file with this tutorial program:\n\n```\nsubsection Distributed Lagrange<1,2>\n  set Initial embedded space refinement            = 8\n  set Initial embedding space refinement           = 4\n  set Local refinements steps near embedded domain = 3\n  subsection Embedded configuration\n    set Function constants  = R=.3, Cx=.4, Cy=.4\n    set Function expression = R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy\n    set Variable names      = x,y,t\n  end\n  subsection Embedded value\n    set Function constants  =\n    set Function expression = 1\n    set Variable names      = x,y,t\n  end\n  subsection Embedding Dirichlet boundary conditions\n    set Function constants  =\n    set Function expression = 0\n    set Variable names      = x,y,t\n  end\n  subsection Embedding rhs function\n    set Function constants  =\n    set Function expression = 0\n    set Variable names      = x,y,t\n  end\nend\n```\n\nand you would obtain exactly the same results as in test case 1 below.\n\n### Test case 1:\n\nFor the default problem the value of \\(u\\) on \\(\\Gamma\\) is set to the constant \\(1\\): this is like imposing a constant Dirichlet boundary condition on \\(\\Gamma\\), seen as boundary of the portion of \\(\\Omega\\) inside \\(\\Gamma\\). Similarly on \\(\\partial\n\\Omega\\) we have zero Dirichlet boundary conditions.\n\n![](images/steps/developer/step-60.1_no_grid.png)\n\n![](images/steps/developer/step-60.1_grid.png)\n\nThe output of the program will look like the following:\n\n```\nDEAL::Embedded dofs: 257\nDEAL::Embedding minimal diameter: 0.0110485, embedded maximal diameter: 0.00736292, ratio: 0.666416\nDEAL::Embedding dofs: 2429\nDEAL:cg::Starting value 0.117692\nDEAL:cg::Convergence step 594 value 8.06558e-13\n \n \n+---------------------------------------------+------------+------------+\n| Total CPU time elapsed since start          |      1.48s |            |\n|                                             |            |            |\n| Section                         | no. calls |  CPU time  | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble coupling system        |         1 |    0.0381s |       2.6% |\n| Assemble system                 |         1 |     0.153s |        10% |\n| Output results                  |         1 |      0.11s |       7.4% |\n| Setup coupling                  |         1 |    0.0364s |       2.5% |\n| Setup grids and dofs            |         1 |     0.168s |        11% |\n| Solve system                    |         1 |     0.974s |        66% |\n+---------------------------------+-----------+------------+------------+\n \n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |     0.798s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble coupling system        |         1 |    0.0469s |       5.9% |\n| Assemble system                 |         1 |    0.0348s |       4.4% |\n| Output results                  |         1 |    0.0821s |        10% |\n| Setup coupling                  |         1 |    0.0371s |       4.7% |\n| Setup grids and dofs            |         1 |     0.157s |        20% |\n| Solve system                    |         1 |     0.436s |        55% |\n+---------------------------------+-----------+------------+------------+\n```\n\nIf the problem was set in a three-dimensional setting, and the immersed mesh was time dependent, it would be much more expensive to recreate the mesh at each step rather than use the technique we present here. Moreover, you may be able to create a very fast and optimized solver on a uniformly refined square or cubic grid, and embed the domain where you want to perform your computation using the technique presented here. This would require you to only have a surface representation of your domain (a much cheaper and easier mesh to produce).\n\nTo play around a little bit, we are going to complicate a little the fictitious domain as well as the boundary conditions we impose on it.\n\n### Test case 2 and 3:\n\nIf we use the following parameter file :\n\n```\nsubsection Distributed Lagrange<1,2>\n  set Coupling quadrature order                    = 3\n  set Embedded configuration finite element degree = 1\n  set Embedded space finite element degree         = 1\n  set Embedding space finite element degree        = 1\n  set Dirichlet boundary ids                       = 0,1,2,3\n  set Initial embedded space refinement            = 8\n  set Initial embedding space refinement           = 4\n  set Local refinements steps near embedded domain = 2\n  set Use displacement in embedded interface       = false\n  set Verbosity level                              = 10\n  subsection Embedded configuration\n    set Function constants  = R=.3, Cx=.5, Cy=.5, r=.1, w=12\n    set Function expression = (R+r*cos(w*pi*x))*cos(2*pi*x)+Cx; (R+r*cos(w*pi*x))*sin(2*pi*x)+Cy\n    set Variable names      = x,y,t\n  end\n  subsection Embedded value\n    set Function constants  =\n    set Function expression = x-.5\n    set Variable names      = x,y,t\n  end\n  subsection Embedding Dirichlet boundary conditions\n    set Function constants  =\n    set Function expression = 0\n    set Variable names      = x,y,t\n  end\n  subsection Embedding rhs function\n    set Function constants  =\n    set Function expression = 0.0\n    set Variable names      = x,y,t\n  end\n  subsection Schur solver control\n    set Log frequency = 1\n    set Log history   = false\n    set Log result    = true\n    set Max steps     = 1000\n    set Reduction     = 1.e-12\n    set Tolerance     = 1.e-12\n  end\nend\n```\n\nWe get a \"flowery\" looking domain, where we impose a linear boundary condition \\(g=x-.5\\). This test shows that the method is actually quite accurate in recovering an exactly linear function from its boundary conditions, and even though the meshes are not aligned, we obtain a pretty good result.\n\nReplacing \\(x-.5\\) with \\(2(x-.5)^2-2(y-.5)^2\\), i.e., modifying the parameter file such that we have\n\n```\n...\nsubsection Embedded value\n  set Function constants  =\n  set Function expression = 2*(x-.5)^2-2*(y-.5)^2\n  set Variable names      = x,y,t\nend\n```\n\nproduces the saddle on the right.\n\n![](images/steps/developer/step-60.3_grid.png)\n\n![](images/steps/developer/step-60.4_grid.png)\n\n### Possibilities for extensions\n\n#### Running with `spacedim` equal to three\n\nWhile the current tutorial program is written for `spacedim` equal to two, there are only minor changes you have to do in order for the program to run in different combinations of dimensions.\n\nIf you want to run with `spacedim` equal to three and `dim` equal to two, then you will almost certainly want to perform the following changes:\n\n* use a different reference domain for the embedded grid, maybe reading it from a file. It is not possible to construct a smooth closed surface with one single parametrization of a square domain, therefore you'll most likely want to use a reference domain that is topologically equivalent to a the boundary of a sphere.\n* use a displacement instead of the deformation to map \\(\\Gamma\\_0\\) into \\(\\Gamma\\)\n\n#### More general domains\n\nWe have seen in other tutorials (for example in [step-5](step_5.html) and [step-54](step_54.html)) how to read grids from input files. A nice generalization for this tutorial program would be to allow the user to select a grid to read from the parameter file itself, instead of hardcoding the mesh type in the tutorial program itself.\n\n#### Preconditioner\n\nAt the moment, we have no preconditioner on the Schur complement. This is ok for two dimensional problems, where a few hundred iterations bring the residual down to the machine precision, but it's not going to work in three dimensions.\n\nIt is not obvious what a good preconditioner would be here. The physical problem we are solving with the Schur complement, is to associate to the Dirichlet data \\(g\\), the value of the Lagrange multiplier \\(\\lambda\\). \\(\\lambda\\) can be interpreted as the *jump* in the normal gradient that needs to be imposed on \\(u\\) across \\(\\Gamma\\), in order to obtain the Dirichlet data \\(g\\).\n\nSo \\(S\\) is some sort of Neumann to Dirichlet map, and we would like to have a good approximation for the Dirichlet to Neumann map. A possibility would be to use a Boundary Element approximation of the problem on \\(\\Gamma\\), and construct a rough approximation of the hyper-singular operator for the Poisson problem associated to \\(\\Gamma\\), which is precisely a Dirichlet to Neumann map.\n\n#### Parallel Code\n\nThe simple code proposed here can serve as a starting point for more complex problems which, to be solved, need to be run on parallel code, possibly using distributed meshes (see [step-17](step_17.html), [step-40](step_40.html), and the documentation for [parallel::shared::Triangulation](classparallel_1_1shared_1_1Triangulation.html) and [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html)).\n\nWhen using non-matching grids in parallel a problem arises: to compute the matrix \\(C\\) a process needs information about both meshes on the same portion of real space but, when working with distributed meshes, this information may not be available, because the locally owned part of the \\(\\Omega\\) triangulation stored on a given processor may not be physically co-located with the locally owned part of the \\(\\Gamma\\) triangulation stored on the same processor.\n\nVarious strategies can be implemented to tackle this problem:\n\n* distribute the two meshes so that this constraint is satisfied;\n* use communication for the parts of real space where the constraint is not satisfied;\n* use a distributed triangulation for the embedding space, and a shared triangulation for the emdedded configuration.\n\nThe latter strategy is clearly the easiest to implement, as most of the functions used in this tutorial program will work unchanged also in the parallel case. Of course one could use the reversal strategy (that is, have a distributed embedded [Triangulation](classTriangulation.html) and a shared embedding [Triangulation](classTriangulation.html)).\n\nHowever, this strategy is most likely going to be more expensive, since by definition the embedding grid is larger than the embedded grid, and it makes more sense to distribute the largest of the two grids, maintaining the smallest one shared among all processors.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2018 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Luca Heltai, Giovanni Alzetta, International School for\n *            Advanced Studies, Trieste, 2018\n */\n \n \n#include <deal.II/base/logstream.h>\n#include <deal.II/base/utilities.h>\n#include <deal.II/base/timer.h>\n \n#include <deal.II/base/parameter_acceptor.h>\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_tools.h>\n \n#include <deal.II/grid/grid_tools_cache.h>\n \n#include <deal.II/fe/fe.h>\n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n \n#include <deal.II/fe/mapping_q_eulerian.h>\n#include <deal.II/fe/mapping_fe_field.h>\n \n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/base/parsed_function.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/matrix_tools.h>\n \n#include <deal.II/non_matching/coupling.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/sparse_direct.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/linear_operator.h>\n#include <deal.II/lac/linear_operator_tools.h>\n \n#include <iostream>\n#include <fstream>\n \nnamespace Step60\n{\n using namespace dealii;\n \n \n template <int dim, int spacedim = dim>\n class DistributedLagrangeProblem\n  {\n public:\n class Parameters : public ParameterAcceptor\n    {\n public:\n      Parameters();\n \n \n unsigned int initial_refinement = 4;\n \n unsigned int delta_refinement = 3;\n \n unsigned int initial_embedded_refinement = 8;\n \n      std::list<types::boundary_id> dirichlet_ids{0, 1, 2, 3};\n \n unsigned int embedding_space_finite_element_degree = 1;\n \n unsigned int embedded_space_finite_element_degree = 1;\n \n unsigned int embedded_configuration_finite_element_degree = 1;\n \n unsigned int coupling_quadrature_order = 3;\n \n bool use_displacement = false;\n \n unsigned int verbosity_level = 10;\n \n bool initialized = false;\n    };\n \n    DistributedLagrangeProblem(const Parameters &parameters);\n \n void run();\n \n private:\n const Parameters &parameters;\n \n \n void setup_grids_and_dofs();\n \n void setup_embedding_dofs();\n \n void setup_embedded_dofs();\n \n \n void setup_coupling();\n \n void assemble_system();\n \n void solve();\n \n void output_results();\n \n \n \n    std::unique_ptr<Triangulation<spacedim>> space_grid;\n    std::unique_ptr<GridTools::Cache<spacedim, spacedim>>\n                                             space_grid_tools_cache;\n    std::unique_ptr<FiniteElement<spacedim>> space_fe;\n    std::unique_ptr<DoFHandler<spacedim>>    space_dh;\n \n \n    std::unique_ptr<Triangulation<dim, spacedim>> embedded_grid;\n    std::unique_ptr<FiniteElement<dim, spacedim>> embedded_fe;\n    std::unique_ptr<DoFHandler<dim, spacedim>>    embedded_dh;\n \n    std::unique_ptr<FiniteElement<dim, spacedim>> embedded_configuration_fe;\n    std::unique_ptr<DoFHandler<dim, spacedim>>    embedded_configuration_dh;\n Vector<double>                                embedded_configuration;\n \n \n ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n      embedded_configuration_function;\n \n    std::unique_ptr<Mapping<dim, spacedim>> embedded_mapping;\n \n ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n      embedding_rhs_function;\n \n ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n      embedded_value_function;\n \n ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n      embedding_dirichlet_boundary_function;\n \n ParameterAcceptorProxy<ReductionControl> schur_solver_control;\n \n SparsityPattern stiffness_sparsity;\n SparsityPattern coupling_sparsity;\n \n SparseMatrix<double> stiffness_matrix;\n SparseMatrix<double> coupling_matrix;\n \n AffineConstraints<double> constraints;\n \n Vector<double> solution;\n Vector<double> embedding_rhs;\n \n Vector<double> lambda;\n Vector<double> embedded_rhs;\n Vector<double> embedded_value;\n \n TimerOutput monitor;\n  };\n \n template <int dim, int spacedim>\n  DistributedLagrangeProblem<dim, spacedim>::Parameters::Parameters()\n    : ParameterAcceptor(\"/Distributed Lagrange<\" +\n Utilities::int_to_string(dim) + \",\" +\n Utilities::int_to_string(spacedim) + \">/\")\n  {\n    add_parameter(\"Initial embedding space refinement\", initial_refinement);\n \n    add_parameter(\"Initial embedded space refinement\",\n                  initial_embedded_refinement);\n \n    add_parameter(\"Local refinements steps near embedded domain\",\n                  delta_refinement);\n \n    add_parameter(\"Dirichlet boundary ids\", dirichlet_ids);\n \n    add_parameter(\"Use displacement in embedded interface\", use_displacement);\n \n    add_parameter(\"Embedding space finite element degree\",\n                  embedding_space_finite_element_degree);\n \n    add_parameter(\"Embedded space finite element degree\",\n                  embedded_space_finite_element_degree);\n \n    add_parameter(\"Embedded configuration finite element degree\",\n                  embedded_configuration_finite_element_degree);\n \n    add_parameter(\"Coupling quadrature order\", coupling_quadrature_order);\n \n    add_parameter(\"Verbosity level\", verbosity_level);\n \n    parse_parameters_call_back.connect([&]() -> void { initialized = true; });\n  }\n \n template <int dim, int spacedim>\n  DistributedLagrangeProblem<dim, spacedim>::DistributedLagrangeProblem(\n const Parameters &parameters)\n    : parameters(parameters)\n    , embedded_configuration_function(\"Embedded configuration\", spacedim)\n    , embedding_rhs_function(\"Embedding rhs function\")\n    , embedded_value_function(\"Embedded value\")\n    , embedding_dirichlet_boundary_function(\n \"Embedding Dirichlet boundary conditions\")\n    , schur_solver_control(\"Schur solver control\")\n    , monitor(std::cout, TimerOutput::summary, TimerOutput::cpu_and_wall_times)\n  {\n    embedded_configuration_function.declare_parameters_call_back.connect(\n      []() -> void {\n ParameterAcceptor::prm.set(\"Function constants\", \"R=.3, Cx=.4, Cy=.4\");\n \n \n ParameterAcceptor::prm.set(\"Function expression\",\n \"R*cos(2*pi*x)+Cx; R*sin(2*pi*x)+Cy\");\n      });\n \n    embedding_rhs_function.declare_parameters_call_back.connect(\n      []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"0\"); });\n \n    embedded_value_function.declare_parameters_call_back.connect(\n      []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"1\"); });\n \n    embedding_dirichlet_boundary_function.declare_parameters_call_back.connect(\n      []() -> void { ParameterAcceptor::prm.set(\"Function expression\", \"0\"); });\n \n    schur_solver_control.declare_parameters_call_back.connect([]() -> void {\n ParameterAcceptor::prm.set(\"Max steps\", \"1000\");\n ParameterAcceptor::prm.set(\"Reduction\", \"1.e-12\");\n ParameterAcceptor::prm.set(\"Tolerance\", \"1.e-12\");\n    });\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::setup_grids_and_dofs()\n  {\n TimerOutput::Scope timer_section(monitor, \"Setup grids and dofs\");\n \n    space_grid = std::make_unique<Triangulation<spacedim>>();\n \n GridGenerator::hyper_cube(*space_grid, 0, 1, true);\n \n    space_grid->refine_global(parameters.initial_refinement);\n    space_grid_tools_cache =\n      std::make_unique<GridTools::Cache<spacedim, spacedim>>(*space_grid);\n \n    embedded_grid = std::make_unique<Triangulation<dim, spacedim>>();\n GridGenerator::hyper_cube(*embedded_grid);\n    embedded_grid->refine_global(parameters.initial_embedded_refinement);\n \n    embedded_configuration_fe = std::make_unique<FESystem<dim, spacedim>>(\n FE_Q<dim, spacedim>(\n        parameters.embedded_configuration_finite_element_degree) ^\n      spacedim);\n \n    embedded_configuration_dh =\n      std::make_unique<DoFHandler<dim, spacedim>>(*embedded_grid);\n \n    embedded_configuration_dh->distribute_dofs(*embedded_configuration_fe);\n    embedded_configuration.reinit(embedded_configuration_dh->n_dofs());\n \n VectorTools::interpolate(*embedded_configuration_dh,\n                             embedded_configuration_function,\n                             embedded_configuration);\n \n \n if (parameters.use_displacement == true)\n      embedded_mapping =\n        std::make_unique<MappingQEulerian<dim, Vector<double>, spacedim>>(\n          parameters.embedded_configuration_finite_element_degree,\n          *embedded_configuration_dh,\n          embedded_configuration);\n else\n      embedded_mapping =\n        std::make_unique<MappingFEField<dim, spacedim, Vector<double>>>(\n          *embedded_configuration_dh, embedded_configuration);\n \n    setup_embedded_dofs();\n \n    std::vector<Point<spacedim>> support_points(embedded_dh->n_dofs());\n if (parameters.delta_refinement != 0)\n DoFTools::map_dofs_to_support_points(*embedded_mapping,\n                                           *embedded_dh,\n                                           support_points);\n \n for (unsigned int i = 0; i < parameters.delta_refinement; ++i)\n      {\n const auto point_locations =\n GridTools::compute_point_locations(*space_grid_tools_cache,\n                                             support_points);\n const auto &cells = std::get<0>(point_locations);\n for (auto &cell : cells)\n          {\n            cell->set_refine_flag();\n for (const auto face_no : cell->face_indices())\n              if (!cell->at_boundary(face_no))\n                cell->neighbor(face_no)->set_refine_flag();\n          }\n        space_grid->execute_coarsening_and_refinement();\n      }\n \n const double embedded_space_maximal_diameter =\n GridTools::maximal_cell_diameter(*embedded_grid, *embedded_mapping);\n double embedding_space_minimal_diameter =\n GridTools::minimal_cell_diameter(*space_grid);\n \n deallog << \"Embedding minimal diameter: \"\n            << embedding_space_minimal_diameter\n            << \", embedded maximal diameter: \"\n            << embedded_space_maximal_diameter << \", ratio: \"\n            << embedded_space_maximal_diameter /\n                 embedding_space_minimal_diameter\n            << std::endl;\n \n AssertThrow(embedded_space_maximal_diameter <\n                  embedding_space_minimal_diameter,\n                ExcMessage(\n \"The embedding grid is too refined (or the embedded grid \"\n \"is too coarse). Adjust the parameters so that the minimal \"\n \"grid size of the embedding grid is larger \"\n \"than the maximal grid size of the embedded grid.\"));\n \n    setup_embedding_dofs();\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::setup_embedding_dofs()\n  {\n    space_dh = std::make_unique<DoFHandler<spacedim>>(*space_grid);\n    space_fe = std::make_unique<FE_Q<spacedim>>(\n      parameters.embedding_space_finite_element_degree);\n    space_dh->distribute_dofs(*space_fe);\n \n DoFTools::make_hanging_node_constraints(*space_dh, constraints);\n for (const types::boundary_id id : parameters.dirichlet_ids)\n      {\n VectorTools::interpolate_boundary_values(\n          *space_dh, id, embedding_dirichlet_boundary_function, constraints);\n      }\n    constraints.close();\n \n DynamicSparsityPattern dsp(space_dh->n_dofs(), space_dh->n_dofs());\n DoFTools::make_sparsity_pattern(*space_dh, dsp, constraints);\n    stiffness_sparsity.copy_from(dsp);\n    stiffness_matrix.reinit(stiffness_sparsity);\n    solution.reinit(space_dh->n_dofs());\n    embedding_rhs.reinit(space_dh->n_dofs());\n \n deallog << \"Embedding dofs: \" << space_dh->n_dofs() << std::endl;\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::setup_embedded_dofs()\n  {\n    embedded_dh = std::make_unique<DoFHandler<dim, spacedim>>(*embedded_grid);\n    embedded_fe = std::make_unique<FE_Q<dim, spacedim>>(\n      parameters.embedded_space_finite_element_degree);\n    embedded_dh->distribute_dofs(*embedded_fe);\n \n lambda.reinit(embedded_dh->n_dofs());\n    embedded_rhs.reinit(embedded_dh->n_dofs());\n    embedded_value.reinit(embedded_dh->n_dofs());\n \n deallog << \"Embedded dofs: \" << embedded_dh->n_dofs() << std::endl;\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::setup_coupling()\n  {\n TimerOutput::Scope timer_section(monitor, \"Setup coupling\");\n \n const QGauss<dim> quad(parameters.coupling_quadrature_order);\n \n DynamicSparsityPattern dsp(space_dh->n_dofs(), embedded_dh->n_dofs());\n \n NonMatching::create_coupling_sparsity_pattern(*space_grid_tools_cache,\n                                                  *space_dh,\n                                                  *embedded_dh,\n                                                  quad,\n                                                  dsp,\n AffineConstraints<double>(),\n ComponentMask(),\n ComponentMask(),\n                                                  *embedded_mapping);\n    coupling_sparsity.copy_from(dsp);\n    coupling_matrix.reinit(coupling_sparsity);\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::assemble_system()\n  {\n    {\n TimerOutput::Scope timer_section(monitor, \"Assemble system\");\n \n MatrixTools::create_laplace_matrix(\n        *space_dh,\n QGauss<spacedim>(2 * space_fe->degree + 1),\n        stiffness_matrix,\n        embedding_rhs_function,\n        embedding_rhs,\n static_cast<const Function<spacedim> *>(nullptr),\n        constraints);\n \n VectorTools::create_right_hand_side(*embedded_mapping,\n                                          *embedded_dh,\n QGauss<dim>(2 * embedded_fe->degree +\n                                                      1),\n                                          embedded_value_function,\n                                          embedded_rhs);\n    }\n    {\n TimerOutput::Scope timer_section(monitor, \"Assemble coupling system\");\n \n const QGauss<dim> quad(parameters.coupling_quadrature_order);\n NonMatching::create_coupling_mass_matrix(*space_grid_tools_cache,\n                                               *space_dh,\n                                               *embedded_dh,\n                                               quad,\n                                               coupling_matrix,\n AffineConstraints<double>(),\n ComponentMask(),\n ComponentMask(),\n                                               *embedded_mapping);\n \n VectorTools::interpolate(*embedded_mapping,\n                               *embedded_dh,\n                               embedded_value_function,\n                               embedded_value);\n    }\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::solve()\n  {\n TimerOutput::Scope timer_section(monitor, \"Solve system\");\n \n SparseDirectUMFPACK K_inv_umfpack;\n    K_inv_umfpack.initialize(stiffness_matrix);\n \n auto K  = linear_operator(stiffness_matrix);\n auto Ct = linear_operator(coupling_matrix);\n auto C  = transpose_operator(Ct);\n \n auto K_inv = linear_operator(K, K_inv_umfpack);\n \n auto                     S = C * K_inv * Ct;\n SolverCG<Vector<double>> solver_cg(schur_solver_control);\n auto S_inv = inverse_operator(S, solver_cg, PreconditionIdentity());\n \n lambda = S_inv * (C * K_inv * embedding_rhs - embedded_rhs);\n \n    solution = K_inv * (embedding_rhs - Ct * lambda);\n \n    constraints.distribute(solution);\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::output_results()\n  {\n TimerOutput::Scope timer_section(monitor, \"Output results\");\n \n DataOut<spacedim> embedding_out;\n \n    std::ofstream embedding_out_file(\"embedding.vtu\");\n \n    embedding_out.attach_dof_handler(*space_dh);\n    embedding_out.add_data_vector(solution, \"solution\");\n    embedding_out.build_patches(\n      parameters.embedding_space_finite_element_degree);\n    embedding_out.write_vtu(embedding_out_file);\n \n \n DataOut<dim, spacedim> embedded_out;\n \n    std::ofstream embedded_out_file(\"embedded.vtu\");\n \n    embedded_out.attach_dof_handler(*embedded_dh);\n    embedded_out.add_data_vector(lambda, \"lambda\");\n    embedded_out.add_data_vector(embedded_value, \"g\");\n    embedded_out.build_patches(*embedded_mapping,\n                               parameters.embedded_space_finite_element_degree);\n    embedded_out.write_vtu(embedded_out_file);\n  }\n \n template <int dim, int spacedim>\n void DistributedLagrangeProblem<dim, spacedim>::run()\n  {\n AssertThrow(parameters.initialized, ExcNotInitialized());\n deallog.depth_console(parameters.verbosity_level);\n \n    setup_grids_and_dofs();\n    setup_coupling();\n    assemble_system();\n    solve();\n    output_results();\n  }\n} // namespace Step60\n \n \n \nint main(int argc, char **argv)\n{\n try\n    {\n using namespace dealii;\n using namespace Step60;\n \n const unsigned int dim = 1, spacedim = 2;\n \n \n      DistributedLagrangeProblem<dim, spacedim>::Parameters parameters;\n      DistributedLagrangeProblem<dim, spacedim>             problem(parameters);\n \n      std::string parameter_file;\n if (argc > 1)\n        parameter_file = argv[1];\n else\n        parameter_file = \"parameters.prm\";\n \n ParameterAcceptor::initialize(parameter_file, \"used_parameters.prm\");\n      problem.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_61.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving the Poisson problem with the \"weak Galerkin\" finite element method.\nTutorial content :\nThis tutorial depends on [step-51](step_51.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_61-Intro)    * [Weak Galerkin finite element methods](#step_61-WeakGalerkinfiniteelementmethods) * [The equation to solve](#step_61-Theequationtosolve) * [Weak Galerkin scheme](#step_61-WeakGalerkinscheme) * [Representing the weak gradient](#step_61-Representingtheweakgradient) * [Assembling the linear system](#step_61-Assemblingthelinearsystem) * [Post-processing and *L2*-errors](#step_61-PostprocessingandiLsub2subierrors)- [The commented program](#step_61-CommProg)      * [Include files](#step_61-Includefiles)* [The WGDarcyEquation class template](#step_61-TheWGDarcyEquationclasstemplate)* [Right hand side, boundary values, and exact solution](#step_61-Righthandsideboundaryvaluesandexactsolution)* [WGDarcyEquation class implementation](#step_61-WGDarcyEquationclassimplementation)              + [WGDarcyEquation::WGDarcyEquation](#step_61-WGDarcyEquationWGDarcyEquation)+ [WGDarcyEquation::make\\_grid](#step_61-WGDarcyEquationmake_grid)+ [WGDarcyEquation::setup\\_system](#step_61-WGDarcyEquationsetup_system)+ [WGDarcyEquation::assemble\\_system](#step_61-WGDarcyEquationassemble_system)+ [WGDarcyEquation::solve](#step_61-WGDarcyEquationdimsolve)+ [WGDarcyEquation::compute\\_postprocessed\\_velocity](#step_61-WGDarcyEquationdimcompute_postprocessed_velocity)+ [WGDarcyEquation::compute\\_pressure\\_error](#step_61-WGDarcyEquationdimcompute_pressure_error)+ [WGDarcyEquation::compute\\_velocity\\_error](#step_61-WGDarcyEquationdimcompute_velocity_error)+ [WGDarcyEquation::output\\_results](#step_61-WGDarcyEquationoutput_results)+ [WGDarcyEquation::run](#step_61-WGDarcyEquationrun)* [The `main` function](#step_61-Thecodemaincodefunction) | 1. [Results](#step_61-Results)    * [Test results on *WG(Q0,Q0;RT[0])*](#step_61-TestresultsoniWGQsub0subQsub0subRTsub0subi)      + [Convergence table for *k=0*](#step_61-Convergencetableforik0i)* [Test results on *WG(Q1,Q1;RT[1])*](#step_61-TestresultsoniWGQsub1subQsub1subRTsub1subi)        + [Convergence table for *k=1*](#step_61-Convergencetableforik1i)* [Test results on *WG(Q2,Q2;RT[2])*](#step_61-TestresultsoniWGQsub2subQsub2subRTsub2subi)          + [Convergence table for *k=2*](#step_61-Convergencetableforik2i)- [The plain program](#step_61-PlainProg) |\n\n*This program was contributed by Zhuoran Wang. Some more information about this program, as well as more numerical results, are presented in [[207]](citelist.html#CITEREF_Wang2019) .*\n\nIntroduction\n============\n\nThis tutorial program presents an implementation of the \"weak Galerkin\" finite element method for the Poisson equation. In some sense, the motivation for considering this method starts from the same point as in [step-51](step_51.html): We would like to consider discontinuous shape functions, but then need to address the fact that the resulting problem has a much larger number of degrees of freedom compared to the usual continuous Galerkin method (because, for example, each vertex carries as many degrees of freedom as there are adjacent cells). We also have to address the fact that, unlike in the continuous Galerkin method, *every* degree of freedom on one cell couples with all of the degrees of freedom on each of its face neighbor cells. Consequently, the matrix one gets from the \"traditional\" discontinuous Galerkin methods are both large and relatively dense.\n\nBoth the hybridized discontinuous Galerkin method (HDG) in [step-51](step_51.html) and the weak Galerkin (WG) method in this tutorial address the issue of coupling by introducing additional degrees of freedom whose shape functions only live on a face between cells (i.e., on the \"skeleton\" of the mesh), and which therefore \"insulate\" the degrees of freedom on the adjacent cells from each other: cell degrees of freedom only couple with other cell degrees of freedom on the same cell, as well as face degrees of freedom, but not with cell degrees of freedom on neighboring cells. Consequently, the coupling of shape functions for these cell degrees of freedom indeed couple on exactly one cell and the degrees of freedom defined on its faces.\n\nFor a given equation, say the second order Poisson equation, the difference between the HDG and the WG method is how precisely one formulates the problem that connects all of these different shape functions. (Indeed, for some WG and HDG formulation, it is possible to show that they are equivalent.) The HDG does things by reformulating second order problems in terms of a system of first order equations and then conceptually considers the face degrees of freedom to be \"fluxes\" of this first order system. In contrast, the WG method keeps things in second order form and considers the face degrees of freedom as of the same type as the primary solution variable, just restricted to the lower-dimensional faces. For the purposes of the equation, one then needs to somehow \"extend\" these shape functions into the interior of the cell when defining what it means to apply a differential operator to them. Compared to the HDG, the method has the advantage that it does not lead to a proliferation of unknowns due to rewriting the equation as a first-order system, but it is also not quite as easy to implement. However, as we will see in the following, this additional effort is not prohibitive.\n\n### Weak Galerkin finite element methods\n\nWeak Galerkin Finite Element Methods (WGFEMs) use discrete weak functions to approximate scalar unknowns, and discrete weak gradients to approximate classical gradients. The method was originally introduced by Junping Wang and Xiu Ye in the paper [*A weak Galerkin finite element method for second order elliptic problems*, J. Comput. Appl. Math., 103-115, 2013](https://doi.org/10.1016/j.cam.2012.10.003). Compared to the continuous Galerkin method, the weak Galerkin method satisfies important physical properties, namely local mass conservation and bulk normal flux continuity. It results in a SPD linear system, and optimal convergence rates can be obtained with mesh refinement.\n\n### The equation to solve\n\nThis program solves the Poisson equation using the weak Galerkin finite element method:\n\n\\begin{align\\*}\n\\nabla \\cdot \\left( -\\mathbf{K} \\nabla p \\right)\n&= f,\n\\qquad \\mathbf{x} \\in \\Omega, \\\\\np &= p\\_D,\\qquad \\mathbf{x} \\in \\Gamma^D, \\\\\n\\mathbf{u} \\cdot \\mathbf{n} &= u\\_N,\n\\qquad \\mathbf{x} \\in \\Gamma^N,\n\\end{align\\*}\n\nwhere \\(\\Omega \\subset \\mathbb{R}^n (n=2,3)\\) is a bounded domain. In the context of the flow of a fluid through a porous medium, \\(p\\) is the pressure, \\(\\mathbf{K}\\) is a permeability tensor, \\(f\\) is the source term, and \\(p\\_D, u\\_N\\) represent Dirichlet and Neumann boundary conditions. We can introduce a flux, \\(\\mathbf{u} = -\\mathbf{K} \\nabla p\\), that corresponds to the Darcy velocity (in the way we did in [step-20](step_20.html)) and this variable will be important in the considerations below.\n\nIn this program, we will consider a test case where the exact pressure is \\(p = \\sin \\left( \\pi x\\right)\\sin\\left(\\pi y \\right)\\) on the unit square domain, with homogeneous Dirichelet boundary conditions and \\(\\mathbf{K}\\) the identity matrix. Then we will calculate \\(L\\_2\\) errors of pressure, velocity, and flux.\n\n### Weak Galerkin scheme\n\nThe Poisson equation above has a solution \\(p\\) that needs to satisfy the weak formulation of the problem,\n\n\\begin{equation\\*}\n\\mathcal{A}\\left(p,q \\right) = \\mathcal{F} \\left(q \\right),\n\\end{equation\\*}\n\nfor all test functions \\(q\\), where\n\n\\begin{equation\\*}\n\\mathcal{A}\\left(p,q\\right)\n\\dealcoloneq \\int\\_\\Omega \\left(\\mathbf{K} \\nabla p\\right) \\cdot \\nabla q \\;\\mathrm{d}x,\n\\end{equation\\*}\n\nand\n\n\\begin{equation\\*}\n\\mathcal{F}\\left(q\\right)\n\\dealcoloneq \\int\\_\\Omega f \\, q \\;\\mathrm{d}x\n- \\int\\_{\\Gamma^N} u\\_N q \\; \\mathrm{d}x.\n\\end{equation\\*}\n\nHere, we have integrated by parts in the bilinear form, and we are evaluating the gradient of \\(p,p\\) in the interior and the values of \\(q\\) on the boundary of the domain. All of this is well defined because we assume that the solution is in \\(H^1\\) for which taking the gradient and evaluating boundary values are valid operations.\n\nThe idea of the weak Galerkin method is now to approximate the exact \\(p\\) solution with a *discontinuous function* \\(p\\_h\\). This function may only be discontinuous along interfaces between cells, and because we will want to evaluate this function also along interfaces, we have to prescribe not only what values it is supposed to have in the cell interiors but also its values along interfaces. We do this by saying that \\(p\\_h\\) is actually a tuple, \\(p\\_h=(p^\\circ,p^\\partial)\\), though it's really just a single function that is either equal to \\(p^\\circ(x)\\) or \\(p^\\partial(x)\\), depending on whether it is evaluated at a point \\(x\\) that lies in the cell interior or on cell interfaces.\n\nWe would then like to simply stick this approximation into the bilinear form above. This works for the case where we have to evaluate the test function \\(q\\_h\\) on the boundary (where we would simply take its interface part \\(q\\_h^\\partial\\)) but we have to be careful with the gradient because that is only defined in cell interiors. Consequently, the weak Galerkin scheme for the Poisson equation is defined by\n\n\\begin{equation\\*}\n\\mathcal{A}\\_h\\left(p\\_h,q \\right) = \\mathcal{F} \\left(q\\_h \\right),\n\\end{equation\\*}\n\nfor all discrete test functions \\(q\\_h\\), where\n\n\\begin{equation\\*}\n\\mathcal{A}\\_h\\left(p\\_h,q\\_h\\right)\n\\dealcoloneq \\sum\\_{K \\in \\mathbb{T}}\n\\int\\_K \\mathbf{K} \\nabla\\_{w,d} p\\_h \\cdot \\nabla\\_{w,d} q\\_h \\;\\mathrm{d}x,\n\\end{equation\\*}\n\nand\n\n\\begin{equation\\*}\n\\mathcal{F}\\left(q\\_h\\right)\n\\dealcoloneq \\sum\\_{K \\in \\mathbb{T}} \\int\\_K f \\, q\\_h^\\circ \\;\\mathrm{d}x\n- \\sum\\_{\\gamma \\in \\Gamma\\_h^N} \\int\\_\\gamma u\\_N q\\_h^\\partial \\;\\mathrm{d}x,\n\\end{equation\\*}\n\nThe key point is that here, we have replaced the gradient \\(\\nabla p\\_h\\) by the *discrete weak gradient* operator \\(\\nabla\\_{w,d} p\\_h\\) that makes sense for our peculiarly defined approximation \\(p\\_h\\).\n\nThe question is then how that operator works. For this, let us first say how we think of the discrete approximation \\(p\\_h\\) of the pressure. As mentioned above, the \"function\" \\(p\\_h\\) actually consists of two parts: the values \\(p\\_h^\\circ\\) in the interior of cells, and \\(p\\_h^\\partial\\) on the interfaces. We have to define discrete (finite-dimensional) function spaces for both of these; in this program, we will use [FE\\_DGQ](classFE__DGQ.html) for \\(p\\_h^\\circ\\) as the space in the interior of cells (defined on each cell, but in general discontinuous along interfaces), and [FE\\_FaceQ](classFE__FaceQ.html) for \\(p\\_h^\\partial\\) as the space on the interfaces.\n\nThen let us consider just a single cell (because the integrals above are all defined cell-wise, and because the weak discrete gradient is defined cell-by-cell). The restriction of \\(p\\_h\\) to cell \\(K\\), \\(p\\_h|\\_K\\) then consists of the pair \\((p\\_h^\\circ|\\_K,p\\_h^\\partial|\\_{\\partial K})\\). In essence, we can think of \\(\\nabla\\_{w,d} p\\_h\\) of some function defined on \\(K\\) that approximates the gradient; in particular, if \\(p\\_h|\\_K\\) was the restriction of a differentiable function (to the interior and boundary of \\(K\\) – which would make it continuous between the interior and boundary), then \\(\\nabla\\_{w,d} p\\_h\\) would simply be the exact gradient \\(\\nabla p\\_h\\). But, since \\(p\\_h|\\_K\\) is not continuous between interior and boundary of \\(K\\), we need a more general definition; furthermore, we can not deal with arbitrary functions, and so require that \\(\\nabla\\_{w,d} p\\_h\\) is also in a finite element space (which, since the gradient is a vector, has to be vector-valued, and because the weak gradient is defined on each cell separately, will also be discontinuous between cells).\n\nThe way this is done is to define this weak gradient operator \\(\\nabla\\_{w,d}|\\_K :\nDGQ\\_k(K) \\times DGQ\\_r(\\partial K) \\rightarrow RT\\_s(K)\\) (where \\(RT\\_s(K)\\) is the vector-valued Raviart-Thomas space of order \\(s\\) on cell \\(K\\)) in the following way:\n\n\\begin{equation\\*}\n\\int\\_K \\mathbf v\\_h \\cdot (\\nabla\\_{w,d} p\\_h)\n=\n-\\int\\_K (\\nabla \\cdot \\mathbf v\\_h) p\\_h^\\circ\n+\\int\\_{\\partial K} (\\mathbf v\\_h \\cdot \\mathbf n) p\\_h^\\partial,\n\\end{equation\\*}\n\nfor all test functions \\(\\mathbf v\\_h \\in RT\\_s(K)\\). This is, in essence, simply an application of the integration-by-parts formula. In other words, for a given \\(p\\_h=(p^\\circ\\_h,p^\\partial\\_h)\\), we need to think of \\(\\nabla\\_{w,d} p\\_h|\\_K\\) as that Raviart-Thomas function of degree \\(s\\) for which the left hand side and right hand side are equal for all test functions.\n\nA key point to make is then the following: While the usual gradient \\(\\nabla\\) is a *local* operator that computes derivatives based simply on the value of a function at a point and its (infinitesimal) neighborhood, the weak discrete gradient \\(\\nabla\\_{w,d}\\) does not have this property: It depends on the values of the function it is applied to on the entire cell, including the cell's boundary. Both are, however, linear operators as is clear from the definition of \\(\\nabla\\_{w,d}\\) above, and that will allow us to represent \\(\\nabla\\_{w,d}\\) via a matrix in the discussion below.\n\nNote\n:   It may be worth pointing out that while the weak discrete gradient is an element of the Raviart-Thomas space \\(RT\\_s(K)\\) on each cell \\(K\\), it is discontinuous between cells. On the other hand, the Raviart-Thomas space \\(RT\\_s=RT\\_s({\\mathbb T})\\) defined on the entire mesh and implemented by the [FE\\_RaviartThomas](classFE__RaviartThomas.html) class represents functions that have continuous normal components at interfaces between cells. This means that *globally*, \\(\\nabla\\_{w,d} p\\_h\\) is not in \\(RT\\_s\\), even though it is on every cell \\(K\\) in \\(RT\\_s(K)\\). Rather, it is in a \"broken\" Raviart-Thomas space that below we will represent by the symbol \\(DGRT\\_s\\). (The term \"broken\" here refers to the process of \"breaking something apart\", and not to the synonym to the expression \"not functional\".) One might therefore (rightfully) argue that the notation used in the weak Galerkin literature is a bit misleading, but as so often it all depends on the context in which a certain notation is used – in the current context, references to the Raviart-Thomas space or element are always understood to be to the \"broken\" spaces.\n:   deal.II happens to have an implementation of this broken Raviart-Thomas space: The [FE\\_DGRaviartThomas](classFE__DGRaviartThomas.html) class. As a consequence, in this tutorial we will simply always use the [FE\\_DGRaviartThomas](classFE__DGRaviartThomas.html) class, even though in all of those places where we have to compute cell-local matrices and vectors, it makes no difference.\n\n### Representing the weak gradient\n\nSince \\(p\\_h\\) is an element of a finite element space, we can expand it in a basis as we always do, i.e., we can write\n\n\\begin{equation\\*}\np\\_h(\\mathbf x) = \\sum\\_j P\\_j \\varphi\\_j(\\mathbf x).\n\\end{equation\\*}\n\nHere, since \\(p\\_h\\) has two components (the interior and the interface components), the same must hold true for the basis functions \\(\\varphi\\_j(\\mathbf x)\\), which we can write as \\(\\varphi\\_j = (\\varphi\\_j^\\circ,\\varphi\\_j^\\partial)\\). If you've followed the descriptions in [step-8](step_8.html), [step-20](step_20.html), and the [documentation topic on vector-valued problems](group__vector__valued.html), it will be no surprise that for some values of \\(j\\), \\(\\varphi\\_j^\\circ\\) will be zero, whereas for other values of \\(j\\), \\(\\varphi\\_j^\\partial\\) will be zero – i.e., shape functions will be of either one or the other kind. That is not important, here, however. What is important is that we need to wonder how we can represent \\(\\nabla\\_{w,d} \\varphi\\_j\\) because that is clearly what will appear in the problem when we want to implement the bilinear form\n\n\\begin{equation\\*}\n\\mathcal{A}\\_h\\left(p\\_h,q\\_h\\right)\n= \\sum\\_{K \\in \\mathbb{T}}\n\\int\\_K \\mathbf{K} \\nabla\\_{w,d} p\\_h \\cdot \\nabla\\_{w,d} q\\_h \\;\\mathrm{d}x,\n\\end{equation\\*}\n\nThe key point is that \\(\\nabla\\_{w,d} \\varphi\\_j\\) is known to be a member of the \"broken\" Raviart-Thomas space \\(DGRT\\_s\\). What this means is that we can represent (on each cell \\(K\\) separately)\n\n\\begin{equation\\*}\n\\nabla\\_{w,d} \\varphi\\_j|\\_K\n= \\sum\\_k C\\_{jk}^K \\mathbf v\\_k|\\_K\n\\end{equation\\*}\n\nwhere the functions \\(\\mathbf v\\_k \\in DGRT\\_s\\), and where \\(C^K\\) is a matrix of dimension\n\n\\begin{align\\*}\n\\text{dim}\\left(DGQ\\_k(K) \\times DGQ\\_r(K)\\right) &\\times \\text{dim}\\left(RT\\_s(K)\\right)\n\\\\\n&=\n\\left(\\text{dim}(DGQ\\_k(K)) + \\text{dim}(DGQ\\_r(K))\\right) \\times \\text{dim}\\left(RT\\_s(K)\\right).\n\\end{align\\*}\n\n(That the weak discrete gradient can be represented as a matrix should not come as a surprise: It is a linear operator from one finite dimensional space to another finite dimensional space. If one chooses bases for both of these spaces, then *every linear operator* can of course be written as a matrix mapping the vector of expansion coefficients with regards to the basis of the domain space of the operator, to the vector of expansion coefficients with regards to the basis in the image space.)\n\nUsing this expansion, we can easily use the definition of the weak discrete gradient above to define what the matrix is going to be:\n\n\\begin{equation\\*}\n\\int\\_K \\mathbf v\\_i \\cdot \\left(\\sum\\_k C\\_{jk}^K \\mathbf v\\_k\\right)\n=\n-\\int\\_K (\\nabla \\cdot \\mathbf v\\_i) \\varphi\\_j^\\circ\n+\\int\\_{\\partial K} (\\mathbf v\\_i \\cdot \\mathbf n) \\varphi\\_j^\\partial,\n\\end{equation\\*}\n\nfor all test functions \\(\\mathbf v\\_i \\in DGRT\\_s\\).\n\nThis clearly leads to a linear system of the form\n\n\\begin{equation\\*}\n\\sum\\_k M\\_{ik}^K C\\_{jk}^K\n=\nG\\_{ij}^K\n\\end{equation\\*}\n\nwith\n\n\\begin{equation\\*}\nM\\_{ik}^K = \\int\\_K \\mathbf v\\_i \\cdot \\mathbf v\\_k,\n\\qquad\\qquad\nG\\_{ij}^K = -\\int\\_K (\\nabla \\cdot \\mathbf v\\_i) \\varphi\\_j^\\circ\n+\\int\\_{\\partial K} (\\mathbf v\\_i \\cdot \\mathbf n) \\varphi\\_j^\\partial,\n\\end{equation\\*}\n\nand consequently\n\n\\begin{equation\\*}\n\\left(C^K\\right)^T = \\left(M^K\\right)^{-1} G^K.\n\\end{equation\\*}\n\n(In this last step, we have assumed that the indices \\(i,j,k\\) only range over those degrees of freedom active on cell \\(K\\), thereby ensuring that the [mass matrix](DEALGlossary.html#GlossMassMatrix) on the space \\(RT\\_s(K)\\) is invertible.) Equivalently, using the symmetry of the matrix \\(M\\), we have that\n\n\\begin{equation\\*}\nC^K = \\left(G^K\\right)^{T} \\left(M^K\\right)^{-1}.\n\\end{equation\\*}\n\nAlso worth pointing out is that the matrices \\(C^K\\) and \\(G^K\\) are of course not square but rectangular.\n\n### Assembling the linear system\n\nHaving explained how the weak discrete gradient is defined, we can now come back to the question of how the linear system for the equation in question should be assembled. Specifically, using the definition of the bilinear form \\({\\cal A}\\_h\\) shown above, we then need to compute the elements of the local contribution to the global matrix,\n\n\\begin{equation\\*}\nA^K\\_{ij} = \\int\\_K \\left({\\mathbf K} \\nabla\\_{w,d} \\varphi\\_i\\right) \\cdot \\nabla\\_{w,d} \\varphi\\_j.\n\\end{equation\\*}\n\nAs explained above, we can expand \\(\\nabla\\_{w,d} \\varphi\\_i\\) in terms of the Raviart-Thomas basis on each cell, and similarly for \\(\\nabla\\_{w,d} \\varphi\\_j\\):\n\n\\begin{equation\\*}\nA^K\\_{ij} = \\int\\_K\n\\left(\n{\\mathbf K}\n\\sum\\_k C\\_{ik}^K \\mathbf v\\_k|\\_K\n\\right)\n\\cdot\n\\sum\\_l C\\_{jl}^K \\mathbf v\\_l|\\_K.\n\\end{equation\\*}\n\nBy re-arranging sums, this yields the following expression:\n\n\\begin{equation\\*}\nA^K\\_{ij} =\n\\sum\\_k \\sum\\_l C\\_{ik}^K C\\_{jl}^K\n\\int\\_K\n\\left(\n{\\mathbf K}\n\\mathbf v\\_k|\\_K\n\\right)\n\\cdot\n\\mathbf v\\_l|\\_K.\n\\end{equation\\*}\n\nSo, if we have the matrix \\(C^K\\) for each cell \\(K\\), then we can easily compute the contribution \\(A^K\\) for cell \\(K\\) to the matrix \\(A\\) as follows:\n\n\\begin{equation\\*}\nA^K\\_{ij} =\n\\sum\\_k \\sum\\_l C\\_{ik}^K C\\_{jl}^K\nH^K\\_{kl}\n=\n\\sum\\_k \\sum\\_l C\\_{ik}^K H^K\\_{kl} C\\_{jl}^K\n=\n\\left(C^K H^K (C^K)^T \\right)\\_{ij}.\n\\end{equation\\*}\n\nHere,\n\n\\begin{equation\\*}\nH^K\\_{kl} =\n\\int\\_K\n\\left(\n{\\mathbf K}\n\\mathbf v\\_k|\\_K\n\\right)\n\\cdot\n\\mathbf v\\_l|\\_K,\n\\end{equation\\*}\n\nwhich is really just the mass matrix on cell \\(K\\) using the Raviart-Thomas basis and weighting by the permeability tensor \\(\\mathbf K\\). The derivation here then shows that the weak Galerkin method really just requires us to compute these \\(C^K\\) and \\(H^K\\) matrices on each cell \\(K\\), and then \\(A^K = C^K H^K (C^K)^T\\), which is easily computed. The code to be shown below does exactly this.\n\nHaving so computed the contribution \\(A^K\\) of cell \\(K\\) to the global matrix, all we have to do is to \"distribute\" these local contributions into the global matrix. How this is done is first shown in [step-3](step_3.html) and [step-4](step_4.html). In the current program, this will be facilitated by calling [AffineConstraints::distribute\\_local\\_to\\_global()](classAffineConstraints.html#a373fbdacd8c486e675b8d2bff8943192).\n\nA linear system of course also needs a right hand side. There is no difficulty associated with computing the right hand side here other than the fact that we only need to use the cell-interior part \\(\\varphi\\_i^\\circ\\) for each shape function \\(\\varphi\\_i\\).\n\n### Post-processing and *L2*-errors\n\nThe discussions in the previous sections have given us a linear system that we can solve for the numerical pressure \\(p\\_h\\). We can use this to compute an approximation to the variable \\(\\mathbf u = -{\\mathbf K}\\nabla p\\) that corresponds to the velocity with which the medium flows in a porous medium if this is the model we are trying to solve. This kind of step – computing a derived quantity from the solution of the discrete problem – is typically called \"post-processing\".\n\nHere, instead of using the exact gradient of \\(p\\_h\\), let us instead use the discrete weak gradient of \\(p\\_h\\) to calculate the velocity on each element. As discussed above, on each element the gradient of the numerical pressure \\(\\nabla p\\) can be approximated by discrete weak gradients \\( \\nabla\\_{w,d}\\phi\\_i\\):\n\n\\begin{equation\\*}\n\\nabla\\_{w,d} p\\_h\n= \\nabla\\_{w,d} \\left(\\sum\\_{i} P\\_i \\phi\\_i\\right)\n= \\sum\\_{i} P\\_i \\nabla\\_{w,d}\\phi\\_i.\n\\end{equation\\*}\n\nOn cell \\(K\\), the numerical velocity \\( \\mathbf{u}\\_h = -\\mathbf{K} \\nabla\\_{w,d}p\\_h\\) can be written as\n\n\\begin{align\\*}\n\\mathbf{u}\\_h\n&= -\\mathbf{K} \\nabla\\_{w,d} p\\_h\n= -\\mathbf{K}\\sum\\_{i} \\sum\\_{j} P\\_i C^K\\_{ij}\\mathbf{v}\\_j,\n\\end{align\\*}\n\nwhere \\(C^K\\) is the expansion matrix from above, and \\(\\mathbf{v}\\_j\\) is the basis function of the \\(RT\\) space on a cell.\n\nUnfortunately, \\(\\mathbf{K} \\mathbf{v}\\_j\\) may not be in the \\(RT\\) space (unless, of course, if \\(\\mathbf K\\) is constant times the identity matrix). So, in order to represent it in a finite element program, we need to project it back into a finite dimensional space we can work with. Here, we will use the \\(L\\_2\\)-projection to project it back to the (broken) \\(RT\\) space.\n\nWe define the projection as \\( \\mathbf{Q}\\_h \\left( \\mathbf{K}\\mathbf{v}\\_j \\right) =\n\\sum\\_{k} d\\_{jk}\\mathbf{v}\\_k\\) on each cell \\(K\\). For any \\(j\\), \\(\\left( \\mathbf{Q}\\_h \\left( \\mathbf{Kv}\\_j \\right),\\mathbf{v}\\_k \\right)\\_K =\n\\left( \\mathbf{Kv}\\_j,\\mathbf{v}\\_k \\right)\\_K.\\) So, rather than the formula shown above, the numerical velocity on cell \\(K\\) instead becomes\n\n\\begin{equation\\*}\n\\mathbf{u}\\_h = \\mathbf{Q}\\_h \\left( -\\mathbf{K}\\nabla\\_{w,d}p\\_h \\right) =\n-\\sum\\_i \\sum\\_j P\\_i B^K\\_{ij}\\mathbf{Q}\\_h \\left( \\mathbf{K}\\mathbf{v}\\_j \\right),\n\\end{equation\\*}\n\nand we have the following system to solve for the coefficients \\(d\\_{jk}\\):\n\n\\begin{equation\\*}\n\\sum\\_j\n\\left(\\mathbf{v}\\_i,\\mathbf{v}\\_j\\right)\nd\\_{jk}\n=\n\\left( \\mathbf{Kv}\\_j,\\mathbf{v}\\_k \\right).\n\\end{equation\\*}\n\nIn the implementation below, the matrix with elements \\(\nd\\_{jk}\n\\) is called `cell_matrix_D`, whereas the matrix with elements \\(\n\\left( \\mathbf{Kv}\\_j,\\mathbf{v}\\_k \\right)\n\\) is called `cell_matrix_E`.\n\nThen the elementwise velocity is\n\n\\begin{equation\\*}\n\\mathbf{u}\\_h = -\\sum\\_{i} \\sum\\_{j}P\\_ic\\_{ij}\\sum\\_{k}d\\_{jk}\\mathbf{v}\\_k =\n\\sum\\_{k}- \\left(\\sum\\_{j} \\sum\\_{i} P\\_ic\\_{ij}d\\_{jk} \\right)\\mathbf{v}\\_k,\n\\end{equation\\*}\n\nwhere \\(-\\sum\\_{j} \\sum\\_{i} P\\_ic\\_{ij}d\\_{jk}\\) is called `cell_velocity` in the code.\n\nUsing this velocity obtained by \"postprocessing\" the solution, we can define the \\(L\\_2\\)-errors of pressure, velocity, and flux by the following formulas:\n\n\\begin{align\\*}\n\\|p-p\\_h^\\circ\\|^2\n&= \\sum\\_{K \\in \\mathbb{T}} \\|p-p\\_h^\\circ\\|\\_{L\\_2(K)}^2, \\\\\n\\|\\mathbf{u}-\\mathbf{u}\\_h\\|^2\n&= \\sum\\_{K \\in \\mathbb{T}} \\|\\mathbf{u}-\\mathbf{u}\\_h\\|\\_{L\\_2(K)^2}^d,\\\\\n\\|(\\mathbf{u}-\\mathbf{u}\\_h) \\cdot \\mathbf{n}\\|^2\n&= \\sum\\_{K \\in \\mathbb{T}} \\sum\\_{\\gamma \\subset \\partial K}\n\\frac{|K|}{|\\gamma|} \\|\\mathbf{u} \\cdot \\mathbf{n} - \\mathbf{u}\\_h \\cdot \\mathbf{n}\\|\\_{L\\_2(\\gamma)}^2,\n\\end{align\\*}\n\nwhere \\(| K |\\) is the area of the element, \\(\\gamma\\) are faces of the element, \\(\\mathbf{n}\\) are unit normal vectors of each face. The last of these norms measures the accuracy of the normal component of the velocity vectors over the interfaces between the cells of the mesh. The scaling factor \\(|K|/|\\gamma|\\) is chosen so as to scale out the difference in the length (or area) of the collection of interfaces as the mesh size changes.\n\nThe first of these errors above is easily computed using [VectorTools::integrate\\_difference](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). The others require a bit more work and are implemented in the code below.\n\nThe commented program\n=====================\n\n### Include files\n\nThis program is based on [step-7](step_7.html), [step-20](step_20.html) and [step-51](step_51.html), so most of the following header files are familiar. We need the following, of which only the one that imports the [FE\\_DGRaviartThomas](classFE__DGRaviartThomas.html) class (namely, `deal.II/fe/fe_dg_vector.h`) is really new; the [FE\\_DGRaviartThomas](classFE__DGRaviartThomas.html) implements the \"broken\" Raviart-Thomas space discussed in the introduction:\n\n```\n   #include <deal.II/base/quadrature.h>\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/tensor_function.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/point.h>\n   #include <deal.II/lac/block_vector.h>\n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/block_sparse_matrix.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   #include <deal.II/fe/fe_dgq.h>\n   #include <deal.II/fe/fe_raviart_thomas.h>\n   #include <deal.II/fe/fe_dg_vector.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/fe/fe_face.h>\n   #include <deal.II/fe/component_mask.h>\n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/data_out_faces.h>\n   \n   #include <fstream>\n   #include <iostream>\n```\n\nOur first step, as always, is to put everything related to this tutorial program into its own namespace:\n\n```\n   namespace Step61\n   {\n     using namespace dealii;\n```\n\n### The WGDarcyEquation class template\n\nThis is the main class of this program. We will solve for the numerical pressure in the interior and on faces using the weak Galerkin (WG) method, and calculate the \\(L\\_2\\) error of pressure. In the post-processing step, we will also calculate \\(L\\_2\\)-errors of the velocity and flux.\n\nThe structure of the class is not fundamentally different from that of previous tutorial programs, so there is little need to comment on the details with one exception: The class has a member variable `fe_dgrt` that corresponds to the \"broken\" Raviart-Thomas space mentioned in the introduction. There is a matching `dof_handler_dgrt` that represents a global enumeration of a finite element field created from this element, and a vector `darcy_velocity` that holds nodal values for this field. We will use these three variables after solving for the pressure to compute a postprocessed velocity field for which we can then evaluate the error and which we can output for visualization.\n\n```\n     template <int dim>\n     class WGDarcyEquation\n     {\n     public:\n       WGDarcyEquation(const unsigned int degree);\n       void run();\n   \n     private:\n       void make_grid();\n       void setup_system();\n       void assemble_system();\n       void solve();\n       void compute_postprocessed_velocity();\n       void compute_velocity_errors();\n       void compute_pressure_error();\n       void output_results() const;\n   \n       Triangulation<dim> triangulation;\n   \n       const FESystem<dim> fe;\n       DoFHandler<dim>     dof_handler;\n   \n       AffineConstraints<double> constraints;\n   \n       SparsityPattern      sparsity_pattern;\n       SparseMatrix<double> system_matrix;\n   \n       Vector<double> solution;\n       Vector<double> system_rhs;\n   \n       const FE_DGRaviartThomas<dim> fe_dgrt;\n       DoFHandler<dim>               dof_handler_dgrt;\n       Vector<double>                darcy_velocity;\n     };\n```\n\n### Right hand side, boundary values, and exact solution\n\nNext, we define the coefficient matrix \\(\\mathbf{K}\\) (here, the identity matrix), Dirichlet boundary conditions, the right-hand side \\(f = 2\\pi^2 \\sin(\\pi x) \\sin(\\pi y)\\), and the exact solution that corresponds to these choices for \\(K\\) and \\(f\\), namely \\(p =\n\\sin(\\pi x) \\sin(\\pi y)\\).\n\n```\n     template <int dim>\n     class Coefficient : public TensorFunction<2, dim>\n     {\n     public:\n       Coefficient()\n         : TensorFunction<2, dim>()\n       {}\n   \n       virtual void value_list(const std::vector<Point<dim>> &points,\n                               std::vector<Tensor<2, dim>> &values) const override;\n     };\n   \n   \n   \n     template <int dim>\n     void Coefficient<dim>::value_list(const std::vector<Point<dim>> &points,\n                                       std::vector<Tensor<2, dim>>   &values) const\n     {\n       AssertDimension(points.size(), values.size());\n       for (unsigned int p = 0; p < points.size(); ++p)\n         values[p] = unit_symmetric_tensor<dim>();\n     }\n   \n   \n   \n     template <int dim>\n     class BoundaryValues : public Function<dim>\n     {\n     public:\n       BoundaryValues()\n         : Function<dim>(2)\n       {}\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double BoundaryValues<dim>::value(const Point<dim> & /*p*/,\n                                       const unsigned int /*component*/) const\n     {\n       return 0;\n     }\n   \n   \n   \n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double RightHandSide<dim>::value(const Point<dim> &p,\n                                      const unsigned int /*component*/) const\n     {\n       return (2 * numbers::PI * numbers::PI * std::sin(numbers::PI * p[0]) *\n               std::sin(numbers::PI * p[1]));\n     }\n```\n\nThe class that implements the exact pressure solution has an oddity in that we implement it as a vector-valued one with two components. (We say that it has two components in the constructor where we call the constructor of the base [Function](classFunction.html) class.) In the `value()` function, we do not test for the value of the `component` argument, which implies that we return the same value for both components of the vector-valued function. We do this because we describe the finite element in use in this program as a vector-valued system that contains the interior and the interface pressures, and when we compute errors, we will want to use the same pressure solution to test both of these components.\n\n```\n     template <int dim>\n     class ExactPressure : public Function<dim>\n     {\n     public:\n       ExactPressure()\n         : Function<dim>(2)\n       {}\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double ExactPressure<dim>::value(const Point<dim> &p,\n                                      const unsigned int /*component*/) const\n     {\n       return std::sin(numbers::PI * p[0]) * std::sin(numbers::PI * p[1]);\n     }\n   \n   \n   \n     template <int dim>\n     class ExactVelocity : public TensorFunction<1, dim>\n     {\n     public:\n       ExactVelocity()\n         : TensorFunction<1, dim>()\n       {}\n   \n       virtual Tensor<1, dim> value(const Point<dim> &p) const override;\n     };\n   \n   \n   \n     template <int dim>\n     Tensor<1, dim> ExactVelocity<dim>::value(const Point<dim> &p) const\n     {\n       Tensor<1, dim> return_value;\n       return_value[0] = -numbers::PI * std::cos(numbers::PI * p[0]) *\n                         std::sin(numbers::PI * p[1]);\n       return_value[1] = -numbers::PI * std::sin(numbers::PI * p[0]) *\n                         std::cos(numbers::PI * p[1]);\n       return return_value;\n     }\n```\n\n### WGDarcyEquation class implementation\n\n#### WGDarcyEquation::WGDarcyEquation\n\nIn this constructor, we create a finite element space for vector valued functions, which will here include the ones used for the interior and interface pressures, \\(p^\\circ\\) and \\(p^\\partial\\).\n\n```\n     template <int dim>\n     WGDarcyEquation<dim>::WGDarcyEquation(const unsigned int degree)\n       : fe(FE_DGQ<dim>(degree), FE_FaceQ<dim>(degree))\n       , dof_handler(triangulation)\n       , fe_dgrt(degree)\n       , dof_handler_dgrt(triangulation)\n     {}\n```\n\n#### WGDarcyEquation::make\\_grid\n\nWe generate a mesh on the unit square domain and refine it.\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::make_grid()\n     {\n       GridGenerator::hyper_cube(triangulation, 0, 1);\n       triangulation.refine_global(5);\n   \n       std::cout << \"   Number of active cells: \" << triangulation.n_active_cells()\n                 << std::endl\n                 << \"   Total number of cells: \" << triangulation.n_cells()\n                 << std::endl;\n     }\n```\n\n#### WGDarcyEquation::setup\\_system\n\nAfter we have created the mesh above, we distribute degrees of freedom and resize matrices and vectors. The only piece of interest in this function is how we interpolate the boundary values for the pressure. Since the pressure consists of interior and interface components, we need to make sure that we only interpolate onto that component of the vector-valued solution space that corresponds to the interface pressures (as these are the only ones that are defined on the boundary of the domain). We do this via a component mask object for only the interface pressures.\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::setup_system()\n     {\n       dof_handler.distribute_dofs(fe);\n       dof_handler_dgrt.distribute_dofs(fe_dgrt);\n   \n       std::cout << \"   Number of pressure degrees of freedom: \"\n                 << dof_handler.n_dofs() << std::endl;\n   \n       solution.reinit(dof_handler.n_dofs());\n       system_rhs.reinit(dof_handler.n_dofs());\n   \n   \n       {\n         constraints.clear();\n         const FEValuesExtractors::Scalar interface_pressure(1);\n         const ComponentMask              interface_pressure_mask =\n           fe.component_mask(interface_pressure);\n         VectorTools::interpolate_boundary_values(dof_handler,\n                                                  0,\n                                                  BoundaryValues<dim>(),\n                                                  constraints,\n                                                  interface_pressure_mask);\n         constraints.close();\n       }\n```\n\nIn the bilinear form, there is no integration term over faces between two neighboring cells, so we can just use `DoFTools::make_sparsity_pattern` to calculate the sparse matrix.\n\n```\n       DynamicSparsityPattern dsp(dof_handler.n_dofs());\n       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints);\n       sparsity_pattern.copy_from(dsp);\n   \n       system_matrix.reinit(sparsity_pattern);\n     }\n```\n\n#### WGDarcyEquation::assemble\\_system\n\nThis function is more interesting. As detailed in the introduction, the assembly of the linear system requires us to evaluate the weak gradient of the shape functions, which is an element in the Raviart-Thomas space. As a consequence, we need to define a Raviart-Thomas finite element object, and have [FEValues](classFEValues.html) objects that evaluate it at quadrature points. We then need to compute the matrix \\(C^K\\) on every cell \\(K\\), for which we need the matrices \\(M^K\\) and \\(G^K\\) mentioned in the introduction.\n\nA point that may not be obvious is that in all previous tutorial programs, we have always called [FEValues::reinit()](classFEValues.html#acc8fe9d042c6b5e5da89858400feb24f) with a cell iterator from a [DoFHandler](classDoFHandler.html). This is so that one can call functions such as [FEValuesBase::get\\_function\\_values()](classFEValuesBase.html#a33e437195106aee8e3ad88b2dd40d223) that extract the values of a finite element function (represented by a vector of DoF values) on the quadrature points of a cell. For this operation to work, one needs to know which vector elements correspond to the degrees of freedom on a given cell – i.e., exactly the kind of information and operation provided by the [DoFHandler](classDoFHandler.html) class.\n\nWe could create a [DoFHandler](classDoFHandler.html) object for the \"broken\" Raviart-Thomas space (using the [FE\\_DGRaviartThomas](classFE__DGRaviartThomas.html) class), but we really don't want to here: At least in the current function, we have no need for any globally defined degrees of freedom associated with this broken space, but really only need to reference the shape functions of such a space on the current cell. As a consequence, we use the fact that one can call [FEValues::reinit()](classFEValues.html#acc8fe9d042c6b5e5da89858400feb24f) also with cell iterators into [Triangulation](classTriangulation.html) objects (rather than [DoFHandler](classDoFHandler.html) objects). In this case, [FEValues](classFEValues.html) can of course only provide us with information that only references information about cells, rather than degrees of freedom enumerated on these cells. So we can't use [FEValuesBase::get\\_function\\_values()](classFEValuesBase.html#a33e437195106aee8e3ad88b2dd40d223), but we can use [FEValues::shape\\_value()](classFEValuesBase.html#aeb39cbae775d47d3267af71434f68510) to obtain the values of shape functions at quadrature points on the current cell. It is this kind of functionality we will make use of below. The variable that will give us this information about the Raviart-Thomas functions below is then the `fe_values_rt` (and corresponding `fe_face_values_rt`) object.\n\nGiven this introduction, the following declarations should be pretty obvious:\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::assemble_system()\n     {\n       const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n       const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n   \n       FEValues<dim>     fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values);\n       FEFaceValues<dim> fe_face_values(fe,\n                                        face_quadrature_formula,\n                                        update_values | update_normal_vectors |\n                                          update_quadrature_points |\n                                          update_JxW_values);\n   \n       FEValues<dim>     fe_values_dgrt(fe_dgrt,\n                                    quadrature_formula,\n                                    update_values | update_gradients |\n                                      update_quadrature_points |\n                                      update_JxW_values);\n       FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                             face_quadrature_formula,\n                                             update_values |\n                                               update_normal_vectors |\n                                               update_quadrature_points |\n                                               update_JxW_values);\n   \n       const unsigned int dofs_per_cell      = fe.n_dofs_per_cell();\n       const unsigned int dofs_per_cell_dgrt = fe_dgrt.n_dofs_per_cell();\n   \n       const unsigned int n_q_points      = fe_values.get_quadrature().size();\n       const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n   \n       const unsigned int n_face_q_points = fe_face_values.get_quadrature().size();\n   \n       RightHandSide<dim>  right_hand_side;\n       std::vector<double> right_hand_side_values(n_q_points);\n   \n       const Coefficient<dim>      coefficient;\n       std::vector<Tensor<2, dim>> coefficient_values(n_q_points);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n```\n\nNext, let us declare the various cell matrices discussed in the introduction:\n\n```\n       FullMatrix<double> cell_matrix_M(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n       FullMatrix<double> cell_matrix_G(dofs_per_cell_dgrt, dofs_per_cell);\n       FullMatrix<double> cell_matrix_C(dofs_per_cell, dofs_per_cell_dgrt);\n       FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<double>     cell_rhs(dofs_per_cell);\n       Vector<double>     cell_solution(dofs_per_cell);\n```\n\nWe need `FEValuesExtractors` to access the `interior` and `face` component of the shape functions.\n\n```\n       const FEValuesExtractors::Vector velocities(0);\n       const FEValuesExtractors::Scalar pressure_interior(0);\n       const FEValuesExtractors::Scalar pressure_face(1);\n```\n\nThis finally gets us in position to loop over all cells. On each cell, we will first calculate the various cell matrices used to construct the local matrix – as they depend on the cell in question, they need to be re-computed on each cell. We need shape functions for the Raviart-Thomas space as well, for which we need to create first an iterator to the cell of the triangulation, which we can obtain by assignment from the cell pointing into the [DoFHandler](classDoFHandler.html).\n\n```\n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           fe_values.reinit(cell);\n   \n           const typename Triangulation<dim>::active_cell_iterator cell_dgrt =\n             cell;\n           fe_values_dgrt.reinit(cell_dgrt);\n   \n           right_hand_side.value_list(fe_values.get_quadrature_points(),\n                                      right_hand_side_values);\n           coefficient.value_list(fe_values.get_quadrature_points(),\n                                  coefficient_values);\n```\n\nThe first cell matrix we will compute is the [mass matrix](DEALGlossary.html#GlossMassMatrix) for the Raviart-Thomas space. Hence, we need to loop over all the quadrature points for the velocity [FEValues](classFEValues.html) object.\n\n```\n           cell_matrix_M = 0;\n           for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n             for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n               {\n                 const Tensor<1, dim> v_i = fe_values_dgrt[velocities].value(i, q);\n                 for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n                   {\n                     const Tensor<1, dim> v_k =\n                       fe_values_dgrt[velocities].value(k, q);\n                     cell_matrix_M(i, k) += (v_i * v_k * fe_values_dgrt.JxW(q));\n                   }\n               }\n```\n\nNext we take the inverse of this matrix by using [FullMatrix::gauss\\_jordan()](classFullMatrix.html#a898466c57e11e6f2599165071ffe5df3). It will be used to calculate the coefficient matrix \\(C^K\\) later. It is worth recalling later that `cell_matrix_M` actually contains the *inverse* of \\(M^K\\) after this call.\n\n```\n           cell_matrix_M.gauss_jordan();\n```\n\nFrom the introduction, we know that the right hand side \\(G^K\\) of the equation that defines \\(C^K\\) is the difference between a face integral and a cell integral. Here, we approximate the negative of the contribution in the interior. Each component of this matrix is the integral of a product between a basis function of the polynomial space and the divergence of a basis function of the Raviart-Thomas space. These basis functions are defined in the interior.\n\n```\n           cell_matrix_G = 0;\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n               {\n                 const double div_v_i =\n                   fe_values_dgrt[velocities].divergence(i, q);\n                 for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                   {\n                     const double phi_j_interior =\n                       fe_values[pressure_interior].value(j, q);\n   \n                     cell_matrix_G(i, j) -=\n                       (div_v_i * phi_j_interior * fe_values.JxW(q));\n                   }\n               }\n```\n\nNext, we approximate the integral on faces by quadrature. Each component is the integral of a product between a basis function of the polynomial space and the dot product of a basis function of the Raviart-Thomas space and the normal vector. So we loop over all the faces of the element and obtain the normal vector.\n\n```\n           for (const auto &face : cell->face_iterators())\n             {\n               fe_face_values.reinit(cell, face);\n               fe_face_values_dgrt.reinit(cell_dgrt, face);\n   \n               for (unsigned int q = 0; q < n_face_q_points; ++q)\n                 {\n                   const Tensor<1, dim> &normal = fe_face_values.normal_vector(q);\n   \n                   for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n                     {\n                       const Tensor<1, dim> v_i =\n                         fe_face_values_dgrt[velocities].value(i, q);\n                       for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                         {\n                           const double phi_j_face =\n                             fe_face_values[pressure_face].value(j, q);\n   \n                           cell_matrix_G(i, j) +=\n                             ((v_i * normal) * phi_j_face * fe_face_values.JxW(q));\n                         }\n                     }\n                 }\n             }\n```\n\n`cell_matrix_C` is then the matrix product between the transpose of \\(G^K\\) and the inverse of the mass matrix (where this inverse is stored in `cell_matrix_M`):\n\n```\n           cell_matrix_G.Tmmult(cell_matrix_C, cell_matrix_M);\n```\n\nFinally we can compute the local matrix \\(A^K\\). Element \\(A^K\\_{ij}\\) is given by \\(\\int\\_{E} \\sum\\_{k,l} C\\_{ik} C\\_{jl}\n(\\mathbf{K} \\mathbf{v}\\_k) \\cdot \\mathbf{v}\\_l\n\\mathrm{d}x\\). We have calculated the coefficients \\(C\\) in the previous step, and so obtain the following after suitably re-arranging the loops:\n\n```\n           local_matrix = 0;\n           for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n             {\n               for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n                 {\n                   const Tensor<1, dim> v_k =\n                     fe_values_dgrt[velocities].value(k, q);\n                   for (unsigned int l = 0; l < dofs_per_cell_dgrt; ++l)\n                     {\n                       const Tensor<1, dim> v_l =\n                         fe_values_dgrt[velocities].value(l, q);\n   \n                       for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                         for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                           local_matrix(i, j) +=\n                             (coefficient_values[q] * cell_matrix_C[i][k] * v_k) *\n                             cell_matrix_C[j][l] * v_l * fe_values_dgrt.JxW(q);\n                     }\n                 }\n             }\n```\n\nNext, we calculate the right hand side, \\(\\int\\_{K} f q \\mathrm{d}x\\):\n\n```\n           cell_rhs = 0;\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             for (unsigned int i = 0; i < dofs_per_cell; ++i)\n               {\n                 cell_rhs(i) += (fe_values[pressure_interior].value(i, q) *\n                                 right_hand_side_values[q] * fe_values.JxW(q));\n               }\n```\n\nThe last step is to distribute components of the local matrix into the system matrix and transfer components of the cell right hand side into the system right hand side:\n\n```\n           cell->get_dof_indices(local_dof_indices);\n           constraints.distribute_local_to_global(\n             local_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\n         }\n     }\n```\n\n#### WGDarcyEquation<dim>::solve\n\nThis step is rather trivial and the same as in many previous tutorial programs:\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::solve()\n     {\n       SolverControl            solver_control(1000, 1e-8 * system_rhs.l2_norm());\n       SolverCG<Vector<double>> solver(solver_control);\n       solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\n       constraints.distribute(solution);\n     }\n```\n\n#### WGDarcyEquation<dim>::compute\\_postprocessed\\_velocity\n\nIn this function, compute the velocity field from the pressure solution previously computed. The velocity is defined as \\(\\mathbf{u}\\_h = \\mathbf{Q}\\_h \\left(\n-\\mathbf{K}\\nabla\\_{w,d}p\\_h \\right)\\), which requires us to compute many of the same terms as in the assembly of the system matrix. There are also the matrices \\(E^K,D^K\\) we need to assemble (see the introduction) but they really just follow the same kind of pattern.\n\nComputing the same matrices here as we have already done in the `assemble_system()` function is of course wasteful in terms of CPU time. Likewise, we copy some of the code from there to this function, and this is also generally a poor idea. A better implementation might provide for a function that encapsulates this duplicated code. One could also think of using the classic trade-off between computing efficiency and memory efficiency to only compute the \\(C^K\\) matrices once per cell during the assembly, storing them somewhere on the side, and re-using them here. (This is what [step-51](step_51.html) does, for example, where the `assemble_system()` function takes an argument that determines whether the local matrices are recomputed, and a similar approach – maybe with storing local matrices elsewhere – could be adapted for the current program.)\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::compute_postprocessed_velocity()\n     {\n       darcy_velocity.reinit(dof_handler_dgrt.n_dofs());\n   \n       const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n       const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values);\n   \n       FEFaceValues<dim> fe_face_values(fe,\n                                        face_quadrature_formula,\n                                        update_values | update_normal_vectors |\n                                          update_quadrature_points |\n                                          update_JxW_values);\n   \n       FEValues<dim> fe_values_dgrt(fe_dgrt,\n                                    quadrature_formula,\n                                    update_values | update_gradients |\n                                      update_quadrature_points |\n                                      update_JxW_values);\n   \n       FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                             face_quadrature_formula,\n                                             update_values |\n                                               update_normal_vectors |\n                                               update_quadrature_points |\n                                               update_JxW_values);\n   \n       const unsigned int dofs_per_cell      = fe.n_dofs_per_cell();\n       const unsigned int dofs_per_cell_dgrt = fe_dgrt.n_dofs_per_cell();\n   \n       const unsigned int n_q_points      = fe_values.get_quadrature().size();\n       const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n   \n       const unsigned int n_face_q_points = fe_face_values.get_quadrature().size();\n   \n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n       std::vector<types::global_dof_index> local_dof_indices_dgrt(\n         dofs_per_cell_dgrt);\n   \n       FullMatrix<double> cell_matrix_M(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n       FullMatrix<double> cell_matrix_G(dofs_per_cell_dgrt, dofs_per_cell);\n       FullMatrix<double> cell_matrix_C(dofs_per_cell, dofs_per_cell_dgrt);\n       FullMatrix<double> cell_matrix_D(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n       FullMatrix<double> cell_matrix_E(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n   \n       Vector<double> cell_solution(dofs_per_cell);\n       Vector<double> cell_velocity(dofs_per_cell_dgrt);\n   \n       const Coefficient<dim>      coefficient;\n       std::vector<Tensor<2, dim>> coefficient_values(n_q_points_dgrt);\n   \n       const FEValuesExtractors::Vector velocities(0);\n       const FEValuesExtractors::Scalar pressure_interior(0);\n       const FEValuesExtractors::Scalar pressure_face(1);\n```\n\nIn the introduction, we explained how to calculate the numerical velocity on the cell. We need the pressure solution values on each cell, coefficients of the Gram matrix and coefficients of the \\(L\\_2\\) projection. We have already calculated the global solution, so we will extract the cell solution from the global solution. The coefficients of the Gram matrix have been calculated when we assembled the system matrix for the pressures. We will do the same way here. For the coefficients of the projection, we do matrix multiplication, i.e., the inverse of the Gram matrix times the matrix with \\((\\mathbf{K} \\mathbf{w}, \\mathbf{w})\\) as components. Then, we multiply all these coefficients and call them beta. The numerical velocity is the product of beta and the basis functions of the Raviart-Thomas space.\n\n```\n       typename DoFHandler<dim>::active_cell_iterator\n         cell = dof_handler.begin_active(),\n         endc = dof_handler.end(), cell_dgrt = dof_handler_dgrt.begin_active();\n       for (; cell != endc; ++cell, ++cell_dgrt)\n         {\n           fe_values.reinit(cell);\n           fe_values_dgrt.reinit(cell_dgrt);\n   \n           coefficient.value_list(fe_values_dgrt.get_quadrature_points(),\n                                  coefficient_values);\n```\n\nThe component of this `cell_matrix_E` is the integral of \\((\\mathbf{K} \\mathbf{w}, \\mathbf{w})\\). `cell_matrix_M` is the Gram matrix.\n\n```\n           cell_matrix_M = 0;\n           cell_matrix_E = 0;\n           for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n             for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n               {\n                 const Tensor<1, dim> v_i = fe_values_dgrt[velocities].value(i, q);\n                 for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n                   {\n                     const Tensor<1, dim> v_k =\n                       fe_values_dgrt[velocities].value(k, q);\n   \n                     cell_matrix_E(i, k) +=\n                       (coefficient_values[q] * v_i * v_k * fe_values_dgrt.JxW(q));\n   \n                     cell_matrix_M(i, k) += (v_i * v_k * fe_values_dgrt.JxW(q));\n                   }\n               }\n```\n\nTo compute the matrix \\(D\\) mentioned in the introduction, we then need to evaluate \\(D=M^{-1}E\\) as explained in the introduction:\n\n```\n           cell_matrix_M.gauss_jordan();\n           cell_matrix_M.mmult(cell_matrix_D, cell_matrix_E);\n```\n\nThen we also need, again, to compute the matrix \\(C\\) that is used to evaluate the weak discrete gradient. This is the exact same code as used in the assembly of the system matrix, so we just copy it from there:\n\n```\n           cell_matrix_G = 0;\n           for (unsigned int q = 0; q < n_q_points; ++q)\n             for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n               {\n                 const double div_v_i =\n                   fe_values_dgrt[velocities].divergence(i, q);\n                 for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                   {\n                     const double phi_j_interior =\n                       fe_values[pressure_interior].value(j, q);\n   \n                     cell_matrix_G(i, j) -=\n                       (div_v_i * phi_j_interior * fe_values.JxW(q));\n                   }\n               }\n   \n           for (const auto &face : cell->face_iterators())\n             {\n               fe_face_values.reinit(cell, face);\n               fe_face_values_dgrt.reinit(cell_dgrt, face);\n   \n               for (unsigned int q = 0; q < n_face_q_points; ++q)\n                 {\n                   const Tensor<1, dim> &normal = fe_face_values.normal_vector(q);\n   \n                   for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n                     {\n                       const Tensor<1, dim> v_i =\n                         fe_face_values_dgrt[velocities].value(i, q);\n                       for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                         {\n                           const double phi_j_face =\n                             fe_face_values[pressure_face].value(j, q);\n   \n                           cell_matrix_G(i, j) +=\n                             ((v_i * normal) * phi_j_face * fe_face_values.JxW(q));\n                         }\n                     }\n                 }\n             }\n           cell_matrix_G.Tmmult(cell_matrix_C, cell_matrix_M);\n```\n\nFinally, we need to extract the pressure unknowns that correspond to the current cell:\n\n```\n           cell->get_dof_values(solution, cell_solution);\n```\n\nWe are now in a position to compute the local velocity unknowns (with respect to the Raviart-Thomas space we are projecting the term \\(-\\mathbf K \\nabla\\_{w,d} p\\_h\\) into):\n\n```\n           cell_velocity = 0;\n           for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n             for (unsigned int j = 0; j < dofs_per_cell_dgrt; ++j)\n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 cell_velocity(k) +=\n                   -(cell_solution(i) * cell_matrix_C(i, j) * cell_matrix_D(k, j));\n```\n\nWe compute Darcy velocity. This is same as cell\\_velocity but used to graph Darcy velocity.\n\n```\n           cell_dgrt->get_dof_indices(local_dof_indices_dgrt);\n           for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n             for (unsigned int j = 0; j < dofs_per_cell_dgrt; ++j)\n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 darcy_velocity(local_dof_indices_dgrt[k]) +=\n                   -(cell_solution(i) * cell_matrix_C(i, j) * cell_matrix_D(k, j));\n         }\n     }\n```\n\n#### WGDarcyEquation<dim>::compute\\_pressure\\_error\n\nThis part is to calculate the \\(L\\_2\\) error of the pressure. We define a vector that holds the norm of the error on each cell. Next, we use VectorTool::integrate\\_difference() to compute the error in the \\(L\\_2\\) norm on each cell. However, we really only care about the error in the interior component of the solution vector (we can't even evaluate the interface pressures at the quadrature points because these are all located in the interior of cells) and consequently have to use a weight function that ensures that the interface component of the solution variable is ignored. This is done by using the [ComponentSelectFunction](classComponentSelectFunction.html) whose arguments indicate which component we want to select (component zero, i.e., the interior pressures) and how many components there are in total (two).\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::compute_pressure_error()\n     {\n       Vector<float> difference_per_cell(triangulation.n_active_cells());\n       const ComponentSelectFunction<dim> select_interior_pressure(0, 2);\n       VectorTools::integrate_difference(dof_handler,\n                                         solution,\n                                         ExactPressure<dim>(),\n                                         difference_per_cell,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::L2_norm,\n                                         &select_interior_pressure);\n   \n       const double L2_error = difference_per_cell.l2_norm();\n       std::cout << \"L2_error_pressure \" << L2_error << std::endl;\n     }\n```\n\n#### WGDarcyEquation<dim>::compute\\_velocity\\_error\n\nIn this function, we evaluate \\(L\\_2\\) errors for the velocity on each cell, and \\(L\\_2\\) errors for the flux on faces. The function relies on the `compute_postprocessed_velocity()` function having previous computed, which computes the velocity field based on the pressure solution that has previously been computed.\n\nWe are going to evaluate velocities on each cell and calculate the difference between numerical and exact velocities.\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::compute_velocity_errors()\n     {\n       const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n       const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n   \n       FEValues<dim> fe_values_dgrt(fe_dgrt,\n                                    quadrature_formula,\n                                    update_values | update_gradients |\n                                      update_quadrature_points |\n                                      update_JxW_values);\n   \n       FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                             face_quadrature_formula,\n                                             update_values |\n                                               update_normal_vectors |\n                                               update_quadrature_points |\n                                               update_JxW_values);\n   \n       const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n       const unsigned int n_face_q_points_dgrt =\n         fe_face_values_dgrt.get_quadrature().size();\n   \n       std::vector<Tensor<1, dim>> velocity_values(n_q_points_dgrt);\n       std::vector<Tensor<1, dim>> velocity_face_values(n_face_q_points_dgrt);\n   \n       const FEValuesExtractors::Vector velocities(0);\n   \n       const ExactVelocity<dim> exact_velocity;\n   \n       double L2_err_velocity_cell_sqr_global = 0;\n       double L2_err_flux_sqr                 = 0;\n```\n\nHaving previously computed the postprocessed velocity, we here only have to extract the corresponding values on each cell and face and compare it to the exact values.\n\n```\n       for (const auto &cell_dgrt : dof_handler_dgrt.active_cell_iterators())\n         {\n           fe_values_dgrt.reinit(cell_dgrt);\n```\n\nFirst compute the \\(L\\_2\\) error between the postprocessed velocity field and the exact one:\n\n```\n           fe_values_dgrt[velocities].get_function_values(darcy_velocity,\n                                                          velocity_values);\n           double L2_err_velocity_cell_sqr_local = 0;\n           for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n             {\n               const Tensor<1, dim> velocity = velocity_values[q];\n               const Tensor<1, dim> true_velocity =\n                 exact_velocity.value(fe_values_dgrt.quadrature_point(q));\n   \n               L2_err_velocity_cell_sqr_local +=\n                 ((velocity - true_velocity) * (velocity - true_velocity) *\n                  fe_values_dgrt.JxW(q));\n             }\n           L2_err_velocity_cell_sqr_global += L2_err_velocity_cell_sqr_local;\n```\n\nFor reconstructing the flux we need the size of cells and faces. Since fluxes are calculated on faces, we have the loop over all four faces of each cell. To calculate the face velocity, we extract values at the quadrature points from the `darcy_velocity` which we have computed previously. Then, we calculate the squared velocity error in normal direction. Finally, we calculate the \\(L\\_2\\) flux error on the cell by appropriately scaling with face and cell areas and add it to the global error.\n\n```\n           const double cell_area = cell_dgrt->measure();\n           for (const auto &face_dgrt : cell_dgrt->face_iterators())\n             {\n               const double face_length = face_dgrt->measure();\n               fe_face_values_dgrt.reinit(cell_dgrt, face_dgrt);\n               fe_face_values_dgrt[velocities].get_function_values(\n                 darcy_velocity, velocity_face_values);\n   \n               double L2_err_flux_face_sqr_local = 0;\n               for (unsigned int q = 0; q < n_face_q_points_dgrt; ++q)\n                 {\n                   const Tensor<1, dim> velocity = velocity_face_values[q];\n                   const Tensor<1, dim> true_velocity =\n                     exact_velocity.value(fe_face_values_dgrt.quadrature_point(q));\n   \n                   const Tensor<1, dim> &normal =\n                     fe_face_values_dgrt.normal_vector(q);\n   \n                   L2_err_flux_face_sqr_local +=\n                     ((velocity * normal - true_velocity * normal) *\n                      (velocity * normal - true_velocity * normal) *\n                      fe_face_values_dgrt.JxW(q));\n                 }\n               const double err_flux_each_face =\n                 L2_err_flux_face_sqr_local / face_length * cell_area;\n               L2_err_flux_sqr += err_flux_each_face;\n             }\n         }\n```\n\nAfter adding up errors over all cells and faces, we take the square root and get the \\(L\\_2\\) errors of velocity and flux. These we output to screen.\n\n```\n       const double L2_err_velocity_cell =\n         std::sqrt(L2_err_velocity_cell_sqr_global);\n       const double L2_err_flux_face = std::sqrt(L2_err_flux_sqr);\n   \n       std::cout << \"L2_error_vel:  \" << L2_err_velocity_cell << std::endl\n                 << \"L2_error_flux: \" << L2_err_flux_face << std::endl;\n     }\n```\n\n#### WGDarcyEquation::output\\_results\n\nWe have two sets of results to output: the interior solution and the skeleton solution. We use `DataOut` to visualize interior results. The graphical output for the skeleton results is done by using the [DataOutFaces](classDataOutFaces.html) class.\n\nIn both of the output files, both the interior and the face variables are stored. For the interface output, the output file simply contains the interpolation of the interior pressures onto the faces, but because it is undefined which of the two interior pressure variables you get from the two adjacent cells, it is best to ignore the interior pressure in the interface output file. Conversely, for the cell interior output file, it is of course impossible to show any interface pressures \\(p^\\partial\\), because these are only available on interfaces and not cell interiors. Consequently, you will see them shown as an invalid value (such as an infinity).\n\nFor the cell interior output, we also want to output the velocity variables. This is a bit tricky since it lives on the same mesh but uses a different [DoFHandler](classDoFHandler.html) object (the pressure variables live on the `dof_handler` object, the Darcy velocity on the `dof_handler_dgrt` object). Fortunately, there are variations of the [DataOut::add\\_data\\_vector()](classDataOut__DoFData.html#ac43d3b1f6e67424f36e474627fe8e401) function that allow specifying which [DoFHandler](classDoFHandler.html) a vector corresponds to, and consequently we can visualize the data from both [DoFHandler](classDoFHandler.html) objects within the same file.\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::output_results() const\n     {\n       {\n         DataOut<dim> data_out;\n```\n\nFirst attach the pressure solution to the [DataOut](classDataOut.html) object:\n\n```\n         const std::vector<std::string> solution_names = {\"interior_pressure\",\n                                                          \"interface_pressure\"};\n         data_out.add_data_vector(dof_handler, solution, solution_names);\n```\n\nThen do the same with the Darcy velocity field, and continue with writing everything out into a file.\n\n```\n         const std::vector<std::string> velocity_names(dim, \"velocity\");\n         const std::vector<\n           DataComponentInterpretation::DataComponentInterpretation>\n           velocity_component_interpretation(\n             dim, DataComponentInterpretation::component_is_part_of_vector);\n         data_out.add_data_vector(dof_handler_dgrt,\n                                  darcy_velocity,\n                                  velocity_names,\n                                  velocity_component_interpretation);\n   \n         data_out.build_patches(fe.degree);\n         std::ofstream output(\"solution_interior.vtu\");\n         data_out.write_vtu(output);\n       }\n   \n       {\n         DataOutFaces<dim> data_out_faces(false);\n         data_out_faces.attach_dof_handler(dof_handler);\n         data_out_faces.add_data_vector(solution, \"Pressure_Face\");\n         data_out_faces.build_patches(fe.degree);\n         std::ofstream face_output(\"solution_interface.vtu\");\n         data_out_faces.write_vtu(face_output);\n       }\n     }\n```\n\n#### WGDarcyEquation::run\n\nThis is the final function of the main class. It calls the other functions of our class.\n\n```\n     template <int dim>\n     void WGDarcyEquation<dim>::run()\n     {\n       std::cout << \"Solving problem in \" << dim << \" space dimensions.\"\n                 << std::endl;\n       make_grid();\n       setup_system();\n       assemble_system();\n       solve();\n       compute_postprocessed_velocity();\n       compute_pressure_error();\n       compute_velocity_errors();\n       output_results();\n     }\n   \n   } // namespace Step61\n```\n\n### The `main` function\n\nThis is the main function. We can change the dimension here to run in 3d.\n\n```\n   int main()\n   {\n     try\n       {\n         Step61::WGDarcyEquation<2> wg_darcy(0);\n         wg_darcy.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nWe run the program with a right hand side that will produce the solution \\(p = \\sin(\\pi x) \\sin(\\pi y)\\) and with homogeneous Dirichlet boundary conditions in the domain \\(\\Omega = (0,1)^2\\). In addition, we choose the coefficient matrix in the differential operator \\(\\mathbf{K}\\) as the identity matrix. We test this setup using \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\), \\(\\mbox{WG}(Q\\_1,Q\\_1;RT\\_{[1]})\\) and \\(\\mbox{WG}(Q\\_2,Q\\_2;RT\\_{[2]})\\) element combinations, which one can select by using the appropriate constructor argument for the `WGDarcyEquation` object in `main()`. We will then visualize pressure values in interiors of cells and on faces. We want to see that the pressure maximum is around 1 and the minimum is around 0. With mesh refinement, the convergence rates of pressure, velocity and flux should then be around 1 for \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\) , 2 for \\(\\mbox{WG}(Q\\_1,Q\\_1;RT\\_{[1]})\\), and 3 for \\(\\mbox{WG}(Q\\_2,Q\\_2;RT\\_{[2]})\\).\n\n### Test results on *WG(Q0,Q0;RT[0])*\n\nThe following figures show interior pressures and face pressures using the \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\) element. The mesh is refined 2 times (top) and 4 times (bottom), respectively. (This number can be adjusted in the `make_grid()` function.) When the mesh is coarse, one can see the face pressures \\(p^\\partial\\) neatly between the values of the interior pressures \\(p^\\circ\\) on the two adjacent cells.\n\n|  |  |\n| --- | --- |\n|  |  |\n|  |  |\n\nFrom the figures, we can see that with the mesh refinement, the maximum and minimum pressure values are approaching the values we expect. Since the mesh is a rectangular mesh and numbers of cells in each direction is even, we have symmetric solutions. From the 3d figures on the right, we can see that on \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\), the pressure is a constant in the interior of the cell, as expected.\n\n#### Convergence table for *k=0*\n\nWe run the code with differently refined meshes (chosen in the `make_grid()` function) and get the following convergence rates of pressure, velocity, and flux (as defined in the introduction).\n\n| number of refinements | \\(\\|p-p\\_h^\\circ\\|\\) | \\(\\|\\mathbf{u}-\\mathbf{u}\\_h\\|\\) | \\(\\|(\\mathbf{u}-\\mathbf{u}\\_h) \\cdot \\mathbf{n}\\|\\) |\n| --- | --- | --- | --- |\n| 2 | 1.587e-01 | 5.113e-01 | 7.062e-01 |\n| 3 | 8.000e-02 | 2.529e-01 | 3.554e-01 |\n| 4 | 4.006e-02 | 1.260e-01 | 1.780e-01 |\n| 5 | 2.004e-02 | 6.297e-02 | 8.902e-02 |\n| Conv.rate | 1.00 | 1.00 | 1.00 |\n\nWe can see that the convergence rates of \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\) are around 1. This, of course, matches our theoretical expectations.\n\n### Test results on *WG(Q1,Q1;RT[1])*\n\nWe can repeat the experiment from above using the next higher polynomial degree: The following figures are interior pressures and face pressures implemented using \\(\\mbox{WG}(Q\\_1,Q\\_1;RT\\_{[1]})\\). The mesh is refined 4 times. Compared to the previous figures using \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\), on each cell, the solution is no longer constant on each cell, as we now use bilinear polynomials to do the approximation. Consequently, there are 4 pressure values in one interior, 2 pressure values on each face.\n\n|  |  |\n| --- | --- |\n|  |  |\n\nCompared to the corresponding image for the \\(\\mbox{WG}(Q\\_0,Q\\_0;RT\\_{[0]})\\) combination, the solution is now substantially more accurate and, in particular so close to being continuous at the interfaces that we can no longer distinguish the interface pressures \\(p^\\partial\\) from the interior pressures \\(p^\\circ\\) on the adjacent cells.\n\n#### Convergence table for *k=1*\n\nThe following are the convergence rates of pressure, velocity, and flux we obtain from using the \\(\\mbox{WG}(Q\\_1,Q\\_1;RT\\_{[1]})\\) element combination:\n\n| number of refinements | \\(\\|p-p\\_h^\\circ\\|\\) | \\(\\|\\mathbf{u}-\\mathbf{u}\\_h\\|\\) | \\(\\|(\\mathbf{u}-\\mathbf{u}\\_h) \\cdot \\mathbf{n}\\|\\) |\n| --- | --- | --- | --- |\n| 2 | 1.613e-02 | 5.093e-02 | 7.167e-02 |\n| 3 | 4.056e-03 | 1.276e-02 | 1.802e-02 |\n| 4 | 1.015e-03 | 3.191e-03 | 4.512e-03 |\n| 5 | 2.540e-04 | 7.979e-04 | 1.128e-03 |\n| Conv.rate | 2.00 | 2.00 | 2.00 |\n\nThe convergence rates of \\(WG(Q\\_1,Q\\_1;RT\\_{[1]})\\) are around 2, as expected.\n\n### Test results on *WG(Q2,Q2;RT[2])*\n\nLet us go one polynomial degree higher. The following are interior pressures and face pressures implemented using \\(WG(Q\\_2,Q\\_2;RT\\_{[2]})\\), with mesh size \\(h = 1/32\\) (i.e., 5 global mesh refinement steps). In the program, we use `data_out_face.build_patches(fe.degree)` when generating graphical output (see the documentation of [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646)), which here implies that we divide each 2d cell interior into 4 subcells in order to provide a better visualization of the quadratic polynomials.\n\n|  |  |\n| --- | --- |\n|  |  |\n\n#### Convergence table for *k=2*\n\nAs before, we can generate convergence data for the \\(L\\_2\\) errors of pressure, velocity, and flux using the \\(\\mbox{WG}(Q\\_2,Q\\_2;RT\\_{[2]})\\) combination:\n\n| number of refinements | \\(\\|p-p\\_h^\\circ\\|\\) | \\(\\|\\mathbf{u}-\\mathbf{u}\\_h\\|\\) | \\(\\|(\\mathbf{u}-\\mathbf{u}\\_h) \\cdot \\mathbf{n}\\|\\) |\n| --- | --- | --- | --- |\n| 2 | 1.072e-03 | 3.375e-03 | 4.762e-03 |\n| 3 | 1.347e-04 | 4.233e-04 | 5.982e-04 |\n| 4 | 1.685e-05 | 5.295e-05 | 7.487e-05 |\n| 5 | 2.107e-06 | 6.620e-06 | 9.362e-06 |\n| Conv.rate | 3.00 | 3.00 | 3.00 |\n\nOnce more, the convergence rates of \\(\\mbox{WG}(Q\\_2,Q\\_2;RT\\_{[2]})\\) is as expected, with values around 3.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2019 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Zhuoran Wang, Colorado State University, 2018\n */\n \n#include <deal.II/base/quadrature.h>\n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/tensor_function.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/point.h>\n#include <deal.II/lac/block_vector.h>\n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/block_sparse_matrix.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n#include <deal.II/fe/fe_dgq.h>\n#include <deal.II/fe/fe_raviart_thomas.h>\n#include <deal.II/fe/fe_dg_vector.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/fe/fe_face.h>\n#include <deal.II/fe/component_mask.h>\n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/data_out_faces.h>\n \n#include <fstream>\n#include <iostream>\n \n \nnamespace Step61\n{\n using namespace dealii;\n \n \n template <int dim>\n class WGDarcyEquation\n  {\n public:\n    WGDarcyEquation(const unsigned int degree);\n void run();\n \n private:\n void make_grid();\n void setup_system();\n void assemble_system();\n void solve();\n void compute_postprocessed_velocity();\n void compute_velocity_errors();\n void compute_pressure_error();\n void output_results() const;\n \n Triangulation<dim> triangulation;\n \n const FESystem<dim> fe;\n DoFHandler<dim>     dof_handler;\n \n AffineConstraints<double> constraints;\n \n SparsityPattern      sparsity_pattern;\n SparseMatrix<double> system_matrix;\n \n Vector<double> solution;\n Vector<double> system_rhs;\n \n const FE_DGRaviartThomas<dim> fe_dgrt;\n DoFHandler<dim>               dof_handler_dgrt;\n Vector<double>                darcy_velocity;\n  };\n \n \n \n \n template <int dim>\n class Coefficient : public TensorFunction<2, dim>\n  {\n public:\n    Coefficient()\n      : TensorFunction<2, dim>()\n    {}\n \n virtual void value_list(const std::vector<Point<dim>> &points,\n                            std::vector<Tensor<2, dim>> &values) const override;\n  };\n \n \n \n template <int dim>\n void Coefficient<dim>::value_list(const std::vector<Point<dim>> &points,\n                                    std::vector<Tensor<2, dim>>   &values) const\n {\n AssertDimension(points.size(), values.size());\n for (unsigned int p = 0; p < points.size(); ++p)\n      values[p] = unit_symmetric_tensor<dim>();\n  }\n \n \n \n template <int dim>\n class BoundaryValues : public Function<dim>\n  {\n public:\n    BoundaryValues()\n      : Function<dim>(2)\n    {}\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double BoundaryValues<dim>::value(const Point<dim> & /*p*/,\n const unsigned int /*component*/) const\n {\n return 0;\n  }\n \n \n \n template <int dim>\n class RightHandSide : public Function<dim>\n  {\n public:\n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double RightHandSide<dim>::value(const Point<dim> &p,\n const unsigned int /*component*/) const\n {\n return (2 * numbers::PI * numbers::PI * std::sin(numbers::PI * p[0]) *\n std::sin(numbers::PI * p[1]));\n  }\n \n \n \n template <int dim>\n class ExactPressure : public Function<dim>\n  {\n public:\n    ExactPressure()\n      : Function<dim>(2)\n    {}\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component) const override;\n  };\n \n \n \n template <int dim>\n double ExactPressure<dim>::value(const Point<dim> &p,\n const unsigned int /*component*/) const\n {\n return std::sin(numbers::PI * p[0]) * std::sin(numbers::PI * p[1]);\n  }\n \n \n \n template <int dim>\n class ExactVelocity : public TensorFunction<1, dim>\n  {\n public:\n    ExactVelocity()\n      : TensorFunction<1, dim>()\n    {}\n \n virtual Tensor<1, dim> value(const Point<dim> &p) const override;\n  };\n \n \n \n template <int dim>\n Tensor<1, dim> ExactVelocity<dim>::value(const Point<dim> &p) const\n {\n Tensor<1, dim> return_value;\n    return_value[0] = -numbers::PI * std::cos(numbers::PI * p[0]) *\n std::sin(numbers::PI * p[1]);\n    return_value[1] = -numbers::PI * std::sin(numbers::PI * p[0]) *\n std::cos(numbers::PI * p[1]);\n return return_value;\n  }\n \n \n \n \n \n template <int dim>\n  WGDarcyEquation<dim>::WGDarcyEquation(const unsigned int degree)\n    : fe(FE_DGQ<dim>(degree), FE_FaceQ<dim>(degree))\n    , dof_handler(triangulation)\n    , fe_dgrt(degree)\n    , dof_handler_dgrt(triangulation)\n  {}\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::make_grid()\n  {\n GridGenerator::hyper_cube(triangulation, 0, 1);\n triangulation.refine_global(5);\n \n    std::cout << \"   Number of active cells: \" << triangulation.n_active_cells()\n              << std::endl\n              << \"   Total number of cells: \" << triangulation.n_cells()\n              << std::endl;\n  }\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::setup_system()\n  {\n    dof_handler.distribute_dofs(fe);\n    dof_handler_dgrt.distribute_dofs(fe_dgrt);\n \n    std::cout << \"   Number of pressure degrees of freedom: \"\n              << dof_handler.n_dofs() << std::endl;\n \n    solution.reinit(dof_handler.n_dofs());\n    system_rhs.reinit(dof_handler.n_dofs());\n \n \n    {\n      constraints.clear();\n const FEValuesExtractors::Scalar interface_pressure(1);\n const ComponentMask              interface_pressure_mask =\n        fe.component_mask(interface_pressure);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                               0,\n                                               BoundaryValues<dim>(),\n                                               constraints,\n                                               interface_pressure_mask);\n      constraints.close();\n    }\n \n \n DynamicSparsityPattern dsp(dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints);\n    sparsity_pattern.copy_from(dsp);\n \n    system_matrix.reinit(sparsity_pattern);\n  }\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::assemble_system()\n  {\n const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n \n FEValues<dim>     fe_values(fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values);\n FEFaceValues<dim> fe_face_values(fe,\n                                     face_quadrature_formula,\n update_values | update_normal_vectors |\n update_quadrature_points |\n update_JxW_values);\n \n FEValues<dim>     fe_values_dgrt(fe_dgrt,\n                                 quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points |\n update_JxW_values);\n FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                          face_quadrature_formula,\n update_values |\n update_normal_vectors |\n update_quadrature_points |\n update_JxW_values);\n \n const unsigned int dofs_per_cell      = fe.n_dofs_per_cell();\n const unsigned int dofs_per_cell_dgrt = fe_dgrt.n_dofs_per_cell();\n \n const unsigned int n_q_points      = fe_values.get_quadrature().size();\n const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n \n const unsigned int n_face_q_points = fe_face_values.get_quadrature().size();\n \n    RightHandSide<dim>  right_hand_side;\n    std::vector<double> right_hand_side_values(n_q_points);\n \n const Coefficient<dim>      coefficient;\n    std::vector<Tensor<2, dim>> coefficient_values(n_q_points);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n \n FullMatrix<double> cell_matrix_M(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n FullMatrix<double> cell_matrix_G(dofs_per_cell_dgrt, dofs_per_cell);\n FullMatrix<double> cell_matrix_C(dofs_per_cell, dofs_per_cell_dgrt);\n FullMatrix<double> local_matrix(dofs_per_cell, dofs_per_cell);\n Vector<double>     cell_rhs(dofs_per_cell);\n Vector<double>     cell_solution(dofs_per_cell);\n \n const FEValuesExtractors::Vector velocities(0);\n const FEValuesExtractors::Scalar pressure_interior(0);\n const FEValuesExtractors::Scalar pressure_face(1);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        fe_values.reinit(cell);\n \n const typename Triangulation<dim>::active_cell_iterator cell_dgrt =\n          cell;\n        fe_values_dgrt.reinit(cell_dgrt);\n \n        right_hand_side.value_list(fe_values.get_quadrature_points(),\n                                   right_hand_side_values);\n        coefficient.value_list(fe_values.get_quadrature_points(),\n                               coefficient_values);\n \n        cell_matrix_M = 0;\n for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n            {\n const Tensor<1, dim> v_i = fe_values_dgrt[velocities].value(i, q);\n for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n                {\n const Tensor<1, dim> v_k =\n                    fe_values_dgrt[velocities].value(k, q);\n                  cell_matrix_M(i, k) += (v_i * v_k * fe_values_dgrt.JxW(q));\n                }\n            }\n        cell_matrix_M.gauss_jordan();\n \n        cell_matrix_G = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n            {\n const double div_v_i =\n                fe_values_dgrt[velocities].divergence(i, q);\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                {\n const double phi_j_interior =\n                    fe_values[pressure_interior].value(j, q);\n \n                  cell_matrix_G(i, j) -=\n                    (div_v_i * phi_j_interior * fe_values.JxW(q));\n                }\n            }\n \n \n for (const auto &face : cell->face_iterators())\n          {\n            fe_face_values.reinit(cell, face);\n            fe_face_values_dgrt.reinit(cell_dgrt, face);\n \n for (unsigned int q = 0; q < n_face_q_points; ++q)\n              {\n const Tensor<1, dim> &normal = fe_face_values.normal_vector(q);\n \n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n                  {\n const Tensor<1, dim> v_i =\n                      fe_face_values_dgrt[velocities].value(i, q);\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                      {\n const double phi_j_face =\n                          fe_face_values[pressure_face].value(j, q);\n \n                        cell_matrix_G(i, j) +=\n                          ((v_i * normal) * phi_j_face * fe_face_values.JxW(q));\n                      }\n                  }\n              }\n          }\n \n        cell_matrix_G.Tmmult(cell_matrix_C, cell_matrix_M);\n \n        local_matrix = 0;\n for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n          {\n for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n              {\n const Tensor<1, dim> v_k =\n                  fe_values_dgrt[velocities].value(k, q);\n for (unsigned int l = 0; l < dofs_per_cell_dgrt; ++l)\n                  {\n const Tensor<1, dim> v_l =\n                      fe_values_dgrt[velocities].value(l, q);\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                        local_matrix(i, j) +=\n                          (coefficient_values[q] * cell_matrix_C[i][k] * v_k) *\n                          cell_matrix_C[j][l] * v_l * fe_values_dgrt.JxW(q);\n                  }\n              }\n          }\n \n        cell_rhs = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n            {\n              cell_rhs(i) += (fe_values[pressure_interior].value(i, q) *\n                              right_hand_side_values[q] * fe_values.JxW(q));\n            }\n \n        cell->get_dof_indices(local_dof_indices);\n        constraints.distribute_local_to_global(\n          local_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\n      }\n  }\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::solve()\n  {\n SolverControl            solver_control(1000, 1e-8 * system_rhs.l2_norm());\n SolverCG<Vector<double>> solver(solver_control);\n    solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\n    constraints.distribute(solution);\n  }\n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::compute_postprocessed_velocity()\n  {\n    darcy_velocity.reinit(dof_handler_dgrt.n_dofs());\n \n const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values);\n \n FEFaceValues<dim> fe_face_values(fe,\n                                     face_quadrature_formula,\n update_values | update_normal_vectors |\n update_quadrature_points |\n update_JxW_values);\n \n FEValues<dim> fe_values_dgrt(fe_dgrt,\n                                 quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points |\n update_JxW_values);\n \n FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                          face_quadrature_formula,\n update_values |\n update_normal_vectors |\n update_quadrature_points |\n update_JxW_values);\n \n const unsigned int dofs_per_cell      = fe.n_dofs_per_cell();\n const unsigned int dofs_per_cell_dgrt = fe_dgrt.n_dofs_per_cell();\n \n const unsigned int n_q_points      = fe_values.get_quadrature().size();\n const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n \n const unsigned int n_face_q_points = fe_face_values.get_quadrature().size();\n \n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n    std::vector<types::global_dof_index> local_dof_indices_dgrt(\n      dofs_per_cell_dgrt);\n \n FullMatrix<double> cell_matrix_M(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n FullMatrix<double> cell_matrix_G(dofs_per_cell_dgrt, dofs_per_cell);\n FullMatrix<double> cell_matrix_C(dofs_per_cell, dofs_per_cell_dgrt);\n FullMatrix<double> cell_matrix_D(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n FullMatrix<double> cell_matrix_E(dofs_per_cell_dgrt, dofs_per_cell_dgrt);\n \n Vector<double> cell_solution(dofs_per_cell);\n Vector<double> cell_velocity(dofs_per_cell_dgrt);\n \n const Coefficient<dim>      coefficient;\n    std::vector<Tensor<2, dim>> coefficient_values(n_q_points_dgrt);\n \n const FEValuesExtractors::Vector velocities(0);\n const FEValuesExtractors::Scalar pressure_interior(0);\n const FEValuesExtractors::Scalar pressure_face(1);\n \n typename DoFHandler<dim>::active_cell_iterator\n      cell = dof_handler.begin_active(),\n      endc = dof_handler.end(), cell_dgrt = dof_handler_dgrt.begin_active();\n for (; cell != endc; ++cell, ++cell_dgrt)\n      {\n        fe_values.reinit(cell);\n        fe_values_dgrt.reinit(cell_dgrt);\n \n        coefficient.value_list(fe_values_dgrt.get_quadrature_points(),\n                               coefficient_values);\n \n        cell_matrix_M = 0;\n        cell_matrix_E = 0;\n for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n            {\n const Tensor<1, dim> v_i = fe_values_dgrt[velocities].value(i, q);\n for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n                {\n const Tensor<1, dim> v_k =\n                    fe_values_dgrt[velocities].value(k, q);\n \n                  cell_matrix_E(i, k) +=\n                    (coefficient_values[q] * v_i * v_k * fe_values_dgrt.JxW(q));\n \n                  cell_matrix_M(i, k) += (v_i * v_k * fe_values_dgrt.JxW(q));\n                }\n            }\n \n        cell_matrix_M.gauss_jordan();\n        cell_matrix_M.mmult(cell_matrix_D, cell_matrix_E);\n \n        cell_matrix_G = 0;\n for (unsigned int q = 0; q < n_q_points; ++q)\n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n            {\n const double div_v_i =\n                fe_values_dgrt[velocities].divergence(i, q);\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                {\n const double phi_j_interior =\n                    fe_values[pressure_interior].value(j, q);\n \n                  cell_matrix_G(i, j) -=\n                    (div_v_i * phi_j_interior * fe_values.JxW(q));\n                }\n            }\n \n for (const auto &face : cell->face_iterators())\n          {\n            fe_face_values.reinit(cell, face);\n            fe_face_values_dgrt.reinit(cell_dgrt, face);\n \n for (unsigned int q = 0; q < n_face_q_points; ++q)\n              {\n const Tensor<1, dim> &normal = fe_face_values.normal_vector(q);\n \n for (unsigned int i = 0; i < dofs_per_cell_dgrt; ++i)\n                  {\n const Tensor<1, dim> v_i =\n                      fe_face_values_dgrt[velocities].value(i, q);\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                      {\n const double phi_j_face =\n                          fe_face_values[pressure_face].value(j, q);\n \n                        cell_matrix_G(i, j) +=\n                          ((v_i * normal) * phi_j_face * fe_face_values.JxW(q));\n                      }\n                  }\n              }\n          }\n        cell_matrix_G.Tmmult(cell_matrix_C, cell_matrix_M);\n \n        cell->get_dof_values(solution, cell_solution);\n \n        cell_velocity = 0;\n for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n for (unsigned int j = 0; j < dofs_per_cell_dgrt; ++j)\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              cell_velocity(k) +=\n                -(cell_solution(i) * cell_matrix_C(i, j) * cell_matrix_D(k, j));\n \n        cell_dgrt->get_dof_indices(local_dof_indices_dgrt);\n for (unsigned int k = 0; k < dofs_per_cell_dgrt; ++k)\n for (unsigned int j = 0; j < dofs_per_cell_dgrt; ++j)\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              darcy_velocity(local_dof_indices_dgrt[k]) +=\n                -(cell_solution(i) * cell_matrix_C(i, j) * cell_matrix_D(k, j));\n      }\n  }\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::compute_pressure_error()\n  {\n Vector<float> difference_per_cell(triangulation.n_active_cells());\n const ComponentSelectFunction<dim> select_interior_pressure(0, 2);\n VectorTools::integrate_difference(dof_handler,\n                                      solution,\n                                      ExactPressure<dim>(),\n                                      difference_per_cell,\n QGauss<dim>(fe.degree + 2),\n VectorTools::L2_norm,\n                                      &select_interior_pressure);\n \n const double L2_error = difference_per_cell.l2_norm();\n    std::cout << \"L2_error_pressure \" << L2_error << std::endl;\n  }\n \n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::compute_velocity_errors()\n  {\n const QGauss<dim>     quadrature_formula(fe_dgrt.degree + 1);\n const QGauss<dim - 1> face_quadrature_formula(fe_dgrt.degree + 1);\n \n FEValues<dim> fe_values_dgrt(fe_dgrt,\n                                 quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points |\n update_JxW_values);\n \n FEFaceValues<dim> fe_face_values_dgrt(fe_dgrt,\n                                          face_quadrature_formula,\n update_values |\n update_normal_vectors |\n update_quadrature_points |\n update_JxW_values);\n \n const unsigned int n_q_points_dgrt = fe_values_dgrt.get_quadrature().size();\n const unsigned int n_face_q_points_dgrt =\n      fe_face_values_dgrt.get_quadrature().size();\n \n    std::vector<Tensor<1, dim>> velocity_values(n_q_points_dgrt);\n    std::vector<Tensor<1, dim>> velocity_face_values(n_face_q_points_dgrt);\n \n const FEValuesExtractors::Vector velocities(0);\n \n const ExactVelocity<dim> exact_velocity;\n \n double L2_err_velocity_cell_sqr_global = 0;\n double L2_err_flux_sqr                 = 0;\n \n for (const auto &cell_dgrt : dof_handler_dgrt.active_cell_iterators())\n      {\n        fe_values_dgrt.reinit(cell_dgrt);\n \n        fe_values_dgrt[velocities].get_function_values(darcy_velocity,\n                                                       velocity_values);\n double L2_err_velocity_cell_sqr_local = 0;\n for (unsigned int q = 0; q < n_q_points_dgrt; ++q)\n          {\n const Tensor<1, dim> velocity = velocity_values[q];\n const Tensor<1, dim> true_velocity =\n              exact_velocity.value(fe_values_dgrt.quadrature_point(q));\n \n            L2_err_velocity_cell_sqr_local +=\n              ((velocity - true_velocity) * (velocity - true_velocity) *\n               fe_values_dgrt.JxW(q));\n          }\n        L2_err_velocity_cell_sqr_global += L2_err_velocity_cell_sqr_local;\n \n const double cell_area = cell_dgrt->measure();\n for (const auto &face_dgrt : cell_dgrt->face_iterators())\n          {\n const double face_length = face_dgrt->measure();\n            fe_face_values_dgrt.reinit(cell_dgrt, face_dgrt);\n            fe_face_values_dgrt[velocities].get_function_values(\n              darcy_velocity, velocity_face_values);\n \n double L2_err_flux_face_sqr_local = 0;\n for (unsigned int q = 0; q < n_face_q_points_dgrt; ++q)\n              {\n const Tensor<1, dim> velocity = velocity_face_values[q];\n const Tensor<1, dim> true_velocity =\n                  exact_velocity.value(fe_face_values_dgrt.quadrature_point(q));\n \n const Tensor<1, dim> &normal =\n                  fe_face_values_dgrt.normal_vector(q);\n \n                L2_err_flux_face_sqr_local +=\n                  ((velocity * normal - true_velocity * normal) *\n                   (velocity * normal - true_velocity * normal) *\n                   fe_face_values_dgrt.JxW(q));\n              }\n const double err_flux_each_face =\n              L2_err_flux_face_sqr_local / face_length * cell_area;\n            L2_err_flux_sqr += err_flux_each_face;\n          }\n      }\n \n const double L2_err_velocity_cell =\n std::sqrt(L2_err_velocity_cell_sqr_global);\n const double L2_err_flux_face = std::sqrt(L2_err_flux_sqr);\n \n    std::cout << \"L2_error_vel:  \" << L2_err_velocity_cell << std::endl\n              << \"L2_error_flux: \" << L2_err_flux_face << std::endl;\n  }\n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::output_results() const\n {\n    {\n DataOut<dim> data_out;\n \n const std::vector<std::string> solution_names = {\"interior_pressure\",\n \"interface_pressure\"};\n      data_out.add_data_vector(dof_handler, solution, solution_names);\n \n const std::vector<std::string> velocity_names(dim, \"velocity\");\n const std::vector<\n DataComponentInterpretation::DataComponentInterpretation>\n        velocity_component_interpretation(\n          dim, DataComponentInterpretation::component_is_part_of_vector);\n      data_out.add_data_vector(dof_handler_dgrt,\n                               darcy_velocity,\n                               velocity_names,\n                               velocity_component_interpretation);\n \n      data_out.build_patches(fe.degree);\n      std::ofstream output(\"solution_interior.vtu\");\n      data_out.write_vtu(output);\n    }\n \n    {\n DataOutFaces<dim> data_out_faces(false);\n      data_out_faces.attach_dof_handler(dof_handler);\n      data_out_faces.add_data_vector(solution, \"Pressure_Face\");\n      data_out_faces.build_patches(fe.degree);\n      std::ofstream face_output(\"solution_interface.vtu\");\n      data_out_faces.write_vtu(face_output);\n    }\n  }\n \n \n \n template <int dim>\n void WGDarcyEquation<dim>::run()\n  {\n    std::cout << \"Solving problem in \" << dim << \" space dimensions.\"\n              << std::endl;\n    make_grid();\n    setup_system();\n    assemble_system();\n    solve();\n    compute_postprocessed_velocity();\n    compute_pressure_error();\n    compute_velocity_errors();\n    output_results();\n  }\n \n} // namespace Step61\n \n \n \nint main()\n{\n try\n    {\n      Step61::WGDarcyEquation<2> wg_darcy(0);\n      wg_darcy.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_62.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nResonance frequency and bandgap of a phononic crystal. Elastic wave equation in the frequency domain with Perfectly Matched Layer boundary conditions. Parallelization via MUMPS and MPI.\nTutorial content :\nThis tutorial depends on [step-8](step_8.html), [step-40](step_40.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_62-Intro)    * [Elastic equations](#step_62-Elasticequations)* [Simulation parameters](#step_62-Simulationparameters)- [The commented program](#step_62-CommProg)      * [Include files](#step_62-Includefiles)* [Auxiliary classes and functions](#step_62-Auxiliaryclassesandfunctions)          + [The `RightHandSide` class](#step_62-TheRightHandSideclass)+ [The `PML` class](#step_62-ThePMLclass)+ [The `Rho` class](#step_62-TheRhoclass)+ [The `Parameters` class](#step_62-TheParametersclass)+ [The `QuadratureCache` class](#step_62-TheQuadratureCacheclass)+ [The `get\\_stiffness\\_tensor()` function](#step_62-Theget_stiffness_tensorfunction)* [The `ElasticWave` class](#step_62-TheElasticWaveclass)* [Implementation of the auxiliary classes](#step_62-Implementationoftheauxiliaryclasses)              + [The `RightHandSide` class implementation](#step_62-TheRightHandSideclassimplementation)+ [The `PML` class implementation](#step_62-ThePMLclassimplementation)+ [The `Rho` class implementation](#step_62-TheRhoclassimplementation)+ [The `Parameters` class implementation](#step_62-TheParametersclassimplementation)+ [The `QuadratureCache` class implementation](#step_62-TheQuadratureCacheclassimplementation)* [Implementation of the `ElasticWave` class](#step_62-ImplementationoftheElasticWaveclass)                + [Constructor](#step_62-Constructor)+ [ElasticWave::setup\\_system](#step_62-ElasticWavesetup_system)+ [ElasticWave::assemble\\_system](#step_62-ElasticWaveassemble_system)+ [ElasticWave::solve](#step_62-ElasticWavesolve)+ [ElasticWave::initialize\\_position\\_vector](#step_62-ElasticWaveinitialize_position_vector)+ [ElasticWave::store\\_frequency\\_step\\_data](#step_62-ElasticWavestore_frequency_step_data)+ [ElasticWave::output\\_results](#step_62-ElasticWaveoutput_results)+ [ElasticWave::setup\\_quadrature\\_cache](#step_62-ElasticWavesetup_quadrature_cache)+ [ElasticWave::frequency\\_sweep](#step_62-ElasticWavefrequency_sweep)+ [ElasticWave::run](#step_62-ElasticWaverun)+ [The main function](#step_62-Themainfunction) | 1. [Results](#step_62-Results)    * [Resonance frequency and bandgap](#step_62-Resonancefrequencyandbandgap)* [Mode profile](#step_62-Modeprofile)* [Experimental applications](#step_62-Experimentalapplications)* [Possibilities for extensions](#step_62-Possibilitiesforextensions)- [The plain program](#step_62-PlainProg) |\n\n*This program was contributed by Daniel Garcia-Sanchez.*\n\nNote\n:   As a prerequisite of this program, you need to have [HDF5](namespaceHDF5.html), complex PETSc, and the p4est libraries installed. The installation of deal.II together with these additional libraries is described in the [README](../../readme.html) file.\n\nIntroduction\n============\n\nA phononic crystal is a periodic nanostructure that modifies the motion of mechanical vibrations or [phonons](https://en.wikipedia.org/wiki/Phonon). Phononic structures can be used to disperse, route and confine mechanical vibrations. These structures have potential applications in [quantum information](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.1391) and have been used to study [macroscopic quantum phenomena](https://science.sciencemag.org/content/358/6360/203). Phononic crystals are usually fabricated in [cleanrooms](https://en.wikipedia.org/wiki/Cleanroom).\n\nIn this tutorial we show how to a design a [phononic superlattice cavity](https://doi.org/10.1103/PhysRevA.94.033813) which is a particular type of phononic crystal that can be used to confine mechanical vibrations. A phononic superlattice cavity is formed by two [Distributed Bragg Reflector](https://en.wikipedia.org/wiki/Distributed_Bragg_reflector), mirrors and a \\(\\lambda/2\\) cavity where \\(\\lambda\\) is the acoustic wavelength. Acoustic DBRs are periodic structures where a set of bilayer stacks with contrasting physical properties (sound velocity index) is repeated \\(N\\) times. Superlattice cavities are usually grown on a [Gallium Arsenide](https://en.wikipedia.org/wiki/Gallium_arsenide) wafer by [Molecular Beam Epitaxy](https://en.wikipedia.org/wiki/Molecular-beam_epitaxy). The bilayers correspond to GaAs/AlAs mirror pairs. As shown below, the thickness of the mirror layers (brown and green) is \\(\\lambda/4\\) and the thickness of the cavity (blue) is \\(\\lambda/2\\).\n\n![Phononic superlattice cavity](images/steps/developer/step-62.01.svg)\n\nIn this tutorial we calculate the [band gap](https://en.wikipedia.org/wiki/Band_gap) and the mechanical resonance of a phononic superlattice cavity but the code presented here can be easily used to design and calculate other types of [phononic crystals](https://science.sciencemag.org/content/358/6360/203).\n\nThe device is a waveguide in which the wave goes from left to right. The simulations of this tutorial are done in 2D, but the code is dimension independent and can be easily used with 3D simulations. The waveguide width is equal to the \\(y\\) dimension of the domain and the waveguide length is equal to the \\(x\\) dimension of the domain. There are two regimes that depend on the waveguide width:\n\n* Single mode: In this case the width of the structure is much smaller than the wavelength. This case can be solved either with FEM (the approach that we take here) or with a simple semi-analytical [1D transfer matrix formalism](https://en.wikipedia.org/wiki/Transfer_matrix).\n* Multimode: In this case the width of the structure is larger than the wavelength. This case can be solved using FEM or with a [scattering matrix formalism](https://doi.org/10.1103/PhysRevA.94.033813). Although we do not study this case in this tutorial, it is very easy to reach the multimode regime by increasing the parameter waveguide width (`dimension_y` in the jupyter notebook).\n\nThe simulations of this tutorial are performed in the frequency domain. To calculate the transmission spectrum, we use a [procedure](https://meep.readthedocs.io/en/latest/Python_Tutorials/Resonant_Modes_and_Transmission_in_a_Waveguide_Cavity/) that is commonly used in time domain [FDTD](https://en.wikipedia.org/wiki/Finite-difference_time-domain_method) simulations. A pulse at a certain frequency is generated on the left side of the structure and the transmitted energy is measured on the right side of the structure. The simulation is run twice. First, we run the simulation with the phononic structure and measure the transmitted energy:\n\n![Phononic superlattice cavity](images/steps/developer/step-62.02.svg)\n\nThen, we run the simulation without the phononic structure and measure the transmitted energy. We use the simulation without the structure for the calibration:\n\n![Phononic superlattice cavity](images/steps/developer/step-62.03.svg)\n\nThe transmission coefficient corresponds to the energy of the first simulation divided by the calibration energy. We repeat this procedure for each frequency step.\n\n### Elastic equations\n\nWhat we want to simulate here is the transmission of elastic waves. Consequently, the right description of the problem uses the elastic equations, which in the time domain are given by\n\n\\[\n\\rho\\partial\\_{tt} u\\_i - \\partial\\_j (c\\_{ijkl} \\varepsilon\\_{kl}) = f\\_i,\n\\qquad i=0,1,2\n\\]\n\nwhere the stiffness tensor \\(c\\_{ijkl}\\) depends on the spatial coordinates and the strain is the symmetrized gradient of the displacement, given by\n\n\\[\n\\varepsilon\\_{kl} =\\frac{1}{2}(\\partial\\_k u\\_l + \\partial\\_l u\\_k)\n\\]\n\n[A perfectly matched layer (PML)](https://en.wikipedia.org/wiki/Perfectly_matched_layer) can be used to truncate the solution at the boundaries. A PML is a transformation that results in a complex coordinate stretching.\n\nInstead of a time domain approach, this tutorial program converts the equations above into the frequency domain by performing a Fourier transform with regard to the time variable. The elastic equations in the frequency domain then read as follows\n\n\\begin{eqnarray\\*}\n\\nabla\\cdot(\\boldsymbol{\\bar\\sigma} \\xi \\boldsymbol{\\Lambda})&=&-\\omega^2\\rho\\xi\\mathbf{\\bar u}\\\\\n\\boldsymbol{\\bar \\sigma} &=&\\mathbf{C}\\boldsymbol{\\bar\\varepsilon}\\\\\n\\boldsymbol{\\bar\\varepsilon}&=&\\frac{1}{2}[(\\nabla\\mathbf{\\bar{u}}\\boldsymbol{\\Lambda}+\\boldsymbol{\\Lambda}^\\mathrm{T}(\\nabla\\mathbf{\\bar{u}})^\\mathrm{T})]\\\\\n\\xi &=&\\prod\\_i^\\textrm{dim}s\\_i\\\\\n\\boldsymbol{\\Lambda} &=& \\operatorname{diag}(1/s\\_0,1/s\\_1,1/s\\_2)\\qquad\\textrm{for 3D}\\\\\n\\boldsymbol{\\Lambda} &=& \\operatorname{diag}(1/s\\_0,1/s\\_1)\\qquad\\textrm{for 2D}\n\\end{eqnarray\\*}\n\nwhere the coefficients \\(s\\_i = 1+is\\_i'(x,y,z)\\) account for the absorption. There are 3 \\(s\\_i\\) coefficients in 3D and 2 in 2D. The imaginary par of \\(s\\_i\\) is equal to zero outside the PML. The PMLs are reflectionless only for the exact wave equations. When the set of equations is discretized the PML is no longer reflectionless. The reflections can be made arbitrarily small as long as the medium is slowly varying, see [the adiabatic theorem](https://doi.org/10.1103/PhysRevE.66.066608). In the code a quadratic turn-on of the PML has been used. A linear and cubic turn-on is also [known to work](https://doi.org/10.1364/OE.16.011376). These equations can be expanded into\n\n\\[\n-\\omega^2\\rho \\xi u\\_m - \\partial\\_n \\left(\\frac{\\xi}{s\\_n}c\\_{mnkl}\n\\varepsilon\\_{kl}\\right) = f\\_m\n\\]\n\n\\[\n\\varepsilon\\_{kl} =\\frac{1}{2}\\left(\\frac{1}{s\\_k}\\partial\\_k u\\_l\n+ \\frac{1}{s\\_l}\\partial\\_l u\\_k\\right)\n\\]\n\nwhere summation over repeated indices (here \\(n\\), as well as \\(k\\) and \\(l\\)) is as always implied. Note that the strain is no longer symmetric after applying the complex coordinate stretching of the PML. This set of equations can be written as\n\n\\[\n-\\omega^2\\rho \\xi u\\_m - \\partial\\_n \\left(\\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_k} \\partial\\_k u\\_l\n+ \\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_l} \\partial\\_l u\\_k\\right) = f\\_m\n\\]\n\nThe same as the strain, the stress tensor is not symmetric inside the PML ( \\(s\\_j\\neq 0\\)). Indeed the fields inside the PML are not physical. It is useful to introduce the tensors \\(\\alpha\\_{mnkl}\\) and \\(\\beta\\_{mnkl}\\).\n\n\\[\n-\\omega^2\\rho \\xi u\\_m - \\partial\\_n \\left(\\alpha\\_{mnkl}\\partial\\_k u\\_l\n+ \\beta\\_{mnkl}\\partial\\_l u\\_k\\right) = f\\_m\n\\]\n\nWe can multiply by \\(\\varphi\\_m\\) and integrate over the domain \\(\\Omega\\) and integrate by parts.\n\n\\begin{eqnarray\\*}\n-\\omega^2\\int\\_\\Omega\\rho\\xi\\varphi\\_m u\\_m + \\int\\_\\Omega\\partial\\_n\\varphi\\_m \\left(\\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_k} \\partial\\_k u\\_l\n+ \\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_l} \\partial\\_l u\\_k\\right) = \\int\\_\\Omega\\varphi\\_m f\\_m\n\\end{eqnarray\\*}\n\nIt is this set of equations we want to solve for a set of frequencies \\(\\omega\\) in order to compute the transmission coefficient as function of frequency. The linear system becomes\n\n\\begin{eqnarray\\*}\nAU&=&F\\\\\nA\\_{ij} &=& -\\omega^2\\int\\_\\Omega\\rho \\xi\\varphi\\_m^i \\varphi\\_m^j + \\int\\_\\Omega\\partial\\_n\\varphi\\_m^i \\left(\\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_k} \\partial\\_k \\varphi\\_l^j\n+ \\frac{\\xi c\\_{mnkl}}{2s\\_n s\\_l} \\partial\\_l \\varphi\\_k^j\\right)\\\\\nF\\_i &=& \\int\\_\\Omega\\varphi\\_m^i f\\_m\n\\end{eqnarray\\*}\n\n### Simulation parameters\n\nIn this tutorial we use a python [jupyter notebook](https://github.com/dealii/dealii/blob/master/examples/step-62/step-62.ipynb) to set up the parameters and run the simulation. First we create a [HDF5](namespaceHDF5.html) file where we store the parameters and the results of the simulation.\n\nEach of the simulations (displacement and calibration) is stored in a separate [HDF5](namespaceHDF5.html) group:\n\n```\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport subprocess\nimport scipy.constants as constants\nimport scipy.optimize\n \n# This considerably reduces the size of the svg data\nplt.rcParams['svg.fonttype'] = 'none'\n \nh5_file = h5py.File('results.h5', 'w')\ndata = h5_file.create_group('data')\ndisplacement = data.create_group('displacement')\ncalibration = data.create_group('calibration')\n \n# Set the parameters\nfor group in [displacement, calibration]:\n # Dimensions of the domain\n # The waveguide length is equal to dimension_x\n    group.attrs['dimension_x'] = 2e-5\n # The waveguide width is equal to dimension_y\n    group.attrs['dimension_y'] = 2e-8\n \n # Position of the probe that we use to measure the flux\n    group.attrs['probe_pos_x']   = 8e-6\n    group.attrs['probe_pos_y']   = 0\n    group.attrs['probe_width_y'] = 2e-08\n \n # Number of points in the probe\n    group.attrs['nb_probe_points'] = 5\n \n # Global refinement\n    group.attrs['grid_level'] = 1\n \n # Cavity\n    group.attrs['cavity_resonance_frequency'] = 20e9\n    group.attrs['nb_mirror_pairs']            = 15\n \n # Material\n    group.attrs['poissons_ratio'] = 0.27\n    group.attrs['youngs_modulus'] = 270000000000.0\n    group.attrs['material_a_rho'] = 3200\n if group == displacement:\n        group.attrs['material_b_rho'] = 2000\n else:\n        group.attrs['material_b_rho'] = 3200\n    group.attrs['lambda'] = (group.attrs['youngs_modulus'] * group.attrs['poissons_ratio'] /\n                           ((1 + group.attrs['poissons_ratio']) *\n                           (1 - 2 * group.attrs['poissons_ratio'])))\n    group.attrs['mu']= (group.attrs['youngs_modulus'] / (2 * (1 + group.attrs['poissons_ratio'])))\n \n # Force\n    group.attrs['max_force_amplitude'] = 1e26\n    group.attrs['force_sigma_x']       = 1e-7\n    group.attrs['force_sigma_y']       = 1\n    group.attrs['max_force_width_x']   = 3e-7\n    group.attrs['max_force_width_y']   = 2e-8\n    group.attrs['force_x_pos']         = -8e-6\n    group.attrs['force_y_pos']         = 0\n \n # PML\n    group.attrs['pml_x']            = True\n    group.attrs['pml_y']            = False\n    group.attrs['pml_width_x']      = 1.8e-6\n    group.attrs['pml_width_y']      = 5e-7\n    group.attrs['pml_coeff']        = 1.6\n    group.attrs['pml_coeff_degree'] = 2\n \n # Frequency sweep\n    group.attrs['center_frequency']    = 20e9\n    group.attrs['frequency_range']     = 0.5e9\n    group.attrs['start_frequency']     = group.attrs['center_frequency'] - group.attrs['frequency_range'] / 2\n    group.attrs['stop_frequency']      = group.attrs['center_frequency'] + group.attrs['frequency_range'] / 2\n    group.attrs['nb_frequency_points'] = 400\n \n # Other parameters\n if group == displacement:\n        group.attrs['simulation_name'] = 'phononic_cavity_displacement'\n else:\n        group.attrs['simulation_name'] = 'phononic_cavity_calibration'\n    group.attrs['save_vtu_files'] = False\n \nh5_file.close()\n```\n\nThe commented program\n=====================\n\n### Include files\n\nMost of the include files we need for this program have already been discussed in previous programs, in particular in [step-40](step_40.html).\n\n```\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/function.h>\n   \n   #include <deal.II/base/index_set.h>\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/timer.h>\n   #include <deal.II/base/utilities.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/generic_linear_algebra.h>\n   #include <deal.II/lac/petsc_solver.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n   \n   #include <fstream>\n   #include <iostream>\n```\n\nThe following header provides the [Tensor](classTensor.html) class that we use to represent the material properties.\n\n```\n   #include <deal.II/base/tensor.h>\n```\n\nThe following header is necessary for the [HDF5](namespaceHDF5.html) interface of deal.II.\n\n```\n   #include <deal.II/base/hdf5.h>\n```\n\nThis header is required for the function [VectorTools::point\\_value](namespaceVectorTools.html#acd358e9b110ccbf4a7f76796d206b9c7) that we use to evaluate the result of the simulation.\n\n```\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nWe need these headers for the function [GridTools::find\\_active\\_cell\\_around\\_point](namespaceGridTools.html#a2e10aeb1c8e76110a84b6945eac3aaf0) that we use in the function `ElasticWave::store_frequency_step_data()`\n\n```\n   #include <deal.II/grid/grid_tools.h>\n   #include <deal.II/grid/grid_tools_cache.h>\n   \n   namespace step62\n   {\n     using namespace dealii;\n```\n\n### Auxiliary classes and functions\n\nThe following classes are used to store the parameters of the simulation.\n\n#### The `RightHandSide` class\n\nThis class is used to define the force pulse on the left side of the structure:\n\n```\n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       RightHandSide(HDF5::Group &data);\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component) const override;\n   \n     private:\n```\n\nThe variable `data` is the [HDF5::Group](classHDF5_1_1Group.html) in which all the simulation results will be stored. Note that the variables `RightHandSide::data`, `PML::data`, `Rho::data` and `Parameters::data` point to the same group of the [HDF5](namespaceHDF5.html) file. When a [HDF5::Group](classHDF5_1_1Group.html) is copied, it will point to the same group of the [HDF5](namespaceHDF5.html) file.\n\n```\n       HDF5::Group data;\n```\n\nThe simulation parameters are stored in `data` as [HDF5](namespaceHDF5.html) attributes. The following attributes are defined in the jupyter notebook, stored in `data` as [HDF5](namespaceHDF5.html) attributes and then read by the constructor.\n\n```\n       const double     max_force_amplitude;\n       const double     force_sigma_x;\n       const double     force_sigma_y;\n       const double     max_force_width_x;\n       const double     max_force_width_y;\n       const Point<dim> force_center;\n   \n     public:\n```\n\nIn this particular simulation the force has only a \\(x\\) component, \\(F\\_y=0\\).\n\n```\n       const unsigned int force_component = 0;\n     };\n```\n\n#### The `PML` class\n\nThis class is used to define the shape of the Perfectly Matches Layer (PML) to absorb waves traveling towards the boundary:\n\n```\n     template <int dim>\n     class PML : public Function<dim, std::complex<double>>\n     {\n     public:\n       PML(HDF5::Group &data);\n   \n       virtual std::complex<double>\n       value(const Point<dim> &p, const unsigned int component) const override;\n   \n     private:\n```\n\n[HDF5::Group](classHDF5_1_1Group.html) in which all the simulation results will be stored.\n\n```\n       HDF5::Group data;\n```\n\nThe same as before, the following attributes are defined in the jupyter notebook, stored in `data` as [HDF5](namespaceHDF5.html) attributes and then read by the constructor.\n\n```\n       const double pml_coeff;\n       const int    pml_coeff_degree;\n       const double dimension_x;\n       const double dimension_y;\n       const bool   pml_x;\n       const bool   pml_y;\n       const double pml_width_x;\n       const double pml_width_y;\n       const double a_coeff_x;\n       const double a_coeff_y;\n     };\n```\n\n#### The `Rho` class\n\nThis class is used to define the mass density.\n\n```\n     template <int dim>\n     class Rho : public Function<dim>\n     {\n     public:\n       Rho(HDF5::Group &data);\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n   \n     private:\n```\n\n[HDF5::Group](classHDF5_1_1Group.html) in which all the simulation results will be stored.\n\n```\n       HDF5::Group data;\n```\n\nThe same as before, the following attributes are defined in the jupyter notebook, stored in `data` as [HDF5](namespaceHDF5.html) attributes and then read by the constructor.\n\n```\n       const double       lambda;\n       const double       mu;\n       const double       material_a_rho;\n       const double       material_b_rho;\n       const double       cavity_resonance_frequency;\n       const unsigned int nb_mirror_pairs;\n       const double       dimension_y;\n       const unsigned int grid_level;\n       double             average_rho_width;\n     };\n```\n\n#### The `Parameters` class\n\nThis class contains all the parameters that will be used in the simulation.\n\n```\n     template <int dim>\n     class Parameters\n     {\n     public:\n       Parameters(HDF5::Group &data);\n```\n\n[HDF5::Group](classHDF5_1_1Group.html) in which all the simulation results will be stored.\n\n```\n       HDF5::Group data;\n```\n\nThe same as before, the following attributes are defined in the jupyter notebook, stored in `data` as [HDF5](namespaceHDF5.html) attributes and then read by the constructor.\n\n```\n       const std::string        simulation_name;\n       const bool               save_vtu_files;\n       const double             start_frequency;\n       const double             stop_frequency;\n       const unsigned int       nb_frequency_points;\n       const double             lambda;\n       const double             mu;\n       const double             dimension_x;\n       const double             dimension_y;\n       const unsigned int       nb_probe_points;\n       const unsigned int       grid_level;\n       const Point<dim>         probe_start_point;\n       const Point<dim>         probe_stop_point;\n       const RightHandSide<dim> right_hand_side;\n       const PML<dim>           pml;\n       const Rho<dim>           rho;\n   \n     private:\n       const double comparison_float_constant = 1e-12;\n     };\n```\n\n#### The `QuadratureCache` class\n\nThe calculation of the mass and stiffness matrices is very expensive. These matrices are the same for all the frequency steps. The right hand side vector is also the same for all the frequency steps. We use this class to store these objects and re-use them at each frequency step. Note that here we don't store the assembled mass and stiffness matrices and right hand sides, but instead the data for a single cell. `QuadratureCache` class is very similar to the `PointHistory` class that has been used in [step-18](step_18.html).\n\n```\n     template <int dim>\n     class QuadratureCache\n     {\n     public:\n       QuadratureCache(const unsigned int dofs_per_cell);\n   \n     private:\n       unsigned int dofs_per_cell;\n   \n     public:\n```\n\nWe store the mass and stiffness matrices in the variables mass\\_coefficient and stiffness\\_coefficient. We store as well the right\\_hand\\_side and JxW values which are going to be the same for all the frequency steps.\n\n```\n       FullMatrix<std::complex<double>>  mass_coefficient;\n       FullMatrix<std::complex<double>>  stiffness_coefficient;\n       std::vector<std::complex<double>> right_hand_side;\n       double                            JxW;\n     };\n```\n\n#### The `get_stiffness_tensor()` function\n\nThis function returns the stiffness tensor of the material. For the sake of simplicity we consider the stiffness to be isotropic and homogeneous; only the density \\(\\rho\\) depends on the position. As we have previously shown in [step-8](step_8.html), if the stiffness is isotropic and homogeneous, the stiffness coefficients \\(c\\_{ijkl}\\) can be expressed as a function of the two coefficients \\(\\lambda\\) and \\(\\mu\\). The coefficient tensor reduces to\n\n\\[\nc\\_{ijkl}\n=\n\\lambda \\delta\\_{ij} \\delta\\_{kl} +\n\\mu (\\delta\\_{ik} \\delta\\_{jl} + \\delta\\_{il} \\delta\\_{jk}).\n\\]\n\n```\n     template <int dim>\n     SymmetricTensor<4, dim> get_stiffness_tensor(const double lambda,\n                                                  const double mu)\n     {\n       SymmetricTensor<4, dim> stiffness_tensor;\n       for (unsigned int i = 0; i < dim; ++i)\n         for (unsigned int j = 0; j < dim; ++j)\n           for (unsigned int k = 0; k < dim; ++k)\n             for (unsigned int l = 0; l < dim; ++l)\n               stiffness_tensor[i][j][k][l] =\n                 (((i == k) && (j == l) ? mu : 0.0) +\n                  ((i == l) && (j == k) ? mu : 0.0) +\n                  ((i == j) && (k == l) ? lambda : 0.0));\n       return stiffness_tensor;\n     }\n```\n\n### The `ElasticWave` class\n\nNext let's declare the main class of this program. Its structure is very similar to the [step-40](step_40.html) tutorial program. The main differences are:\n\n* The sweep over the frequency values.\n* We save the stiffness and mass matrices in `quadrature_cache` and use them for each frequency step.\n* We store the measured energy by the probe for each frequency step in the [HDF5](namespaceHDF5.html) file.\n\n```\n     template <int dim>\n     class ElasticWave\n     {\n     public:\n       ElasticWave(const Parameters<dim> &parameters);\n       void run();\n   \n     private:\n       void setup_system();\n       void assemble_system(const double omega,\n                            const bool   calculate_quadrature_data);\n       void solve();\n       void initialize_probe_positions_vector();\n       void store_frequency_step_data(const unsigned int frequency_idx);\n       void output_results();\n```\n\nThis is called before every frequency step to set up a pristine state for the cache variables.\n\n```\n       void setup_quadrature_cache();\n```\n\nThis function loops over the frequency vector and runs the simulation for each frequency step.\n\n```\n       void frequency_sweep();\n```\n\nThe parameters are stored in this variable.\n\n```\n       Parameters<dim> parameters;\n   \n       MPI_Comm mpi_communicator;\n   \n       parallel::distributed::Triangulation<dim> triangulation;\n   \n       const QGauss<dim> quadrature_formula;\n```\n\nWe store the mass and stiffness matrices for each cell this vector.\n\n```\n       std::vector<QuadratureCache<dim>> quadrature_cache;\n   \n   \n       const FESystem<dim> fe;\n       DoFHandler<dim>     dof_handler;\n   \n       IndexSet locally_owned_dofs;\n       IndexSet locally_relevant_dofs;\n   \n       AffineConstraints<std::complex<double>> constraints;\n   \n       LinearAlgebraPETSc::MPI::SparseMatrix system_matrix;\n       LinearAlgebraPETSc::MPI::Vector       locally_relevant_solution;\n       LinearAlgebraPETSc::MPI::Vector       system_rhs;\n```\n\nThis vector contains the range of frequencies that we are going to simulate.\n\n```\n       std::vector<double> frequency;\n```\n\nThis vector contains the coordinates \\((x,y)\\) of the points of the measurement probe.\n\n```\n       FullMatrix<double> probe_positions;\n```\n\n[HDF5](namespaceHDF5.html) datasets to store the frequency and `probe_positions` vectors.\n\n```\n       HDF5::DataSet frequency_dataset;\n       HDF5::DataSet probe_positions_dataset;\n```\n\n[HDF5](namespaceHDF5.html) dataset that stores the values of the energy measured by the probe.\n\n```\n       HDF5::DataSet displacement;\n   \n   \n       ConditionalOStream pcout;\n       TimerOutput        computing_timer;\n     };\n```\n\n### Implementation of the auxiliary classes\n\n#### The `RightHandSide` class implementation\n\nThe constructor reads all the parameters from the [HDF5::Group](classHDF5_1_1Group.html) `data` using the [HDF5::Group::get\\_attribute()](classHDF5_1_1HDF5Object.html#a25c71292aba2399ad5a21d5d855ea2eb) function.\n\n```\n     template <int dim>\n     RightHandSide<dim>::RightHandSide(HDF5::Group &data)\n       : Function<dim>(dim)\n       , data(data)\n       , max_force_amplitude(data.get_attribute<double>(\"max_force_amplitude\"))\n       , force_sigma_x(data.get_attribute<double>(\"force_sigma_x\"))\n       , force_sigma_y(data.get_attribute<double>(\"force_sigma_y\"))\n       , max_force_width_x(data.get_attribute<double>(\"max_force_width_x\"))\n       , max_force_width_y(data.get_attribute<double>(\"max_force_width_y\"))\n       , force_center(Point<dim>(data.get_attribute<double>(\"force_x_pos\"),\n                                 data.get_attribute<double>(\"force_y_pos\")))\n     {}\n```\n\nThis function defines the spatial shape of the force vector pulse which takes the form of a Gaussian function\n\n\\begin{align\\*}\nF\\_x &=\n\\left\\{\n\\begin{array}{ll}\na \\exp(- (\\frac{(x-b\\_x)^2 }{ 2 \\sigma\\_x^2}+\\frac{(y-b\\_y)^2 }{ 2\n\\sigma\\_y^2}))\n& \\text{if}\\, x\\_\\textrm{min} <x<x\\_\\textrm{max}\\, \\text{and}\\,\ny\\_\\textrm{min} <y<y\\_\\textrm{max} \\\\ 0 & \\text{otherwise},\n\\end{array}\n\\right.\\\\ F\\_y &= 0\n\\end{align\\*}\n\nwhere \\(a\\) is the maximum amplitude that takes the force and \\(\\sigma\\_x\\) and \\(\\sigma\\_y\\) are the standard deviations for the \\(x\\) and \\(y\\) components. Note that the pulse has been cropped to \\(x\\_\\textrm{min}<x<x\\_\\textrm{max}\\) and \\(y\\_\\textrm{min} <y<y\\_\\textrm{max}\\).\n\n```\n     template <int dim>\n     double RightHandSide<dim>::value(const Point<dim>  &p,\n                                      const unsigned int component) const\n     {\n       if (component == force_component)\n         {\n           if (std::abs(p[0] - force_center[0]) < max_force_width_x / 2 &&\n               std::abs(p[1] - force_center[1]) < max_force_width_y / 2)\n             {\n               return max_force_amplitude *\n                      std::exp(\n                        -(Utilities::fixed_power<2>(p[0] - force_center[0]) /\n                            (2 * Utilities::fixed_power<2>(force_sigma_x)) +\n                          Utilities::fixed_power<2>(p[1] - force_center[1]) /\n                            (2 * Utilities::fixed_power<2>(force_sigma_y))));\n             }\n           else\n             {\n               return 0;\n             }\n         }\n       else\n         {\n           return 0;\n         }\n     }\n```\n\n#### The `PML` class implementation\n\nAs before, the constructor reads all the parameters from the [HDF5::Group](classHDF5_1_1Group.html) `data` using the [HDF5::Group::get\\_attribute()](classHDF5_1_1HDF5Object.html#a25c71292aba2399ad5a21d5d855ea2eb) function. As we have discussed, a quadratic turn-on of the PML has been defined in the jupyter notebook. It is possible to use a linear, cubic or another power degree by changing the parameter `pml_coeff_degree`. The parameters `pml_x` and `pml_y` can be used to turn on and off the `x` and `y` PMLs.\n\n```\n     template <int dim>\n     PML<dim>::PML(HDF5::Group &data)\n       : Function<dim, std::complex<double>>(dim)\n       , data(data)\n       , pml_coeff(data.get_attribute<double>(\"pml_coeff\"))\n       , pml_coeff_degree(data.get_attribute<int>(\"pml_coeff_degree\"))\n       , dimension_x(data.get_attribute<double>(\"dimension_x\"))\n       , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n       , pml_x(data.get_attribute<bool>(\"pml_x\"))\n       , pml_y(data.get_attribute<bool>(\"pml_y\"))\n       , pml_width_x(data.get_attribute<double>(\"pml_width_x\"))\n       , pml_width_y(data.get_attribute<double>(\"pml_width_y\"))\n       , a_coeff_x(pml_coeff / std::pow(pml_width_x, pml_coeff_degree))\n       , a_coeff_y(pml_coeff / std::pow(pml_width_y, pml_coeff_degree))\n     {}\n```\n\nThe PML coefficient for the `x` component takes the form \\(s'\\_x = a\\_x x^{\\textrm{degree}}\\)\n\n```\n     template <int dim>\n     std::complex<double> PML<dim>::value(const Point<dim>  &p,\n                                          const unsigned int component) const\n     {\n       double calculated_pml_x_coeff = 0;\n       double calculated_pml_y_coeff = 0;\n   \n       if ((component == 0) && pml_x)\n         {\n           const double pml_x_start_position = dimension_x / 2 - pml_width_x;\n           if (std::abs(p[0]) > pml_x_start_position)\n             {\n               const double x_prime = std::abs(p[0]) - pml_x_start_position;\n               calculated_pml_x_coeff =\n                 a_coeff_x * std::pow(x_prime, pml_coeff_degree);\n             }\n         }\n   \n       if ((component == 1) && pml_y)\n         {\n           const double pml_y_start_position = dimension_y / 2 - pml_width_y;\n           if (std::abs(p[1]) > pml_y_start_position)\n             {\n               const double y_prime = std::abs(p[1]) - pml_y_start_position;\n               calculated_pml_y_coeff =\n                 a_coeff_y * std::pow(y_prime, pml_coeff_degree);\n             }\n         }\n   \n       return 1. + std::max(calculated_pml_x_coeff, calculated_pml_y_coeff) *\n                     std::complex<double>(0., 1.);\n     }\n```\n\n#### The `Rho` class implementation\n\nThis class is used to define the mass density. As we have explained before, a phononic superlattice cavity is formed by two [Distributed Reflector](https://en.wikipedia.org/wiki/Band_gap), mirrors and a \\(\\lambda/2\\) cavity where \\(\\lambda\\) is the acoustic wavelength. Acoustic DBRs are periodic structures where a set of bilayer stacks with contrasting physical properties (sound velocity index) is repeated \\(N\\) times. The change of in the wave velocity is generated by alternating layers with different density.\n\n```\n     template <int dim>\n     Rho<dim>::Rho(HDF5::Group &data)\n       : Function<dim>(1)\n       , data(data)\n       , lambda(data.get_attribute<double>(\"lambda\"))\n       , mu(data.get_attribute<double>(\"mu\"))\n       , material_a_rho(data.get_attribute<double>(\"material_a_rho\"))\n       , material_b_rho(data.get_attribute<double>(\"material_b_rho\"))\n       , cavity_resonance_frequency(\n           data.get_attribute<double>(\"cavity_resonance_frequency\"))\n       , nb_mirror_pairs(data.get_attribute<int>(\"nb_mirror_pairs\"))\n       , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n       , grid_level(data.get_attribute<int>(\"grid_level\"))\n     {\n```\n\nIn order to increase the precision we use [subpixel smoothing](https://meep.readthedocs.io/en/latest/Subpixel_Smoothing/).\n\n```\n       average_rho_width = dimension_y / (std::pow(2.0, grid_level));\n       data.set_attribute(\"average_rho_width\", average_rho_width);\n     }\n   \n   \n   \n     template <int dim>\n     double Rho<dim>::value(const Point<dim> &p,\n                            const unsigned int /*component*/) const\n     {\n```\n\nThe speed of sound is defined by\n\n\\[\nc = \\frac{K\\_e}{\\rho}\n\\]\n\nwhere \\(K\\_e\\) is the effective elastic constant and \\(\\rho\\) the density. Here we consider the case in which the waveguide width is much smaller than the wavelength. In this case it can be shown that for the two dimensional case\n\n\\[\nK\\_e = 4\\mu\\frac{\\lambda +\\mu}{\\lambda+2\\mu}\n\\]\n\nand for the three dimensional case \\(K\\_e\\) is equal to the Young's modulus.\n\n\\[\nK\\_e = \\mu\\frac{3\\lambda +2\\mu}{\\lambda+\\mu}\n\\]\n\n```\n       double elastic_constant;\n       if (dim == 2)\n         {\n           elastic_constant = 4 * mu * (lambda + mu) / (lambda + 2 * mu);\n         }\n       else if (dim == 3)\n         {\n           elastic_constant = mu * (3 * lambda + 2 * mu) / (lambda + mu);\n         }\n       else\n         DEAL_II_NOT_IMPLEMENTED();\n   \n       const double material_a_speed_of_sound =\n         std::sqrt(elastic_constant / material_a_rho);\n       const double material_a_wavelength =\n         material_a_speed_of_sound / cavity_resonance_frequency;\n       const double material_b_speed_of_sound =\n         std::sqrt(elastic_constant / material_b_rho);\n       const double material_b_wavelength =\n         material_b_speed_of_sound / cavity_resonance_frequency;\n```\n\nThe density \\(\\rho\\) takes the following form ![Phononic superlattice cavity](images/steps/developer/step-62.04.svg) where the brown color represents material\\_a and the green color represents material\\_b.\n\n```\n       for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n         {\n           const double layer_transition_center =\n             material_a_wavelength / 2 +\n             idx * (material_b_wavelength / 4 + material_a_wavelength / 4);\n           if (std::abs(p[0]) >=\n                 (layer_transition_center - average_rho_width / 2) &&\n               std::abs(p[0]) <= (layer_transition_center + average_rho_width / 2))\n             {\n               const double coefficient =\n                 (std::abs(p[0]) -\n                  (layer_transition_center - average_rho_width / 2)) /\n                 average_rho_width;\n               return (1 - coefficient) * material_a_rho +\n                      coefficient * material_b_rho;\n             }\n         }\n```\n\nHere we define the [subpixel smoothing](https://meep.readthedocs.io/en/latest/Subpixel_Smoothing/) which improves the precision of the simulation.\n\n```\n       for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n         {\n           const double layer_transition_center =\n             material_a_wavelength / 2 +\n             idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n             material_b_wavelength / 4;\n           if (std::abs(p[0]) >=\n                 (layer_transition_center - average_rho_width / 2) &&\n               std::abs(p[0]) <= (layer_transition_center + average_rho_width / 2))\n             {\n               const double coefficient =\n                 (std::abs(p[0]) -\n                  (layer_transition_center - average_rho_width / 2)) /\n                 average_rho_width;\n               return (1 - coefficient) * material_b_rho +\n                      coefficient * material_a_rho;\n             }\n         }\n```\n\nthen the cavity\n\n```\n       if (std::abs(p[0]) <= material_a_wavelength / 2)\n         {\n           return material_a_rho;\n         }\n```\n\nthe material\\_a layers\n\n```\n       for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n         {\n           const double layer_center =\n             material_a_wavelength / 2 +\n             idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n             material_b_wavelength / 4 + material_a_wavelength / 8;\n           const double layer_width = material_a_wavelength / 4;\n           if (std::abs(p[0]) >= (layer_center - layer_width / 2) &&\n               std::abs(p[0]) <= (layer_center + layer_width / 2))\n             {\n               return material_a_rho;\n             }\n         }\n```\n\nthe material\\_b layers\n\n```\n       for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n         {\n           const double layer_center =\n             material_a_wavelength / 2 +\n             idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n             material_b_wavelength / 8;\n           const double layer_width = material_b_wavelength / 4;\n           if (std::abs(p[0]) >= (layer_center - layer_width / 2) &&\n               std::abs(p[0]) <= (layer_center + layer_width / 2))\n             {\n               return material_b_rho;\n             }\n         }\n```\n\nand finally the default is material\\_a.\n\n```\n       return material_a_rho;\n     }\n```\n\n#### The `Parameters` class implementation\n\nThe constructor reads all the parameters from the [HDF5::Group](classHDF5_1_1Group.html) `data` using the [HDF5::Group::get\\_attribute()](classHDF5_1_1HDF5Object.html#a25c71292aba2399ad5a21d5d855ea2eb) function.\n\n```\n     template <int dim>\n     Parameters<dim>::Parameters(HDF5::Group &data)\n       : data(data)\n       , simulation_name(data.get_attribute<std::string>(\"simulation_name\"))\n       , save_vtu_files(data.get_attribute<bool>(\"save_vtu_files\"))\n       , start_frequency(data.get_attribute<double>(\"start_frequency\"))\n       , stop_frequency(data.get_attribute<double>(\"stop_frequency\"))\n       , nb_frequency_points(data.get_attribute<int>(\"nb_frequency_points\"))\n       , lambda(data.get_attribute<double>(\"lambda\"))\n       , mu(data.get_attribute<double>(\"mu\"))\n       , dimension_x(data.get_attribute<double>(\"dimension_x\"))\n       , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n       , nb_probe_points(data.get_attribute<int>(\"nb_probe_points\"))\n       , grid_level(data.get_attribute<int>(\"grid_level\"))\n       , probe_start_point(data.get_attribute<double>(\"probe_pos_x\"),\n                           data.get_attribute<double>(\"probe_pos_y\") -\n                             data.get_attribute<double>(\"probe_width_y\") / 2)\n       , probe_stop_point(data.get_attribute<double>(\"probe_pos_x\"),\n                          data.get_attribute<double>(\"probe_pos_y\") +\n                            data.get_attribute<double>(\"probe_width_y\") / 2)\n       , right_hand_side(data)\n       , pml(data)\n       , rho(data)\n     {}\n```\n\n#### The `QuadratureCache` class implementation\n\nWe need to reserve enough space for the mass and stiffness matrices and the right hand side vector.\n\n```\n     template <int dim>\n     QuadratureCache<dim>::QuadratureCache(const unsigned int dofs_per_cell)\n       : dofs_per_cell(dofs_per_cell)\n       , mass_coefficient(dofs_per_cell, dofs_per_cell)\n       , stiffness_coefficient(dofs_per_cell, dofs_per_cell)\n       , right_hand_side(dofs_per_cell)\n     {}\n```\n\n### Implementation of the `ElasticWave` class\n\n#### Constructor\n\nThis is very similar to the constructor of [step-40](step_40.html). In addition we create the [HDF5](namespaceHDF5.html) datasets `frequency_dataset`, `position_dataset` and `displacement`. Note the use of the `template` keyword for the creation of the [HDF5](namespaceHDF5.html) datasets. It is a C++ requirement to use the `template` keyword in order to treat `create_dataset` as a dependent template name.\n\n```\n     template <int dim>\n     ElasticWave<dim>::ElasticWave(const Parameters<dim> &parameters)\n       : parameters(parameters)\n       , mpi_communicator(MPI_COMM_WORLD)\n       , triangulation(mpi_communicator,\n                       typename Triangulation<dim>::MeshSmoothing(\n                         Triangulation<dim>::smoothing_on_refinement |\n                         Triangulation<dim>::smoothing_on_coarsening))\n       , quadrature_formula(2)\n       , fe(FE_Q<dim>(1) ^ dim)\n       , dof_handler(triangulation)\n       , frequency(parameters.nb_frequency_points)\n       , probe_positions(parameters.nb_probe_points, dim)\n       , frequency_dataset(parameters.data.template create_dataset<double>(\n           \"frequency\",\n           std::vector<hsize_t>{parameters.nb_frequency_points}))\n       , probe_positions_dataset(parameters.data.template create_dataset<double>(\n           \"position\",\n           std::vector<hsize_t>{parameters.nb_probe_points, dim}))\n       , displacement(\n           parameters.data.template create_dataset<std::complex<double>>(\n             \"displacement\",\n             std::vector<hsize_t>{parameters.nb_probe_points,\n                                  parameters.nb_frequency_points}))\n       , pcout(std::cout,\n               (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n       , computing_timer(mpi_communicator,\n                         pcout,\n                         TimerOutput::never,\n                         TimerOutput::wall_times)\n     {}\n```\n\n#### ElasticWave::setup\\_system\n\nThere is nothing new in this function, the only difference with [step-40](step_40.html) is that we don't have to apply boundary conditions because we use the PMLs to truncate the domain.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::setup_system()\n     {\n       TimerOutput::Scope t(computing_timer, \"setup\");\n   \n       dof_handler.distribute_dofs(fe);\n   \n       locally_owned_dofs = dof_handler.locally_owned_dofs();\n       locally_relevant_dofs =\n         DoFTools::extract_locally_relevant_dofs(dof_handler);\n   \n       locally_relevant_solution.reinit(locally_owned_dofs,\n                                        locally_relevant_dofs,\n                                        mpi_communicator);\n   \n       system_rhs.reinit(locally_owned_dofs, mpi_communicator);\n   \n       constraints.clear();\n       constraints.reinit(locally_relevant_dofs);\n       DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n   \n       constraints.close();\n   \n       DynamicSparsityPattern dsp(locally_relevant_dofs);\n   \n       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n       SparsityTools::distribute_sparsity_pattern(dsp,\n                                                  locally_owned_dofs,\n                                                  mpi_communicator,\n                                                  locally_relevant_dofs);\n   \n       system_matrix.reinit(locally_owned_dofs,\n                            locally_owned_dofs,\n                            dsp,\n                            mpi_communicator);\n     }\n```\n\n#### ElasticWave::assemble\\_system\n\nThis function is also very similar to [step-40](step_40.html), though there are notable differences. We assemble the system for each frequency/omega step. In the first step we set `calculate_quadrature_data = True` and we calculate the mass and stiffness matrices and the right hand side vector. In the subsequent steps we will use that data to accelerate the calculation.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::assemble_system(const double omega,\n                                            const bool   calculate_quadrature_data)\n     {\n       TimerOutput::Scope t(computing_timer, \"assembly\");\n   \n       FEValues<dim>      fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_gradients |\n                                 update_quadrature_points | update_JxW_values);\n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<std::complex<double>> cell_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<std::complex<double>>     cell_rhs(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n```\n\nHere we store the value of the right hand side, rho and the PML.\n\n```\n       std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim));\n       std::vector<double>         rho_values(n_q_points);\n       std::vector<Vector<std::complex<double>>> pml_values(\n         n_q_points, Vector<std::complex<double>>(dim));\n```\n\nWe calculate the stiffness tensor for the \\(\\lambda\\) and \\(\\mu\\) that have been defined in the jupyter notebook. Note that contrary to \\(\\rho\\) the stiffness is constant among for the whole domain.\n\n```\n       const SymmetricTensor<4, dim> stiffness_tensor =\n         get_stiffness_tensor<dim>(parameters.lambda, parameters.mu);\n```\n\nWe use the same method of [step-20](step_20.html) for vector-valued problems.\n\n```\n       const FEValuesExtractors::Vector displacement(0);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             cell_matrix = 0;\n             cell_rhs    = 0;\n```\n\nWe have to calculate the values of the right hand side, rho and the PML only if we are going to calculate the mass and the stiffness matrices. Otherwise we can skip this calculation which considerably reduces the total calculation time.\n\n```\n             if (calculate_quadrature_data)\n               {\n                 fe_values.reinit(cell);\n   \n                 parameters.right_hand_side.vector_value_list(\n                   fe_values.get_quadrature_points(), rhs_values);\n                 parameters.rho.value_list(fe_values.get_quadrature_points(),\n                                           rho_values);\n                 parameters.pml.vector_value_list(\n                   fe_values.get_quadrature_points(), pml_values);\n               }\n```\n\nWe have done this in [step-18](step_18.html). Get a pointer to the quadrature cache data local to the present cell, and, as a defensive measure, make sure that this pointer is within the bounds of the global array:\n\n```\n             QuadratureCache<dim> *local_quadrature_points_data =\n               reinterpret_cast<QuadratureCache<dim> *>(cell->user_pointer());\n             Assert(local_quadrature_points_data >= &quadrature_cache.front(),\n                    ExcInternalError());\n             Assert(local_quadrature_points_data <= &quadrature_cache.back(),\n                    ExcInternalError());\n             for (unsigned int q = 0; q < n_q_points; ++q)\n               {\n```\n\nThe quadrature\\_data variable is used to store the mass and stiffness matrices, the right hand side vector and the value of `JxW`.\n\n```\n                 QuadratureCache<dim> &quadrature_data =\n                   local_quadrature_points_data[q];\n```\n\nBelow we declare the force vector and the parameters of the PML \\(s\\) and \\(\\xi\\).\n\n```\n                 Tensor<1, dim>                       force;\n                 Tensor<1, dim, std::complex<double>> s;\n                 std::complex<double>                 xi(1, 0);\n```\n\nThe following block is calculated only in the first frequency step.\n\n```\n                 if (calculate_quadrature_data)\n                   {\n```\n\nStore the value of `JxW`.\n\n```\n                     quadrature_data.JxW = fe_values.JxW(q);\n   \n                     for (unsigned int component = 0; component < dim; ++component)\n                       {\n```\n\nConvert vectors to tensors and calculate xi\n\n```\n                         force[component] = rhs_values[q][component];\n                         s[component]     = pml_values[q][component];\n                         xi *= s[component];\n                       }\n```\n\nHere we calculate the \\(\\alpha\\_{mnkl}\\) and \\(\\beta\\_{mnkl}\\) tensors.\n\n```\n                     Tensor<4, dim, std::complex<double>> alpha;\n                     Tensor<4, dim, std::complex<double>> beta;\n                     for (unsigned int m = 0; m < dim; ++m)\n                       for (unsigned int n = 0; n < dim; ++n)\n                         for (unsigned int k = 0; k < dim; ++k)\n                           for (unsigned int l = 0; l < dim; ++l)\n                             {\n                               alpha[m][n][k][l] = xi *\n                                                   stiffness_tensor[m][n][k][l] /\n                                                   (2.0 * s[n] * s[k]);\n                               beta[m][n][k][l] = xi *\n                                                  stiffness_tensor[m][n][k][l] /\n                                                  (2.0 * s[n] * s[l]);\n                             }\n   \n                     for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                       {\n                         const Tensor<1, dim> phi_i =\n                           fe_values[displacement].value(i, q);\n                         const Tensor<2, dim> grad_phi_i =\n                           fe_values[displacement].gradient(i, q);\n   \n                         for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                           {\n                             const Tensor<1, dim> phi_j =\n                               fe_values[displacement].value(j, q);\n                             const Tensor<2, dim> grad_phi_j =\n                               fe_values[displacement].gradient(j, q);\n```\n\ncalculate the values of the [mass matrix](DEALGlossary.html#GlossMassMatrix).\n\n```\n                             quadrature_data.mass_coefficient[i][j] =\n                               rho_values[q] * xi * phi_i * phi_j;\n```\n\nLoop over the \\(mnkl\\) indices of the stiffness tensor.\n\n```\n                             std::complex<double> stiffness_coefficient = 0;\n                             for (unsigned int m = 0; m < dim; ++m)\n                               for (unsigned int n = 0; n < dim; ++n)\n                                 for (unsigned int k = 0; k < dim; ++k)\n                                   for (unsigned int l = 0; l < dim; ++l)\n                                     {\n```\n\nHere we calculate the stiffness matrix. Note that the stiffness matrix is not symmetric because of the PMLs. We use the gradient function (see the [documentation](https://www.dealii.org/current/doxygen/deal.II/group__vector__valued.html)) which is a `Tensor<2,dim>`. The matrix \\(G\\_{ij}\\) consists of entries\n\n\\[\nG\\_{ij}=\n\\frac{\\partial\\phi\\_i}{\\partial x\\_j}\n=\\partial\\_j \\phi\\_i\n\\]\n\nNote the position of the indices \\(i\\) and \\(j\\) and the notation that we use in this tutorial: \\(\\partial\\_j\\phi\\_i\\). As the stiffness tensor is not symmetric, it is very easy to make a mistake.\n\n```\n                                       stiffness_coefficient +=\n                                         grad_phi_i[m][n] *\n                                         (alpha[m][n][k][l] * grad_phi_j[l][k] +\n                                          beta[m][n][k][l] * grad_phi_j[k][l]);\n                                     }\n```\n\nWe save the value of the stiffness matrix in quadrature\\_data\n\n```\n                             quadrature_data.stiffness_coefficient[i][j] =\n                               stiffness_coefficient;\n                           }\n```\n\nand the value of the right hand side in quadrature\\_data.\n\n```\n                         quadrature_data.right_hand_side[i] =\n                           phi_i * force * fe_values.JxW(q);\n                       }\n                   }\n```\n\nWe loop again over the degrees of freedom of the cells to calculate the system matrix. These loops are really quick because we have already calculated the stiffness and mass matrices, only the value of \\(\\omega\\) changes.\n\n```\n                 for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                   {\n                     for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                       {\n                         std::complex<double> matrix_sum = 0;\n                         matrix_sum += -Utilities::fixed_power<2>(omega) *\n                                       quadrature_data.mass_coefficient[i][j];\n                         matrix_sum += quadrature_data.stiffness_coefficient[i][j];\n                         cell_matrix(i, j) += matrix_sum * quadrature_data.JxW;\n                       }\n                     cell_rhs(i) += quadrature_data.right_hand_side[i];\n                   }\n               }\n             cell->get_dof_indices(local_dof_indices);\n             constraints.distribute_local_to_global(cell_matrix,\n                                                    cell_rhs,\n                                                    local_dof_indices,\n                                                    system_matrix,\n                                                    system_rhs);\n           }\n   \n       system_matrix.compress(VectorOperation::add);\n       system_rhs.compress(VectorOperation::add);\n     }\n```\n\n#### ElasticWave::solve\n\nThis is even more simple than in [step-40](step_40.html). We use the parallel direct solver MUMPS which requires less options than an iterative solver. The drawback is that it does not scale very well. It is not straightforward to solve the Helmholtz equation with an iterative solver. The shifted Laplacian multigrid method is a well known approach to precondition this system, but this is beyond the scope of this tutorial.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::solve()\n     {\n       TimerOutput::Scope              t(computing_timer, \"solve\");\n       LinearAlgebraPETSc::MPI::Vector completely_distributed_solution(\n         locally_owned_dofs, mpi_communicator);\n   \n       SolverControl                    solver_control;\n       PETScWrappers::SparseDirectMUMPS solver(solver_control, mpi_communicator);\n       solver.solve(system_matrix, completely_distributed_solution, system_rhs);\n   \n       pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n             << std::endl;\n       constraints.distribute(completely_distributed_solution);\n       locally_relevant_solution = completely_distributed_solution;\n     }\n```\n\n#### ElasticWave::initialize\\_position\\_vector\n\nWe use this function to calculate the values of the position vector.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::initialize_probe_positions_vector()\n     {\n       for (unsigned int position_idx = 0;\n            position_idx < parameters.nb_probe_points;\n            ++position_idx)\n         {\n```\n\nBecause of the way the operator + and - are overloaded to subtract two points, the following has to be done: `Point_b<dim> + (-Point_a<dim>)`\n\n```\n           const Point<dim> p =\n             (position_idx / ((double)(parameters.nb_probe_points - 1))) *\n               (parameters.probe_stop_point + (-parameters.probe_start_point)) +\n             parameters.probe_start_point;\n           probe_positions[position_idx][0] = p[0];\n           probe_positions[position_idx][1] = p[1];\n           if (dim == 3)\n             {\n               probe_positions[position_idx][2] = p[2];\n             }\n         }\n     }\n```\n\n#### ElasticWave::store\\_frequency\\_step\\_data\n\nThis function stores in the [HDF5](namespaceHDF5.html) file the measured energy by the probe.\n\n```\n     template <int dim>\n     void\n     ElasticWave<dim>::store_frequency_step_data(const unsigned int frequency_idx)\n     {\n       TimerOutput::Scope t(computing_timer, \"store_frequency_step_data\");\n```\n\nWe store the displacement in the \\(x\\) direction; the displacement in the \\(y\\) direction is negligible.\n\n```\n       const unsigned int probe_displacement_component = 0;\n```\n\nThe vector coordinates contains the coordinates in the [HDF5](namespaceHDF5.html) file of the points of the probe that are located in locally owned cells. The vector displacement\\_data contains the value of the displacement at these points.\n\n```\n       std::vector<hsize_t>              coordinates;\n       std::vector<std::complex<double>> displacement_data;\n   \n       const auto &mapping = get_default_linear_mapping(triangulation);\n       GridTools::Cache<dim, dim> cache(triangulation, mapping);\n       typename Triangulation<dim, dim>::active_cell_iterator cell_hint{};\n       std::vector<bool>                                      marked_vertices = {};\n       const double                                           tolerance = 1.e-10;\n   \n       for (unsigned int position_idx = 0;\n            position_idx < parameters.nb_probe_points;\n            ++position_idx)\n         {\n           Point<dim> point;\n           for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n             {\n               point[dim_idx] = probe_positions[position_idx][dim_idx];\n             }\n           bool point_in_locally_owned_cell = false;\n           {\n             auto cell_and_ref_point = GridTools::find_active_cell_around_point(\n               cache, point, cell_hint, marked_vertices, tolerance);\n             if (cell_and_ref_point.first.state() == IteratorState::valid)\n               {\n                 cell_hint = cell_and_ref_point.first;\n                 point_in_locally_owned_cell =\n                   cell_and_ref_point.first->is_locally_owned();\n               }\n           }\n           if (point_in_locally_owned_cell)\n             {\n```\n\nThen we can store the values of the displacement in the points of the probe in `displacement_data`.\n\n```\n               Vector<std::complex<double>> tmp_vector(dim);\n               VectorTools::point_value(dof_handler,\n                                        locally_relevant_solution,\n                                        point,\n                                        tmp_vector);\n               coordinates.emplace_back(position_idx);\n               coordinates.emplace_back(frequency_idx);\n               displacement_data.emplace_back(\n                 tmp_vector(probe_displacement_component));\n             }\n         }\n```\n\nWe write the displacement data in the [HDF5](namespaceHDF5.html) file. The call [HDF5::DataSet::write\\_selection()](classHDF5_1_1DataSet.html#a75f9f53f0c656a7e4aa00757290efb9e) is MPI collective which means that all the processes have to participate.\n\n```\n       if (coordinates.size() > 0)\n         {\n           displacement.write_selection(displacement_data, coordinates);\n         }\n```\n\nTherefore even if the process has no data to write it has to participate in the collective call. For this we can use [HDF5::DataSet::write\\_none()](classHDF5_1_1DataSet.html#a9ca9525c41fe37c9c64f2b41ad0b871e). Note that we have to specify the data type, in this case `std::complex<double>`.\n\n```\n       else\n         {\n           displacement.write_none<std::complex<double>>();\n         }\n```\n\nIf the variable `save_vtu_files` in the input file equals `True` then all the data will be saved as vtu. The procedure to write `vtu` files has been described in [step-40](step_40.html).\n\n```\n       if (parameters.save_vtu_files)\n         {\n           std::vector<std::string> solution_names(dim, \"displacement\");\n           std::vector<DataComponentInterpretation::DataComponentInterpretation>\n             interpretation(\n               dim, DataComponentInterpretation::component_is_part_of_vector);\n   \n           DataOut<dim> data_out;\n           data_out.add_data_vector(dof_handler,\n                                    locally_relevant_solution,\n                                    solution_names,\n                                    interpretation);\n           Vector<float> subdomain(triangulation.n_active_cells());\n           for (unsigned int i = 0; i < subdomain.size(); ++i)\n             subdomain(i) = triangulation.locally_owned_subdomain();\n           data_out.add_data_vector(subdomain, \"subdomain\");\n   \n           std::vector<Vector<double>> force(\n             dim, Vector<double>(triangulation.n_active_cells()));\n           std::vector<Vector<double>> pml(\n             dim, Vector<double>(triangulation.n_active_cells()));\n           Vector<double> rho(triangulation.n_active_cells());\n   \n           for (auto &cell : triangulation.active_cell_iterators())\n             {\n               if (cell->is_locally_owned())\n                 {\n                   for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n                     {\n                       force[dim_idx](cell->active_cell_index()) =\n                         parameters.right_hand_side.value(cell->center(), dim_idx);\n                       pml[dim_idx](cell->active_cell_index()) =\n                         parameters.pml.value(cell->center(), dim_idx).imag();\n                     }\n                   rho(cell->active_cell_index()) =\n                     parameters.rho.value(cell->center());\n                 }\n```\n\nAnd on the cells that we are not interested in, set the respective value to a bogus value in order to make sure that if we were somehow wrong about our assumption we would find out by looking at the graphical output:\n\n```\n               else\n                 {\n                   for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n                     {\n                       force[dim_idx](cell->active_cell_index()) = -1e+20;\n                       pml[dim_idx](cell->active_cell_index())   = -1e+20;\n                     }\n                   rho(cell->active_cell_index()) = -1e+20;\n                 }\n             }\n   \n           for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n             {\n               data_out.add_data_vector(force[dim_idx],\n                                        \"force_\" + std::to_string(dim_idx));\n               data_out.add_data_vector(pml[dim_idx],\n                                        \"pml_\" + std::to_string(dim_idx));\n             }\n           data_out.add_data_vector(rho, \"rho\");\n   \n           data_out.build_patches();\n   \n           std::stringstream  frequency_idx_stream;\n           const unsigned int nb_number_positions =\n             ((unsigned int)std::log10(parameters.nb_frequency_points)) + 1;\n           frequency_idx_stream << std::setw(nb_number_positions)\n                                << std::setfill('0') << frequency_idx;\n           const std::string filename = (parameters.simulation_name + \"_\" +\n                                         frequency_idx_stream.str() + \".vtu\");\n           data_out.write_vtu_in_parallel(filename, mpi_communicator);\n         }\n     }\n```\n\n#### ElasticWave::output\\_results\n\nThis function writes the datasets that have not already been written.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::output_results()\n     {\n```\n\nThe vectors `frequency` and `position` are the same for all the processes. Therefore any of the processes can write the corresponding `datasets`. Because the call [HDF5::DataSet::write](classHDF5_1_1DataSet.html#a0f51f04d2fcddac7c0c5f863d665253f) is MPI collective, the rest of the processes will have to call [HDF5::DataSet::write\\_none](classHDF5_1_1DataSet.html#a9ca9525c41fe37c9c64f2b41ad0b871e).\n\n```\n       if (Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n         {\n           frequency_dataset.write(frequency);\n           probe_positions_dataset.write(probe_positions);\n         }\n       else\n         {\n           frequency_dataset.write_none<double>();\n           probe_positions_dataset.write_none<double>();\n         }\n     }\n```\n\n#### ElasticWave::setup\\_quadrature\\_cache\n\nWe use this function at the beginning of our computations to set up initial values of the cache variables. This function has been described in [step-18](step_18.html). There are no differences with the function of [step-18](step_18.html).\n\n```\n     template <int dim>\n     void ElasticWave<dim>::setup_quadrature_cache()\n     {\n       triangulation.clear_user_data();\n   \n       {\n         std::vector<QuadratureCache<dim>> tmp;\n         quadrature_cache.swap(tmp);\n       }\n   \n       quadrature_cache.resize(triangulation.n_locally_owned_active_cells() *\n                                 quadrature_formula.size(),\n                               QuadratureCache<dim>(fe.n_dofs_per_cell()));\n       unsigned int cache_index = 0;\n       for (const auto &cell : triangulation.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             cell->set_user_pointer(&quadrature_cache[cache_index]);\n             cache_index += quadrature_formula.size();\n           }\n       Assert(cache_index == quadrature_cache.size(), ExcInternalError());\n     }\n```\n\n#### ElasticWave::frequency\\_sweep\n\nFor clarity we divide the function `run` of [step-40](step_40.html) into the functions `run` and `frequency_sweep`. In the function `frequency_sweep` we place the iteration over the frequency vector.\n\n```\n     template <int dim>\n     void ElasticWave<dim>::frequency_sweep()\n     {\n       for (unsigned int frequency_idx = 0;\n            frequency_idx < parameters.nb_frequency_points;\n            ++frequency_idx)\n         {\n           pcout << parameters.simulation_name + \" frequency idx: \"\n                 << frequency_idx << '/' << parameters.nb_frequency_points - 1\n                 << std::endl;\n   \n   \n   \n           setup_system();\n           if (frequency_idx == 0)\n             {\n               pcout << \"   Number of active cells :       \"\n                     << triangulation.n_active_cells() << std::endl;\n               pcout << \"   Number of degrees of freedom : \"\n                     << dof_handler.n_dofs() << std::endl;\n             }\n   \n           if (frequency_idx == 0)\n             {\n```\n\nWrite the simulation parameters only once\n\n```\n               parameters.data.set_attribute(\"active_cells\",\n                                             triangulation.n_active_cells());\n               parameters.data.set_attribute(\"degrees_of_freedom\",\n                                             dof_handler.n_dofs());\n             }\n```\n\nWe calculate the frequency and omega values for this particular step.\n\n```\n           const double current_loop_frequency =\n             (parameters.start_frequency +\n              frequency_idx *\n                (parameters.stop_frequency - parameters.start_frequency) /\n                (parameters.nb_frequency_points - 1));\n           const double current_loop_omega =\n             2 * numbers::PI * current_loop_frequency;\n```\n\nIn the first frequency step we calculate the mass and stiffness matrices and the right hand side. In the subsequent frequency steps we will use those values. This improves considerably the calculation time.\n\n```\n           assemble_system(current_loop_omega,\n                           (frequency_idx == 0) ? true : false);\n           solve();\n   \n           frequency[frequency_idx] = current_loop_frequency;\n           store_frequency_step_data(frequency_idx);\n   \n           computing_timer.print_summary();\n           computing_timer.reset();\n           pcout << std::endl;\n         }\n     }\n```\n\n#### ElasticWave::run\n\nThis function is very similar to the one in [step-40](step_40.html).\n\n```\n     template <int dim>\n     void ElasticWave<dim>::run()\n     {\n   #ifdef DEBUG\n       pcout << \"Debug mode\" << std::endl;\n   #else\n       pcout << \"Release mode\" << std::endl;\n   #endif\n   \n       {\n         Point<dim> p1;\n         p1(0) = -parameters.dimension_x / 2;\n         p1(1) = -parameters.dimension_y / 2;\n         if (dim == 3)\n           {\n             p1(2) = -parameters.dimension_y / 2;\n           }\n         Point<dim> p2;\n         p2(0) = parameters.dimension_x / 2;\n         p2(1) = parameters.dimension_y / 2;\n         if (dim == 3)\n           {\n             p2(2) = parameters.dimension_y / 2;\n           }\n         std::vector<unsigned int> divisions(dim);\n         divisions[0] = int(parameters.dimension_x / parameters.dimension_y);\n         divisions[1] = 1;\n         if (dim == 3)\n           {\n             divisions[2] = 1;\n           }\n         GridGenerator::subdivided_hyper_rectangle(triangulation,\n                                                   divisions,\n                                                   p1,\n                                                   p2);\n       }\n   \n       triangulation.refine_global(parameters.grid_level);\n   \n       setup_quadrature_cache();\n   \n       initialize_probe_positions_vector();\n   \n       frequency_sweep();\n   \n       output_results();\n     }\n   } // namespace step62\n```\n\n#### The main function\n\nThe main function is very similar to the one in [step-40](step_40.html).\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         using namespace dealii;\n         const unsigned int dim = 2;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n   \n         HDF5::File data_file(\"results.h5\",\n                              HDF5::File::FileAccessMode::create,\n                              MPI_COMM_WORLD);\n         auto       data = data_file.create_group(\"data\");\n```\n\nEach of the simulations (displacement and calibration) is stored in a separate [HDF5](namespaceHDF5.html) group:\n\n```\n         const std::array<std::string, 2> group_names{\n           {\"displacement\", \"calibration\"}};\n         for (const std::string &group_name : group_names)\n           {\n```\n\nFor each of these two group names, we now create the group and put attributes into these groups. Specifically, these are:\n\n* The dimensions of the waveguide (in \\(x\\) and \\(y\\) directions)\n* The position of the probe (in \\(x\\) and \\(y\\) directions)\n* The number of points in the probe\n* The global refinement level\n* The cavity resonance frequency\n* The number of mirror pairs\n* The material properties\n* The force parameters\n* The PML parameters\n* The frequency parameters\n\n```\n             auto group = data.create_group(group_name);\n   \n             group.set_attribute<double>(\"dimension_x\", 2e-5);\n             group.set_attribute<double>(\"dimension_y\", 2e-8);\n             group.set_attribute<double>(\"probe_pos_x\", 8e-6);\n             group.set_attribute<double>(\"probe_pos_y\", 0);\n             group.set_attribute<double>(\"probe_width_y\", 2e-08);\n             group.set_attribute<unsigned int>(\"nb_probe_points\", 5);\n             group.set_attribute<unsigned int>(\"grid_level\", 1);\n             group.set_attribute<double>(\"cavity_resonance_frequency\", 20e9);\n             group.set_attribute<unsigned int>(\"nb_mirror_pairs\", 15);\n   \n             group.set_attribute<double>(\"poissons_ratio\", 0.27);\n             group.set_attribute<double>(\"youngs_modulus\", 270000000000.0);\n             group.set_attribute<double>(\"material_a_rho\", 3200);\n   \n             if (group_name == \"displacement\")\n               group.set_attribute<double>(\"material_b_rho\", 2000);\n             else\n               group.set_attribute<double>(\"material_b_rho\", 3200);\n   \n             group.set_attribute(\n               \"lambda\",\n               group.get_attribute<double>(\"youngs_modulus\") *\n                 group.get_attribute<double>(\"poissons_ratio\") /\n                 ((1 + group.get_attribute<double>(\"poissons_ratio\")) *\n                  (1 - 2 * group.get_attribute<double>(\"poissons_ratio\"))));\n             group.set_attribute(\"mu\",\n                                 group.get_attribute<double>(\"youngs_modulus\") /\n                                   (2 * (1 + group.get_attribute<double>(\n                                               \"poissons_ratio\"))));\n   \n             group.set_attribute<double>(\"max_force_amplitude\", 1e26);\n             group.set_attribute<double>(\"force_sigma_x\", 1e-7);\n             group.set_attribute<double>(\"force_sigma_y\", 1);\n             group.set_attribute<double>(\"max_force_width_x\", 3e-7);\n             group.set_attribute<double>(\"max_force_width_y\", 2e-8);\n             group.set_attribute<double>(\"force_x_pos\", -8e-6);\n             group.set_attribute<double>(\"force_y_pos\", 0);\n   \n             group.set_attribute<bool>(\"pml_x\", true);\n             group.set_attribute<bool>(\"pml_y\", false);\n             group.set_attribute<double>(\"pml_width_x\", 1.8e-6);\n             group.set_attribute<double>(\"pml_width_y\", 5e-7);\n             group.set_attribute<double>(\"pml_coeff\", 1.6);\n             group.set_attribute<unsigned int>(\"pml_coeff_degree\", 2);\n   \n             group.set_attribute<double>(\"center_frequency\", 20e9);\n             group.set_attribute<double>(\"frequency_range\", 0.5e9);\n             group.set_attribute<double>(\n               \"start_frequency\",\n               group.get_attribute<double>(\"center_frequency\") -\n                 group.get_attribute<double>(\"frequency_range\") / 2);\n             group.set_attribute<double>(\n               \"stop_frequency\",\n               group.get_attribute<double>(\"center_frequency\") +\n                 group.get_attribute<double>(\"frequency_range\") / 2);\n             group.set_attribute<unsigned int>(\"nb_frequency_points\", 400);\n   \n             if (group_name == std::string(\"displacement\"))\n               group.set_attribute<std::string>(\n                 \"simulation_name\", std::string(\"phononic_cavity_displacement\"));\n             else\n               group.set_attribute<std::string>(\n                 \"simulation_name\", std::string(\"phononic_cavity_calibration\"));\n   \n             group.set_attribute<bool>(\"save_vtu_files\", false);\n           }\n   \n         {\n```\n\nDisplacement simulation. The parameters are read from the displacement [HDF5](namespaceHDF5.html) group and the results are saved in the same [HDF5](namespaceHDF5.html) group.\n\n```\n           auto                    displacement = data.open_group(\"displacement\");\n           step62::Parameters<dim> parameters(displacement);\n   \n           step62::ElasticWave<dim> elastic_problem(parameters);\n           elastic_problem.run();\n         }\n   \n         {\n```\n\nCalibration simulation. The parameters are read from the calibration [HDF5](namespaceHDF5.html) group and the results are saved in the same [HDF5](namespaceHDF5.html) group.\n\n```\n           auto                    calibration = data.open_group(\"calibration\");\n           step62::Parameters<dim> parameters(calibration);\n   \n           step62::ElasticWave<dim> elastic_problem(parameters);\n           elastic_problem.run();\n         }\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### Resonance frequency and bandgap\n\nThe results are analyzed in the [jupyter notebook](https://github.com/dealii/dealii/blob/master/examples/step-62/step-62.ipynb) with the following code\n\n```\nh5_file = h5py.File('results.h5', 'r')\ndata = h5_file['data']\n \n# Gaussian function that we use to fit the resonance\ndef resonance_f(freq, freq_m, quality_factor, max_amplitude):\n    omega = 2 * constants.pi * freq\n    omega_m = 2 * constants.pi * freq_m\n    gamma = omega_m / quality_factor\n return max_amplitude * omega_m**2 * gamma**2 / (((omega_m**2 - omega**2)**2 + gamma**2 * omega**2))\n \nfrequency = data['displacement']['frequency'][...]\n# Average the probe points\ndisplacement = np.mean(data['displacement']['displacement'], axis=0)\ncalibration_displacement = np.mean(data['calibration']['displacement'], axis=0)\nreflection_coefficient = displacement / calibration_displacement\nreflectivity = (np.abs(np.mean(data['displacement']['displacement'][...]**2, axis=0))/\n                np.abs(np.mean(data['calibration']['displacement'][...]**2, axis=0)))\n \ntry:\n    x_data = frequency\n    y_data = reflectivity\n    quality_factor_guess = 1e3\n    freq_guess = x_data[np.argmax(y_data)]\n    amplitude_guess = np.max(y_data)\n    fit_result, covariance = scipy.optimize.curve_fit(resonance_f, x_data, y_data,\n                                                      [freq_guess, quality_factor_guess, amplitude_guess])\n    freq_m = fit_result[0]\n    quality_factor = np.abs(fit_result[1])\n    max_amplitude = fit_result[2]\n    y_data_fit = resonance_f(x_data, freq_m, quality_factor, max_amplitude)\n \n    fig = plt.figure()\n    plt.plot(frequency / 1e9, reflectivity, frequency / 1e9, y_data_fit)\n    plt.xlabel('frequency (GHz)')\n    plt.ylabel('amplitude^2 (a.u.)')\n    plt.title('Transmission\\n' + 'freq = ' + \"%.7g\" % (freq_guess / 1e9) + 'GHz Q = ' + \"%.6g\" % quality_factor)\nexcept:\n    fig = plt.figure()\n    plt.plot(frequency / 1e9, reflectivity)\n    plt.xlabel('frequency (GHz)')\n    plt.ylabel('amplitude^2 (a.u.)')\n    plt.title('Transmission')\n \nfig = plt.figure()\nplt.plot(frequency / 1e9, np.angle(reflection_coefficient))\nplt.xlabel('frequency (GHz)')\nplt.ylabel('phase (rad)')\nplt.title('Phase (transmission coefficient)\\n')\n \nplt.show()\nh5_file.close()\n```\n\nA phononic cavity is characterized by the [resonance frequency](https://en.wikipedia.org/wiki/Resonance) and the [the quality factor](https://en.wikipedia.org/wiki/Q_factor). The quality factor is equal to the ratio between the stored energy in the resonator and the energy dissipated energy per cycle, which is approximately equivalent to the ratio between the resonance frequency and the [full width at half maximum (FWHM)](https://en.wikipedia.org/wiki/Full_width_at_half_maximum). The FWHM is equal to the bandwidth over which the power of vibration is greater than half the power at the resonant frequency.\n\n\\[\nQ = \\frac{f\\_r}{\\Delta f} = \\frac{\\omega\\_r}{\\Delta \\omega} =\n2 \\pi \\times \\frac{\\text{energy stored}}{\\text{energy dissipated per cycle}}\n\\]\n\nThe square of the amplitude of the mechanical resonance \\(a^2\\) as a function of the frequency has a gaussian shape\n\n\\[\na^2 = a\\_\\textrm{max}^2\\frac{\\omega^2\\Gamma^2}{(\\omega\\_r^2-\\omega^2)^2+\\Gamma^2\\omega^2}\n\\]\n\nwhere \\(f\\_r = \\frac{\\omega\\_r}{2\\pi}\\) is the resonance frequency and \\(\\Gamma=\\frac{\\omega\\_r}{Q}\\) is the dissipation rate. We used the previous equation in the jupyter notebook to fit the mechanical resonance.\n\nGiven the values we have chosen for the parameters, one could estimate the resonance frequency analytically. Indeed, this is then confirmed by what we get in this program: the phononic superlattice cavity exhibits a mechanical resonance at 20GHz and a quality factor of 5046. The following images show the transmission amplitude and phase as a function of frequency in the vicinity of the resonance frequency:\n\n![Phononic superlattice cavity](images/steps/developer/step-62.05.png) ![Phononic superlattice cavity](images/steps/developer/step-62.06.png)\n\nThe images above suggest that the periodic structure has its intended effect: It really only lets waves of a very specific frequency pass through, whereas all other waves are reflected. This is of course precisely what one builds these sorts of devices for. But it is not quite this easy. In practice, there is really only a \"band gap\", i.e., the device blocks waves other than the desired one at 20GHz only within a certain frequency range. Indeed, to find out how large this \"gap\" is within which waves are blocked, we can extend the frequency range to 16 GHz through the appropriate parameters in the input file. We then obtain the following image:\n\n![Phononic superlattice cavity](images/steps/developer/step-62.07.png)\n\nWhat this image suggests is that in the range of around 18 to around 22 GHz, really only the waves with a frequency of 20 GHz are allowed to pass through, but beyond this range, there are plenty of other frequencies that can pass through the device.\n\n### Mode profile\n\nWe can inspect the mode profile with Paraview or VisIt. As we have discussed, at resonance all the mechanical energy is transmitted and the amplitude of motion is amplified inside the cavity. It can be observed that the PMLs are quite effective to truncate the solution. The following image shows the mode profile at resonance:\n\n![Phononic superlattice cavity](images/steps/developer/step-62.08.png)\n\nOn the other hand, out of resonance all the mechanical energy is reflected. The following image shows the profile at 19.75 GHz. Note the interference between the force pulse and the reflected wave at the position \\(x=-8\\mu\\textrm{m}\\).\n\n![Phononic superlattice cavity](images/steps/developer/step-62.09.png)\n\n### Experimental applications\n\nPhononic superlattice cavities find application in [quantum optomechanics](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.1391). Here we have presented the simulation of a 2D superlattice cavity, but this code can be used as well to simulate \"real world\" 3D devices such as [micropillar superlattice cavities](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.99.060101), which are promising candidates to study macroscopic quantum phenomena. The 20GHz mode of a micropillar superlattice cavity is essentially a mechanical harmonic oscillator that is very well isolated from the environment. If the device is cooled down to 20mK in a dilution fridge, the mode would then become a macroscopic quantum harmonic oscillator.\n\n### Possibilities for extensions\n\nInstead of setting the parameters in the C++ file we could set the parameters using a python script and save them in the [HDF5](namespaceHDF5.html) file that we will use for the simulations. Then the deal.II program will read the parameters from the [HDF5](namespaceHDF5.html) file.\n\n```\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport subprocess\nimport scipy.constants as constants\nimport scipy.optimize\n \n# This considerably reduces the size of the svg data\nplt.rcParams['svg.fonttype'] = 'none'\n \nh5_file = h5py.File('results.h5', 'w')\ndata = h5_file.create_group('data')\ndisplacement = data.create_group('displacement')\ncalibration = data.create_group('calibration')\n \n# Set the parameters\nfor group in [displacement, calibration]:\n # Dimensions of the domain\n # The waveguide length is equal to dimension_x\n    group.attrs['dimension_x'] = 2e-5\n # The waveguide width is equal to dimension_y\n    group.attrs['dimension_y'] = 2e-8\n \n # Position of the probe that we use to measure the flux\n    group.attrs['probe_pos_x']   = 8e-6\n    group.attrs['probe_pos_y']   = 0\n    group.attrs['probe_width_y'] = 2e-08\n \n # Number of points in the probe\n    group.attrs['nb_probe_points'] = 5\n \n # Global refinement\n    group.attrs['grid_level'] = 1\n \n # Cavity\n    group.attrs['cavity_resonance_frequency'] = 20e9\n    group.attrs['nb_mirror_pairs']            = 15\n \n # Material\n    group.attrs['poissons_ratio'] = 0.27\n    group.attrs['youngs_modulus'] = 270000000000.0\n    group.attrs['material_a_rho'] = 3200\n if group == displacement:\n        group.attrs['material_b_rho'] = 2000\n else:\n        group.attrs['material_b_rho'] = 3200\n    group.attrs['lambda'] = (group.attrs['youngs_modulus'] * group.attrs['poissons_ratio'] /\n                           ((1 + group.attrs['poissons_ratio']) *\n                           (1 - 2 * group.attrs['poissons_ratio'])))\n    group.attrs['mu']= (group.attrs['youngs_modulus'] / (2 * (1 + group.attrs['poissons_ratio'])))\n \n # Force\n    group.attrs['max_force_amplitude'] = 1e26\n    group.attrs['force_sigma_x']       = 1e-7\n    group.attrs['force_sigma_y']       = 1\n    group.attrs['max_force_width_x']   = 3e-7\n    group.attrs['max_force_width_y']   = 2e-8\n    group.attrs['force_x_pos']         = -8e-6\n    group.attrs['force_y_pos']         = 0\n \n # PML\n    group.attrs['pml_x']            = True\n    group.attrs['pml_y']            = False\n    group.attrs['pml_width_x']      = 1.8e-6\n    group.attrs['pml_width_y']      = 5e-7\n    group.attrs['pml_coeff']        = 1.6\n    group.attrs['pml_coeff_degree'] = 2\n \n # Frequency sweep\n    group.attrs['center_frequency']    = 20e9\n    group.attrs['frequency_range']     = 0.5e9\n    group.attrs['start_frequency']     = group.attrs['center_frequency'] - group.attrs['frequency_range'] / 2\n    group.attrs['stop_frequency']      = group.attrs['center_frequency'] + group.attrs['frequency_range'] / 2\n    group.attrs['nb_frequency_points'] = 400\n \n # Other parameters\n if group == displacement:\n        group.attrs['simulation_name'] = 'phononic_cavity_displacement'\n else:\n        group.attrs['simulation_name'] = 'phononic_cavity_calibration'\n    group.attrs['save_vtu_files'] = False\n \nh5_file.close()\n```\n\nIn order to read the [HDF5](namespaceHDF5.html) parameters we have to use the [HDF5::File::FileAccessMode::open](classHDF5_1_1File.html#ac3dc680d4e4ca3dd7139085c5056ff5fa7cef8a734855777c2a9d0caf42666e69) flag.\n\n```\nHDF5::File data_file(\"results.h5\",\n                     HDF5::File::FileAccessMode::open,\n                     MPI_COMM_WORLD);\nauto       data = data_file.open_group(\"data\");\n```\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2019 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Daniel Garcia-Sanchez, CNRS, 2019\n */\n \n \n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/function.h>\n \n#include <deal.II/base/index_set.h>\n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/timer.h>\n#include <deal.II/base/utilities.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/generic_linear_algebra.h>\n#include <deal.II/lac/petsc_solver.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n \n#include <fstream>\n#include <iostream>\n \n#include <deal.II/base/tensor.h>\n \n \n#include <deal.II/base/hdf5.h>\n \n#include <deal.II/numerics/vector_tools.h>\n \n#include <deal.II/grid/grid_tools.h>\n#include <deal.II/grid/grid_tools_cache.h>\n \nnamespace step62\n{\n using namespace dealii;\n \n \n template <int dim>\n class RightHandSide : public Function<dim>\n  {\n public:\n    RightHandSide(HDF5::Group &data);\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component) const override;\n \n private:\n HDF5::Group data;\n \n const double     max_force_amplitude;\n const double     force_sigma_x;\n const double     force_sigma_y;\n const double     max_force_width_x;\n const double     max_force_width_y;\n const Point<dim> force_center;\n \n public:\n const unsigned int force_component = 0;\n  };\n \n template <int dim>\n class PML : public Function<dim, std::complex<double>>\n  {\n public:\n    PML(HDF5::Group &data);\n \n virtual std::complex<double>\n    value(const Point<dim> &p, const unsigned int component) const override;\n \n private:\n HDF5::Group data;\n \n const double pml_coeff;\n const int    pml_coeff_degree;\n const double dimension_x;\n const double dimension_y;\n const bool   pml_x;\n const bool   pml_y;\n const double pml_width_x;\n const double pml_width_y;\n const double a_coeff_x;\n const double a_coeff_y;\n  };\n \n \n \n template <int dim>\n class Rho : public Function<dim>\n  {\n public:\n    Rho(HDF5::Group &data);\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n \n private:\n HDF5::Group data;\n \n const double lambda;\n const double       mu;\n const double       material_a_rho;\n const double       material_b_rho;\n const double       cavity_resonance_frequency;\n const unsigned int nb_mirror_pairs;\n const double       dimension_y;\n const unsigned int grid_level;\n double             average_rho_width;\n  };\n \n \n \n template <int dim>\n class Parameters\n  {\n public:\n    Parameters(HDF5::Group &data);\n \n HDF5::Group data;\n \n const std::string        simulation_name;\n const bool               save_vtu_files;\n const double             start_frequency;\n const double             stop_frequency;\n const unsigned int       nb_frequency_points;\n const double lambda;\n const double             mu;\n const double             dimension_x;\n const double             dimension_y;\n const unsigned int       nb_probe_points;\n const unsigned int       grid_level;\n const Point<dim>         probe_start_point;\n const Point<dim>         probe_stop_point;\n const RightHandSide<dim> right_hand_side;\n const PML<dim>           pml;\n const Rho<dim>           rho;\n \n private:\n const double comparison_float_constant = 1e-12;\n  };\n \n \n \n template <int dim>\n class QuadratureCache\n  {\n public:\n    QuadratureCache(const unsigned int dofs_per_cell);\n \n private:\n unsigned int dofs_per_cell;\n \n public:\n FullMatrix<std::complex<double>>  mass_coefficient;\n FullMatrix<std::complex<double>>  stiffness_coefficient;\n    std::vector<std::complex<double>> right_hand_side;\n double                            JxW;\n  };\n \n \n \n \n template <int dim>\n SymmetricTensor<4, dim> get_stiffness_tensor(const double lambda,\n const double mu)\n  {\n SymmetricTensor<4, dim> stiffness_tensor;\n for (unsigned int i = 0; i < dim; ++i)\n for (unsigned int j = 0; j < dim; ++j)\n for (unsigned int k = 0; k < dim; ++k)\n for (unsigned int l = 0; l < dim; ++l)\n            stiffness_tensor[i][j][k][l] =\n              (((i == k) && (j == l) ? mu : 0.0) +\n               ((i == l) && (j == k) ? mu : 0.0) +\n               ((i == j) && (k == l) ? lambda : 0.0));\n return stiffness_tensor;\n  }\n \n \n \n \n template <int dim>\n class ElasticWave\n  {\n public:\n    ElasticWave(const Parameters<dim> &parameters);\n void run();\n \n private:\n void setup_system();\n void assemble_system(const double omega,\n const bool   calculate_quadrature_data);\n void solve();\n void initialize_probe_positions_vector();\n void store_frequency_step_data(const unsigned int frequency_idx);\n void output_results();\n \n void setup_quadrature_cache();\n \n void frequency_sweep();\n \n    Parameters<dim> parameters;\n \n MPI_Comm mpi_communicator;\n \n parallel::distributed::Triangulation<dim> triangulation;\n \n const QGauss<dim> quadrature_formula;\n \n    std::vector<QuadratureCache<dim>> quadrature_cache;\n \n \n const FESystem<dim> fe;\n DoFHandler<dim>     dof_handler;\n \n IndexSet locally_owned_dofs;\n IndexSet locally_relevant_dofs;\n \n AffineConstraints<std::complex<double>> constraints;\n \n LinearAlgebraPETSc::MPI::SparseMatrix system_matrix;\n LinearAlgebraPETSc::MPI::Vector       locally_relevant_solution;\n LinearAlgebraPETSc::MPI::Vector       system_rhs;\n \n \n    std::vector<double> frequency;\n \n FullMatrix<double> probe_positions;\n \n HDF5::DataSet frequency_dataset;\n HDF5::DataSet probe_positions_dataset;\n \n HDF5::DataSet displacement;\n \n \n ConditionalOStream pcout;\n TimerOutput        computing_timer;\n  };\n \n \n \n \n \n template <int dim>\n  RightHandSide<dim>::RightHandSide(HDF5::Group &data)\n    : Function<dim>(dim)\n    , data(data)\n    , max_force_amplitude(data.get_attribute<double>(\"max_force_amplitude\"))\n    , force_sigma_x(data.get_attribute<double>(\"force_sigma_x\"))\n    , force_sigma_y(data.get_attribute<double>(\"force_sigma_y\"))\n    , max_force_width_x(data.get_attribute<double>(\"max_force_width_x\"))\n    , max_force_width_y(data.get_attribute<double>(\"max_force_width_y\"))\n    , force_center(Point<dim>(data.get_attribute<double>(\"force_x_pos\"),\n                              data.get_attribute<double>(\"force_y_pos\")))\n  {}\n \n template <int dim>\n double RightHandSide<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n if (component == force_component)\n      {\n if (std::abs(p[0] - force_center[0]) < max_force_width_x / 2 &&\n std::abs(p[1] - force_center[1]) < max_force_width_y / 2)\n          {\n return max_force_amplitude *\n std::exp(\n                     -(Utilities::fixed_power<2>(p[0] - force_center[0]) /\n                         (2 * Utilities::fixed_power<2>(force_sigma_x)) +\n Utilities::fixed_power<2>(p[1] - force_center[1]) /\n                         (2 * Utilities::fixed_power<2>(force_sigma_y))));\n          }\n else\n          {\n return 0;\n          }\n      }\n else\n      {\n return 0;\n      }\n  }\n \n \n \n \n template <int dim>\n  PML<dim>::PML(HDF5::Group &data)\n    : Function<dim, std::complex<double>>(dim)\n    , data(data)\n    , pml_coeff(data.get_attribute<double>(\"pml_coeff\"))\n    , pml_coeff_degree(data.get_attribute<int>(\"pml_coeff_degree\"))\n    , dimension_x(data.get_attribute<double>(\"dimension_x\"))\n    , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n    , pml_x(data.get_attribute<bool>(\"pml_x\"))\n    , pml_y(data.get_attribute<bool>(\"pml_y\"))\n    , pml_width_x(data.get_attribute<double>(\"pml_width_x\"))\n    , pml_width_y(data.get_attribute<double>(\"pml_width_y\"))\n    , a_coeff_x(pml_coeff / std::pow(pml_width_x, pml_coeff_degree))\n    , a_coeff_y(pml_coeff / std::pow(pml_width_y, pml_coeff_degree))\n  {}\n \n \n \n template <int dim>\n  std::complex<double> PML<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n double calculated_pml_x_coeff = 0;\n double calculated_pml_y_coeff = 0;\n \n if ((component == 0) && pml_x)\n      {\n const double pml_x_start_position = dimension_x / 2 - pml_width_x;\n if (std::abs(p[0]) > pml_x_start_position)\n          {\n const double x_prime = std::abs(p[0]) - pml_x_start_position;\n            calculated_pml_x_coeff =\n              a_coeff_x * std::pow(x_prime, pml_coeff_degree);\n          }\n      }\n \n if ((component == 1) && pml_y)\n      {\n const double pml_y_start_position = dimension_y / 2 - pml_width_y;\n if (std::abs(p[1]) > pml_y_start_position)\n          {\n const double y_prime = std::abs(p[1]) - pml_y_start_position;\n            calculated_pml_y_coeff =\n              a_coeff_y * std::pow(y_prime, pml_coeff_degree);\n          }\n      }\n \n return 1. + std::max(calculated_pml_x_coeff, calculated_pml_y_coeff) *\n                  std::complex<double>(0., 1.);\n  }\n \n \n \n \n template <int dim>\n  Rho<dim>::Rho(HDF5::Group &data)\n    : Function<dim>(1)\n    , data(data)\n    , lambda(data.get_attribute<double>(\"lambda\"))\n    , mu(data.get_attribute<double>(\"mu\"))\n    , material_a_rho(data.get_attribute<double>(\"material_a_rho\"))\n    , material_b_rho(data.get_attribute<double>(\"material_b_rho\"))\n    , cavity_resonance_frequency(\n        data.get_attribute<double>(\"cavity_resonance_frequency\"))\n    , nb_mirror_pairs(data.get_attribute<int>(\"nb_mirror_pairs\"))\n    , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n    , grid_level(data.get_attribute<int>(\"grid_level\"))\n  {\n    average_rho_width = dimension_y / (std::pow(2.0, grid_level));\n    data.set_attribute(\"average_rho_width\", average_rho_width);\n  }\n \n \n \n template <int dim>\n double Rho<dim>::value(const Point<dim> &p,\n const unsigned int /*component*/) const\n {\n double elastic_constant;\n if (dim == 2)\n      {\n        elastic_constant = 4 * mu * (lambda + mu) / (lambda + 2 * mu);\n      }\n else if (dim == 3)\n      {\n        elastic_constant = mu * (3 * lambda + 2 * mu) / (lambda + mu);\n      }\n else\n DEAL_II_NOT_IMPLEMENTED();\n \n const double material_a_speed_of_sound =\n std::sqrt(elastic_constant / material_a_rho);\n const double material_a_wavelength =\n      material_a_speed_of_sound / cavity_resonance_frequency;\n const double material_b_speed_of_sound =\n std::sqrt(elastic_constant / material_b_rho);\n const double material_b_wavelength =\n      material_b_speed_of_sound / cavity_resonance_frequency;\n \n for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n      {\n const double layer_transition_center =\n          material_a_wavelength / 2 +\n          idx * (material_b_wavelength / 4 + material_a_wavelength / 4);\n if (std::abs(p[0]) >=\n              (layer_transition_center - average_rho_width / 2) &&\n std::abs(p[0]) <= (layer_transition_center + average_rho_width / 2))\n          {\n const double coefficient =\n              (std::abs(p[0]) -\n               (layer_transition_center - average_rho_width / 2)) /\n              average_rho_width;\n return (1 - coefficient) * material_a_rho +\n                   coefficient * material_b_rho;\n          }\n      }\n \n for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n      {\n const double layer_transition_center =\n          material_a_wavelength / 2 +\n          idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n          material_b_wavelength / 4;\n if (std::abs(p[0]) >=\n              (layer_transition_center - average_rho_width / 2) &&\n std::abs(p[0]) <= (layer_transition_center + average_rho_width / 2))\n          {\n const double coefficient =\n              (std::abs(p[0]) -\n               (layer_transition_center - average_rho_width / 2)) /\n              average_rho_width;\n return (1 - coefficient) * material_b_rho +\n                   coefficient * material_a_rho;\n          }\n      }\n \n if (std::abs(p[0]) <= material_a_wavelength / 2)\n      {\n return material_a_rho;\n      }\n \n for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n      {\n const double layer_center =\n          material_a_wavelength / 2 +\n          idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n          material_b_wavelength / 4 + material_a_wavelength / 8;\n const double layer_width = material_a_wavelength / 4;\n if (std::abs(p[0]) >= (layer_center - layer_width / 2) &&\n std::abs(p[0]) <= (layer_center + layer_width / 2))\n          {\n return material_a_rho;\n          }\n      }\n \n for (unsigned int idx = 0; idx < nb_mirror_pairs; ++idx)\n      {\n const double layer_center =\n          material_a_wavelength / 2 +\n          idx * (material_b_wavelength / 4 + material_a_wavelength / 4) +\n          material_b_wavelength / 8;\n const double layer_width = material_b_wavelength / 4;\n if (std::abs(p[0]) >= (layer_center - layer_width / 2) &&\n std::abs(p[0]) <= (layer_center + layer_width / 2))\n          {\n return material_b_rho;\n          }\n      }\n \n return material_a_rho;\n  }\n \n \n \n \n template <int dim>\n  Parameters<dim>::Parameters(HDF5::Group &data)\n    : data(data)\n    , simulation_name(data.get_attribute<std::string>(\"simulation_name\"))\n    , save_vtu_files(data.get_attribute<bool>(\"save_vtu_files\"))\n    , start_frequency(data.get_attribute<double>(\"start_frequency\"))\n    , stop_frequency(data.get_attribute<double>(\"stop_frequency\"))\n    , nb_frequency_points(data.get_attribute<int>(\"nb_frequency_points\"))\n    , lambda(data.get_attribute<double>(\"lambda\"))\n    , mu(data.get_attribute<double>(\"mu\"))\n    , dimension_x(data.get_attribute<double>(\"dimension_x\"))\n    , dimension_y(data.get_attribute<double>(\"dimension_y\"))\n    , nb_probe_points(data.get_attribute<int>(\"nb_probe_points\"))\n    , grid_level(data.get_attribute<int>(\"grid_level\"))\n    , probe_start_point(data.get_attribute<double>(\"probe_pos_x\"),\n                        data.get_attribute<double>(\"probe_pos_y\") -\n                          data.get_attribute<double>(\"probe_width_y\") / 2)\n    , probe_stop_point(data.get_attribute<double>(\"probe_pos_x\"),\n                       data.get_attribute<double>(\"probe_pos_y\") +\n                         data.get_attribute<double>(\"probe_width_y\") / 2)\n    , right_hand_side(data)\n    , pml(data)\n    , rho(data)\n  {}\n \n \n \n \n template <int dim>\n  QuadratureCache<dim>::QuadratureCache(const unsigned int dofs_per_cell)\n    : dofs_per_cell(dofs_per_cell)\n    , mass_coefficient(dofs_per_cell, dofs_per_cell)\n    , stiffness_coefficient(dofs_per_cell, dofs_per_cell)\n    , right_hand_side(dofs_per_cell)\n  {}\n \n \n \n \n \n template <int dim>\n  ElasticWave<dim>::ElasticWave(const Parameters<dim> &parameters)\n    : parameters(parameters)\n    , mpi_communicator(MPI_COMM_WORLD)\n    , triangulation(mpi_communicator,\n                    typename Triangulation<dim>::MeshSmoothing(\n Triangulation<dim>::smoothing_on_refinement |\n Triangulation<dim>::smoothing_on_coarsening))\n    , quadrature_formula(2)\n    , fe(FE_Q<dim>(1) ^ dim)\n    , dof_handler(triangulation)\n    , frequency(parameters.nb_frequency_points)\n    , probe_positions(parameters.nb_probe_points, dim)\n    , frequency_dataset(parameters.data.template create_dataset<double>(\n \"frequency\",\n std::vector<hsize_t>{parameters.nb_frequency_points}))\n    , probe_positions_dataset(parameters.data.template create_dataset<double>(\n \"position\",\n        std::vector<hsize_t>{parameters.nb_probe_points, dim}))\n    , displacement(\n        parameters.data.template create_dataset<std::complex<double>>(\n \"displacement\",\n          std::vector<hsize_t>{parameters.nb_probe_points,\n                               parameters.nb_frequency_points}))\n    , pcout(std::cout,\n            (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n    , computing_timer(mpi_communicator,\n                      pcout,\n TimerOutput::never,\n TimerOutput::wall_times)\n  {}\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::setup_system()\n  {\n TimerOutput::Scope t(computing_timer, \"setup\");\n \n    dof_handler.distribute_dofs(fe);\n \n    locally_owned_dofs = dof_handler.locally_owned_dofs();\n    locally_relevant_dofs =\n DoFTools::extract_locally_relevant_dofs(dof_handler);\n \n    locally_relevant_solution.reinit(locally_owned_dofs,\n                                     locally_relevant_dofs,\n                                     mpi_communicator);\n \n    system_rhs.reinit(locally_owned_dofs, mpi_communicator);\n \n    constraints.clear();\n    constraints.reinit(locally_relevant_dofs);\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n \n    constraints.close();\n \n DynamicSparsityPattern dsp(locally_relevant_dofs);\n \n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n SparsityTools::distribute_sparsity_pattern(dsp,\n                                               locally_owned_dofs,\n                                               mpi_communicator,\n                                               locally_relevant_dofs);\n \n    system_matrix.reinit(locally_owned_dofs,\n                         locally_owned_dofs,\n                         dsp,\n                         mpi_communicator);\n  }\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::assemble_system(const double omega,\n const bool   calculate_quadrature_data)\n  {\n TimerOutput::Scope t(computing_timer, \"assembly\");\n \n FEValues<dim>      fe_values(fe,\n                            quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points | update_JxW_values);\n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<std::complex<double>> cell_matrix(dofs_per_cell, dofs_per_cell);\n Vector<std::complex<double>>     cell_rhs(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n    std::vector<Vector<double>> rhs_values(n_q_points, Vector<double>(dim));\n    std::vector<double>         rho_values(n_q_points);\n    std::vector<Vector<std::complex<double>>> pml_values(\n      n_q_points, Vector<std::complex<double>>(dim));\n \n const SymmetricTensor<4, dim> stiffness_tensor =\n      get_stiffness_tensor<dim>(parameters.lambda, parameters.mu);\n \n const FEValuesExtractors::Vector displacement(0);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n cell_matrix = 0;\n          cell_rhs    = 0;\n \n if (calculate_quadrature_data)\n            {\n              fe_values.reinit(cell);\n \n              parameters.right_hand_side.vector_value_list(\n                fe_values.get_quadrature_points(), rhs_values);\n              parameters.rho.value_list(fe_values.get_quadrature_points(),\n                                        rho_values);\n              parameters.pml.vector_value_list(\n                fe_values.get_quadrature_points(), pml_values);\n            }\n \n          QuadratureCache<dim> *local_quadrature_points_data =\n reinterpret_cast<QuadratureCache<dim> *>(cell->user_pointer());\n Assert(local_quadrature_points_data >= &quadrature_cache.front(),\n                 ExcInternalError());\n Assert(local_quadrature_points_data <= &quadrature_cache.back(),\n                 ExcInternalError());\n for (unsigned int q = 0; q < n_q_points; ++q)\n            {\n              QuadratureCache<dim> &quadrature_data =\n                local_quadrature_points_data[q];\n \n Tensor<1, dim>                       force;\n Tensor<1, dim, std::complex<double>> s;\n              std::complex<double>                 xi(1, 0);\n \n if (calculate_quadrature_data)\n                {\n                  quadrature_data.JxW = fe_values.JxW(q);\n \n for (unsigned int component = 0; component < dim; ++component)\n                    {\n                      force[component] = rhs_values[q][component];\n                      s[component]     = pml_values[q][component];\n                      xi *= s[component];\n                    }\n \n Tensor<4, dim, std::complex<double>> alpha;\n Tensor<4, dim, std::complex<double>> beta;\n for (unsigned int m = 0; m < dim; ++m)\n for (unsigned int n = 0; n < dim; ++n)\n for (unsigned int k = 0; k < dim; ++k)\n for (unsigned int l = 0; l < dim; ++l)\n                          {\n                            alpha[m][n][k][l] = xi *\n                                                stiffness_tensor[m][n][k][l] /\n                                                (2.0 * s[n] * s[k]);\n                            beta[m][n][k][l] = xi *\n                                               stiffness_tensor[m][n][k][l] /\n                                               (2.0 * s[n] * s[l]);\n                          }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                    {\n const Tensor<1, dim> phi_i =\n                        fe_values[displacement].value(i, q);\n const Tensor<2, dim> grad_phi_i =\n                        fe_values[displacement].gradient(i, q);\n \n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                        {\n const Tensor<1, dim> phi_j =\n                            fe_values[displacement].value(j, q);\n const Tensor<2, dim> grad_phi_j =\n                            fe_values[displacement].gradient(j, q);\n \n                          quadrature_data.mass_coefficient[i][j] =\n                            rho_values[q] * xi * phi_i * phi_j;\n \n                          std::complex<double> stiffness_coefficient = 0;\n for (unsigned int m = 0; m < dim; ++m)\n for (unsigned int n = 0; n < dim; ++n)\n for (unsigned int k = 0; k < dim; ++k)\n for (unsigned int l = 0; l < dim; ++l)\n                                  {\n                                    stiffness_coefficient +=\n                                      grad_phi_i[m][n] *\n                                      (alpha[m][n][k][l] * grad_phi_j[l][k] +\n                                       beta[m][n][k][l] * grad_phi_j[k][l]);\n                                  }\n \n                          quadrature_data.stiffness_coefficient[i][j] =\n                            stiffness_coefficient;\n                        }\n \n                      quadrature_data.right_hand_side[i] =\n                        phi_i * force * fe_values.JxW(q);\n                    }\n                }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                    {\n                      std::complex<double> matrix_sum = 0;\n                      matrix_sum += -Utilities::fixed_power<2>(omega) *\n                                    quadrature_data.mass_coefficient[i][j];\n                      matrix_sum += quadrature_data.stiffness_coefficient[i][j];\n cell_matrix(i, j) += matrix_sum * quadrature_data.JxW;\n                    }\n                  cell_rhs(i) += quadrature_data.right_hand_side[i];\n                }\n            }\n          cell->get_dof_indices(local_dof_indices);\n          constraints.distribute_local_to_global(cell_matrix,\n                                                 cell_rhs,\n                                                 local_dof_indices,\n                                                 system_matrix,\n                                                 system_rhs);\n        }\n \n    system_matrix.compress(VectorOperation::add);\n    system_rhs.compress(VectorOperation::add);\n  }\n \n \n template <int dim>\n void ElasticWave<dim>::solve()\n  {\n TimerOutput::Scope              t(computing_timer, \"solve\");\n LinearAlgebraPETSc::MPI::Vector completely_distributed_solution(\n      locally_owned_dofs, mpi_communicator);\n \n SolverControl                    solver_control;\n PETScWrappers::SparseDirectMUMPS solver(solver_control, mpi_communicator);\n    solver.solve(system_matrix, completely_distributed_solution, system_rhs);\n \n    pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n          << std::endl;\n    constraints.distribute(completely_distributed_solution);\n    locally_relevant_solution = completely_distributed_solution;\n  }\n \n \n template <int dim>\n void ElasticWave<dim>::initialize_probe_positions_vector()\n  {\n for (unsigned int position_idx = 0;\n         position_idx < parameters.nb_probe_points;\n         ++position_idx)\n      {\n const Point<dim> p =\n          (position_idx / ((double)(parameters.nb_probe_points - 1))) *\n            (parameters.probe_stop_point + (-parameters.probe_start_point)) +\n          parameters.probe_start_point;\n        probe_positions[position_idx][0] = p[0];\n        probe_positions[position_idx][1] = p[1];\n if (dim == 3)\n          {\n            probe_positions[position_idx][2] = p[2];\n          }\n      }\n  }\n \n \n template <int dim>\n void\n  ElasticWave<dim>::store_frequency_step_data(const unsigned int frequency_idx)\n  {\n TimerOutput::Scope t(computing_timer, \"store_frequency_step_data\");\n \n const unsigned int probe_displacement_component = 0;\n \n    std::vector<hsize_t>              coordinates;\n    std::vector<std::complex<double>> displacement_data;\n \n const auto &mapping = get_default_linear_mapping(triangulation);\n GridTools::Cache<dim, dim> cache(triangulation, mapping);\n typename Triangulation<dim, dim>::active_cell_iterator cell_hint{};\n    std::vector<bool>                                      marked_vertices = {};\n const double                                           tolerance = 1.e-10;\n \n for (unsigned int position_idx = 0;\n         position_idx < parameters.nb_probe_points;\n         ++position_idx)\n      {\n Point<dim> point;\n for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n          {\n point[dim_idx] = probe_positions[position_idx][dim_idx];\n          }\n bool point_in_locally_owned_cell = false;\n        {\n auto cell_and_ref_point = GridTools::find_active_cell_around_point(\n            cache, point, cell_hint, marked_vertices, tolerance);\n if (cell_and_ref_point.first.state() == IteratorState::valid)\n            {\n              cell_hint = cell_and_ref_point.first;\n              point_in_locally_owned_cell =\n                cell_and_ref_point.first->is_locally_owned();\n            }\n        }\n if (point_in_locally_owned_cell)\n          {\n Vector<std::complex<double>> tmp_vector(dim);\n VectorTools::point_value(dof_handler,\n                                     locally_relevant_solution,\n                                     point,\n                                     tmp_vector);\n            coordinates.emplace_back(position_idx);\n            coordinates.emplace_back(frequency_idx);\n            displacement_data.emplace_back(\n              tmp_vector(probe_displacement_component));\n          }\n      }\n \n if (coordinates.size() > 0)\n      {\n        displacement.write_selection(displacement_data, coordinates);\n      }\n else\n      {\n        displacement.write_none<std::complex<double>>();\n      }\n \n if (parameters.save_vtu_files)\n      {\n        std::vector<std::string> solution_names(dim, \"displacement\");\n        std::vector<DataComponentInterpretation::DataComponentInterpretation>\n          interpretation(\n            dim, DataComponentInterpretation::component_is_part_of_vector);\n \n DataOut<dim> data_out;\n        data_out.add_data_vector(dof_handler,\n                                 locally_relevant_solution,\n                                 solution_names,\n                                 interpretation);\n Vector<float> subdomain(triangulation.n_active_cells());\n for (unsigned int i = 0; i < subdomain.size(); ++i)\n          subdomain(i) = triangulation.locally_owned_subdomain();\n        data_out.add_data_vector(subdomain, \"subdomain\");\n \n        std::vector<Vector<double>> force(\n          dim, Vector<double>(triangulation.n_active_cells()));\n        std::vector<Vector<double>> pml(\n          dim, Vector<double>(triangulation.n_active_cells()));\n Vector<double> rho(triangulation.n_active_cells());\n \n for (auto &cell : triangulation.active_cell_iterators())\n          {\n if (cell->is_locally_owned())\n              {\n for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n                  {\n                    force[dim_idx](cell->active_cell_index()) =\n                      parameters.right_hand_side.value(cell->center(), dim_idx);\n                    pml[dim_idx](cell->active_cell_index()) =\n                      parameters.pml.value(cell->center(), dim_idx).imag();\n                  }\n                rho(cell->active_cell_index()) =\n                  parameters.rho.value(cell->center());\n              }\n else\n              {\n for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n                  {\n                    force[dim_idx](cell->active_cell_index()) = -1e+20;\n                    pml[dim_idx](cell->active_cell_index())   = -1e+20;\n                  }\n                rho(cell->active_cell_index()) = -1e+20;\n              }\n          }\n \n for (unsigned int dim_idx = 0; dim_idx < dim; ++dim_idx)\n          {\n            data_out.add_data_vector(force[dim_idx],\n \"force_\" + std::to_string(dim_idx));\n            data_out.add_data_vector(pml[dim_idx],\n \"pml_\" + std::to_string(dim_idx));\n          }\n        data_out.add_data_vector(rho, \"rho\");\n \n        data_out.build_patches();\n \n        std::stringstream  frequency_idx_stream;\n const unsigned int nb_number_positions =\n          ((unsigned int)std::log10(parameters.nb_frequency_points)) + 1;\n        frequency_idx_stream << std::setw(nb_number_positions)\n                             << std::setfill('0') << frequency_idx;\n const std::string filename = (parameters.simulation_name + \"_\" +\n                                      frequency_idx_stream.str() + \".vtu\");\n        data_out.write_vtu_in_parallel(filename, mpi_communicator);\n      }\n  }\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::output_results()\n  {\n if (Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n      {\n        frequency_dataset.write(frequency);\n        probe_positions_dataset.write(probe_positions);\n      }\n else\n      {\n        frequency_dataset.write_none<double>();\n        probe_positions_dataset.write_none<double>();\n      }\n  }\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::setup_quadrature_cache()\n  {\n triangulation.clear_user_data();\n \n    {\n      std::vector<QuadratureCache<dim>> tmp;\n      quadrature_cache.swap(tmp);\n    }\n \n    quadrature_cache.resize(triangulation.n_locally_owned_active_cells() *\n                              quadrature_formula.size(),\n                            QuadratureCache<dim>(fe.n_dofs_per_cell()));\n unsigned int cache_index = 0;\n for (const auto &cell : triangulation.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n          cell->set_user_pointer(&quadrature_cache[cache_index]);\n          cache_index += quadrature_formula.size();\n        }\n Assert(cache_index == quadrature_cache.size(), ExcInternalError());\n  }\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::frequency_sweep()\n  {\n for (unsigned int frequency_idx = 0;\n         frequency_idx < parameters.nb_frequency_points;\n         ++frequency_idx)\n      {\n        pcout << parameters.simulation_name + \" frequency idx: \"\n              << frequency_idx << '/' << parameters.nb_frequency_points - 1\n              << std::endl;\n \n \n \n        setup_system();\n if (frequency_idx == 0)\n          {\n            pcout << \"   Number of active cells :       \"\n                  << triangulation.n_active_cells() << std::endl;\n            pcout << \"   Number of degrees of freedom : \"\n                  << dof_handler.n_dofs() << std::endl;\n          }\n \n if (frequency_idx == 0)\n          {\n            parameters.data.set_attribute(\"active_cells\",\n triangulation.n_active_cells());\n            parameters.data.set_attribute(\"degrees_of_freedom\",\n                                          dof_handler.n_dofs());\n          }\n \n const double current_loop_frequency =\n          (parameters.start_frequency +\n           frequency_idx *\n             (parameters.stop_frequency - parameters.start_frequency) /\n             (parameters.nb_frequency_points - 1));\n const double current_loop_omega =\n          2 * numbers::PI * current_loop_frequency;\n \n        assemble_system(current_loop_omega,\n                        (frequency_idx == 0) ? true : false);\n        solve();\n \n        frequency[frequency_idx] = current_loop_frequency;\n        store_frequency_step_data(frequency_idx);\n \n        computing_timer.print_summary();\n        computing_timer.reset();\n        pcout << std::endl;\n      }\n  }\n \n \n \n \n template <int dim>\n void ElasticWave<dim>::run()\n  {\n#ifdef DEBUG\n    pcout << \"Debug mode\" << std::endl;\n#else\n    pcout << \"Release mode\" << std::endl;\n#endif\n \n    {\n Point<dim> p1;\n      p1(0) = -parameters.dimension_x / 2;\n      p1(1) = -parameters.dimension_y / 2;\n if (dim == 3)\n        {\n          p1(2) = -parameters.dimension_y / 2;\n        }\n Point<dim> p2;\n      p2(0) = parameters.dimension_x / 2;\n      p2(1) = parameters.dimension_y / 2;\n if (dim == 3)\n        {\n          p2(2) = parameters.dimension_y / 2;\n        }\n      std::vector<unsigned int> divisions(dim);\n      divisions[0] = int(parameters.dimension_x / parameters.dimension_y);\n      divisions[1] = 1;\n if (dim == 3)\n        {\n          divisions[2] = 1;\n        }\n GridGenerator::subdivided_hyper_rectangle(triangulation,\n                                                divisions,\n                                                p1,\n                                                p2);\n    }\n \n triangulation.refine_global(parameters.grid_level);\n \n    setup_quadrature_cache();\n \n    initialize_probe_positions_vector();\n \n    frequency_sweep();\n \n    output_results();\n  }\n} // namespace step62\n \n \n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n using namespace dealii;\n const unsigned int dim = 2;\n \n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n \n HDF5::File data_file(\"results.h5\",\n HDF5::File::FileAccessMode::create,\n                           MPI_COMM_WORLD);\n auto       data = data_file.create_group(\"data\");\n \n const std::array<std::string, 2> group_names{\n        {\"displacement\", \"calibration\"}};\n for (const std::string &group_name : group_names)\n        {\n \n auto group = data.create_group(group_name);\n \n group.set_attribute<double>(\"dimension_x\", 2e-5);\n group.set_attribute<double>(\"dimension_y\", 2e-8);\n group.set_attribute<double>(\"probe_pos_x\", 8e-6);\n group.set_attribute<double>(\"probe_pos_y\", 0);\n group.set_attribute<double>(\"probe_width_y\", 2e-08);\n group.set_attribute<unsigned int>(\"nb_probe_points\", 5);\n group.set_attribute<unsigned int>(\"grid_level\", 1);\n group.set_attribute<double>(\"cavity_resonance_frequency\", 20e9);\n group.set_attribute<unsigned int>(\"nb_mirror_pairs\", 15);\n \n group.set_attribute<double>(\"poissons_ratio\", 0.27);\n group.set_attribute<double>(\"youngs_modulus\", 270000000000.0);\n group.set_attribute<double>(\"material_a_rho\", 3200);\n \n if (group_name == \"displacement\")\n group.set_attribute<double>(\"material_b_rho\", 2000);\n else\n group.set_attribute<double>(\"material_b_rho\", 3200);\n \n group.set_attribute(\n \"lambda\",\n group.get_attribute<double>(\"youngs_modulus\") *\n group.get_attribute<double>(\"poissons_ratio\") /\n              ((1 + group.get_attribute<double>(\"poissons_ratio\")) *\n               (1 - 2 * group.get_attribute<double>(\"poissons_ratio\"))));\n group.set_attribute(\"mu\",\n group.get_attribute<double>(\"youngs_modulus\") /\n                                (2 * (1 + group.get_attribute<double>(\n \"poissons_ratio\"))));\n \n group.set_attribute<double>(\"max_force_amplitude\", 1e26);\n group.set_attribute<double>(\"force_sigma_x\", 1e-7);\n group.set_attribute<double>(\"force_sigma_y\", 1);\n group.set_attribute<double>(\"max_force_width_x\", 3e-7);\n group.set_attribute<double>(\"max_force_width_y\", 2e-8);\n group.set_attribute<double>(\"force_x_pos\", -8e-6);\n group.set_attribute<double>(\"force_y_pos\", 0);\n \n group.set_attribute<bool>(\"pml_x\", true);\n group.set_attribute<bool>(\"pml_y\", false);\n group.set_attribute<double>(\"pml_width_x\", 1.8e-6);\n group.set_attribute<double>(\"pml_width_y\", 5e-7);\n group.set_attribute<double>(\"pml_coeff\", 1.6);\n group.set_attribute<unsigned int>(\"pml_coeff_degree\", 2);\n \n group.set_attribute<double>(\"center_frequency\", 20e9);\n group.set_attribute<double>(\"frequency_range\", 0.5e9);\n group.set_attribute<double>(\n \"start_frequency\",\n group.get_attribute<double>(\"center_frequency\") -\n group.get_attribute<double>(\"frequency_range\") / 2);\n group.set_attribute<double>(\n \"stop_frequency\",\n group.get_attribute<double>(\"center_frequency\") +\n group.get_attribute<double>(\"frequency_range\") / 2);\n group.set_attribute<unsigned int>(\"nb_frequency_points\", 400);\n \n if (group_name == std::string(\"displacement\"))\n group.set_attribute<std::string>(\n \"simulation_name\", std::string(\"phononic_cavity_displacement\"));\n else\n group.set_attribute<std::string>(\n \"simulation_name\", std::string(\"phononic_cavity_calibration\"));\n \n group.set_attribute<bool>(\"save_vtu_files\", false);\n        }\n \n      {\n auto                    displacement = data.open_group(\"displacement\");\n        step62::Parameters<dim> parameters(displacement);\n \n        step62::ElasticWave<dim> elastic_problem(parameters);\n        elastic_problem.run();\n      }\n \n      {\n auto                    calibration = data.open_group(\"calibration\");\n        step62::Parameters<dim> parameters(calibration);\n \n        step62::ElasticWave<dim> elastic_problem(parameters);\n        elastic_problem.run();\n      }\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_63.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nBlock smoothers for geometric multigrid. A scalar convection diffusion equation is solved with different additive or multiplicative multigrid smoothers.\nTutorial content :\nThis tutorial depends on [step-16](step_16.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_63-Intro)    * [Equation](#step_63-Equation)      + [Streamline diffusion](#step_63-Streamlinediffusion)* [Smoothers](#step_63-Smoothers)* [Test problem](#step_63-Testproblem)- [The commented program](#step_63-CommProg)      * [Include files](#step_63-Includefiles)* [MeshWorker data](#step_63-MeshWorkerdata)* [Problem parameters](#step_63-Problemparameters)* [Cell permutations](#step_63-Cellpermutations)* [Right-hand side and boundary values](#step_63-Righthandsideandboundaryvalues)* [Streamline diffusion implementation](#step_63-Streamlinediffusionimplementation)* [`AdvectionProblem` class](#step_63-codeAdvectionProblemcodeclass)                    + [`AdvectionProblem::setup_system()`](#step_63-codeAdvectionProblemsetup_systemcode)+ [`AdvectionProblem::assemble_cell()`](#step_63-codeAdvectionProblemassemble_cellcode)+ [`AdvectionProblem::assemble_system_and_multigrid()`](#step_63-codeAdvectionProblemassemble_system_and_multigridcode)+ [`AdvectionProblem::setup_smoother()`](#step_63-codeAdvectionProblemsetup_smoothercode)+ [`AdvectionProblem::solve()`](#step_63-codeAdvectionProblemsolvecode)+ [`AdvectionProblem::output_results()`](#step_63-codeAdvectionProblemoutput_resultscode)+ [`AdvectionProblem::run()`](#step_63-codeAdvectionProblemruncode)* [The `main` function](#step_63-Thecodemaincodefunction) | 1. [Results](#step_63-Results)    * [GMRES Iteration Numbers](#step_63-GMRESIterationNumbers)       + [DoF/Cell Renumbering](#step_63-DoFCellRenumbering) + [Point vs. block smoothers](#step_63-Pointvsblocksmoothers)* [Cost](#step_63-Cost) * [Additional points](#step_63-Additionalpoints) * [Possibilities for extensions](#step_63-Possibilitiesforextensions)             + [Constant iterations for Q5](#step_63-ConstantiterationsforQsub5sub) + [Effectiveness of renumbering for changing epsilon](#step_63-Effectivenessofrenumberingforchangingepsilon) + [Mesh adaptivity](#step_63-Meshadaptivity)- [The plain program](#step_63-PlainProg) |\n\n*This program was contributed by Thomas C. Clevenger and Timo Heister.*\n\n*The creation of this tutorial was partially supported by NSF Award DMS-1522191, DMS-1901529, OAC-1835452, by the Computational Infrastructure in Geodynamics initiative (CIG), through the NSF under Award EAR-0949446 and EAR-1550901 and The University of California - Davis.*\n\nNote\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.3382899](https://zenodo.org/badge/DOI/10.5281/zenodo.3382899.svg)](https://doi.org/10.5281/zenodo.3382899)\n\nIntroduction\n============\n\nThis program solves an advection-diffusion problem using a geometric multigrid (GMG) preconditioner. The basics of this preconditioner are discussed in [step-16](step_16.html); here we discuss the necessary changes needed for a non-symmetric PDE. Additionally, we introduce the idea of block smoothing (as compared to point smoothing in [step-16](step_16.html)), and examine the effects of DoF renumbering for additive and multiplicative smoothers.\n\n### Equation\n\nThe advection-diffusion equation is given by\n\n\\begin{align\\*}\n-\\varepsilon \\Delta u + \\boldsymbol{\\beta}\\cdot \\nabla u & = f &\n\\text{ in } \\Omega\\\\\nu &= g & \\text{ on } \\partial\\Omega\n\\end{align\\*}\n\nwhere \\(\\varepsilon>0\\), \\(\\boldsymbol{\\beta}\\) is the *advection direction*, and \\(f\\) is a source. A few notes:\n\n1. If \\(\\boldsymbol{\\beta}=\\boldsymbol{0}\\), this is the Laplace equation solved in [step-16](step_16.html) (and many other places).\n2. If \\(\\varepsilon=0\\) then this is the stationary advection equation solved in [step-9](step_9.html).\n3. One can define a dimensionless number for this problem, called the *Peclet number*: \\(\\mathcal{P} \\dealcoloneq \\frac{\\|\\boldsymbol{\\beta}\\|\n   L}{\\varepsilon}\\), where \\(L\\) is the length scale of the domain. It characterizes the kind of equation we are considering: If \\(\\mathcal{P}>1\\), we say the problem is *advection-dominated*, else if \\(\\mathcal{P}<1\\) we will say the problem is *diffusion-dominated*.\n\nFor the discussion in this tutorial we will be concerned with advection-dominated flow. This is the complicated case: We know that for diffusion-dominated problems, the standard Galerkin method works just fine, and we also know that simple multigrid methods such as those defined in [step-16](step_16.html) are very efficient. On the other hand, for advection-dominated problems, the standard Galerkin approach leads to oscillatory and unstable discretizations, and simple solvers are often not very efficient. This tutorial program is therefore intended to address both of these issues.\n\n#### Streamline diffusion\n\nUsing the standard Galerkin finite element method, for suitable test functions \\(v\\_h\\), a discrete weak form of the PDE would read\n\n\\begin{align\\*}\na(u\\_h,v\\_h) = F(v\\_h)\n\\end{align\\*}\n\nwhere\n\n\\begin{align\\*}\na(u\\_h,v\\_h) &= (\\varepsilon \\nabla v\\_h,\\, \\nabla u\\_h) +\n(v\\_h,\\,\\boldsymbol{\\beta}\\cdot \\nabla u\\_h),\\\\\nF(v\\_h) &= (v\\_h,\\,f).\n\\end{align\\*}\n\nUnfortunately, one typically gets oscillatory solutions with this approach. Indeed, the following error estimate can be shown for this formulation:\n\n\\begin{align\\*}\n\\|\\nabla (u-u\\_h)\\| \\leq (1+\\mathcal{P}) \\inf\\_{v\\_h} \\|\\nabla (u-v\\_h)\\|.\n\\end{align\\*}\n\nThe infimum on the right can be estimated as follows if the exact solution is sufficiently smooth:\n\n\\begin{align\\*}\n\\inf\\_{v\\_h} \\|\\nabla (u-v\\_h)\\|.\n\\le\n\\|\\nabla (u-I\\_h u)\\|\n\\le\nh^k\nC\n\\|\\nabla^k u)\\|\n\\end{align\\*}\n\nwhere \\(k\\) is the polynomial degree of the finite elements used. As a consequence, we obtain the estimate\n\n\\begin{align\\*}\n\\|\\nabla (u-u\\_h)\\|\n\\leq (1+\\mathcal{P}) C h^k\n\\|\\nabla^k u)\\|.\n\\end{align\\*}\n\nIn other words, the numerical solution will converge. On the other hand, given the definition of \\(\\mathcal{P}\\) above, we have to expect poor numerical solutions with a large error when \\(\\varepsilon \\ll\n\\|\\boldsymbol{\\beta}\\| L\\), i.e., if the problem has only a small amount of diffusion.\n\nTo combat this, we will consider the new weak form\n\n\\begin{align\\*}\na(u\\_h,\\,v\\_h) + \\sum\\_K (-\\varepsilon \\Delta u\\_h +\n\\boldsymbol{\\beta}\\cdot \\nabla u\\_h-f,\\,\\delta\\_K\n\\boldsymbol{\\beta}\\cdot \\nabla v\\_h)\\_K = F(v\\_h)\n\\end{align\\*}\n\nwhere the sum is done over all cells \\(K\\) with the inner product taken for each cell, and \\(\\delta\\_K\\) is a cell-wise constant stabilization parameter defined in [[122]](citelist.html#CITEREF_john2006discontinuity).\n\nEssentially, adding in the discrete strong form residual enhances the coercivity of the bilinear form \\(a(\\cdot,\\cdot)\\) which increases the stability of the discrete solution. This method is commonly referred to as *streamline diffusion* or *SUPG* (streamline upwind/Petrov-Galerkin).\n\n### Smoothers\n\nOne of the goals of this tutorial is to expand from using a simple (point-wise) Gauss-Seidel (SOR) smoother that is used in [step-16](step_16.html) (class [PreconditionSOR](classPreconditionSOR.html)) on each level of the multigrid hierarchy. The term \"point-wise\" is traditionally used in solvers to indicate that one solves at one \"grid point\" at a time; for scalar problems, this means to use a solver that updates one unknown of the linear system at a time, keeping all of the others fixed; one would then iterate over all unknowns in the problem and, once done, start over again from the first unknown until these \"sweeps\" converge. Jacobi, Gauss-Seidel, and SOR iterations can all be interpreted in this way. In the context of multigrid, one does not think of these methods as \"solvers\", but as \"smoothers\". As such, one is not interested in actually solving the linear system. It is enough to remove the high-frequency part of the residual for the multigrid method to work, because that allows restricting the solution to a coarser mesh. Therefore, one only does a few, fixed number of \"sweeps\" over all unknowns. In the code in this tutorial this is controlled by the \"Smoothing steps\" parameter.\n\nBut these methods are known to converge rather slowly when used as solvers. While as multigrid smoothers, they are surprisingly good, they can also be improved upon. In particular, we consider \"cell-based\" smoothers here as well. These methods solve for all unknowns on a cell at once, keeping all other unknowns fixed; they then move on to the next cell, and so on and so forth. One can think of them as \"block\" versions of Jacobi, Gauss-Seidel, or SOR, but because degrees of freedom are shared among multiple cells, these blocks overlap and the methods are in fact best be explained within the framework of additive and multiplicative Schwarz methods.\n\nIn contrast to [step-16](step_16.html), our test problem contains an advective term. Especially with a small diffusion constant \\(\\varepsilon\\), information is transported along streamlines in the given advection direction. This means that smoothers are likely to be more effective if they allow information to travel in downstream direction within a single smoother application. If we want to solve one unknown (or block of unknowns) at a time in the order in which these unknowns (or blocks) are enumerated, then this information propagation property requires reordering degrees of freedom or cells (for the cell-based smoothers) accordingly so that the ones further upstream are treated earlier (have lower indices) and those further downstream are treated later (have larger indices). The influence of the ordering will be visible in the results section.\n\nLet us now briefly define the smoothers used in this tutorial. For a more detailed introduction, we refer to [[125]](citelist.html#CITEREF_KanschatNotesIterative) and the books [[195]](citelist.html#CITEREF_smith2004domain) and [[200]](citelist.html#CITEREF_toselli2006domain). A Schwarz preconditioner requires a decomposition\n\n\\begin{align\\*}\nV = \\sum\\_{j=1}^J V\\_j\n\\end{align\\*}\n\nof our finite element space \\(V\\). Each subproblem \\(V\\_j\\) also has a Ritz projection \\(P\\_j: V \\rightarrow V\\_j\\) based on the bilinear form \\(a(\\cdot,\\cdot)\\). This projection induces a local operator \\(A\\_j\\) for each subproblem \\(V\\_j\\). If \\(\\Pi\\_j:V\\rightarrow V\\_j\\) is the orthogonal projector onto \\(V\\_j\\), one can show \\(A\\_jP\\_j=\\Pi\\_j^TA\\).\n\nWith this we can define an *additive Schwarz preconditioner* for the operator \\(A\\) as\n\n\\begin{align\\*}\nB^{-1} = \\sum\\_{j=1}^J P\\_j A^{-1} = \\sum\\_{j=1}^J A\\_j^{-1} \\Pi\\_j^T.\n\\end{align\\*}\n\nIn other words, we project our solution into each subproblem, apply the inverse of the subproblem \\(A\\_j\\), and sum the contributions up over all \\(j\\).\n\nNote that one can interpret the point-wise (one unknown at a time) Jacobi method as an additive Schwarz method by defining a subproblem \\(V\\_j\\) for each degree of freedom. Then, \\(A\\_j^{-1}\\) becomes a multiplication with the inverse of a diagonal entry of \\(A\\).\n\nFor the \"Block Jacobi\" method used in this tutorial, we define a subproblem \\(V\\_j\\) for each cell of the mesh on the current level. Note that we use a continuous finite element, so these blocks are overlapping, as degrees of freedom on an interface between two cells belong to both subproblems. The logic for the Schwarz operator operating on the subproblems (in deal.II they are called \"blocks\") is implemented in the class [RelaxationBlock](classRelaxationBlock.html). The \"Block\nJacobi\" method is implemented in the class [RelaxationBlockJacobi](classRelaxationBlockJacobi.html). Many aspects of the class (for example how the blocks are defined and how to invert the local subproblems \\(A\\_j\\)) can be configured in the smoother data, see [RelaxationBlock::AdditionalData](classRelaxationBlock_1_1AdditionalData.html) and [DoFTools::make\\_cell\\_patches()](namespaceDoFTools.html#a43ee44769769065bc594d1730477a4b9) for details.\n\nSo far, we discussed additive smoothers where the updates can be applied independently and there is no information flowing within a single smoother application. A *multiplicative Schwarz preconditioner* addresses this and is defined by\n\n\\begin{align\\*}\nB^{-1} = \\left( I- \\prod\\_{j=1}^J \\left(I-P\\_j\\right) \\right) A^{-1}.\n\\end{align\\*}\n\nIn contrast to above, the updates on the subproblems \\(V\\_j\\) are applied sequentially. This means that the update obtained when inverting the subproblem \\(A\\_j\\) is immediately used in \\(A\\_{j+1}\\). This becomes visible when writing out the project:\n\n\\begin{align\\*}\nB^{-1}\n=\n\\left(\nI\n-\n\\left(I-P\\_1\\right)\\left(I-P\\_2\\right)\\cdots\\left(I-P\\_J\\right)\n\\right)\nA^{-1}\n=\nA^{-1}\n-\n\\left[ \\left(I-P\\_1\\right)\n\\left[ \\left(I-P\\_2\\right)\\cdots\n\\left[\\left(I-P\\_J\\right) A^{-1}\\right] \\cdots \\right] \\right]\n\\end{align\\*}\n\nWhen defining the sub-spaces \\(V\\_j\\) as whole blocks of degrees of freedom, this method is implemented in the class [RelaxationBlockSOR](classRelaxationBlockSOR.html) and used when you select \"Block SOR\" in this tutorial. The class [RelaxationBlockSOR](classRelaxationBlockSOR.html) is also derived from [RelaxationBlock](classRelaxationBlock.html). As such, both additive and multiplicative Schwarz methods are implemented in a unified framework.\n\nFinally, let us note that the standard Gauss-Seidel (or SOR) method can be seen as a multiplicative Schwarz method with a subproblem for each DoF.\n\n### Test problem\n\nWe will be considering the following test problem: \\(\\Omega =\n[-1,\\,1]\\times[-1,\\,1]\\backslash B\\_{0.3}(0)\\), i.e., a square with a circle of radius 0.3 centered at the origin removed. In addition, we use \\(\\varepsilon=0.005\\), \\(\\boldsymbol{\\beta} =\n[-\\sin(\\pi/6),\\,\\cos(\\pi/6)]\\), \\(f=0\\), and Dirichlet boundary values\n\n\\begin{align\\*}\ng = \\left\\{\\begin{array}{ll} 1 & \\text{if } x=-1 \\text{ or } y=-1,\\,x\\geq 0.5 \\\\\n0 & \\text{otherwise} \\end{array}\\right.\n\\end{align\\*}\n\nThe following figures depict the solutions with (left) and without (right) streamline diffusion. Without streamline diffusion we see large oscillations around the boundary layer, demonstrating the instability of the standard Galerkin finite element method for this problem.\n\n|  |  |\n| --- | --- |\n|  |  |\n\nThe commented program\n=====================\n\n### Include files\n\nTypical files needed for standard deal.II:\n\n```\n   #include <deal.II/base/tensor_function.h>\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/timer.h>\n   #include <deal.II/base/parameter_handler.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/vector.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/solver_gmres.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/relaxation_block.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   #include <deal.II/grid/manifold_lib.h>\n   #include <deal.II/grid/grid_out.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/mapping_q.h>\n   #include <deal.II/fe/fe_values.h>\n   \n   #include <deal.II/numerics/vector_tools.h>\n   #include <deal.II/numerics/data_out.h>\n```\n\nInclude all relevant multilevel files:\n\n```\n   #include <deal.II/multigrid/mg_constrained_dofs.h>\n   #include <deal.II/multigrid/multigrid.h>\n   #include <deal.II/multigrid/mg_transfer.h>\n   #include <deal.II/multigrid/mg_tools.h>\n   #include <deal.II/multigrid/mg_coarse.h>\n   #include <deal.II/multigrid/mg_smoother.h>\n   #include <deal.II/multigrid/mg_matrix.h>\n```\n\nC++:\n\n```\n   #include <algorithm>\n   #include <fstream>\n   #include <iostream>\n   #include <random>\n```\n\nWe will be using [MeshWorker::mesh\\_loop](group__MeshWorker.html#ga76ec61fbd188fb320fe8ca166a79b322) functionality for assembling matrices:\n\n```\n   #include <deal.II/meshworker/mesh_loop.h>\n```\n\n### [MeshWorker](namespaceMeshWorker.html) data\n\nAs always, we will be putting everything related to this program into a namespace of its own.\n\nSince we will be using the [MeshWorker](namespaceMeshWorker.html) framework, the first step is to define the following structures needed by the assemble\\_cell() function used by [MeshWorker::mesh\\_loop()](group__MeshWorker.html#ga76ec61fbd188fb320fe8ca166a79b322): `ScratchData` contains an [FEValues](classFEValues.html) object which is needed for assembling a cell's local contribution, while `CopyData` contains the output from a cell's local contribution and necessary information to copy that to the global system. (Their purpose is also explained in the documentation of the [WorkStream](namespaceWorkStream.html) class.)\n\n```\n   namespace Step63\n   {\n     using namespace dealii;\n   \n     template <int dim>\n     struct ScratchData\n     {\n       ScratchData(const FiniteElement<dim> &fe,\n                   const unsigned int        quadrature_degree)\n         : fe_values(fe,\n                     QGauss<dim>(quadrature_degree),\n                     update_values | update_gradients | update_hessians |\n                       update_quadrature_points | update_JxW_values)\n       {}\n   \n       ScratchData(const ScratchData<dim> &scratch_data)\n         : fe_values(scratch_data.fe_values.get_fe(),\n                     scratch_data.fe_values.get_quadrature(),\n                     update_values | update_gradients | update_hessians |\n                       update_quadrature_points | update_JxW_values)\n       {}\n   \n       FEValues<dim> fe_values;\n     };\n   \n   \n   \n     struct CopyData\n     {\n       CopyData() = default;\n   \n       unsigned int level;\n       unsigned int dofs_per_cell;\n   \n       FullMatrix<double>                   cell_matrix;\n       Vector<double>                       cell_rhs;\n       std::vector<types::global_dof_index> local_dof_indices;\n     };\n```\n\n### Problem parameters\n\nThe second step is to define the classes that deal with run-time parameters to be read from an input file.\n\nWe will use [ParameterHandler](classParameterHandler.html) to pass in parameters at runtime. The structure `Settings` parses and stores the parameters to be queried throughout the program.\n\n```\n     struct Settings\n     {\n       enum DoFRenumberingStrategy\n       {\n         none,\n         downstream,\n         upstream,\n         random\n       };\n   \n       void get_parameters(const std::string &prm_filename);\n   \n       double                 epsilon;\n       unsigned int           fe_degree;\n       std::string            smoother_type;\n       unsigned int           smoothing_steps;\n       DoFRenumberingStrategy dof_renumbering;\n       bool                   with_streamline_diffusion;\n       bool                   output;\n     };\n   \n   \n   \n     void Settings::get_parameters(const std::string &prm_filename)\n     {\n       /* First declare the parameters... */\n       ParameterHandler prm;\n   \n       prm.declare_entry(\"Epsilon\",\n                         \"0.005\",\n                         Patterns::Double(0),\n                         \"Diffusion parameter\");\n   \n       prm.declare_entry(\"Fe degree\",\n                         \"1\",\n                         Patterns::Integer(1),\n                         \"Finite Element degree\");\n       prm.declare_entry(\"Smoother type\",\n                         \"block SOR\",\n                         Patterns::Selection(\"SOR|Jacobi|block SOR|block Jacobi\"),\n                         \"Select smoother: SOR|Jacobi|block SOR|block Jacobi\");\n       prm.declare_entry(\"Smoothing steps\",\n                         \"2\",\n                         Patterns::Integer(1),\n                         \"Number of smoothing steps\");\n       prm.declare_entry(\n         \"DoF renumbering\",\n         \"downstream\",\n         Patterns::Selection(\"none|downstream|upstream|random\"),\n         \"Select DoF renumbering: none|downstream|upstream|random\");\n       prm.declare_entry(\"With streamline diffusion\",\n                         \"true\",\n                         Patterns::Bool(),\n                         \"Enable streamline diffusion stabilization: true|false\");\n       prm.declare_entry(\"Output\",\n                         \"true\",\n                         Patterns::Bool(),\n                         \"Generate graphical output: true|false\");\n   \n       /* ...and then try to read their values from the input file: */\n       if (prm_filename.empty())\n         {\n           prm.print_parameters(std::cout, ParameterHandler::Text);\n           AssertThrow(\n             false, ExcMessage(\"Please pass a .prm file as the first argument!\"));\n         }\n   \n       prm.parse_input(prm_filename);\n   \n       epsilon         = prm.get_double(\"Epsilon\");\n       fe_degree       = prm.get_integer(\"Fe degree\");\n       smoother_type   = prm.get(\"Smoother type\");\n       smoothing_steps = prm.get_integer(\"Smoothing steps\");\n   \n       const std::string renumbering = prm.get(\"DoF renumbering\");\n       if (renumbering == \"none\")\n         dof_renumbering = DoFRenumberingStrategy::none;\n       else if (renumbering == \"downstream\")\n         dof_renumbering = DoFRenumberingStrategy::downstream;\n       else if (renumbering == \"upstream\")\n         dof_renumbering = DoFRenumberingStrategy::upstream;\n       else if (renumbering == \"random\")\n         dof_renumbering = DoFRenumberingStrategy::random;\n       else\n         AssertThrow(false,\n                     ExcMessage(\"The <DoF renumbering> parameter has \"\n                                \"an invalid value.\"));\n   \n       with_streamline_diffusion = prm.get_bool(\"With streamline diffusion\");\n       output                    = prm.get_bool(\"Output\");\n     }\n```\n\n### Cell permutations\n\nThe ordering in which cells and degrees of freedom are traversed will play a role in the speed of convergence for multiplicative methods. Here we define functions which return a specific ordering of cells to be used by the block smoothers.\n\nFor each type of cell ordering, we define a function for the active mesh and one for a level mesh (i.e., for the cells at one level of a multigrid hierarchy). While the only reordering necessary for solving the system will be on the level meshes, we include the active reordering for visualization purposes in output\\_results().\n\nFor the two downstream ordering functions, we first create an array with all of the relevant cells that we then sort in downstream direction using a \"comparator\" object. The output of the functions is then simply an array of the indices of the cells in the just computed order.\n\n```\n     template <int dim>\n     std::vector<unsigned int>\n     create_downstream_cell_ordering(const DoFHandler<dim> &dof_handler,\n                                     const Tensor<1, dim>   direction,\n                                     const unsigned int level)\n     {\n       std::vector<typename DoFHandler<dim>::level_cell_iterator> ordered_cells;\n       ordered_cells.reserve(dof_handler.get_triangulation().n_cells(level));\n       for (const auto &cell : dof_handler.cell_iterators_on_level(level))\n         ordered_cells.push_back(cell);\n   \n       const DoFRenumbering::\n         CompareDownstream<typename DoFHandler<dim>::level_cell_iterator, dim>\n           comparator(direction);\n       std::sort(ordered_cells.begin(), ordered_cells.end(), comparator);\n   \n       std::vector<unsigned> ordered_indices;\n       ordered_indices.reserve(dof_handler.get_triangulation().n_cells(level));\n   \n       for (const auto &cell : ordered_cells)\n         ordered_indices.push_back(cell->index());\n   \n       return ordered_indices;\n     }\n   \n   \n   \n     template <int dim>\n     std::vector<unsigned int>\n     create_downstream_cell_ordering(const DoFHandler<dim> &dof_handler,\n                                     const Tensor<1, dim>   direction)\n     {\n       std::vector<typename DoFHandler<dim>::active_cell_iterator> ordered_cells;\n       ordered_cells.reserve(dof_handler.get_triangulation().n_active_cells());\n       for (const auto &cell : dof_handler.active_cell_iterators())\n         ordered_cells.push_back(cell);\n   \n       const DoFRenumbering::\n         CompareDownstream<typename DoFHandler<dim>::active_cell_iterator, dim>\n           comparator(direction);\n       std::sort(ordered_cells.begin(), ordered_cells.end(), comparator);\n   \n       std::vector<unsigned int> ordered_indices;\n       ordered_indices.reserve(dof_handler.get_triangulation().n_active_cells());\n   \n       for (const auto &cell : ordered_cells)\n         ordered_indices.push_back(cell->index());\n   \n       return ordered_indices;\n     }\n```\n\nThe functions that produce a random ordering are similar in spirit in that they first put information about all cells into an array. But then, instead of sorting them, they shuffle the elements randomly using the facilities C++ offers to generate random numbers. The way this is done is by iterating over all elements of the array, drawing a random number for another element before that, and then exchanging these elements. The result is a random shuffle of the elements of the array.\n\n```\n     template <int dim>\n     std::vector<unsigned int>\n     create_random_cell_ordering(const DoFHandler<dim> &dof_handler,\n                                 const unsigned int level)\n     {\n       std::vector<unsigned int> ordered_cells;\n       ordered_cells.reserve(dof_handler.get_triangulation().n_cells(level));\n       for (const auto &cell : dof_handler.cell_iterators_on_level(level))\n         ordered_cells.push_back(cell->index());\n   \n       std::mt19937 random_number_generator;\n       std::shuffle(ordered_cells.begin(),\n                    ordered_cells.end(),\n                    random_number_generator);\n   \n       return ordered_cells;\n     }\n   \n   \n   \n     template <int dim>\n     std::vector<unsigned int>\n     create_random_cell_ordering(const DoFHandler<dim> &dof_handler)\n     {\n       std::vector<unsigned int> ordered_cells;\n       ordered_cells.reserve(dof_handler.get_triangulation().n_active_cells());\n       for (const auto &cell : dof_handler.active_cell_iterators())\n         ordered_cells.push_back(cell->index());\n   \n       std::mt19937 random_number_generator;\n       std::shuffle(ordered_cells.begin(),\n                    ordered_cells.end(),\n                    random_number_generator);\n   \n       return ordered_cells;\n     }\n```\n\n### Right-hand side and boundary values\n\nThe problem solved in this tutorial is an adaptation of Ex. 3.1.3 found on pg. 118 of [Finite Elements and Fast Iterative Solvers: with Applications in Incompressible Fluid Dynamics by Elman, Silvester, and Wathen](https://global.oup.com/academic/product/finite-elements-and-fast-iterative-solvers-9780199678808). The main difference being that we add a hole in the center of our domain with zero Dirichlet boundary conditions.\n\nFor a complete description, we need classes that implement the zero right-hand side first (we could of course have just used [Functions::ZeroFunction](classFunctions_1_1ZeroFunction.html)):\n\n```\n     template <int dim>\n     class RightHandSide : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n   \n       virtual void value_list(const std::vector<Point<dim>> &points,\n                               std::vector<double>           &values,\n                               const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double RightHandSide<dim>::value(const Point<dim> &,\n                                      const unsigned int component) const\n     {\n       Assert(component == 0, ExcIndexRange(component, 0, 1));\n       (void)component;\n   \n       return 0.0;\n     }\n   \n   \n   \n     template <int dim>\n     void RightHandSide<dim>::value_list(const std::vector<Point<dim>> &points,\n                                         std::vector<double>           &values,\n                                         const unsigned int component) const\n     {\n       AssertDimension(values.size(), points.size());\n   \n       for (unsigned int i = 0; i < points.size(); ++i)\n         values[i] = RightHandSide<dim>::value(points[i], component);\n     }\n```\n\nWe also have Dirichlet boundary conditions. On a connected portion of the outer, square boundary we set the value to 1, and we set the value to 0 everywhere else (including the inner, circular boundary):\n\n```\n     template <int dim>\n     class BoundaryValues : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n   \n       virtual void value_list(const std::vector<Point<dim>> &points,\n                               std::vector<double>           &values,\n                               const unsigned int component = 0) const override;\n     };\n   \n   \n   \n     template <int dim>\n     double BoundaryValues<dim>::value(const Point<dim>  &p,\n                                       const unsigned int component) const\n     {\n       Assert(component == 0, ExcIndexRange(component, 0, 1));\n       (void)component;\n```\n\nSet boundary to 1 if \\(x=1\\), or if \\(x>0.5\\) and \\(y=-1\\).\n\n```\n       if (std::fabs(p[0] - 1) < 1e-8 ||\n           (std::fabs(p[1] + 1) < 1e-8 && p[0] >= 0.5))\n         {\n           return 1.0;\n         }\n       else\n         {\n           return 0.0;\n         }\n     }\n   \n   \n   \n     template <int dim>\n     void BoundaryValues<dim>::value_list(const std::vector<Point<dim>> &points,\n                                          std::vector<double>           &values,\n                                          const unsigned int component) const\n     {\n       AssertDimension(values.size(), points.size());\n   \n       for (unsigned int i = 0; i < points.size(); ++i)\n         values[i] = BoundaryValues<dim>::value(points[i], component);\n     }\n```\n\n### Streamline diffusion implementation\n\nThe streamline diffusion method has a stabilization constant that we need to be able to compute. The choice of how this parameter is computed is taken from [On Discontinuity-Capturing Methods for Convection-Diffusion Equations by Volker John and Petr Knobloch](https://link.springer.com/chapter/10.1007/978-3-540-34288-5_27).\n\n```\n     template <int dim>\n     double compute_stabilization_delta(const double         hk,\n                                        const double         eps,\n                                        const Tensor<1, dim> dir,\n                                        const double         pk)\n     {\n       const double Peclet = dir.norm() * hk / (2.0 * eps * pk);\n       const double coth =\n         (1.0 + std::exp(-2.0 * Peclet)) / (1.0 - std::exp(-2.0 * Peclet));\n   \n       return hk / (2.0 * dir.norm() * pk) * (coth - 1.0 / Peclet);\n     }\n```\n\n### `AdvectionProblem` class\n\nThis is the main class of the program, and should look very similar to [step-16](step_16.html). The major difference is that, since we are defining our multigrid smoother at runtime, we choose to define a function `create_smoother()` and a class object `mg_smoother` which is a `std::unique_ptr` to a smoother that is derived from [MGSmoother](classMGSmoother.html). Note that for smoothers derived from [RelaxationBlock](classRelaxationBlock.html), we must include a `smoother_data` object for each level. This will contain information about the cell ordering and the method of inverting cell matrices.\n\n```\n     template <int dim>\n     class AdvectionProblem\n     {\n     public:\n       AdvectionProblem(const Settings &settings);\n       void run();\n   \n     private:\n       void setup_system();\n   \n       template <class IteratorType>\n       void assemble_cell(const IteratorType &cell,\n                          ScratchData<dim>   &scratch_data,\n                          CopyData           &copy_data);\n       void assemble_system_and_multigrid();\n   \n       void setup_smoother();\n   \n       void solve();\n       void refine_grid();\n       void output_results(const unsigned int cycle) const;\n   \n       Triangulation<dim> triangulation;\n       DoFHandler<dim>    dof_handler;\n   \n       const FE_Q<dim>     fe;\n       const MappingQ<dim> mapping;\n   \n       AffineConstraints<double> constraints;\n   \n       SparsityPattern      sparsity_pattern;\n       SparseMatrix<double> system_matrix;\n   \n       Vector<double> solution;\n       Vector<double> system_rhs;\n   \n       MGLevelObject<SparsityPattern> mg_sparsity_patterns;\n       MGLevelObject<SparsityPattern> mg_interface_sparsity_patterns;\n   \n       MGLevelObject<SparseMatrix<double>> mg_matrices;\n       MGLevelObject<SparseMatrix<double>> mg_interface_in;\n       MGLevelObject<SparseMatrix<double>> mg_interface_out;\n   \n       mg::Matrix<Vector<double>> mg_matrix;\n       mg::Matrix<Vector<double>> mg_interface_matrix_in;\n       mg::Matrix<Vector<double>> mg_interface_matrix_out;\n   \n       std::unique_ptr<MGSmoother<Vector<double>>> mg_smoother;\n   \n       using SmootherType =\n         RelaxationBlock<SparseMatrix<double>, double, Vector<double>>;\n       using SmootherAdditionalDataType = SmootherType::AdditionalData;\n       MGLevelObject<SmootherAdditionalDataType> smoother_data;\n   \n       MGConstrainedDoFs mg_constrained_dofs;\n   \n       Tensor<1, dim> advection_direction;\n   \n       const Settings settings;\n     };\n   \n   \n   \n     template <int dim>\n     AdvectionProblem<dim>::AdvectionProblem(const Settings &settings)\n       : triangulation(Triangulation<dim>::limit_level_difference_at_vertices)\n       , dof_handler(triangulation)\n       , fe(settings.fe_degree)\n       , mapping(settings.fe_degree)\n       , settings(settings)\n     {\n       advection_direction[0] = -std::sin(numbers::PI / 6.0);\n       if (dim >= 2)\n         advection_direction[1] = std::cos(numbers::PI / 6.0);\n       if (dim >= 3)\n         AssertThrow(false, ExcNotImplemented());\n     }\n```\n\n#### `AdvectionProblem::setup_system()`\n\nHere we first set up the [DoFHandler](classDoFHandler.html), [AffineConstraints](classAffineConstraints.html), and [SparsityPattern](classSparsityPattern.html) objects for both active and multigrid level meshes.\n\nWe could renumber the active DoFs with the [DoFRenumbering](namespaceDoFRenumbering.html) class, but the smoothers only act on multigrid levels and as such, this would not matter for the computations. Instead, we will renumber the DoFs on each multigrid level below.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::setup_system()\n     {\n       const unsigned int n_levels = triangulation.n_levels();\n   \n       dof_handler.distribute_dofs(fe);\n   \n       solution.reinit(dof_handler.n_dofs());\n       system_rhs.reinit(dof_handler.n_dofs());\n   \n       constraints.clear();\n       DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n   \n       VectorTools::interpolate_boundary_values(\n         mapping, dof_handler, 0, BoundaryValues<dim>(), constraints);\n       VectorTools::interpolate_boundary_values(\n         mapping, dof_handler, 1, BoundaryValues<dim>(), constraints);\n       constraints.close();\n   \n       DynamicSparsityPattern dsp(dof_handler.n_dofs());\n       DoFTools::make_sparsity_pattern(dof_handler,\n                                       dsp,\n                                       constraints,\n                                       /*keep_constrained_dofs = */ false);\n   \n       sparsity_pattern.copy_from(dsp);\n       system_matrix.reinit(sparsity_pattern);\n   \n       dof_handler.distribute_mg_dofs();\n```\n\nHaving enumerated the global degrees of freedom as well as (in the last line above) the level degrees of freedom, let us renumber the level degrees of freedom to get a better smoother as explained in the introduction. The first block below renumbers DoFs on each level in downstream or upstream direction if needed. This is only necessary for point smoothers (SOR and Jacobi) as the block smoothers operate on cells (see `create_smoother()`). The blocks below then also implement random numbering.\n\n```\n       if (settings.smoother_type == \"SOR\" || settings.smoother_type == \"Jacobi\")\n         {\n           if (settings.dof_renumbering ==\n                 Settings::DoFRenumberingStrategy::downstream ||\n               settings.dof_renumbering ==\n                 Settings::DoFRenumberingStrategy::upstream)\n             {\n               const Tensor<1, dim> direction =\n                 (settings.dof_renumbering ==\n                      Settings::DoFRenumberingStrategy::upstream ?\n                    -1.0 :\n                    1.0) *\n                 advection_direction;\n   \n               for (unsigned int level = 0; level < n_levels; ++level)\n                 DoFRenumbering::downstream(dof_handler,\n                                            level,\n                                            direction,\n                                            /*dof_wise_renumbering = */ true);\n             }\n           else if (settings.dof_renumbering ==\n                    Settings::DoFRenumberingStrategy::random)\n             {\n               for (unsigned int level = 0; level < n_levels; ++level)\n                 DoFRenumbering::random(dof_handler, level);\n             }\n           else\n             DEAL_II_NOT_IMPLEMENTED();\n         }\n```\n\nThe rest of the function just sets up data structures. The last lines of the code below is unlike the other GMG tutorials, as it sets up both the interface in and out matrices. We need this since our problem is non-symmetric.\n\n```\n       mg_constrained_dofs.clear();\n       mg_constrained_dofs.initialize(dof_handler);\n   \n       mg_constrained_dofs.make_zero_boundary_constraints(dof_handler, {0, 1});\n   \n       mg_matrices.resize(0, n_levels - 1);\n       mg_matrices.clear_elements();\n       mg_interface_in.resize(0, n_levels - 1);\n       mg_interface_in.clear_elements();\n       mg_interface_out.resize(0, n_levels - 1);\n       mg_interface_out.clear_elements();\n       mg_sparsity_patterns.resize(0, n_levels - 1);\n       mg_interface_sparsity_patterns.resize(0, n_levels - 1);\n   \n       for (unsigned int level = 0; level < n_levels; ++level)\n         {\n           {\n             DynamicSparsityPattern dsp(dof_handler.n_dofs(level),\n                                        dof_handler.n_dofs(level));\n             MGTools::make_sparsity_pattern(dof_handler, dsp, level);\n             mg_sparsity_patterns[level].copy_from(dsp);\n             mg_matrices[level].reinit(mg_sparsity_patterns[level]);\n           }\n           {\n             DynamicSparsityPattern dsp(dof_handler.n_dofs(level),\n                                        dof_handler.n_dofs(level));\n             MGTools::make_interface_sparsity_pattern(dof_handler,\n                                                      mg_constrained_dofs,\n                                                      dsp,\n                                                      level);\n             mg_interface_sparsity_patterns[level].copy_from(dsp);\n   \n             mg_interface_in[level].reinit(mg_interface_sparsity_patterns[level]);\n             mg_interface_out[level].reinit(mg_interface_sparsity_patterns[level]);\n           }\n         }\n     }\n```\n\n#### `AdvectionProblem::assemble_cell()`\n\nHere we define the assembly of the linear system on each cell to be used by the mesh\\_loop() function below. This one function assembles the cell matrix for either an active or a level cell (whatever it is passed as its first argument), and only assembles a right-hand side if called with an active cell.\n\n```\n     template <int dim>\n     template <class IteratorType>\n     void AdvectionProblem<dim>::assemble_cell(const IteratorType &cell,\n                                               ScratchData<dim>   &scratch_data,\n                                               CopyData           &copy_data)\n     {\n       copy_data.level = cell->level();\n   \n       const unsigned int dofs_per_cell =\n         scratch_data.fe_values.get_fe().n_dofs_per_cell();\n       copy_data.dofs_per_cell = dofs_per_cell;\n       copy_data.cell_matrix.reinit(dofs_per_cell, dofs_per_cell);\n   \n       const unsigned int n_q_points =\n         scratch_data.fe_values.get_quadrature().size();\n   \n       if (cell->is_level_cell() == false)\n         copy_data.cell_rhs.reinit(dofs_per_cell);\n   \n       copy_data.local_dof_indices.resize(dofs_per_cell);\n       cell->get_active_or_mg_dof_indices(copy_data.local_dof_indices);\n   \n       scratch_data.fe_values.reinit(cell);\n   \n       RightHandSide<dim>  right_hand_side;\n       std::vector<double> rhs_values(n_q_points);\n   \n       right_hand_side.value_list(scratch_data.fe_values.get_quadrature_points(),\n                                  rhs_values);\n```\n\nIf we are using streamline diffusion we must add its contribution to both the cell matrix and the cell right-hand side. If we are not using streamline diffusion, setting \\(\\delta=0\\) negates this contribution below and we are left with the standard, Galerkin finite element assembly.\n\n```\n       const double delta = (settings.with_streamline_diffusion ?\n                               compute_stabilization_delta(cell->diameter(),\n                                                           settings.epsilon,\n                                                           advection_direction,\n                                                           settings.fe_degree) :\n                               0.0);\n   \n       for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n         for (unsigned int i = 0; i < dofs_per_cell; ++i)\n           {\n             for (unsigned int j = 0; j < dofs_per_cell; ++j)\n               {\n```\n\nThe assembly of the local matrix has two parts. First the Galerkin contribution:\n\n```\n                 copy_data.cell_matrix(i, j) +=\n                   (settings.epsilon *\n                    scratch_data.fe_values.shape_grad(i, q_point) *\n                    scratch_data.fe_values.shape_grad(j, q_point) *\n                    scratch_data.fe_values.JxW(q_point)) +\n                   (scratch_data.fe_values.shape_value(i, q_point) *\n                    (advection_direction *\n                     scratch_data.fe_values.shape_grad(j, q_point)) *\n                    scratch_data.fe_values.JxW(q_point))\n```\n\nand then the streamline diffusion contribution:\n\n```\n                   + delta *\n                       (advection_direction *\n                        scratch_data.fe_values.shape_grad(j, q_point)) *\n                       (advection_direction *\n                        scratch_data.fe_values.shape_grad(i, q_point)) *\n                       scratch_data.fe_values.JxW(q_point) -\n                   delta * settings.epsilon *\n                     trace(scratch_data.fe_values.shape_hessian(j, q_point)) *\n                     (advection_direction *\n                      scratch_data.fe_values.shape_grad(i, q_point)) *\n                     scratch_data.fe_values.JxW(q_point);\n               }\n             if (cell->is_level_cell() == false)\n               {\n```\n\nThe same applies to the right hand side. First the Galerkin contribution:\n\n```\n                 copy_data.cell_rhs(i) +=\n                   scratch_data.fe_values.shape_value(i, q_point) *\n                     rhs_values[q_point] * scratch_data.fe_values.JxW(q_point)\n```\n\nand then the streamline diffusion contribution:\n\n```\n                   + delta * rhs_values[q_point] * advection_direction *\n                       scratch_data.fe_values.shape_grad(i, q_point) *\n                       scratch_data.fe_values.JxW(q_point);\n               }\n           }\n     }\n```\n\n#### `AdvectionProblem::assemble_system_and_multigrid()`\n\nHere we employ [MeshWorker::mesh\\_loop()](group__MeshWorker.html#ga76ec61fbd188fb320fe8ca166a79b322) to go over cells and assemble the system\\_matrix, system\\_rhs, and all mg\\_matrices for us.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::assemble_system_and_multigrid()\n     {\n       const auto cell_worker_active =\n         [&](const decltype(dof_handler.begin_active()) &cell,\n             ScratchData<dim>                           &scratch_data,\n             CopyData                                   &copy_data) {\n           this->assemble_cell(cell, scratch_data, copy_data);\n         };\n   \n       const auto copier_active = [&](const CopyData &copy_data) {\n         constraints.distribute_local_to_global(copy_data.cell_matrix,\n                                                copy_data.cell_rhs,\n                                                copy_data.local_dof_indices,\n                                                system_matrix,\n                                                system_rhs);\n       };\n   \n   \n       MeshWorker::mesh_loop(dof_handler.begin_active(),\n                             dof_handler.end(),\n                             cell_worker_active,\n                             copier_active,\n                             ScratchData<dim>(fe, fe.degree + 1),\n                             CopyData(),\n                             MeshWorker::assemble_own_cells);\n```\n\nUnlike the constraints for the active level, we choose to create constraint objects for each multigrid level local to this function since they are never needed elsewhere in the program.\n\n```\n       std::vector<AffineConstraints<double>> boundary_constraints(\n         triangulation.n_global_levels());\n       for (unsigned int level = 0; level < triangulation.n_global_levels();\n            ++level)\n         {\n           boundary_constraints[level].reinit(\n             dof_handler.locally_owned_mg_dofs(level),\n             DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\n   \n           for (const types::global_dof_index dof_index :\n                mg_constrained_dofs.get_refinement_edge_indices(level))\n             boundary_constraints[level].constrain_dof_to_zero(dof_index);\n           for (const types::global_dof_index dof_index :\n                mg_constrained_dofs.get_boundary_indices(level))\n             boundary_constraints[level].constrain_dof_to_zero(dof_index);\n           boundary_constraints[level].close();\n         }\n   \n       const auto cell_worker_mg =\n         [&](const decltype(dof_handler.begin_mg()) &cell,\n             ScratchData<dim>                       &scratch_data,\n             CopyData                               &copy_data) {\n           this->assemble_cell(cell, scratch_data, copy_data);\n         };\n   \n       const auto copier_mg = [&](const CopyData &copy_data) {\n         boundary_constraints[copy_data.level].distribute_local_to_global(\n           copy_data.cell_matrix,\n           copy_data.local_dof_indices,\n           mg_matrices[copy_data.level]);\n```\n\nIf \\((i,j)\\) is an `interface_out` dof pair, then \\((j,i)\\) is an `interface_in` dof pair. Note: For `interface_in`, we load the transpose of the interface entries, i.e., the entry for dof pair \\((j,i)\\) is stored in `interface_in(i,j)`. This is an optimization for the symmetric case which allows only one matrix to be used when setting the edge\\_matrices in solve(). Here, however, since our problem is non-symmetric, we must store both `interface_in` and `interface_out` matrices.\n\n```\n         for (unsigned int i = 0; i < copy_data.dofs_per_cell; ++i)\n           for (unsigned int j = 0; j < copy_data.dofs_per_cell; ++j)\n             if (mg_constrained_dofs.is_interface_matrix_entry(\n                   copy_data.level,\n                   copy_data.local_dof_indices[i],\n                   copy_data.local_dof_indices[j]))\n               {\n                 mg_interface_out[copy_data.level].add(\n                   copy_data.local_dof_indices[i],\n                   copy_data.local_dof_indices[j],\n                   copy_data.cell_matrix(i, j));\n                 mg_interface_in[copy_data.level].add(\n                   copy_data.local_dof_indices[i],\n                   copy_data.local_dof_indices[j],\n                   copy_data.cell_matrix(j, i));\n               }\n       };\n   \n       MeshWorker::mesh_loop(dof_handler.begin_mg(),\n                             dof_handler.end_mg(),\n                             cell_worker_mg,\n                             copier_mg,\n                             ScratchData<dim>(fe, fe.degree + 1),\n                             CopyData(),\n                             MeshWorker::assemble_own_cells);\n     }\n```\n\n#### `AdvectionProblem::setup_smoother()`\n\nNext, we set up the smoother based on the settings in the `.prm` file. The two options that are of significance is the number of pre- and post-smoothing steps on each level of the multigrid v-cycle and the relaxation parameter.\n\nSince multiplicative methods tend to be more powerful than additive method, fewer smoothing steps are required to see convergence independent of mesh size. The same holds for block smoothers over point smoothers. This is reflected in the choice for the number of smoothing steps for each type of smoother below.\n\nThe relaxation parameter for point smoothers is chosen based on trial and error, and reflects values necessary to keep the iteration counts in the GMRES solve constant (or as close as possible) as we refine the mesh. The two values given for both \"Jacobi\" and \"SOR\" in the `.prm` files are for degree 1 and degree 3 finite elements. If the user wants to change to another degree, they may need to adjust these numbers. For block smoothers, this parameter has a more straightforward interpretation, namely that for additive methods in 2d, a DoF can have a repeated contribution from up to 4 cells, therefore we must relax these methods by 0.25 to compensate. This is not an issue for multiplicative methods as each cell's inverse application carries new information to all its DoFs.\n\nFinally, as mentioned above, the point smoothers only operate on DoFs, and the block smoothers on cells, so only the block smoothers need to be given information regarding cell orderings. DoF ordering for point smoothers has already been taken care of in `setup_system()`.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::setup_smoother()\n     {\n       if (settings.smoother_type == \"SOR\")\n         {\n           using Smoother = PreconditionSOR<SparseMatrix<double>>;\n   \n           auto smoother =\n             std::make_unique<MGSmootherPrecondition<SparseMatrix<double>,\n                                                     Smoother,\n                                                     Vector<double>>>();\n           smoother->initialize(mg_matrices,\n                                Smoother::AdditionalData(fe.degree == 1 ? 1.0 :\n                                                                          0.62));\n           smoother->set_steps(settings.smoothing_steps);\n           mg_smoother = std::move(smoother);\n         }\n       else if (settings.smoother_type == \"Jacobi\")\n         {\n           using Smoother = PreconditionJacobi<SparseMatrix<double>>;\n           auto smoother =\n             std::make_unique<MGSmootherPrecondition<SparseMatrix<double>,\n                                                     Smoother,\n                                                     Vector<double>>>();\n           smoother->initialize(mg_matrices,\n                                Smoother::AdditionalData(fe.degree == 1 ? 0.6667 :\n                                                                          0.47));\n           smoother->set_steps(settings.smoothing_steps);\n           mg_smoother = std::move(smoother);\n         }\n       else if (settings.smoother_type == \"block SOR\" ||\n                settings.smoother_type == \"block Jacobi\")\n         {\n           smoother_data.resize(0, triangulation.n_levels() - 1);\n   \n           for (unsigned int level = 0; level < triangulation.n_levels(); ++level)\n             {\n               DoFTools::make_cell_patches(smoother_data[level].block_list,\n                                           dof_handler,\n                                           level);\n   \n               smoother_data[level].relaxation =\n                 (settings.smoother_type == \"block SOR\" ? 1.0 : 0.25);\n               smoother_data[level].inversion = PreconditionBlockBase<double>::svd;\n   \n               std::vector<unsigned int> ordered_indices;\n               switch (settings.dof_renumbering)\n                 {\n                   case Settings::DoFRenumberingStrategy::downstream:\n                     ordered_indices =\n                       create_downstream_cell_ordering(dof_handler,\n                                                       advection_direction,\n                                                       level);\n                     break;\n   \n                   case Settings::DoFRenumberingStrategy::upstream:\n                     ordered_indices =\n                       create_downstream_cell_ordering(dof_handler,\n                                                       -1.0 * advection_direction,\n                                                       level);\n                     break;\n   \n                   case Settings::DoFRenumberingStrategy::random:\n                     ordered_indices =\n                       create_random_cell_ordering(dof_handler, level);\n                     break;\n   \n                   case Settings::DoFRenumberingStrategy::none:\n                     break;\n   \n                   default:\n                     AssertThrow(false, ExcNotImplemented());\n                     break;\n                 }\n   \n               smoother_data[level].order =\n                 std::vector<std::vector<unsigned int>>(1, ordered_indices);\n             }\n   \n           if (settings.smoother_type == \"block SOR\")\n             {\n               auto smoother = std::make_unique<MGSmootherPrecondition<\n                 SparseMatrix<double>,\n                 RelaxationBlockSOR<SparseMatrix<double>, double, Vector<double>>,\n                 Vector<double>>>();\n               smoother->initialize(mg_matrices, smoother_data);\n               smoother->set_steps(settings.smoothing_steps);\n               mg_smoother = std::move(smoother);\n             }\n           else if (settings.smoother_type == \"block Jacobi\")\n             {\n               auto smoother = std::make_unique<\n                 MGSmootherPrecondition<SparseMatrix<double>,\n                                        RelaxationBlockJacobi<SparseMatrix<double>,\n                                                              double,\n                                                              Vector<double>>,\n                                        Vector<double>>>();\n               smoother->initialize(mg_matrices, smoother_data);\n               smoother->set_steps(settings.smoothing_steps);\n               mg_smoother = std::move(smoother);\n             }\n         }\n       else\n         AssertThrow(false, ExcNotImplemented());\n     }\n```\n\n#### `AdvectionProblem::solve()`\n\nBefore we can solve the system, we must first set up the multigrid preconditioner. This requires the setup of the transfer between levels, the coarse matrix solver, and the smoother. This setup follows almost identically to [step-16](step_16.html), the main difference being the various smoothers defined above and the fact that we need different interface edge matrices for in and out since our problem is non-symmetric. (In reality, for this tutorial these interface matrices are empty since we are only using global refinement, and thus have no refinement edges. However, we have still included both here since if one made the simple switch to an adaptively refined method, the program would still run correctly.)\n\nThe last thing to note is that since our problem is non-symmetric, we must use an appropriate Krylov subspace method. We choose here to use GMRES since it offers the guarantee of residual reduction in each iteration. The major disadvantage of GMRES is that, for each iteration, the number of stored temporary vectors increases by one, and one also needs to compute a scalar product with all previously stored vectors. This is rather expensive. This requirement is relaxed by using the restarted GMRES method which puts a cap on the number of vectors we are required to store at any one time (here we restart after 50 temporary vectors, or 48 iterations). This then has the disadvantage that we lose information we have gathered throughout the iteration and therefore we could see slower convergence. As a consequence, where to restart is a question of balancing memory consumption, CPU effort, and convergence speed. However, the goal of this tutorial is to have very low iteration counts by using a powerful GMG preconditioner, so we have picked the restart length such that all of the results shown below converge prior to restart happening, and thus we have a standard GMRES method. If the user is interested, another suitable method offered in deal.II would be BiCGStab.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::solve()\n     {\n       const unsigned int max_iters       = 200;\n       const double       solve_tolerance = 1e-8 * system_rhs.l2_norm();\n       SolverControl      solver_control(max_iters, solve_tolerance, true, true);\n       solver_control.enable_history_data();\n   \n       using Transfer = MGTransferPrebuilt<Vector<double>>;\n       Transfer mg_transfer(mg_constrained_dofs);\n       mg_transfer.build(dof_handler);\n   \n       FullMatrix<double> coarse_matrix;\n       coarse_matrix.copy_from(mg_matrices[0]);\n       MGCoarseGridHouseholder<double, Vector<double>> coarse_grid_solver;\n       coarse_grid_solver.initialize(coarse_matrix);\n   \n       setup_smoother();\n   \n       mg_matrix.initialize(mg_matrices);\n       mg_interface_matrix_in.initialize(mg_interface_in);\n       mg_interface_matrix_out.initialize(mg_interface_out);\n   \n       Multigrid<Vector<double>> mg(\n         mg_matrix, coarse_grid_solver, mg_transfer, *mg_smoother, *mg_smoother);\n       mg.set_edge_matrices(mg_interface_matrix_out, mg_interface_matrix_in);\n   \n       PreconditionMG<dim, Vector<double>, Transfer> preconditioner(dof_handler,\n                                                                    mg,\n                                                                    mg_transfer);\n   \n       std::cout << \"     Solving with GMRES to tol \" << solve_tolerance << \"...\"\n                 << std::endl;\n       SolverGMRES<Vector<double>> solver(\n         solver_control, SolverGMRES<Vector<double>>::AdditionalData(50, true));\n   \n       Timer time;\n       time.start();\n       solver.solve(system_matrix, solution, system_rhs, preconditioner);\n       time.stop();\n   \n       std::cout << \"          converged in \" << solver_control.last_step()\n                 << \" iterations\"\n                 << \" in \" << time.last_wall_time() << \" seconds \" << std::endl;\n   \n       constraints.distribute(solution);\n   \n       mg_smoother.release();\n     }\n```\n\n#### `AdvectionProblem::output_results()`\n\nThe final function of interest generates graphical output. Here we output the solution and cell ordering in a .vtu format.\n\nAt the top of the function, we generate an index for each cell to visualize the ordering used by the smoothers. Note that we do this only for the active cells instead of the levels, where the smoothers are actually used. For the point smoothers we renumber DoFs instead of cells, so this is only an approximation of what happens in reality. Finally, the random ordering is not the random ordering we actually use (see `create_smoother()` for that).\n\nThe (integer) ordering of cells is then copied into a (floating point) vector for graphical output.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::output_results(const unsigned int cycle) const\n     {\n       const unsigned int n_active_cells = triangulation.n_active_cells();\n       Vector<double>     cell_indices(n_active_cells);\n       {\n         std::vector<unsigned int> ordered_indices;\n         switch (settings.dof_renumbering)\n           {\n             case Settings::DoFRenumberingStrategy::downstream:\n               ordered_indices =\n                 create_downstream_cell_ordering(dof_handler, advection_direction);\n               break;\n   \n             case Settings::DoFRenumberingStrategy::upstream:\n               ordered_indices =\n                 create_downstream_cell_ordering(dof_handler,\n                                                 -1.0 * advection_direction);\n               break;\n   \n             case Settings::DoFRenumberingStrategy::random:\n               ordered_indices = create_random_cell_ordering(dof_handler);\n               break;\n   \n             case Settings::DoFRenumberingStrategy::none:\n               ordered_indices.resize(n_active_cells);\n               for (unsigned int i = 0; i < n_active_cells; ++i)\n                 ordered_indices[i] = i;\n               break;\n   \n             default:\n               AssertThrow(false, ExcNotImplemented());\n               break;\n           }\n   \n         for (unsigned int i = 0; i < n_active_cells; ++i)\n           cell_indices(ordered_indices[i]) = static_cast<double>(i);\n       }\n```\n\nThe remainder of the function is then straightforward, given previous tutorial programs:\n\n```\n       DataOut<dim> data_out;\n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(solution, \"solution\");\n       data_out.add_data_vector(cell_indices, \"cell_index\");\n       data_out.build_patches();\n   \n       const std::string filename =\n         \"solution-\" + Utilities::int_to_string(cycle) + \".vtu\";\n       std::ofstream output(filename);\n       data_out.write_vtu(output);\n     }\n```\n\n#### `AdvectionProblem::run()`\n\nAs in most tutorials, this function creates/refines the mesh and calls the various functions defined above to set up, assemble, solve, and output the results.\n\nIn cycle zero, we generate the mesh for the on the square `[-1,1]^dim` with a hole of radius 3/10 units centered at the origin. For objects with `manifold_id` equal to one (namely, the faces adjacent to the hole), we assign a spherical manifold.\n\n```\n     template <int dim>\n     void AdvectionProblem<dim>::run()\n     {\n       for (unsigned int cycle = 0; cycle < (settings.fe_degree == 1 ? 7u : 5u);\n            ++cycle)\n         {\n           std::cout << \"  Cycle \" << cycle << ':' << std::endl;\n   \n           if (cycle == 0)\n             {\n               GridGenerator::hyper_cube_with_cylindrical_hole(triangulation,\n                                                               0.3,\n                                                               1.0);\n   \n               const SphericalManifold<dim> manifold_description(Point<dim>(0, 0));\n               triangulation.set_manifold(1, manifold_description);\n             }\n   \n           triangulation.refine_global();\n   \n           setup_system();\n   \n           std::cout << \"     Number of active cells:       \"\n                     << triangulation.n_active_cells() << \" (\"\n                     << triangulation.n_levels() << \" levels)\" << std::endl;\n           std::cout << \"     Number of degrees of freedom: \"\n                     << dof_handler.n_dofs() << std::endl;\n   \n           assemble_system_and_multigrid();\n   \n           solve();\n   \n           if (settings.output)\n             output_results(cycle);\n   \n           std::cout << std::endl;\n         }\n     }\n   } // namespace Step63\n```\n\n### The `main` function\n\nFinally, the main function is like most tutorials. The only interesting bit is that we require the user to pass a `.prm` file as a sole command line argument. If no parameter file is given, the program will output the contents of a sample parameter file with all default values to the screen that the user can then copy and paste into their own `.prm` file.\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         Step63::Settings settings;\n         settings.get_parameters((argc > 1) ? (argv[1]) : \"\");\n   \n         Step63::AdvectionProblem<2> advection_problem_2d(settings);\n         advection_problem_2d.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### GMRES Iteration Numbers\n\nThe major advantage for GMG is that it is an \\(\\mathcal{O}(n)\\) method, that is, the complexity of the problem increases linearly with the problem size. To show then that the linear solver presented in this tutorial is in fact \\(\\mathcal{O}(n)\\), all one needs to do is show that the iteration counts for the GMRES solve stay roughly constant as we refine the mesh.\n\nEach of the following tables gives the GMRES iteration counts to reduce the initial residual by a factor of \\(10^8\\). We selected a sufficient number of smoothing steps (based on the method) to get iteration numbers independent of mesh size. As can be seen from the tables below, the method is indeed \\(\\mathcal{O}(n)\\).\n\n#### DoF/Cell Renumbering\n\nThe point-wise smoothers (\"Jacobi\" and \"SOR\") get applied in the order the DoFs are numbered on each level. We can influence this using the [DoFRenumbering](namespaceDoFRenumbering.html) namespace. The block smoothers are applied based on the ordering we set in `setup_smoother()`. We can visualize this numbering. The following pictures show the cell numbering of the active cells in downstream, random, and upstream numbering (left to right):\n\n![](images/steps/developer/step-63-cell-order.png)\n\nLet us start with the additive smoothers. The following table shows the number of iterations necessary to obtain convergence from GMRES:\n\n|  |  | \\(Q\\_1\\) | Smoother (smoothing steps) | | | | | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  |  |  | Jacobi (6) | | |  | Block Jacobi (3) | | |\n|  |  |  | Renumbering Strategy | | |  | Renumbering Strategy | | |\n| Cells |  | DoFs | Downstream | Random | Upstream |  | Downstream | Random | Upstream |\n| 32 |  | 48 | 3 | 3 | 3 |  | 3 | 3 | 3 |\n| 128 |  | 160 | 6 | 6 | 6 |  | 6 | 6 | 6 |\n| 512 |  | 576 | 11 | 11 | 11 |  | 9 | 9 | 9 |\n| 2048 |  | 2176 | 15 | 15 | 15 |  | 13 | 13 | 13 |\n| 8192 |  | 8448 | 18 | 18 | 18 |  | 15 | 15 | 15 |\n| 32768 |  | 33280 | 20 | 20 | 20 |  | 16 | 16 | 16 |\n| 131072 |  | 132096 | 20 | 20 | 20 |  | 16 | 16 | 16 |\n\nWe see that renumbering the DoFs/cells has no effect on convergence speed. This is because these smoothers compute operations on each DoF (point-smoother) or cell (block-smoother) independently and add up the results. Since we can define these smoothers as an application of a sum of matrices, and matrix addition is commutative, the order at which we sum the different components will not affect the end result.\n\nOn the other hand, the situation is different for multiplicative smoothers:\n\n|  |  | \\(Q\\_1\\) | Smoother (smoothing steps) | | | | | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  |  |  | SOR (3) | | |  | Block SOR (1) | | |\n|  |  |  | Renumbering Strategy | | |  | Renumbering Strategy | | |\n| Cells |  | DoFs | Downstream | Random | Upstream |  | Downstream | Random | Upstream |\n| 32 |  | 48 | 2 | 2 | 3 |  | 2 | 2 | 3 |\n| 128 |  | 160 | 5 | 5 | 7 |  | 5 | 5 | 7 |\n| 512 |  | 576 | 7 | 9 | 11 |  | 7 | 7 | 12 |\n| 2048 |  | 2176 | 10 | 12 | 15 |  | 8 | 10 | 17 |\n| 8192 |  | 8448 | 11 | 15 | 19 |  | 10 | 11 | 20 |\n| 32768 |  | 33280 | 12 | 16 | 20 |  | 10 | 12 | 21 |\n| 131072 |  | 132096 | 12 | 16 | 19 |  | 11 | 12 | 21 |\n\nHere, we can speed up convergence by renumbering the DoFs/cells in the advection direction, and similarly, we can slow down convergence if we do the renumbering in the opposite direction. This is because advection-dominated problems have a directional flow of information (in the advection direction) which, given the right renumbering of DoFs/cells, multiplicative methods are able to capture.\n\nThis feature of multiplicative methods is, however, dependent on the value of \\(\\varepsilon\\). As we increase \\(\\varepsilon\\) and the problem becomes more diffusion-dominated, we have a more uniform propagation of information over the mesh and there is a diminished advantage for renumbering in the advection direction. On the opposite end, in the extreme case of \\(\\varepsilon=0\\) (advection-only), we have a 1st-order PDE and multiplicative methods with the right renumbering become effective solvers: A correct downstream numbering may lead to methods that require only a single iteration because information can be propagated from the inflow boundary downstream, with no information transport in the opposite direction. (Note, however, that in the case of \\(\\varepsilon=0\\), special care must be taken for the boundary conditions in this case).\n\n#### Point vs. block smoothers\n\nWe will limit the results to runs using the downstream renumbering. Here is a cross comparison of all four smoothers for both \\(Q\\_1\\) and \\(Q\\_3\\) elements:\n\n|  |  |  |  |  |  |  |  |  |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  |  | \\(Q\\_1\\) | Smoother (smoothing steps) | | | |  | \\(Q\\_3\\) | Smoother (smoothing steps) | | | |\n| Cells |  | DoFs | Jacobi (6) | Block Jacobi (3) | SOR (3) | Block SOR (1) |  | DoFs | Jacobi (6) | Block Jacobi (3) | SOR (3) | Block SOR (1) |\n| 32 |  | 48 | 3 | 3 | 2 | 2 |  | 336 | 15 | 14 | 15 | 6 |\n| 128 |  | 160 | 6 | 6 | 5 | 5 |  | 1248 | 23 | 18 | 21 | 9 |\n| 512 |  | 576 | 11 | 9 | 7 | 7 |  | 4800 | 29 | 21 | 28 | 9 |\n| 2048 |  | 2176 | 15 | 13 | 10 | 8 |  | 18816 | 33 | 22 | 32 | 9 |\n| 8192 |  | 8448 | 18 | 15 | 11 | 10 |  | 74496 | 35 | 22 | 34 | 10 |\n| 32768 |  | 33280 | 20 | 16 | 12 | 10 |  |\n| 131072 |  | 132096 | 20 | 16 | 12 | 11 |  |\n\nWe see that for \\(Q\\_1\\), both multiplicative smoothers require a smaller combination of smoothing steps and iteration counts than either additive smoother. However, when we increase the degree to a \\(Q\\_3\\) element, there is a clear advantage for the block smoothers in terms of the number of smoothing steps and iterations required to solve. Specifically, the block SOR smoother gives constant iteration counts over the degree, and the block Jacobi smoother only sees about a 38% increase in iterations compared to 75% and 183% for Jacobi and SOR respectively.\n\n### Cost\n\nIteration counts do not tell the full story in the optimality of a one smoother over another. Obviously we must examine the cost of an iteration. Block smoothers here are at a disadvantage as they are having to construct and invert a cell matrix for each cell. Here is a comparison of solve times for a \\(Q\\_3\\) element with 74,496 DoFs:\n\n| \\(Q\\_3\\) | Smoother (smoothing steps) | | | |\n| --- | --- | --- | --- | --- |\n| DoFs | Jacobi (6) | Block Jacobi (3) | SOR (3) | Block SOR (1) |\n| 74496 | 0.68s | 5.82s | 1.18s | 1.02s |\n\nThe smoother that requires the most iterations (Jacobi) actually takes the shortest time (roughly 2/3 the time of the next fastest method). This is because all that is required to apply a Jacobi smoothing step is multiplication by a diagonal matrix which is very cheap. On the other hand, while SOR requires over 3x more iterations (each with 3x more smoothing steps) than block SOR, the times are roughly equivalent, implying that a smoothing step of block SOR is roughly 9x slower than a smoothing step of SOR. Lastly, block Jacobi is almost 6x more expensive than block SOR, which intuitively makes sense from the fact that 1 step of each method has the same cost (inverting the cell matrices and either adding or multiply them together), and block Jacobi has 3 times the number of smoothing steps per iteration with 2 times the iterations.\n\n### Additional points\n\nThere are a few more important points to mention:\n\n1. For a mesh distributed in parallel, multiplicative methods cannot be executed over the entire domain. This is because they operate one cell at a time, and downstream cells can only be handled once upstream cells have already been done. This is fine on a single processor: The processor just goes through the list of cells one after the other. However, in parallel, it would imply that some processors are idle because upstream processors have not finished doing the work on cells upstream from the ones owned by the current processor. Once the upstream processors are done, the downstream ones can start, but by that time the upstream processors have no work left. In other words, most of the time during these smoother steps, most processors are in fact idle. This is not how one obtains good parallel scalability!\n\n   One can use a hybrid method where a multiplicative smoother is applied on each subdomain, but as you increase the number of subdomains, the method approaches the behavior of an additive method. This is a major disadvantage to these methods.\n2. Current research into block smoothers suggest that soon we will be able to compute the inverse of the cell matrices much cheaper than what is currently being done inside deal.II. This research is based on the fast diagonalization method (dating back to the 1960s) and has been used in the spectral community for around 20 years (see, e.g., [Hybrid Multigrid/Schwarz Algorithms for the Spectral Element Method by Lottes and Fischer](https://doi.org/10.1007/s10915-004-4787-3)). There are currently efforts to generalize these methods to DG and make them more robust. Also, it seems that one should be able to take advantage of matrix-free implementations and the fact that, in the interior of the domain, cell matrices tend to look very similar, allowing fewer matrix inverse computations.\n\nCombining 1. and 2. gives a good reason for expecting that a method like block Jacobi could become very powerful in the future, even though currently for these examples it is quite slow.\n\n### Possibilities for extensions\n\n#### Constant iterations for Q5\n\nChange the number of smoothing steps and the smoother relaxation parameter (set in `Smoother::AdditionalData()` inside `create_smoother()`, only necessary for point smoothers) so that we maintain a constant number of iterations for a \\(Q\\_5\\) element.\n\n#### Effectiveness of renumbering for changing epsilon\n\nIncrease/decrease the parameter \"Epsilon\" in the `.prm` files of the multiplicative methods and observe for which values renumbering no longer influences convergence speed.\n\n#### Mesh adaptivity\n\nThe code is set up to work correctly with an adaptively refined mesh (the interface matrices are created and set). Devise a suitable refinement criterium or try the [KellyErrorEstimator](classKellyErrorEstimator.html) class.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2018 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Thomas C. Clevenger, Clemson University\n *          Timo Heister, Clemson University and University of Utah\n */\n \n \n#include <deal.II/base/tensor_function.h>\n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/timer.h>\n#include <deal.II/base/parameter_handler.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/vector.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/solver_gmres.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/relaxation_block.h>\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n#include <deal.II/grid/manifold_lib.h>\n#include <deal.II/grid/grid_out.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/mapping_q.h>\n#include <deal.II/fe/fe_values.h>\n \n#include <deal.II/numerics/vector_tools.h>\n#include <deal.II/numerics/data_out.h>\n \n#include <deal.II/multigrid/mg_constrained_dofs.h>\n#include <deal.II/multigrid/multigrid.h>\n#include <deal.II/multigrid/mg_transfer.h>\n#include <deal.II/multigrid/mg_tools.h>\n#include <deal.II/multigrid/mg_coarse.h>\n#include <deal.II/multigrid/mg_smoother.h>\n#include <deal.II/multigrid/mg_matrix.h>\n \n#include <algorithm>\n#include <fstream>\n#include <iostream>\n#include <random>\n \n#include <deal.II/meshworker/mesh_loop.h>\n \n \n \nnamespace Step63\n{\n using namespace dealii;\n \n template <int dim>\n struct ScratchData\n  {\n    ScratchData(const FiniteElement<dim> &fe,\n const unsigned int        quadrature_degree)\n      : fe_values(fe,\n QGauss<dim>(quadrature_degree),\n update_values | update_gradients | update_hessians |\n update_quadrature_points | update_JxW_values)\n    {}\n \n    ScratchData(const ScratchData<dim> &scratch_data)\n      : fe_values(scratch_data.fe_values.get_fe(),\n                  scratch_data.fe_values.get_quadrature(),\n update_values | update_gradients | update_hessians |\n update_quadrature_points | update_JxW_values)\n    {}\n \n FEValues<dim> fe_values;\n  };\n \n \n \n struct CopyData\n  {\n    CopyData() = default;\n \n unsigned int level;\n unsigned int dofs_per_cell;\n \n FullMatrix<double> cell_matrix;\n Vector<double>                       cell_rhs;\n    std::vector<types::global_dof_index> local_dof_indices;\n  };\n \n \n \n \n struct Settings\n  {\n enum DoFRenumberingStrategy\n    {\n none,\n downstream,\n      upstream,\n random\n    };\n \n void get_parameters(const std::string &prm_filename);\n \n double epsilon;\n unsigned int           fe_degree;\n    std::string            smoother_type;\n unsigned int           smoothing_steps;\n    DoFRenumberingStrategy dof_renumbering;\n bool                   with_streamline_diffusion;\n bool                   output;\n  };\n \n \n \n void Settings::get_parameters(const std::string &prm_filename)\n  {\n /* First declare the parameters... */\n ParameterHandler prm;\n \n    prm.declare_entry(\"Epsilon\",\n \"0.005\",\n Patterns::Double(0),\n \"Diffusion parameter\");\n \n    prm.declare_entry(\"Fe degree\",\n \"1\",\n Patterns::Integer(1),\n \"Finite Element degree\");\n    prm.declare_entry(\"Smoother type\",\n \"block SOR\",\n Patterns::Selection(\"SOR|Jacobi|block SOR|block Jacobi\"),\n \"Select smoother: SOR|Jacobi|block SOR|block Jacobi\");\n    prm.declare_entry(\"Smoothing steps\",\n \"2\",\n Patterns::Integer(1),\n \"Number of smoothing steps\");\n    prm.declare_entry(\n \"DoF renumbering\",\n \"downstream\",\n Patterns::Selection(\"none|downstream|upstream|random\"),\n \"Select DoF renumbering: none|downstream|upstream|random\");\n    prm.declare_entry(\"With streamline diffusion\",\n \"true\",\n Patterns::Bool(),\n \"Enable streamline diffusion stabilization: true|false\");\n    prm.declare_entry(\"Output\",\n \"true\",\n Patterns::Bool(),\n \"Generate graphical output: true|false\");\n \n /* ...and then try to read their values from the input file: */\n if (prm_filename.empty())\n      {\n        prm.print_parameters(std::cout, ParameterHandler::Text);\n AssertThrow(\n false, ExcMessage(\"Please pass a .prm file as the first argument!\"));\n      }\n \n    prm.parse_input(prm_filename);\n \n epsilon         = prm.get_double(\"Epsilon\");\n    fe_degree       = prm.get_integer(\"Fe degree\");\n    smoother_type   = prm.get(\"Smoother type\");\n    smoothing_steps = prm.get_integer(\"Smoothing steps\");\n \n const std::string renumbering = prm.get(\"DoF renumbering\");\n if (renumbering == \"none\")\n      dof_renumbering = DoFRenumberingStrategy::none;\n else if (renumbering == \"downstream\")\n      dof_renumbering = DoFRenumberingStrategy::downstream;\n else if (renumbering == \"upstream\")\n      dof_renumbering = DoFRenumberingStrategy::upstream;\n else if (renumbering == \"random\")\n      dof_renumbering = DoFRenumberingStrategy::random;\n else\n AssertThrow(false,\n                  ExcMessage(\"The <DoF renumbering> parameter has \"\n \"an invalid value.\"));\n \n    with_streamline_diffusion = prm.get_bool(\"With streamline diffusion\");\n    output                    = prm.get_bool(\"Output\");\n  }\n \n \n template <int dim>\n  std::vector<unsigned int>\n  create_downstream_cell_ordering(const DoFHandler<dim> &dof_handler,\n const Tensor<1, dim>   direction,\n const unsigned int level)\n  {\n    std::vector<typename DoFHandler<dim>::level_cell_iterator> ordered_cells;\n    ordered_cells.reserve(dof_handler.get_triangulation().n_cells(level));\n for (const auto &cell : dof_handler.cell_iterators_on_level(level))\n      ordered_cells.push_back(cell);\n \n const DoFRenumbering::\n      CompareDownstream<typename DoFHandler<dim>::level_cell_iterator, dim>\n        comparator(direction);\n    std::sort(ordered_cells.begin(), ordered_cells.end(), comparator);\n \n    std::vector<unsigned> ordered_indices;\n    ordered_indices.reserve(dof_handler.get_triangulation().n_cells(level));\n \n for (const auto &cell : ordered_cells)\n      ordered_indices.push_back(cell->index());\n \n return ordered_indices;\n  }\n \n \n \n template <int dim>\n  std::vector<unsigned int>\n  create_downstream_cell_ordering(const DoFHandler<dim> &dof_handler,\n const Tensor<1, dim>   direction)\n  {\n    std::vector<typename DoFHandler<dim>::active_cell_iterator> ordered_cells;\n    ordered_cells.reserve(dof_handler.get_triangulation().n_active_cells());\n for (const auto &cell : dof_handler.active_cell_iterators())\n      ordered_cells.push_back(cell);\n \n const DoFRenumbering::\n      CompareDownstream<typename DoFHandler<dim>::active_cell_iterator, dim>\n        comparator(direction);\n    std::sort(ordered_cells.begin(), ordered_cells.end(), comparator);\n \n    std::vector<unsigned int> ordered_indices;\n    ordered_indices.reserve(dof_handler.get_triangulation().n_active_cells());\n \n for (const auto &cell : ordered_cells)\n      ordered_indices.push_back(cell->index());\n \n return ordered_indices;\n  }\n \n \n template <int dim>\n  std::vector<unsigned int>\n  create_random_cell_ordering(const DoFHandler<dim> &dof_handler,\n const unsigned int level)\n  {\n    std::vector<unsigned int> ordered_cells;\n    ordered_cells.reserve(dof_handler.get_triangulation().n_cells(level));\n for (const auto &cell : dof_handler.cell_iterators_on_level(level))\n      ordered_cells.push_back(cell->index());\n \n    std::mt19937 random_number_generator;\n    std::shuffle(ordered_cells.begin(),\n                 ordered_cells.end(),\n                 random_number_generator);\n \n return ordered_cells;\n  }\n \n \n \n template <int dim>\n  std::vector<unsigned int>\n  create_random_cell_ordering(const DoFHandler<dim> &dof_handler)\n  {\n    std::vector<unsigned int> ordered_cells;\n    ordered_cells.reserve(dof_handler.get_triangulation().n_active_cells());\n for (const auto &cell : dof_handler.active_cell_iterators())\n      ordered_cells.push_back(cell->index());\n \n    std::mt19937 random_number_generator;\n    std::shuffle(ordered_cells.begin(),\n                 ordered_cells.end(),\n                 random_number_generator);\n \n return ordered_cells;\n  }\n \n \n \n template <int dim>\n class RightHandSide : public Function<dim>\n  {\n public:\n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n \n virtual void value_list(const std::vector<Point<dim>> &points,\n                            std::vector<double>           &values,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double RightHandSide<dim>::value(const Point<dim> &,\n const unsigned int component) const\n {\n Assert(component == 0, ExcIndexRange(component, 0, 1));\n    (void)component;\n \n return 0.0;\n  }\n \n \n \n template <int dim>\n void RightHandSide<dim>::value_list(const std::vector<Point<dim>> &points,\n                                      std::vector<double>           &values,\n const unsigned int component) const\n {\n AssertDimension(values.size(), points.size());\n \n for (unsigned int i = 0; i < points.size(); ++i)\n      values[i] = RightHandSide<dim>::value(points[i], component);\n  }\n \n \n template <int dim>\n class BoundaryValues : public Function<dim>\n  {\n public:\n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n \n virtual void value_list(const std::vector<Point<dim>> &points,\n                            std::vector<double>           &values,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double BoundaryValues<dim>::value(const Point<dim>  &p,\n const unsigned int component) const\n {\n Assert(component == 0, ExcIndexRange(component, 0, 1));\n    (void)component;\n \n if (std::fabs(p[0] - 1) < 1e-8 ||\n        (std::fabs(p[1] + 1) < 1e-8 && p[0] >= 0.5))\n      {\n return 1.0;\n      }\n else\n      {\n return 0.0;\n      }\n  }\n \n \n \n template <int dim>\n void BoundaryValues<dim>::value_list(const std::vector<Point<dim>> &points,\n                                       std::vector<double>           &values,\n const unsigned int component) const\n {\n AssertDimension(values.size(), points.size());\n \n for (unsigned int i = 0; i < points.size(); ++i)\n      values[i] = BoundaryValues<dim>::value(points[i], component);\n  }\n \n \n \n \n template <int dim>\n double compute_stabilization_delta(const double         hk,\n const double         eps,\n const Tensor<1, dim> dir,\n const double         pk)\n  {\n const double Peclet = dir.norm() * hk / (2.0 * eps * pk);\n const double coth =\n      (1.0 + std::exp(-2.0 * Peclet)) / (1.0 - std::exp(-2.0 * Peclet));\n \n return hk / (2.0 * dir.norm() * pk) * (coth - 1.0 / Peclet);\n  }\n \n \n \n \n template <int dim>\n class AdvectionProblem\n  {\n public:\n    AdvectionProblem(const Settings &settings);\n void run();\n \n private:\n void setup_system();\n \n template <class IteratorType>\n void assemble_cell(const IteratorType &cell,\n                       ScratchData<dim>   &scratch_data,\n                       CopyData           &copy_data);\n void assemble_system_and_multigrid();\n \n void setup_smoother();\n \n void solve();\n void refine_grid();\n void output_results(const unsigned int cycle) const;\n \n Triangulation<dim> triangulation;\n DoFHandler<dim>    dof_handler;\n \n const FE_Q<dim>     fe;\n const MappingQ<dim> mapping;\n \n AffineConstraints<double> constraints;\n \n SparsityPattern      sparsity_pattern;\n SparseMatrix<double> system_matrix;\n \n Vector<double> solution;\n Vector<double> system_rhs;\n \n MGLevelObject<SparsityPattern> mg_sparsity_patterns;\n MGLevelObject<SparsityPattern> mg_interface_sparsity_patterns;\n \n MGLevelObject<SparseMatrix<double>> mg_matrices;\n MGLevelObject<SparseMatrix<double>> mg_interface_in;\n MGLevelObject<SparseMatrix<double>> mg_interface_out;\n \n mg::Matrix<Vector<double>> mg_matrix;\n mg::Matrix<Vector<double>> mg_interface_matrix_in;\n mg::Matrix<Vector<double>> mg_interface_matrix_out;\n \n    std::unique_ptr<MGSmoother<Vector<double>>> mg_smoother;\n \n using SmootherType =\n RelaxationBlock<SparseMatrix<double>, double, Vector<double>>;\n using SmootherAdditionalDataType = SmootherType::AdditionalData;\n MGLevelObject<SmootherAdditionalDataType> smoother_data;\n \n MGConstrainedDoFs mg_constrained_dofs;\n \n Tensor<1, dim> advection_direction;\n \n const Settings settings;\n  };\n \n \n \n template <int dim>\n  AdvectionProblem<dim>::AdvectionProblem(const Settings &settings)\n    : triangulation(Triangulation<dim>::limit_level_difference_at_vertices)\n    , dof_handler(triangulation)\n    , fe(settings.fe_degree)\n    , mapping(settings.fe_degree)\n    , settings(settings)\n  {\n    advection_direction[0] = -std::sin(numbers::PI / 6.0);\n if (dim >= 2)\n      advection_direction[1] = std::cos(numbers::PI / 6.0);\n if (dim >= 3)\n AssertThrow(false, ExcNotImplemented());\n  }\n \n \n \n template <int dim>\n void AdvectionProblem<dim>::setup_system()\n  {\n const unsigned int n_levels = triangulation.n_levels();\n \n    dof_handler.distribute_dofs(fe);\n \n    solution.reinit(dof_handler.n_dofs());\n    system_rhs.reinit(dof_handler.n_dofs());\n \n    constraints.clear();\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n \n VectorTools::interpolate_boundary_values(\n      mapping, dof_handler, 0, BoundaryValues<dim>(), constraints);\n VectorTools::interpolate_boundary_values(\n      mapping, dof_handler, 1, BoundaryValues<dim>(), constraints);\n    constraints.close();\n \n DynamicSparsityPattern dsp(dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler,\n                                    dsp,\n                                    constraints,\n /*keep_constrained_dofs = */ false);\n \n    sparsity_pattern.copy_from(dsp);\n    system_matrix.reinit(sparsity_pattern);\n \n    dof_handler.distribute_mg_dofs();\n \n if (settings.smoother_type == \"SOR\" || settings.smoother_type == \"Jacobi\")\n      {\n if (settings.dof_renumbering ==\n              Settings::DoFRenumberingStrategy::downstream ||\n            settings.dof_renumbering ==\n              Settings::DoFRenumberingStrategy::upstream)\n          {\n const Tensor<1, dim> direction =\n              (settings.dof_renumbering ==\n                   Settings::DoFRenumberingStrategy::upstream ?\n                 -1.0 :\n                 1.0) *\n              advection_direction;\n \n for (unsigned int level = 0; level < n_levels; ++level)\n DoFRenumbering::downstream(dof_handler,\n level,\n                                         direction,\n /*dof_wise_renumbering = */ true);\n          }\n else if (settings.dof_renumbering ==\n                 Settings::DoFRenumberingStrategy::random)\n          {\n for (unsigned int level = 0; level < n_levels; ++level)\n DoFRenumbering::random(dof_handler, level);\n          }\n else\n DEAL_II_NOT_IMPLEMENTED();\n      }\n \n    mg_constrained_dofs.clear();\n    mg_constrained_dofs.initialize(dof_handler);\n \n    mg_constrained_dofs.make_zero_boundary_constraints(dof_handler, {0, 1});\n \n    mg_matrices.resize(0, n_levels - 1);\n    mg_matrices.clear_elements();\n    mg_interface_in.resize(0, n_levels - 1);\n    mg_interface_in.clear_elements();\n    mg_interface_out.resize(0, n_levels - 1);\n    mg_interface_out.clear_elements();\n    mg_sparsity_patterns.resize(0, n_levels - 1);\n    mg_interface_sparsity_patterns.resize(0, n_levels - 1);\n \n for (unsigned int level = 0; level < n_levels; ++level)\n      {\n        {\n DynamicSparsityPattern dsp(dof_handler.n_dofs(level),\n                                     dof_handler.n_dofs(level));\n MGTools::make_sparsity_pattern(dof_handler, dsp, level);\n          mg_sparsity_patterns[level].copy_from(dsp);\n          mg_matrices[level].reinit(mg_sparsity_patterns[level]);\n        }\n        {\n DynamicSparsityPattern dsp(dof_handler.n_dofs(level),\n                                     dof_handler.n_dofs(level));\n MGTools::make_interface_sparsity_pattern(dof_handler,\n                                                   mg_constrained_dofs,\n                                                   dsp,\n level);\n          mg_interface_sparsity_patterns[level].copy_from(dsp);\n \n          mg_interface_in[level].reinit(mg_interface_sparsity_patterns[level]);\n          mg_interface_out[level].reinit(mg_interface_sparsity_patterns[level]);\n        }\n      }\n  }\n \n \n \n \n template <int dim>\n template <class IteratorType>\n void AdvectionProblem<dim>::assemble_cell(const IteratorType &cell,\n                                            ScratchData<dim>   &scratch_data,\n                                            CopyData           &copy_data)\n  {\n    copy_data.level = cell->level();\n \n const unsigned int dofs_per_cell =\n      scratch_data.fe_values.get_fe().n_dofs_per_cell();\n    copy_data.dofs_per_cell = dofs_per_cell;\n    copy_data.cell_matrix.reinit(dofs_per_cell, dofs_per_cell);\n \n const unsigned int n_q_points =\n      scratch_data.fe_values.get_quadrature().size();\n \n if (cell->is_level_cell() == false)\n      copy_data.cell_rhs.reinit(dofs_per_cell);\n \n    copy_data.local_dof_indices.resize(dofs_per_cell);\n    cell->get_active_or_mg_dof_indices(copy_data.local_dof_indices);\n \n    scratch_data.fe_values.reinit(cell);\n \n    RightHandSide<dim>  right_hand_side;\n    std::vector<double> rhs_values(n_q_points);\n \n    right_hand_side.value_list(scratch_data.fe_values.get_quadrature_points(),\n                               rhs_values);\n \n const double delta = (settings.with_streamline_diffusion ?\n                            compute_stabilization_delta(cell->diameter(),\n                                                        settings.epsilon,\n                                                        advection_direction,\n                                                        settings.fe_degree) :\n                            0.0);\n \n for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n        {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n            {\n              copy_data.cell_matrix(i, j) +=\n                (settings.epsilon *\n                 scratch_data.fe_values.shape_grad(i, q_point) *\n                 scratch_data.fe_values.shape_grad(j, q_point) *\n                 scratch_data.fe_values.JxW(q_point)) +\n                (scratch_data.fe_values.shape_value(i, q_point) *\n                 (advection_direction *\n                  scratch_data.fe_values.shape_grad(j, q_point)) *\n                 scratch_data.fe_values.JxW(q_point))\n                + delta *\n                    (advection_direction *\n                     scratch_data.fe_values.shape_grad(j, q_point)) *\n                    (advection_direction *\n                     scratch_data.fe_values.shape_grad(i, q_point)) *\n                    scratch_data.fe_values.JxW(q_point) -\n                delta * settings.epsilon *\n trace(scratch_data.fe_values.shape_hessian(j, q_point)) *\n                  (advection_direction *\n                   scratch_data.fe_values.shape_grad(i, q_point)) *\n                  scratch_data.fe_values.JxW(q_point);\n            }\n if (cell->is_level_cell() == false)\n            {\n              copy_data.cell_rhs(i) +=\n                scratch_data.fe_values.shape_value(i, q_point) *\n                  rhs_values[q_point] * scratch_data.fe_values.JxW(q_point)\n                + delta * rhs_values[q_point] * advection_direction *\n                    scratch_data.fe_values.shape_grad(i, q_point) *\n                    scratch_data.fe_values.JxW(q_point);\n            }\n        }\n  }\n \n \n \n \n template <int dim>\n void AdvectionProblem<dim>::assemble_system_and_multigrid()\n  {\n const auto cell_worker_active =\n      [&](const decltype(dof_handler.begin_active()) &cell,\n          ScratchData<dim>                           &scratch_data,\n          CopyData                                   &copy_data) {\n        this->assemble_cell(cell, scratch_data, copy_data);\n      };\n \n const auto copier_active = [&](const CopyData &copy_data) {\n      constraints.distribute_local_to_global(copy_data.cell_matrix,\n                                             copy_data.cell_rhs,\n                                             copy_data.local_dof_indices,\n                                             system_matrix,\n                                             system_rhs);\n    };\n \n \n MeshWorker::mesh_loop(dof_handler.begin_active(),\n                          dof_handler.end(),\n                          cell_worker_active,\n                          copier_active,\n                          ScratchData<dim>(fe, fe.degree + 1),\n                          CopyData(),\n MeshWorker::assemble_own_cells);\n \n    std::vector<AffineConstraints<double>> boundary_constraints(\n triangulation.n_global_levels());\n for (unsigned int level = 0; level < triangulation.n_global_levels();\n         ++level)\n      {\n        boundary_constraints[level].reinit(\n          dof_handler.locally_owned_mg_dofs(level),\n DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\n \n for (const types::global_dof_index dof_index :\n             mg_constrained_dofs.get_refinement_edge_indices(level))\n          boundary_constraints[level].constrain_dof_to_zero(dof_index);\n for (const types::global_dof_index dof_index :\n             mg_constrained_dofs.get_boundary_indices(level))\n          boundary_constraints[level].constrain_dof_to_zero(dof_index);\n        boundary_constraints[level].close();\n      }\n \n const auto cell_worker_mg =\n      [&](const decltype(dof_handler.begin_mg()) &cell,\n          ScratchData<dim>                       &scratch_data,\n          CopyData                               &copy_data) {\n        this->assemble_cell(cell, scratch_data, copy_data);\n      };\n \n const auto copier_mg = [&](const CopyData &copy_data) {\n      boundary_constraints[copy_data.level].distribute_local_to_global(\n        copy_data.cell_matrix,\n        copy_data.local_dof_indices,\n        mg_matrices[copy_data.level]);\n \n for (unsigned int i = 0; i < copy_data.dofs_per_cell; ++i)\n for (unsigned int j = 0; j < copy_data.dofs_per_cell; ++j)\n if (mg_constrained_dofs.is_interface_matrix_entry(\n                copy_data.level,\n                copy_data.local_dof_indices[i],\n                copy_data.local_dof_indices[j]))\n            {\n              mg_interface_out[copy_data.level].add(\n                copy_data.local_dof_indices[i],\n                copy_data.local_dof_indices[j],\n                copy_data.cell_matrix(i, j));\n              mg_interface_in[copy_data.level].add(\n                copy_data.local_dof_indices[i],\n                copy_data.local_dof_indices[j],\n                copy_data.cell_matrix(j, i));\n            }\n    };\n \n MeshWorker::mesh_loop(dof_handler.begin_mg(),\n                          dof_handler.end_mg(),\n                          cell_worker_mg,\n                          copier_mg,\n                          ScratchData<dim>(fe, fe.degree + 1),\n                          CopyData(),\n MeshWorker::assemble_own_cells);\n  }\n \n \n \n \n \n \n \n template <int dim>\n void AdvectionProblem<dim>::setup_smoother()\n  {\n if (settings.smoother_type == \"SOR\")\n      {\n using Smoother = PreconditionSOR<SparseMatrix<double>>;\n \n auto smoother =\n          std::make_unique<MGSmootherPrecondition<SparseMatrix<double>,\n                                                  Smoother,\n Vector<double>>>();\n        smoother->initialize(mg_matrices,\n                             Smoother::AdditionalData(fe.degree == 1 ? 1.0 :\n                                                                       0.62));\n        smoother->set_steps(settings.smoothing_steps);\n        mg_smoother = std::move(smoother);\n      }\n else if (settings.smoother_type == \"Jacobi\")\n      {\n using Smoother = PreconditionJacobi<SparseMatrix<double>>;\n auto smoother =\n          std::make_unique<MGSmootherPrecondition<SparseMatrix<double>,\n                                                  Smoother,\n Vector<double>>>();\n        smoother->initialize(mg_matrices,\n                             Smoother::AdditionalData(fe.degree == 1 ? 0.6667 :\n                                                                       0.47));\n        smoother->set_steps(settings.smoothing_steps);\n        mg_smoother = std::move(smoother);\n      }\n else if (settings.smoother_type == \"block SOR\" ||\n             settings.smoother_type == \"block Jacobi\")\n      {\n        smoother_data.resize(0, triangulation.n_levels() - 1);\n \n for (unsigned int level = 0; level < triangulation.n_levels(); ++level)\n          {\n DoFTools::make_cell_patches(smoother_data[level].block_list,\n                                        dof_handler,\n level);\n \n            smoother_data[level].relaxation =\n              (settings.smoother_type == \"block SOR\" ? 1.0 : 0.25);\n            smoother_data[level].inversion = PreconditionBlockBase<double>::svd;\n \n            std::vector<unsigned int> ordered_indices;\n switch (settings.dof_renumbering)\n              {\n case Settings::DoFRenumberingStrategy::downstream:\n                  ordered_indices =\n                    create_downstream_cell_ordering(dof_handler,\n                                                    advection_direction,\n level);\n break;\n \n case Settings::DoFRenumberingStrategy::upstream:\n                  ordered_indices =\n                    create_downstream_cell_ordering(dof_handler,\n                                                    -1.0 * advection_direction,\n level);\n break;\n \n case Settings::DoFRenumberingStrategy::random:\n                  ordered_indices =\n                    create_random_cell_ordering(dof_handler, level);\n break;\n \n case Settings::DoFRenumberingStrategy::none:\n break;\n \n default:\n AssertThrow(false, ExcNotImplemented());\n break;\n              }\n \n            smoother_data[level].order =\n              std::vector<std::vector<unsigned int>>(1, ordered_indices);\n          }\n \n if (settings.smoother_type == \"block SOR\")\n          {\n auto smoother = std::make_unique<MGSmootherPrecondition<\n SparseMatrix<double>,\n RelaxationBlockSOR<SparseMatrix<double>, double, Vector<double>>,\n Vector<double>>>();\n            smoother->initialize(mg_matrices, smoother_data);\n            smoother->set_steps(settings.smoothing_steps);\n            mg_smoother = std::move(smoother);\n          }\n else if (settings.smoother_type == \"block Jacobi\")\n          {\n auto smoother = std::make_unique<\n MGSmootherPrecondition<SparseMatrix<double>,\n RelaxationBlockJacobi<SparseMatrix<double>,\n                                                           double,\n Vector<double>>,\n Vector<double>>>();\n            smoother->initialize(mg_matrices, smoother_data);\n            smoother->set_steps(settings.smoothing_steps);\n            mg_smoother = std::move(smoother);\n          }\n      }\n else\n AssertThrow(false, ExcNotImplemented());\n  }\n \n \n \n \n \n template <int dim>\n void AdvectionProblem<dim>::solve()\n  {\n const unsigned int max_iters       = 200;\n const double       solve_tolerance = 1e-8 * system_rhs.l2_norm();\n SolverControl      solver_control(max_iters, solve_tolerance, true, true);\n    solver_control.enable_history_data();\n \n using Transfer = MGTransferPrebuilt<Vector<double>>;\n    Transfer mg_transfer(mg_constrained_dofs);\n    mg_transfer.build(dof_handler);\n \n FullMatrix<double> coarse_matrix;\n    coarse_matrix.copy_from(mg_matrices[0]);\n MGCoarseGridHouseholder<double, Vector<double>> coarse_grid_solver;\n    coarse_grid_solver.initialize(coarse_matrix);\n \n    setup_smoother();\n \n    mg_matrix.initialize(mg_matrices);\n    mg_interface_matrix_in.initialize(mg_interface_in);\n    mg_interface_matrix_out.initialize(mg_interface_out);\n \n Multigrid<Vector<double>> mg(\n      mg_matrix, coarse_grid_solver, mg_transfer, *mg_smoother, *mg_smoother);\n mg.set_edge_matrices(mg_interface_matrix_out, mg_interface_matrix_in);\n \n PreconditionMG<dim, Vector<double>, Transfer> preconditioner(dof_handler,\n mg,\n                                                                 mg_transfer);\n \n    std::cout << \"     Solving with GMRES to tol \" << solve_tolerance << \"...\"\n              << std::endl;\n SolverGMRES<Vector<double>> solver(\n      solver_control, SolverGMRES<Vector<double>>::AdditionalData(50, true));\n \n Timer time;\n    time.start();\n    solver.solve(system_matrix, solution, system_rhs, preconditioner);\n    time.stop();\n \n    std::cout << \"          converged in \" << solver_control.last_step()\n              << \" iterations\"\n              << \" in \" << time.last_wall_time() << \" seconds \" << std::endl;\n \n    constraints.distribute(solution);\n \n    mg_smoother.release();\n  }\n \n \n \n \n template <int dim>\n void AdvectionProblem<dim>::output_results(const unsigned int cycle) const\n {\n const unsigned int n_active_cells = triangulation.n_active_cells();\n Vector<double>     cell_indices(n_active_cells);\n    {\n      std::vector<unsigned int> ordered_indices;\n switch (settings.dof_renumbering)\n        {\n case Settings::DoFRenumberingStrategy::downstream:\n            ordered_indices =\n              create_downstream_cell_ordering(dof_handler, advection_direction);\n break;\n \n case Settings::DoFRenumberingStrategy::upstream:\n            ordered_indices =\n              create_downstream_cell_ordering(dof_handler,\n                                              -1.0 * advection_direction);\n break;\n \n case Settings::DoFRenumberingStrategy::random:\n            ordered_indices = create_random_cell_ordering(dof_handler);\n break;\n \n case Settings::DoFRenumberingStrategy::none:\n            ordered_indices.resize(n_active_cells);\n for (unsigned int i = 0; i < n_active_cells; ++i)\n              ordered_indices[i] = i;\n break;\n \n default:\n AssertThrow(false, ExcNotImplemented());\n break;\n        }\n \n for (unsigned int i = 0; i < n_active_cells; ++i)\n        cell_indices(ordered_indices[i]) = static_cast<double>(i);\n    }\n \n DataOut<dim> data_out;\n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(solution, \"solution\");\n    data_out.add_data_vector(cell_indices, \"cell_index\");\n    data_out.build_patches();\n \n const std::string filename =\n \"solution-\" + Utilities::int_to_string(cycle) + \".vtu\";\n    std::ofstream output(filename);\n    data_out.write_vtu(output);\n  }\n \n \n \n \n \n template <int dim>\n void AdvectionProblem<dim>::run()\n  {\n for (unsigned int cycle = 0; cycle < (settings.fe_degree == 1 ? 7u : 5u);\n         ++cycle)\n      {\n        std::cout << \"  Cycle \" << cycle << ':' << std::endl;\n \n if (cycle == 0)\n          {\n GridGenerator::hyper_cube_with_cylindrical_hole(triangulation,\n                                                            0.3,\n                                                            1.0);\n \n const SphericalManifold<dim> manifold_description(Point<dim>(0, 0));\n triangulation.set_manifold(1, manifold_description);\n          }\n \n triangulation.refine_global();\n \n        setup_system();\n \n        std::cout << \"     Number of active cells:       \"\n                  << triangulation.n_active_cells() << \" (\"\n                  << triangulation.n_levels() << \" levels)\" << std::endl;\n        std::cout << \"     Number of degrees of freedom: \"\n                  << dof_handler.n_dofs() << std::endl;\n \n        assemble_system_and_multigrid();\n \n        solve();\n \n if (settings.output)\n          output_results(cycle);\n \n        std::cout << std::endl;\n      }\n  }\n} // namespace Step63\n \n \n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n      Step63::Settings settings;\n      settings.get_parameters((argc > 1) ? (argv[1]) : \"\");\n \n      Step63::AdvectionProblem<2> advection_problem_2d(settings);\n      advection_problem_2d.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_64.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving a Helmholtz problem using matrix-free methods on the GPU with MPI parallelization.\nTutorial content :\nThis tutorial depends on [step-7](step_7.html), [step-37](step_37.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_64-Intro)    * [The test case](#step_64-Thetestcase)* [Moving data to and from the device](#step_64-Movingdatatoandfromthedevice)* [Matrix-vector product implementation](#step_64-Matrixvectorproductimplementation)- [The commented program](#step_64-CommProg)      * [Class `VaryingCoefficientFunctor`](#step_64-ClasscodeVaryingCoefficientFunctorcode)* [Class `HelmholtzOperatorQuad`](#step_64-ClasscodeHelmholtzOperatorQuadcode)* [Class `LocalHelmholtzOperator`](#step_64-ClasscodeLocalHelmholtzOperatorcode)* [Class `HelmholtzOperator`](#step_64-ClasscodeHelmholtzOperatorcode)* [Class `HelmholtzProblem`](#step_64-ClasscodeHelmholtzProblemcode)* [The `main()` function](#step_64-Thecodemaincodefunction) | 1. [Results](#step_64-Results)    * [Possibilities for extensions](#step_64-Possibilitiesforextensions)- [The plain program](#step_64-PlainProg) |\n\n*This program was contributed by Bruno Turcksin and Daniel Arndt, Oak Ridge National Laboratory.*\n\nIntroduction\n============\n\nThis example shows how to implement a matrix-free method on the GPU using CUDA for the Helmholtz equation with variable coefficients on a hypercube. The linear system will be solved using the conjugate gradient method and is parallelized with MPI.\n\nIn the last few years, heterogeneous computing in general and GPUs in particular have gained a lot of popularity. This is because GPUs offer better computing capabilities and memory bandwidth than CPUs for a given power budget. Among the architectures available in early 2019, GPUs are about 2x-3x as power efficient than server CPUs with wide [SIMD](https://en.wikipedia.org/wiki/SIMD) for PDE-related tasks. GPUs are also the most popular architecture for machine learning. On the other hand, GPUs are not easy to program. This program explores the deal.II capabilities to see how efficiently such a program can be implemented.\n\nWhile we have tried for the interface of the matrix-free classes for the CPU and the GPU to be as close as possible, there are a few differences. When using the matrix-free framework on a GPU, one must write some CUDA code. However, the amount is fairly small and the use of CUDA is limited to a few keywords.\n\n### The test case\n\nIn this example, we consider the Helmholtz problem\n\n\\begin{eqnarray\\*} - \\nabla \\cdot\n\\nabla u + a(\\mathbf x) u &=&1,\\\\ u &=& 0 \\quad \\text{on } \\partial \\Omega \\end{eqnarray\\*}\n\nwhere \\(a(\\mathbf x)\\) is a variable coefficient.\n\nWe choose as domain \\(\\Omega=[0,1]^3\\) and \\(a(\\mathbf x)=\\frac{10}{0.05 +\n2\\|\\mathbf x\\|^2}\\). Since the coefficient is symmetric around the origin but the domain is not, we will end up with a non-symmetric solution.\n\nIf you've made it this far into the tutorial, you will know how the weak formulation of this problem looks like and how, in principle, one assembles linear systems for it. Of course, in this program we will in fact not actually form the matrix, but rather only represent its action when one multiplies with it.\n\n### Moving data to and from the device\n\nGPUs (we will use the term \"device\" from now on to refer to the GPU) have their own memory that is separate from the memory accessible to the CPU (we will use the term \"host\" from now on). A normal calculation on the device can be divided in three separate steps:\n\n1. the data is moved from the host to the device,\n2. the computation is done on the device,\n3. the result is moved back from the device to the host\n\nThe data movements can either be done explicitly by the user code or done automatically using UVM (Unified Virtual Memory). In deal.II, only the first method is supported. While it means an extra burden for the user, this allows for better control of data movement and more importantly it avoids to mistakenly run important kernels on the host instead of the device.\n\nThe data movement in deal.II is done using [LinearAlgebra::ReadWriteVector](classLinearAlgebra_1_1ReadWriteVector.html). These vectors can be seen as buffers on the host that are used to either store data received from the device or to send data to the device. There are two types of vectors that can be used on the device:\n\n* [LinearAlgebra::CUDAWrappers::Vector](classLinearAlgebra_1_1CUDAWrappers_1_1Vector.html), which is similar to the more common Vector<Number>, and\n* [LinearAlgebra::distributed::Vector](classLinearAlgebra_1_1distributed_1_1Vector.html)<Number, [MemorySpace::CUDA](namespaceMemorySpace.html#a9cbbb82b03c2d7e2f1f8ada9e669f5f3)>, which is a regular [LinearAlgebra::distributed::Vector](classLinearAlgebra_1_1distributed_1_1Vector.html) where we have specified which memory space to use.\n\nIf no memory space is specified, the default is [MemorySpace::Host](structMemorySpace_1_1Host.html).\n\nNext, we show how to move data to/from the device using [LinearAlgebra::CUDAWrappers::Vector](classLinearAlgebra_1_1CUDAWrappers_1_1Vector.html):\n\n```\nunsigned int size = 10;\nLinearAlgebra::ReadWriteVector<double> rw_vector(size);\n \n...do something with the rw_vector...\n \n// Move the data to the device:\nLinearAlgebra::CUDAWrappers::Vector<double> vector_dev(size);\nvector_dev.import_elements(rw_vector, VectorOperations::insert);\n \n...do some computations on the device...\n \n// Move the data back to the host:\nrw_vector.import_elements(vector_dev, VectorOperations::insert);\n```\n\nBoth of the vector classes used here only work on a single machine, i.e., one memory space on a host and one on a device.\n\nBut there are cases where one wants to run a parallel computation between multiple MPI processes on a number of machines, each of which is equipped with GPUs. In that case, one wants to use `LinearAlgebra::distributed::Vector<Number,MemorySpace::CUDA>`, which is similar but the `import()` stage may involve MPI communication:\n\n```\nIndexSet locally_owned_dofs, locally_relevant_dofs;\n...fill the two IndexSet objects...\n \n// Create the ReadWriteVector using an IndexSet instead of the size\nLinearAlgebra::ReadWriteVector<double> owned_rw_vector(locally_owned_dofs);\n \n...do something with the rw_vector...\n \n// Move the data to the device:\nLinearAlgebra::distributed::Vector<double, MemorySpace::CUDA>\n  distributed_vector_dev(locally_owned_dofs, MPI_COMM_WORLD);\ndistributed_vector_dev.import_elements(owned_rw_vector, VectorOperations::insert);\n \n...do something with the dev_vector...\n \n// Create a ReadWriteVector with a different IndexSet:\nLinearAlgebra::ReadWriteVector<double>\n  relevant_rw_vector(locally_relevant_dofs);\n \n// Move the data to the host, possibly using MPI communication:\nrelevant_rw_vector.import_elements(distributed_vector_dev, VectorOperations::insert);\n```\n\nThe `relevant_rw_vector` is an object that stores a subset of all elements of the vector. Typically, these are the [locally relevant DoFs](DEALGlossary.html#GlossLocallyRelevantDof), which implies that they overlap between different MPI processes. Consequently, the elements stored in that vector on one machine may not coincide with the ones stored by the GPU on that machine, requiring MPI communication to import them.\n\nIn all of these cases, while importing a vector, values can either be inserted (using [VectorOperation::insert](structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964cae5042eefddc828c7c31e1e8e26da8b09)) or added to prior content of the vector (using [VectorOperation::add](structVectorOperation.html#a40c50779cd14ba89bbf0bd9b4561964cae1077e8dbf4afea5d2df8c8b723c0708)).\n\n### Matrix-vector product implementation\n\nThe code necessary to evaluate the matrix-free operator on the device is very similar to the one on the host. However, there are a few differences, the main ones being that the `local_apply()` function in [step-37](step_37.html) and the loop over quadrature points both need to be encapsulated in their own functors.\n\nThe commented program\n=====================\n\nFirst include the necessary files from the deal.II library known from the previous tutorials.\n\n```\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/quadrature_lib.h>\n   \n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/tria.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/la_parallel_vector.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/solver_cg.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nThe following ones include the data structures for the implementation of matrix-free methods on GPU:\n\n```\n   #include <deal.II/matrix_free/portable_fe_evaluation.h>\n   #include <deal.II/matrix_free/portable_matrix_free.h>\n   #include <deal.II/matrix_free/operators.h>\n   \n   #include <fstream>\n```\n\nAs usual, we enclose everything into a namespace of its own:\n\n```\n   namespace Step64\n   {\n     using namespace dealii;\n```\n\n### Class `VaryingCoefficientFunctor`\n\nNext, we define a class that implements the varying coefficients we want to use in the Helmholtz operator. Later, we want to pass an object of this type to a [Portable::MatrixFree](classPortable_1_1MatrixFree.html) object that expects the class to have an `operator()` that fills the values provided in the constructor for a given cell. This operator needs to run on the device, so it needs to be marked as `DEAL_II_HOST_DEVICE` for the compiler.\n\n```\n     template <int dim, int fe_degree>\n     class VaryingCoefficientFunctor\n     {\n     public:\n       VaryingCoefficientFunctor(double *coefficient)\n         : coef(coefficient)\n       {}\n   \n       DEAL_II_HOST_DEVICE void\n       operator()(const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n                  const unsigned int                                      cell,\n                  const unsigned int                                      q) const;\n```\n\nSince [Portable::MatrixFree::Data](structPortable_1_1MatrixFree_1_1Data.html) doesn't know about the size of its arrays, we need to store the number of quadrature points and the number of degrees of freedom in this class to do necessary index conversions.\n\n```\n       static const unsigned int n_dofs_1d    = fe_degree + 1;\n       static const unsigned int n_local_dofs = Utilities::pow(n_dofs_1d, dim);\n       static const unsigned int n_q_points   = Utilities::pow(n_dofs_1d, dim);\n   \n     private:\n       double *coef;\n     };\n```\n\nThe following function implements this coefficient. Recall from the introduction that we have defined it as \\(a(\\mathbf\nx)=\\frac{10}{0.05 + 2\\|\\mathbf x\\|^2}\\)\n\n```\n     template <int dim, int fe_degree>\n     DEAL_II_HOST_DEVICE void\n     VaryingCoefficientFunctor<dim, fe_degree>::operator()(\n       const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n       const unsigned int                                      cell,\n       const unsigned int                                      q) const\n     {\n       const unsigned int pos = gpu_data->local_q_point_id(cell, n_q_points, q);\n       const Point<dim>   q_point = gpu_data->get_quadrature_point(cell, q);\n   \n       double p_square = 0.;\n       for (unsigned int i = 0; i < dim; ++i)\n         {\n           const double coord = q_point[i];\n           p_square += coord * coord;\n         }\n       coef[pos] = 10. / (0.05 + 2. * p_square);\n     }\n```\n\n### Class `HelmholtzOperatorQuad`\n\nThe class `HelmholtzOperatorQuad` implements the evaluation of the Helmholtz operator at each quadrature point. It uses a similar mechanism as the [MatrixFree](classMatrixFree.html) framework introduced in [step-37](step_37.html). In contrast to there, the actual quadrature point index is treated implicitly by converting the current thread index. As before, the functions of this class need to run on the device, so need to be marked as `DEAL_II_HOST_DEVICE` for the compiler.\n\n```\n     template <int dim, int fe_degree>\n     class HelmholtzOperatorQuad\n     {\n     public:\n       DEAL_II_HOST_DEVICE HelmholtzOperatorQuad(\n         const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n         double                                                 *coef,\n         int                                                     cell)\n         : gpu_data(gpu_data)\n         , coef(coef)\n         , cell(cell)\n       {}\n   \n       DEAL_II_HOST_DEVICE void operator()(\n         Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> *fe_eval,\n         const int q_point) const;\n   \n       static const unsigned int n_q_points =\n         ::Utilities::pow(fe_degree + 1, dim);\n   \n     private:\n       const typename Portable::MatrixFree<dim, double>::Data *gpu_data;\n       double                                                 *coef;\n       int                                                     cell;\n     };\n```\n\nThe Helmholtz problem we want to solve here reads in weak form as follows:\n\n\\begin{eqnarray\\*}\n(\\nabla v, \\nabla u)+ (v, a(\\mathbf x) u) &=&(v,1) \\quad \\forall v.\n\\end{eqnarray\\*}\n\nIf you have seen [step-37](step_37.html), then it will be obvious that the two terms on the left-hand side correspond to the two function calls here:\n\n```\n     template <int dim, int fe_degree>\n     DEAL_II_HOST_DEVICE void HelmholtzOperatorQuad<dim, fe_degree>::operator()(\n       Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> *fe_eval,\n       const int q_point) const\n     {\n       const unsigned int pos =\n         gpu_data->local_q_point_id(cell, n_q_points, q_point);\n   \n       fe_eval->submit_value(coef[pos] * fe_eval->get_value(q_point), q_point);\n       fe_eval->submit_gradient(fe_eval->get_gradient(q_point), q_point);\n     }\n```\n\n### Class `LocalHelmholtzOperator`\n\nFinally, we need to define a class that implements the whole operator evaluation that corresponds to a matrix-vector product in matrix-based approaches.\n\n```\n     template <int dim, int fe_degree>\n     class LocalHelmholtzOperator\n     {\n     public:\n```\n\nAgain, the [Portable::MatrixFree](classPortable_1_1MatrixFree.html) object doesn't know about the number of degrees of freedom and the number of quadrature points so we need to store these for index calculations in the call operator.\n\n```\n       static constexpr unsigned int n_dofs_1d = fe_degree + 1;\n       static constexpr unsigned int n_local_dofs =\n         Utilities::pow(fe_degree + 1, dim);\n       static constexpr unsigned int n_q_points =\n         Utilities::pow(fe_degree + 1, dim);\n   \n       LocalHelmholtzOperator(double *coefficient)\n         : coef(coefficient)\n       {}\n   \n       DEAL_II_HOST_DEVICE void\n       operator()(const unsigned int                                      cell,\n                  const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n                  Portable::SharedData<dim, double> *shared_data,\n                  const double                      *src,\n                  double                            *dst) const;\n   \n     private:\n       double *coef;\n     };\n```\n\nThis is the call operator that performs the Helmholtz operator evaluation on a given cell similar to the [MatrixFree](classMatrixFree.html) framework on the CPU. In particular, we need access to both values and gradients of the source vector and we write value and gradient information to the destination vector.\n\n```\n     template <int dim, int fe_degree>\n     DEAL_II_HOST_DEVICE void LocalHelmholtzOperator<dim, fe_degree>::operator()(\n       const unsigned int                                      cell,\n       const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n       Portable::SharedData<dim, double>                      *shared_data,\n       const double                                           *src,\n       double                                                 *dst) const\n     {\n       Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> fe_eval(\n         gpu_data, shared_data);\n       fe_eval.read_dof_values(src);\n       fe_eval.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n       fe_eval.apply_for_each_quad_point(\n         HelmholtzOperatorQuad<dim, fe_degree>(gpu_data, coef, cell));\n       fe_eval.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\n       fe_eval.distribute_local_to_global(dst);\n     }\n```\n\n### Class `HelmholtzOperator`\n\nThe `HelmholtzOperator` class acts as wrapper for `LocalHelmholtzOperator` defining an interface that can be used with linear solvers like [SolverCG](classSolverCG.html). In particular, like every class that implements the interface of a linear operator, it needs to have a `vmult()` function that performs the action of the linear operator on a source vector.\n\n```\n     template <int dim, int fe_degree>\n     class HelmholtzOperator\n     {\n     public:\n       HelmholtzOperator(const DoFHandler<dim>           &dof_handler,\n                         const AffineConstraints<double> &constraints);\n   \n       void\n       vmult(LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &dst,\n             const LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n               &src) const;\n   \n       void initialize_dof_vector(\n         LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &vec)\n         const;\n   \n     private:\n       Portable::MatrixFree<dim, double>                                mf_data;\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Default> coef;\n     };\n```\n\nThe following is the implementation of the constructor of this class. In the first part, we initialize the `mf_data` member variable that is going to provide us with the necessary information when evaluating the operator.\n\nIn the second half, we need to store the value of the coefficient for each quadrature point in every active, locally owned cell. We can ask the parallel triangulation for the number of active, locally owned cells but only have a [DoFHandler](classDoFHandler.html) object at hand. Since [DoFHandler::get\\_triangulation()](classDoFHandler.html#a6b34912e24edd20b7dee84dd9a7f4acd) returns a [Triangulation](classTriangulation.html) object, not a [parallel::TriangulationBase](classparallel_1_1TriangulationBase.html) object, we have to downcast the return value. This is safe to do here because we know that the triangulation is a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) object in fact.\n\n```\n     template <int dim, int fe_degree>\n     HelmholtzOperator<dim, fe_degree>::HelmholtzOperator(\n       const DoFHandler<dim>           &dof_handler,\n       const AffineConstraints<double> &constraints)\n     {\n       MappingQ<dim> mapping(fe_degree);\n       typename Portable::MatrixFree<dim, double>::AdditionalData additional_data;\n       additional_data.mapping_update_flags = update_values | update_gradients |\n                                              update_JxW_values |\n                                              update_quadrature_points;\n       const QGauss<1> quad(fe_degree + 1);\n       mf_data.reinit(mapping, dof_handler, constraints, quad, additional_data);\n   \n   \n       const unsigned int n_owned_cells =\n         dynamic_cast<const parallel::TriangulationBase<dim> *>(\n           &dof_handler.get_triangulation())\n           ->n_locally_owned_active_cells();\n       coef.reinit(Utilities::pow(fe_degree + 1, dim) * n_owned_cells);\n   \n       const VaryingCoefficientFunctor<dim, fe_degree> functor(coef.get_values());\n       mf_data.evaluate_coefficients(functor);\n     }\n```\n\nThe key step then is to use all of the previous classes to loop over all cells to perform the matrix-vector product. We implement this in the next function.\n\nWhen applying the Helmholtz operator, we have to be careful to handle boundary conditions correctly. Since the local operator doesn't know about constraints, we have to copy the correct values from the source to the destination vector afterwards.\n\n```\n     template <int dim, int fe_degree>\n     void HelmholtzOperator<dim, fe_degree>::vmult(\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Default>       &dst,\n       const LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &src)\n       const\n     {\n       dst = 0.;\n       LocalHelmholtzOperator<dim, fe_degree> helmholtz_operator(\n         coef.get_values());\n       mf_data.cell_loop(helmholtz_operator, src, dst);\n       mf_data.copy_constrained_values(src, dst);\n     }\n   \n   \n   \n     template <int dim, int fe_degree>\n     void HelmholtzOperator<dim, fe_degree>::initialize_dof_vector(\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &vec) const\n     {\n       mf_data.initialize_dof_vector(vec);\n     }\n```\n\n### Class `HelmholtzProblem`\n\nThis is the main class of this program. It defines the usual framework we use for tutorial programs. The only point worth commenting on is the `solve()` function and the choice of vector types.\n\n```\n     template <int dim, int fe_degree>\n     class HelmholtzProblem\n     {\n     public:\n       HelmholtzProblem();\n   \n       void run();\n   \n     private:\n       void setup_system();\n   \n       void assemble_rhs();\n   \n       void solve();\n   \n       void output_results(const unsigned int cycle) const;\n   \n       MPI_Comm mpi_communicator;\n   \n       parallel::distributed::Triangulation<dim> triangulation;\n   \n       const FE_Q<dim> fe;\n       DoFHandler<dim> dof_handler;\n   \n       IndexSet locally_owned_dofs;\n       IndexSet locally_relevant_dofs;\n   \n       AffineConstraints<double>                          constraints;\n       std::unique_ptr<HelmholtzOperator<dim, fe_degree>> system_matrix_dev;\n```\n\nSince all the operations in the `solve()` function are executed on the graphics card, it is necessary for the vectors used to store their values on the GPU as well. [LinearAlgebra::distributed::Vector](classLinearAlgebra_1_1distributed_1_1Vector.html) can be told which memory space to use. There is also [LinearAlgebra::CUDAWrappers::Vector](classLinearAlgebra_1_1CUDAWrappers_1_1Vector.html) that always uses GPU memory storage but doesn't work with MPI. It might be worth noticing that the communication between different MPI processes can be improved if the MPI implementation is GPU-aware and the configure flag `DEAL_II_MPI_WITH_DEVICE_SUPPORT` is enabled. (The value of this flag needs to be set at the time you call `cmake` when installing deal.II.)\n\nIn addition, we also keep a solution vector with CPU storage such that we can view and display the solution as usual.\n\n```\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Host>\n         ghost_solution_host;\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n         solution_dev;\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n         system_rhs_dev;\n   \n       ConditionalOStream pcout;\n     };\n```\n\nThe implementation of all the remaining functions of this class apart from `Helmholtzproblem::solve()` doesn't contain anything new and we won't further comment much on the overall approach.\n\n```\n     template <int dim, int fe_degree>\n     HelmholtzProblem<dim, fe_degree>::HelmholtzProblem()\n       : mpi_communicator(MPI_COMM_WORLD)\n       , triangulation(mpi_communicator)\n       , fe(fe_degree)\n       , dof_handler(triangulation)\n       , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n     {}\n   \n   \n   \n     template <int dim, int fe_degree>\n     void HelmholtzProblem<dim, fe_degree>::setup_system()\n     {\n       dof_handler.distribute_dofs(fe);\n   \n       locally_owned_dofs = dof_handler.locally_owned_dofs();\n       locally_relevant_dofs =\n         DoFTools::extract_locally_relevant_dofs(dof_handler);\n       system_rhs_dev.reinit(locally_owned_dofs, mpi_communicator);\n   \n       constraints.clear();\n       constraints.reinit(locally_owned_dofs, locally_relevant_dofs);\n       DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n       VectorTools::interpolate_boundary_values(dof_handler,\n                                                0,\n                                                Functions::ZeroFunction<dim>(),\n                                                constraints);\n       constraints.close();\n   \n       system_matrix_dev.reset(\n         new HelmholtzOperator<dim, fe_degree>(dof_handler, constraints));\n   \n       ghost_solution_host.reinit(locally_owned_dofs,\n                                  locally_relevant_dofs,\n                                  mpi_communicator);\n       system_matrix_dev->initialize_dof_vector(solution_dev);\n       system_rhs_dev.reinit(solution_dev);\n     }\n```\n\nUnlike programs such as [step-4](step_4.html) or [step-6](step_6.html), we will not have to assemble the whole linear system but only the right hand side vector. This looks in essence like we did in [step-4](step_4.html), for example, but we have to pay attention to using the right constraints object when copying local contributions into the global vector. In particular, we need to make sure the entries that correspond to boundary nodes are properly zeroed out. This is necessary for CG to converge. (Another solution would be to modify the `vmult()` function above in such a way that we pretend the source vector has zero entries by just not taking them into account in matrix-vector products. But the approach used here is simpler.)\n\nAt the end of the function, we can't directly copy the values from the host to the device but need to use an intermediate object of type [LinearAlgebra::ReadWriteVector](classLinearAlgebra_1_1ReadWriteVector.html) to construct the correct communication pattern necessary.\n\n```\n     template <int dim, int fe_degree>\n     void HelmholtzProblem<dim, fe_degree>::assemble_rhs()\n     {\n       LinearAlgebra::distributed::Vector<double, MemorySpace::Host>\n                         system_rhs_host(locally_owned_dofs,\n                         locally_relevant_dofs,\n                         mpi_communicator);\n       const QGauss<dim> quadrature_formula(fe_degree + 1);\n   \n       FEValues<dim> fe_values(fe,\n                               quadrature_formula,\n                               update_values | update_quadrature_points |\n                                 update_JxW_values);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       Vector<double> cell_rhs(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             cell_rhs = 0;\n   \n             fe_values.reinit(cell);\n   \n             for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n               {\n                 for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                   cell_rhs(i) += (fe_values.shape_value(i, q_index) * 1.0 *\n                                   fe_values.JxW(q_index));\n               }\n   \n             cell->get_dof_indices(local_dof_indices);\n             constraints.distribute_local_to_global(cell_rhs,\n                                                    local_dof_indices,\n                                                    system_rhs_host);\n           }\n       system_rhs_host.compress(VectorOperation::add);\n   \n       LinearAlgebra::ReadWriteVector<double> rw_vector(locally_owned_dofs);\n       rw_vector.import_elements(system_rhs_host, VectorOperation::insert);\n       system_rhs_dev.import_elements(rw_vector, VectorOperation::insert);\n     }\n```\n\nThis solve() function finally contains the calls to the new classes previously discussed. Here we don't use any preconditioner, i.e., precondition by the identity matrix, to focus just on the peculiarities of the [Portable::MatrixFree](classPortable_1_1MatrixFree.html) framework. Of course, in a real application the choice of a suitable preconditioner is crucial but we have at least the same restrictions as in [step-37](step_37.html) since matrix entries are computed on the fly and not stored.\n\nAfter solving the linear system in the first part of the function, we copy the solution from the device to the host to be able to view its values and display it in `output_results()`. This transfer works the same as at the end of the previous function.\n\n```\n     template <int dim, int fe_degree>\n     void HelmholtzProblem<dim, fe_degree>::solve()\n     {\n       PreconditionIdentity preconditioner;\n   \n       SolverControl solver_control(system_rhs_dev.size(),\n                                    1e-12 * system_rhs_dev.l2_norm());\n       SolverCG<LinearAlgebra::distributed::Vector<double, MemorySpace::Default>>\n         cg(solver_control);\n       cg.solve(*system_matrix_dev, solution_dev, system_rhs_dev, preconditioner);\n   \n       pcout << \"  Solved in \" << solver_control.last_step() << \" iterations.\"\n             << std::endl;\n   \n       LinearAlgebra::ReadWriteVector<double> rw_vector(locally_owned_dofs);\n       rw_vector.import_elements(solution_dev, VectorOperation::insert);\n       ghost_solution_host.import_elements(rw_vector, VectorOperation::insert);\n   \n       constraints.distribute(ghost_solution_host);\n   \n       ghost_solution_host.update_ghost_values();\n     }\n```\n\nThe output results function is as usual since we have already copied the values back from the GPU to the CPU.\n\nWhile we're already doing something with the function, we might as well compute the \\(L\\_2\\) norm of the solution. We do this by calling [VectorTools::integrate\\_difference()](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). That function is meant to compute the error by evaluating the difference between the numerical solution (given by a vector of values for the degrees of freedom) and an object representing the exact solution. But we can easily compute the \\(L\\_2\\) norm of the solution by passing in a zero function instead. That is, instead of evaluating the error \\(\\|u\\_h-u\\|\\_{L\\_2(\\Omega)}\\), we are just evaluating \\(\\|u\\_h-0\\|\\_{L\\_2(\\Omega)}=\\|u\\_h\\|\\_{L\\_2(\\Omega)}\\) instead.\n\n```\n     template <int dim, int fe_degree>\n     void HelmholtzProblem<dim, fe_degree>::output_results(\n       const unsigned int cycle) const\n     {\n       DataOut<dim> data_out;\n   \n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(ghost_solution_host, \"solution\");\n       data_out.build_patches();\n   \n       DataOutBase::VtkFlags flags;\n       flags.compression_level = DataOutBase::CompressionLevel::best_speed;\n       data_out.set_flags(flags);\n       data_out.write_vtu_with_pvtu_record(\n         \"./\", \"solution\", cycle, mpi_communicator, 2);\n   \n       Vector<float> cellwise_norm(triangulation.n_active_cells());\n       VectorTools::integrate_difference(dof_handler,\n                                         ghost_solution_host,\n                                         Functions::ZeroFunction<dim>(),\n                                         cellwise_norm,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::L2_norm);\n       const double global_norm =\n         VectorTools::compute_global_error(triangulation,\n                                           cellwise_norm,\n                                           VectorTools::L2_norm);\n       pcout << \"  solution norm: \" << global_norm << std::endl;\n     }\n```\n\nThere is nothing surprising in the `run()` function either. We simply compute the solution on a series of (globally) refined meshes.\n\n```\n     template <int dim, int fe_degree>\n     void HelmholtzProblem<dim, fe_degree>::run()\n     {\n       for (unsigned int cycle = 0; cycle < 7 - dim; ++cycle)\n         {\n           pcout << \"Cycle \" << cycle << std::endl;\n   \n           if (cycle == 0)\n             GridGenerator::hyper_cube(triangulation, 0., 1.);\n           triangulation.refine_global(1);\n   \n           setup_system();\n   \n           pcout << \"   Number of active cells:       \"\n                 << triangulation.n_global_active_cells() << std::endl\n                 << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n                 << std::endl;\n   \n           assemble_rhs();\n           solve();\n           output_results(cycle);\n           pcout << std::endl;\n         }\n     }\n   } // namespace Step64\n```\n\n### The `main()` function\n\nFinally for the `main()` function. By default, all the MPI ranks will try to access the device with number 0, which we assume to be the GPU device associated with the CPU on which a particular MPI rank runs. This works, but if we are running with MPI support it may be that multiple MPI processes are running on the same machine (for example, one per CPU core) and then they would all want to access the same GPU on that machine. If there is only one GPU in the machine, there is nothing we can do about it: All MPI ranks on that machine need to share it. But if there are more than one GPU, then it is better to address different graphic cards for different processes. The choice below is based on the MPI process id by assigning GPUs round robin to GPU ranks. (To work correctly, this scheme assumes that the MPI ranks on one machine are consecutive. If that were not the case, then the rank-GPU association may just not be optimal.) To make this work, MPI needs to be initialized before using this function.\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         using namespace Step64;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\n   \n         HelmholtzProblem<3, 3> helmholtz_problem;\n         helmholtz_problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nSince the main purpose of this tutorial is to demonstrate how to use the [Portable::MatrixFree](classPortable_1_1MatrixFree.html) interface, not to compute anything useful in itself, we just show the expected output here:\n\n```\nCycle 0\n   Number of active cells:       8\n   Number of degrees of freedom: 343\n  Solved in 27 iterations.\n  solution norm: 0.0205439\n \nCycle 1\n   Number of active cells:       64\n   Number of degrees of freedom: 2197\n  Solved in 60 iterations.\n  solution norm: 0.0205269\n \nCycle 2\n   Number of active cells:       512\n   Number of degrees of freedom: 15625\n  Solved in 114 iterations.\n  solution norm: 0.0205261\n \nCycle 3\n   Number of active cells:       4096\n   Number of degrees of freedom: 117649\n  Solved in 227 iterations.\n  solution norm: 0.0205261\n```\n\nOne can make two observations here: First, the norm of the numerical solution converges, presumably to the norm of the exact (but unknown) solution. And second, the number of iterations roughly doubles with each refinement of the mesh. (This is in keeping with the expectation that the number of CG iterations grows with the square root of the condition number of the matrix; and that we know that the condition number of the matrix of a second-order differential operation grows like \\({\\cal O}(h^{-2})\\).) This is of course rather inefficient, as an optimal solver would have a number of iterations that is independent of the size of the problem. But having such a solver would require using a better preconditioner than the identity matrix we have used here.\n\n### Possibilities for extensions\n\nCurrently, this program uses no preconditioner at all. This is mainly since constructing an efficient matrix-free preconditioner is non-trivial. However, simple choices just requiring the diagonal of the corresponding matrix are good candidates and these can be computed in a matrix-free way as well. Alternatively, and maybe even better, one could extend the tutorial to use multigrid with Chebyshev smoothers similar to [step-37](step_37.html).\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2019 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Bruno Turcksin, Daniel Arndt, Oak Ridge National Laboratory, 2019\n */\n \n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/quadrature_lib.h>\n \n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/tria.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/la_parallel_vector.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/solver_cg.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <deal.II/matrix_free/portable_fe_evaluation.h>\n#include <deal.II/matrix_free/portable_matrix_free.h>\n#include <deal.II/matrix_free/operators.h>\n \n#include <fstream>\n \n \nnamespace Step64\n{\n using namespace dealii;\n \n \n \n template <int dim, int fe_degree>\n class VaryingCoefficientFunctor\n  {\n public:\n    VaryingCoefficientFunctor(double *coefficient)\n      : coef(coefficient)\n    {}\n \n DEAL_II_HOST_DEVICE void\n    operator()(const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n const unsigned int                                      cell,\n const unsigned int                                      q) const;\n \n static const unsigned int n_dofs_1d    = fe_degree + 1;\n static const unsigned int n_local_dofs = Utilities::pow(n_dofs_1d, dim);\n static const unsigned int n_q_points   = Utilities::pow(n_dofs_1d, dim);\n \n private:\n double *coef;\n  };\n \n \n \n template <int dim, int fe_degree>\n DEAL_II_HOST_DEVICE void\n  VaryingCoefficientFunctor<dim, fe_degree>::operator()(\n const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n const unsigned int                                      cell,\n const unsigned int                                      q) const\n {\n const unsigned int pos = gpu_data->local_q_point_id(cell, n_q_points, q);\n const Point<dim>   q_point = gpu_data->get_quadrature_point(cell, q);\n \n double p_square = 0.;\n for (unsigned int i = 0; i < dim; ++i)\n      {\n const double coord = q_point[i];\n        p_square += coord * coord;\n      }\n    coef[pos] = 10. / (0.05 + 2. * p_square);\n  }\n \n \n \n template <int dim, int fe_degree>\n class HelmholtzOperatorQuad\n  {\n public:\n DEAL_II_HOST_DEVICE HelmholtzOperatorQuad(\n const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n double                                                 *coef,\n int                                                     cell)\n      : gpu_data(gpu_data)\n      , coef(coef)\n      , cell(cell)\n    {}\n \n DEAL_II_HOST_DEVICE void operator()(\n Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> *fe_eval,\n const int q_point) const;\n \n static const unsigned int n_q_points =\n ::Utilities::pow(fe_degree + 1, dim);\n \n private:\n const typename Portable::MatrixFree<dim, double>::Data *gpu_data;\n double                                                 *coef;\n int                                                     cell;\n  };\n \n \n template <int dim, int fe_degree>\n DEAL_II_HOST_DEVICE void HelmholtzOperatorQuad<dim, fe_degree>::operator()(\n Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> *fe_eval,\n const int q_point) const\n {\n const unsigned int pos =\n      gpu_data->local_q_point_id(cell, n_q_points, q_point);\n \n    fe_eval->submit_value(coef[pos] * fe_eval->get_value(q_point), q_point);\n    fe_eval->submit_gradient(fe_eval->get_gradient(q_point), q_point);\n  }\n \n \n \n template <int dim, int fe_degree>\n class LocalHelmholtzOperator\n  {\n public:\n static constexpr unsigned int n_dofs_1d = fe_degree + 1;\n static constexpr unsigned int n_local_dofs =\n Utilities::pow(fe_degree + 1, dim);\n static constexpr unsigned int n_q_points =\n Utilities::pow(fe_degree + 1, dim);\n \n    LocalHelmholtzOperator(double *coefficient)\n      : coef(coefficient)\n    {}\n \n DEAL_II_HOST_DEVICE void\n    operator()(const unsigned int                                      cell,\n const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n Portable::SharedData<dim, double> *shared_data,\n const double                      *src,\n double                            *dst) const;\n \n private:\n double *coef;\n  };\n \n \n template <int dim, int fe_degree>\n DEAL_II_HOST_DEVICE void LocalHelmholtzOperator<dim, fe_degree>::operator()(\n const unsigned int                                      cell,\n const typename Portable::MatrixFree<dim, double>::Data *gpu_data,\n Portable::SharedData<dim, double>                      *shared_data,\n const double                                           *src,\n double                                                 *dst) const\n {\n Portable::FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> fe_eval(\n      gpu_data, shared_data);\n    fe_eval.read_dof_values(src);\n    fe_eval.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n    fe_eval.apply_for_each_quad_point(\n      HelmholtzOperatorQuad<dim, fe_degree>(gpu_data, coef, cell));\n    fe_eval.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\n    fe_eval.distribute_local_to_global(dst);\n  }\n \n \n \n template <int dim, int fe_degree>\n class HelmholtzOperator\n  {\n public:\n    HelmholtzOperator(const DoFHandler<dim>           &dof_handler,\n const AffineConstraints<double> &constraints);\n \n void\n    vmult(LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &dst,\n const LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n            &src) const;\n \n void initialize_dof_vector(\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &vec)\n const;\n \n private:\n Portable::MatrixFree<dim, double>                                mf_data;\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default> coef;\n  };\n \n \n \n template <int dim, int fe_degree>\n  HelmholtzOperator<dim, fe_degree>::HelmholtzOperator(\n const DoFHandler<dim>           &dof_handler,\n const AffineConstraints<double> &constraints)\n  {\n MappingQ<dim> mapping(fe_degree);\n typename Portable::MatrixFree<dim, double>::AdditionalData additional_data;\n    additional_data.mapping_update_flags = update_values | update_gradients |\n update_JxW_values |\n update_quadrature_points;\n const QGauss<1> quad(fe_degree + 1);\n    mf_data.reinit(mapping, dof_handler, constraints, quad, additional_data);\n \n \n const unsigned int n_owned_cells =\n dynamic_cast<const parallel::TriangulationBase<dim> *>(\n        &dof_handler.get_triangulation())\n        ->n_locally_owned_active_cells();\n    coef.reinit(Utilities::pow(fe_degree + 1, dim) * n_owned_cells);\n \n const VaryingCoefficientFunctor<dim, fe_degree> functor(coef.get_values());\n    mf_data.evaluate_coefficients(functor);\n  }\n \n \n template <int dim, int fe_degree>\n void HelmholtzOperator<dim, fe_degree>::vmult(\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default>       &dst,\n const LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &src)\n    const\n {\n    dst = 0.;\n    LocalHelmholtzOperator<dim, fe_degree> helmholtz_operator(\n      coef.get_values());\n    mf_data.cell_loop(helmholtz_operator, src, dst);\n    mf_data.copy_constrained_values(src, dst);\n  }\n \n \n \n template <int dim, int fe_degree>\n void HelmholtzOperator<dim, fe_degree>::initialize_dof_vector(\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default> &vec) const\n {\n    mf_data.initialize_dof_vector(vec);\n  }\n \n \n \n template <int dim, int fe_degree>\n class HelmholtzProblem\n  {\n public:\n    HelmholtzProblem();\n \n void run();\n \n private:\n void setup_system();\n \n void assemble_rhs();\n \n void solve();\n \n void output_results(const unsigned int cycle) const;\n \n MPI_Comm mpi_communicator;\n \n parallel::distributed::Triangulation<dim> triangulation;\n \n const FE_Q<dim> fe;\n DoFHandler<dim> dof_handler;\n \n IndexSet locally_owned_dofs;\n IndexSet locally_relevant_dofs;\n \n AffineConstraints<double>                          constraints;\n    std::unique_ptr<HelmholtzOperator<dim, fe_degree>> system_matrix_dev;\n \n LinearAlgebra::distributed::Vector<double, MemorySpace::Host>\n      ghost_solution_host;\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n      solution_dev;\n LinearAlgebra::distributed::Vector<double, MemorySpace::Default>\n      system_rhs_dev;\n \n ConditionalOStream pcout;\n  };\n \n \n template <int dim, int fe_degree>\n  HelmholtzProblem<dim, fe_degree>::HelmholtzProblem()\n    : mpi_communicator(MPI_COMM_WORLD)\n    , triangulation(mpi_communicator)\n    , fe(fe_degree)\n    , dof_handler(triangulation)\n    , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n  {}\n \n \n \n template <int dim, int fe_degree>\n void HelmholtzProblem<dim, fe_degree>::setup_system()\n  {\n    dof_handler.distribute_dofs(fe);\n \n    locally_owned_dofs = dof_handler.locally_owned_dofs();\n    locally_relevant_dofs =\n DoFTools::extract_locally_relevant_dofs(dof_handler);\n    system_rhs_dev.reinit(locally_owned_dofs, mpi_communicator);\n \n    constraints.clear();\n    constraints.reinit(locally_owned_dofs, locally_relevant_dofs);\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                             0,\n Functions::ZeroFunction<dim>(),\n                                             constraints);\n    constraints.close();\n \n    system_matrix_dev.reset(\n new HelmholtzOperator<dim, fe_degree>(dof_handler, constraints));\n \n    ghost_solution_host.reinit(locally_owned_dofs,\n                               locally_relevant_dofs,\n                               mpi_communicator);\n    system_matrix_dev->initialize_dof_vector(solution_dev);\n    system_rhs_dev.reinit(solution_dev);\n  }\n \n \n \n template <int dim, int fe_degree>\n void HelmholtzProblem<dim, fe_degree>::assemble_rhs()\n  {\n LinearAlgebra::distributed::Vector<double, MemorySpace::Host>\n                      system_rhs_host(locally_owned_dofs,\n                      locally_relevant_dofs,\n                      mpi_communicator);\n const QGauss<dim> quadrature_formula(fe_degree + 1);\n \n FEValues<dim> fe_values(fe,\n                            quadrature_formula,\n update_values | update_quadrature_points |\n update_JxW_values);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n Vector<double> cell_rhs(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n          cell_rhs = 0;\n \n          fe_values.reinit(cell);\n \n for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n            {\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                cell_rhs(i) += (fe_values.shape_value(i, q_index) * 1.0 *\n                                fe_values.JxW(q_index));\n            }\n \n          cell->get_dof_indices(local_dof_indices);\n          constraints.distribute_local_to_global(cell_rhs,\n                                                 local_dof_indices,\n                                                 system_rhs_host);\n        }\n    system_rhs_host.compress(VectorOperation::add);\n \n LinearAlgebra::ReadWriteVector<double> rw_vector(locally_owned_dofs);\n    rw_vector.import_elements(system_rhs_host, VectorOperation::insert);\n    system_rhs_dev.import_elements(rw_vector, VectorOperation::insert);\n  }\n \n \n \n template <int dim, int fe_degree>\n void HelmholtzProblem<dim, fe_degree>::solve()\n  {\n PreconditionIdentity preconditioner;\n \n SolverControl solver_control(system_rhs_dev.size(),\n                                 1e-12 * system_rhs_dev.l2_norm());\n SolverCG<LinearAlgebra::distributed::Vector<double, MemorySpace::Default>>\n      cg(solver_control);\n    cg.solve(*system_matrix_dev, solution_dev, system_rhs_dev, preconditioner);\n \n    pcout << \"  Solved in \" << solver_control.last_step() << \" iterations.\"\n          << std::endl;\n \n LinearAlgebra::ReadWriteVector<double> rw_vector(locally_owned_dofs);\n    rw_vector.import_elements(solution_dev, VectorOperation::insert);\n    ghost_solution_host.import_elements(rw_vector, VectorOperation::insert);\n \n    constraints.distribute(ghost_solution_host);\n \n    ghost_solution_host.update_ghost_values();\n  }\n \n template <int dim, int fe_degree>\n void HelmholtzProblem<dim, fe_degree>::output_results(\n const unsigned int cycle) const\n {\n DataOut<dim> data_out;\n \n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(ghost_solution_host, \"solution\");\n    data_out.build_patches();\n \n DataOutBase::VtkFlags flags;\n    flags.compression_level = DataOutBase::CompressionLevel::best_speed;\n    data_out.set_flags(flags);\n    data_out.write_vtu_with_pvtu_record(\n \"./\", \"solution\", cycle, mpi_communicator, 2);\n \n Vector<float> cellwise_norm(triangulation.n_active_cells());\n VectorTools::integrate_difference(dof_handler,\n                                      ghost_solution_host,\n Functions::ZeroFunction<dim>(),\n                                      cellwise_norm,\n QGauss<dim>(fe.degree + 2),\n VectorTools::L2_norm);\n const double global_norm =\n VectorTools::compute_global_error(triangulation,\n                                        cellwise_norm,\n VectorTools::L2_norm);\n    pcout << \"  solution norm: \" << global_norm << std::endl;\n  }\n \n \n template <int dim, int fe_degree>\n void HelmholtzProblem<dim, fe_degree>::run()\n  {\n for (unsigned int cycle = 0; cycle < 7 - dim; ++cycle)\n      {\n        pcout << \"Cycle \" << cycle << std::endl;\n \n if (cycle == 0)\n GridGenerator::hyper_cube(triangulation, 0., 1.);\n triangulation.refine_global(1);\n \n        setup_system();\n \n        pcout << \"   Number of active cells:       \"\n              << triangulation.n_global_active_cells() << std::endl\n              << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n              << std::endl;\n \n        assemble_rhs();\n        solve();\n        output_results(cycle);\n        pcout << std::endl;\n      }\n  }\n} // namespace Step64\n \n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n using namespace Step64;\n \n Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\n \n      HelmholtzProblem<3, 3> helmholtz_problem;\n      helmholtz_problem.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_65.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nTheTransfiniteInterpolationManifoldandMappingQCacheclasses for advanced manifold operations.\nTutorial content :\nThis tutorial depends on [step-49](step_49.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_65-Intro)    * [Working with manifolds](#step_65-Workingwithmanifolds)      + [What we want](#step_65-Whatwewant)* [The class TransfiniteInterpolationManifold](#step_65-TheclassTransfiniteInterpolationManifold)        + [How it works](#step_65-Howitworks)* [Transfinite interpolation is expensive and how to deal with it](#step_65-Transfiniteinterpolationisexpensiveandhowtodealwithit)* [The test case](#step_65-Thetestcase)- [The commented program](#step_65-CommProg)      * [Include files](#step_65-Includefiles)* [Analytical solution and coefficient](#step_65-Analyticalsolutionandcoefficient)* [The PoissonProblem class](#step_65-ThePoissonProblemclass)* [Grid creation and initialization of the manifolds](#step_65-Gridcreationandinitializationofthemanifolds)* [Setup of data structures](#step_65-Setupofdatastructures)* [Assembly of the system matrix and right hand side](#step_65-Assemblyofthesystemmatrixandrighthandside)* [Solution of the linear system](#step_65-Solutionofthelinearsystem)* [Output of the solution and computation of errors](#step_65-Outputofthesolutionandcomputationoferrors)* [The PoissonProblem::run() function](#step_65-ThePoissonProblemrunfunction) | 1. [Results](#step_65-Results)    * [Program output](#step_65-Programoutput)- [The plain program](#step_65-PlainProg) |\n\n*This program was contributed by Martin Kronbichler.*\n\nIntroduction\n============\n\nThis tutorial program presents an advanced manifold class, [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html), and how to work around its main disadvantage, the relatively high cost.\n\n### Working with manifolds\n\n#### What we want\n\nIn many applications, the finite element mesh must be able to represent a relatively complex geometry. In the [step-1](step_1.html), [step-49](step_49.html), and [step-53](step_53.html) tutorial programs, some techniques to generate grids available within the deal.II library have been introduced. Given a base mesh, deal.II is then able to create a finer mesh by subdividing the cells into children, either uniformly or only in selected parts of the computational domain. Besides the basic meshing capabilities collected in the [GridGenerator](namespaceGridGenerator.html) namespace, deal.II also comes with interfaces to read in meshes generated by (quad- and hex-only) mesh generators using the functions of namespace [GridIn](classGridIn.html), as for example demonstrated in [step-5](step_5.html). A fundamental limitation of externally generated meshes is that the information provided by the generated cells in the mesh only consists of the position of the vertices and their connectivity, without the context of the underlying geometry that used to be available in the mesh generator that originally created this mesh. This becomes problematic once the mesh is refined within deal.II and additional points need to be placed. The [step-54](step_54.html) tutorial program shows how to overcome this limitation by using CAD surfaces in terms of the [OpenCASCADE](namespaceOpenCASCADE.html) library, and [step-53](step_53.html) by providing the same kind of information programmatically from within the source code.\n\nWithin deal.II, the placement of new points during mesh refinement or for the definition of higher order mappings is controlled by manifold objects, see the [manifold topic](group__manifold.html) for details. To give an example, consider the following situation of a two-dimensional annulus (with pictures taken from the manifold topic). If we start with an initial mesh of 10 cells and refine the mesh three times globally without attaching any manifolds, we would obtain the following mesh:\n\n![](hypershell-nothing.png)\n\nThe picture looks like this because, by default, deal.II only knows where to put the vertices of child cells by averaging the locations of the vertices of the parent cell. This yields a polygonal domain whose faces are the edges of the original (coarse mesh) cells. Obviously, we must attach a curved description to the boundary faces of the triangulation to reproduce the circular shape upon mesh refinement, like in the following picture:\n\n![](hypershell-boundary-only.png)\n\nThis is better: At least the inner and outer boundaries are now approaching real circles if we continue to refine the mesh. However, the mesh in this picture is still not optimal for an annulus in the sense that the *interior* lines from one cell to the next have kinks at certain vertices, and one would rather like to use the following mesh:\n\n![](hypershell-all.png)\n\nIn this last (optimal) case, which is also the default produced by [GridGenerator::hyper\\_shell()](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3), the curved manifold description (in this case a polar manifold description) is applied not only to the boundary faces, but to the whole domain. Whenever the triangulation requests a new point, e.g., the mid point of the edges or the cells when it refines a cell into four children, it will place them along the respective mid points in the polar coordinate system. By contrast, the case above where only the boundary was subject to the polar manifold, only mid points along the boundary would be placed along the curved description, whereas mid points in the interior would be computed by suitable averages of the surrounding points in the Cartesian coordinate system (see the [manifold topic](group__manifold.html) for more details).\n\nAt this point, one might assume that curved volume descriptions are the way to go. This is generally not wrong, though it is sometimes not so easy to describe how exactly this should work. Here are a couple of examples:\n\n* Imagine that the mesh above had actually been a disk, not just a ring. In that case the polar manifold degenerates at the origin and would not produce reasonable new points. In fact, defining a manifold description for things that are supposed \"to look round\" but might have points at or close to the origin is surprisingly very difficult.\n* A similar thing happens at the origin of the three-dimensional ball when one tries to attach a spherical manifold to the whole volume – in this case, the computation of new manifold points would abort with an exception.\n* CAD geometries often only describe the boundary of the domain, in a similar way to how we only attached a manifold to the boundary in the second picture above. Similarly, [step-54](step_54.html) only uses the CAD geometry to generate a surface mesh (maybe because that is what is needed to solve the problem in question), but if one wanted to solve a problem in the water or the air around the ship described there, we would need to have a volume mesh. The question is then how exactly we should describe what is supposed to happen in the interior of the domain.\n\nThese simple examples make it clear that for many interesting cases we must step back from the desire to have an analytic curved description for the full volume: There will need to be *some* kind of information that leads to curvature also in the interior, but it must be possible to do this without actually writing down an explicit formula that describes the kind of geometry.\n\nSo what happens if we don't do anything at all in the interior and only describe the surface as a manifold? Sometimes, as in the ring shown above, the result is not terrible. But sometimes it is. Consider the case of a torus (e.g. generated with [GridGenerator::torus()](namespaceGridGenerator.html#ad28d951eba1e5191f5473489f2e6fb25)) with a [TorusManifold](classTorusManifold.html) object attached to the surface only, no additional manifolds on the interior cells and faces, and with six cells in toroidal direction before refinement. If the mesh is refined once, we would obtain the following mesh, shown with the upper half of the mesh clipped away:\n\n![](torus_no_inner_manifold.png)\n\nThis is clearly sub-optimal. Indeed, if we had started with fewer than the six cells shown above in toroidal direction, the mapping actually inverts in some regions because the new points placed along interior cells intersect with the boundary as they are not following the circular shape along the toroidal direction. The simple case of a torus can still be fixed because we know that the toroidal direction follows a cylindrical coordinate system, so attaching a [TorusManifold](classTorusManifold.html) to the surface combined with [CylindricalManifold](classCylindricalManifold.html) with appropriate periodicity in toroidal direction applied to all interior entities would produce a high-quality mesh as follows, now shown with two top cells hidden:\n\n![](torus_cylindrical_inner_manifold.png)\n\nThis mesh is pretty good, but obviously it is linked to a good description of the volume, which we lack in other cases. Actually, there is an imperfection also in this case, as we can see some unnatural kinks of two adjacent cells in the interior of the domain which are hidden by the top two boundary cells, as opposed to the following setup (the default manifolds applied by [GridGenerator::torus()](namespaceGridGenerator.html#ad28d951eba1e5191f5473489f2e6fb25) and using the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html)):\n\n![](torus_transfinite_manifold.png)\n\n### The class [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html)\n\nIn order to find a better strategy, let us look at the two-dimensional disk again (that is also the base entity rotated along the toroidal direction in the torus). As we learned above, we can only apply the curved polar description to the boundary (or a rim of cells sufficiently far away from the origin) but must eventually transition to a straight description towards the disk's center. If we use a flat manifold in the interior of the cells (i.e., one in which new vertices are created by averaging of the adjacent existing ones) and a polar manifold only for the boundary of the disk, we get the following mesh upon four global refinements:\n\n![](circular_mesh_only_boundary_manifold.png)\n\nThat's not a terrible mesh. At the same time, if you know that the original coarse mesh consisted of a single square in the middle, with four caps around it, then it's not hard to see every refinement step that happened to this mesh to get the picture above.\n\nWhile the triangulation class of deal.II tries to propagate information from the boundary into the interior when creating new points, the reach of this algorithm is limited:\n\n![](circular_mesh_boundary_cells.png)\n\nThe picture above highlights those cells on the disk that are touching the boundary and where boundary information could in principle be taken into account when only looking at a single cell at the time. Clearly, the area where some curvature can be taken into account gets more limited as the mesh is refined, thus creating the seemingly irregular spots in the mesh: When computing the center of any one of the boundary cells in the leftmost picture, the ideal position is the mid point between the outer circle and the cell in the middle. This is exactly what is used for the first refinement step in the [Triangulation](classTriangulation.html) class. However, for the second refinement all interior edges as well as the interior cell layers can only add points according to a flat manifold description.\n\nAt this point, we realize what would be needed to create a better mesh: For *all* new points in *any* child cell that is created within the red shaded layer on the leftmost picture, we want to compute the interpolation with respect to the curvature in the area covered by the respective coarse cell. This is achieved by adding the class [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) to the highlighted cells of the coarse grid in the leftmost panel of the figure above. This class adheres to the general manifold interfaces, i.e., given any set of points within its domain of definition, it can compute weighted averages conforming to the manifold (using a formula that will be given in a minute). These weighted averages are used whenever the mesh is refined, or when a higher order mapping (such as [MappingQ](classMappingQ.html) or [MappingC1](classMappingC1.html)) is evaluated on a given cell subject to this manifold. Using this manifold on the shaded cells of the coarse grid of the disk (i.e., not only in the outer-most layer of cells) produces the following mesh upon four global steps of refinement:\n\n![](circular_mesh_transfinite_interpolation.png)\n\nThere are still some kinks in the lines of this mesh, but they are restricted to the faces between coarse mesh cells, whereas the rest of the mesh is about as smooth as one would like. Indeed, given a straight-sided central cell, this representation is the best possible one as all mesh cells follow a smooth transition from the straight sides in the square block in the interior to the circular shape on the boundary. (One could possibly do a bit better by allowing some curvature also in the central square block, that eventually vanishes as the center is approached.)\n\n#### How it works\n\nIn the simple case of a disk with one curved and three straight edges, we can explicitly write down how to achieve the blending of the shapes. For this, it is useful to map the physical cell, like the top one, back to the reference coordinate system \\((\\xi,\\eta)\\in (0,1)^2\\) where we compute averages between certain points. If we were to use a simple bilinear map spanned by four vertices \\((x\\_0,y\\_0), (x\\_1,y\\_1), (x\\_2,y\\_2), (x\\_3, y\\_3)\\), the image of a point \\((\\xi, \\eta)\\in (0,1)^2\\) would be\n\n\\begin{align\\*}\n(x,y) = (1-\\xi)(1-\\eta) (x\\_0,y\\_0) + \\xi(1-\\eta) (x\\_1,y\\_1) +\n(1-\\xi)\\eta (x\\_2,y\\_2) + \\xi\\eta (x\\_3,y\\_3).\n\\end{align\\*}\n\nFor the case of the curved surface, we want to modify this formula. For the top cell of the coarse mesh of the disk, we can assume that the points \\((x\\_0,y\\_0)\\) and \\((x\\_1,y\\_1)\\) sit along the straight line at the lower end and the points \\((x\\_2,y\\_2)\\) and \\((x\\_3,y\\_3)\\) are connected by a quarter circle along the top. We would then map a point \\((\\xi, \\eta)\\) as\n\n\\begin{align\\*}\n(x,y) = (1-\\eta) \\big[(1-\\xi) (x\\_0,y\\_0) + \\xi (x\\_1,y\\_1)\\big] +\n\\eta \\mathbf{c}\\_3(\\xi),\n\\end{align\\*}\n\nwhere \\(\\mathbf{c}\\_3(\\xi)\\) is a curve that describes the \\((x,y)\\) coordinates of the quarter circle in terms of an arclength parameter \\(\\xi\\in (0,1)\\). This represents a linear interpolation between the straight lower edge and the curved upper edge of the cell, and is the basis for the picture shown above.\n\nThis formula is easily generalized to the case where all four edges are described by a curve rather than a straight line. We call the four functions, parameterized by a single coordinate \\(\\xi\\) or \\(\\eta\\) in the horizontal and vertical directions, \\(\\mathbf{c}\\_0, \\mathbf{c}\\_1, \\mathbf{c}\\_2,\n\\mathbf{c}\\_3\\) for the left, right, lower, and upper edge of a quadrilateral, respectively. The interpolation then reads\n\n\\begin{align\\*}\n(x,y) =& (1-\\xi)\\mathbf{c}\\_0(\\eta) + \\xi \\mathbf{c}\\_1(\\eta)\n+(1-\\eta)\\mathbf{c}\\_2(\\xi) + \\eta \\mathbf{c}\\_3(\\xi)\\\\\n&-\\big[(1-\\xi)(1-\\eta) (x\\_0,y\\_0) + \\xi(1-\\eta) (x\\_1,y\\_1) +\n(1-\\xi)\\eta (x\\_2,y\\_2) + \\xi\\eta (x\\_3,y\\_3)\\big].\n\\end{align\\*}\n\nThis formula assumes that the boundary curves match and coincide with the vertices \\((x\\_0,y\\_0), (x\\_1,y\\_1), (x\\_2,y\\_2), (x\\_3, y\\_3)\\), e.g. \\(\\mathbf{c}\\_0(0)\n= (x\\_0,y\\_0)\\) or \\(\\mathbf{c}\\_0(1) = (x\\_2,y\\_2)\\). The subtraction of the bilinear interpolation in the second line of the formula makes sure that the prescribed curves are followed exactly on the boundary: Along each of the four edges, we need to subtract the contribution of the two adjacent edges evaluated in the corners, which is then simply a vertex position. It is easy to check that the formula for the circle above is reproduced if three of the four curves \\(\\mathbf{c}\\_i\\) are straight and thus coincide with the bilinear interpolation.\n\nThis formula, called transfinite interpolation, was introduced in 1973 by [Gordon and Hall](https://doi.org/10.1002%2Fnme.1620070405). Even though transfinite interpolation essentially only represents a linear blending of the bounding curves, the interpolation exactly follows the boundary curves for each real number \\(\\xi\\in (0,1)\\) or \\(\\eta\\in (0,1)\\), i.e., it interpolates in an infinite number of points, which was the original motivation to label this variant of interpolation a transfinite one by Gordon and Hall. Another interpretation is that the transfinite interpolation interpolates from the left and right and the top and bottom linearly, from which we need to subtract the bilinear interpolation to ensure a unit weight in the interior of the domain.\n\nThe transfinite interpolation is easily generalized to three spatial dimensions. In that case, the interpolation allows to blend 6 different surface descriptions for any of the quads of a three-dimensional cell and 12 edge descriptions for the lines of a cell. Again, to ensure a consistent map, it is necessary to subtract the contribution of edges and add the contribution of vertices again to make the curves follow the prescribed surface or edge description. In the three-dimensional case, it is also possible to use a transfinite interpolation from a curved edge both into the adjacent faces and the adjacent cells.\n\nThe interpolation of the transfinite interpolation in deal.II is general in the sense that it can deal with arbitrary curves. It will evaluate the curves in terms of their original coordinates of the \\(d\\)-dimensional space but with one (or two, in the case of edges in 3D) coordinate held fixed at \\(0\\) or \\(1\\) to ensure that any other manifold class, including CAD files if desired, can be applied out of the box. Transfinite interpolation is a standard ingredient in mesh generators, so the main strength of the integration of this feature within the deal.II library is to enable it during adaptive refinement and coarsening of the mesh, and for creating higher-degree mappings that use manifolds to insert additional points beyond the mesh vertices.\n\nAs a final remark on transfinite interpolation, we mention that the mesh refinement strategies in deal.II in absence of a volume manifold description are also based on the weights of the transfinite interpolation and optimal in that sense. The difference is that the default algorithm sees only one cell at a time, and so will apply the optimal algorithm only on those cells touching the curved manifolds. In contrast, using the transfinite mapping on entire *patches* of cells (originating from one coarser cell) allows to use the transfinite interpolation method in a way that propagates information from the boundary to cells far away.\n\n### Transfinite interpolation is expensive and how to deal with it\n\nA mesh with a transfinite manifold description is typically set up in two steps. The first step is to create a coarse mesh (or read it in from a file) and to attach a curved manifold to some of the mesh entities. For the above example of the disk, we attach a polar manifold to the faces along the outer circle (this is done automatically by [GridGenerator::hyper\\_ball()](namespaceGridGenerator.html#a533c4778cbc9bcbed365dcab42ca4418)). Before we start refining the mesh, we then assign a [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) to all interior cells and edges of the mesh, which of course needs to be based on some manifold id that we have assigned to those entities (everything except the circle on the boundary). It does not matter whether we also assign a [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) to the inner square of the disk or not because the transfinite interpolation on a coarse cell with straight edges (or flat faces in 3d) simply yields subdivided children with straight edges (flat faces).\n\nLater, when the mesh is refined or when a higher-order mapping is set up based on this mesh, the cells will query the underlying manifold object for new points. This process takes a set of surrounding points, for example the four vertices of a two-dimensional cell, and a set of weights to each of these points, for definition a new point. For the mid point of a cell, each of the four vertices would get weight 0.25. For the transfinite interpolation manifold, the process of building weighted sums requires some serious work. By construction, we want to combine the points in terms of the reference coordinates \\(\\xi\\) and \\(\\eta\\) (or \\(\\xi, \\eta, \\zeta\\) in 3D) of the surrounding points. However, the interface of the manifold classes in deal.II does not get the reference coordinates of the surrounding points (as they are not stored globally) but rather the physical coordinates only. Thus, the first step the transfinite interpolation manifold has to do is to invert the mapping and find the reference coordinates within one of the coarse cells of the transfinite interpolation (e.g. one of the four shaded coarse-grid cells of the disk mesh above). This inversion is done by a Newton iteration (or rather, finite-difference based Newton scheme combined with Broyden's method) and queries the transfinite interpolation according to the formula above several times. Each of these queries in turn might call an expensive manifold, e.g. a spherical description of a ball, and be expensive on its own. Since the [Manifold](classManifold.html) interface class of deal.II only provides a set of points, the transfinite interpolation initially does not even know to which coarse grid cell the set of surrounding points belong to and needs to search among several cells based on some heuristics. In terms of [charts](https://en.wikipedia.org/wiki/Atlas_(topology)#Charts), one could describe the implementation of the transfinite interpolation as an [atlas](https://en.wikipedia.org/wiki/Atlas_(topology))-based implementation: Each cell of the initial coarse grid of the triangulation represents a chart with its own reference space, and the surrounding manifolds provide a way to transform from the chart space (i.e., the reference cell) to the physical space. The collection of the charts of the coarse grid cells is an atlas, and as usual, the first thing one does when looking up something in an atlas is to find the right chart.\n\nOnce the reference coordinates of the surrounding points have been found, a new point in the reference coordinate system is computed by a simple weighted sum. Finally, the reference point is inserted into the formula for the transfinite interpolation, which gives the desired new point.\n\nIn a number of cases, the curved manifold is not only used during mesh refinement, but also to ensure a curved representation of boundaries within the cells of the computational domain. This is a necessity to guarantee high-order convergence for high-order polynomials on complex geometries anyway, but sometimes an accurate geometry is also desired with linear shape functions. This is often done by polynomial descriptions of the cells and called the isoparametric concept if the polynomial degree to represent the curved mesh elements is the same as the degree of the polynomials for the numerical solution. If the degree of the geometry is higher or lower than the solution, one calls that a super- or sub-parametric geometry representation, respectively. In deal.II, the standard class for polynomial representation is [MappingQ](classMappingQ.html). If, for example, this class is used with polynomial degree \\(4\\) in 3D, a total of 125 (i.e., \\((4+1)^3\\)) points are needed for the interpolation. Among these points, 8 are the cell's vertices and already available from the mesh, but the other 117 need to be provided by the manifold. In case the transfinite interpolation manifold is used, we can imagine that going through the pull-back into reference coordinates of some yet to be determined coarse cell, followed by subsequent push-forward on each of the 117 points, is a lot of work and can be very time consuming.\n\nWhat makes things worse is that the structure of many programs is such that the mapping is queried several times independently for the same cell. Its primary use is in the assembly of the linear system, i.e., the computation of the system matrix and the right hand side, via the `mapping` argument of the [FEValues](classFEValues.html) object. However, also the interpolation of boundary values, the computation of numerical errors, writing the output, and evaluation of error estimators must involve the same mapping to ensure a consistent interpretation of the solution vectors. Thus, even a linear stationary problem that is solved once will evaluate the points of the mapping several times. For the cubic case in 3D mentioned above, this means computing 117 points per cell by an expensive algorithm many times. The situation is more pressing for nonlinear or time-dependent problems where those operations are done over and over again.\n\nAs the manifold description via a transfinite interpolation can easily be hundreds of times more expensive than a similar query on a flat manifold, it makes sense to compute the additional points only once and use them in all subsequent calls. The deal.II library provides the class [MappingQCache](classMappingQCache.html) for exactly this purpose. The cache is typically not overly big compared to the memory consumed by a system matrix, as will become clear when looking at the results of this tutorial program. The usage of [MappingQCache](classMappingQCache.html) is simple: Once the mesh has been set up (or changed during refinement), we call [MappingQCache::initialize()](classMappingQCache.html#ab7c3ac515088ee08df64075954629314) with the desired triangulation as well as a desired mapping as arguments. The initialization then goes through all cells of the mesh and queries the given mapping for its additional points. Those get stored for an identifier of the cell so that they can later be returned whenever the mapping computes some quantities related to the cell (like the Jacobians of the map between the reference and physical coordinates).\n\nAs a final note, we mention that the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) also makes the refinement of the mesh more expensive. In this case, the [MappingQCache](classMappingQCache.html) does not help because it would compute points that can subsequently not be re-used; there currently does not exist a more efficient mechanism in deal.II. However, the mesh refinement contains many other expensive steps as well, so it is not as big as an issue compared to the rest of the computation. It also only happens at most once per time step or nonlinear iteration.\n\n### The test case\n\nIn this tutorial program, the usage of [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) is exemplified in combination with [MappingQCache](classMappingQCache.html). The test case is relatively simple and takes up the solution stages involved in many typical programs, e.g., the [step-6](step_6.html) tutorial program. As a geometry, we select one prototype use of [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html), namely a setup involving a spherical ball that is in turn surrounded by a cube. Such a setup would be used, for example, for a spherical inclusion embedded in a background medium, and if that inclusion has different material properties that require that the interface between the two materials needs to be tracked by element interfaces. A visualization of the grid is given here:\n\n![](images/steps/developer/step-65-mesh.png)\n\nFor this case, we want to attach a spherical description to the surface inside the domain and use the transfinite interpolation to smoothly switch to the straight lines of the outer cube and the cube at the center of the ball.\n\nWithin the program, we will follow a typical flow in finite element programs, starting from the setup of [DoFHandler](classDoFHandler.html) and sparsity patterns, the assembly of a linear system for solving the Poisson equation with a jumping coefficient, its solution with a simple iterative method, computation of some numerical error with [VectorTools::integrate\\_difference()](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b) as well as an error estimator. We record timings for each section and run the code twice. In the first run, we hand a [MappingQ](classMappingQ.html) object to each stage of the program separately, where points get re-computed over and over again. In the second run, we use [MappingQCache](classMappingQCache.html) instead.\n\nThe commented program\n=====================\n\n### Include files\n\nThe include files for this tutorial are essentially the same as in [step-6](step_6.html). Importantly, the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) class we will be using is provided by `deal.II/grid/manifold_lib.h`.\n\n```\n   #include <deal.II/base/timer.h>\n   \n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_refinement.h>\n   #include <deal.II/grid/manifold_lib.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/fe/mapping_q.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n   #include <deal.II/numerics/vector_tools.h>\n   \n   #include <fstream>\n```\n\nThe only new include file is the one for the [MappingQCache](classMappingQCache.html) class.\n\n```\n   #include <deal.II/fe/mapping_q_cache.h>\n   \n   \n   namespace Step65\n   {\n     using namespace dealii;\n```\n\n### Analytical solution and coefficient\n\nIn this tutorial program, we want to solve the Poisson equation with a coefficient that jumps along a sphere of radius 0.5, and using a constant right hand side of value \\(f(\\mathbf{x}) = -3\\). (This setup is similar to [step-5](step_5.html) and [step-6](step_6.html), but the concrete values for the coefficient and the right hand side are different.) Due to the jump in the coefficient, the analytical solution must have a kink where the coefficient switches from one value to the other. To keep things simple, we select an analytical solution that is quadratic in all components, i.e., \\(u(x,y,z) = x^2 + y^2 + z^2\\) in the ball of radius 0.5 and \\(u(x,y,z) = 0.1(x^2 + y^2 + z^2) + 0.25-0.025\\) in the outer part of the domain. This analytical solution is compatible with the right hand side in case the coefficient is 0.5 in the inner ball and 5 outside. It is also continuous along the circle of radius 0.5.\n\n```\n     template <int dim>\n     class ExactSolution : public Function<dim>\n     {\n     public:\n       virtual double value(const Point<dim> &p,\n                            const unsigned int /*component*/ = 0) const override\n       {\n         if (p.norm_square() < 0.25)\n           return p.norm_square();\n         else\n           return 0.1 * p.norm_square() + (0.25 - 0.025);\n       }\n   \n       virtual Tensor<1, dim>\n       gradient(const Point<dim> &p,\n                const unsigned int /*component*/ = 0) const override\n       {\n         if (p.norm_square() < 0.25)\n           return 2. * p;\n         else\n           return 0.2 * p;\n       }\n     };\n   \n   \n     template <int dim>\n     double coefficient(const Point<dim> &p)\n     {\n       if (p.norm_square() < 0.25)\n         return 0.5;\n       else\n         return 5.0;\n     }\n```\n\n### The PoissonProblem class\n\nThe implementation of the Poisson problem is very similar to what we used in the [step-5](step_5.html) tutorial program. The two main differences are that we pass a mapping object to the various steps in the program in order to switch between two mapping representations as explained in the introduction, and the `timer` object (of type [TimerOutput](classTimerOutput.html)) that will be used for measuring the run times in the various cases. (The concept of mapping objects was first introduced in [step-10](step_10.html) and [step-11](step_11.html), in case you want to look up the use of these classes.)\n\n```\n     template <int dim>\n     class PoissonProblem\n     {\n     public:\n       PoissonProblem();\n       void run();\n   \n     private:\n       void create_grid();\n       void setup_system(const Mapping<dim> &mapping);\n       void assemble_system(const Mapping<dim> &mapping);\n       void solve();\n       void postprocess(const Mapping<dim> &mapping);\n   \n       Triangulation<dim> triangulation;\n       const FE_Q<dim>    fe;\n       DoFHandler<dim>    dof_handler;\n   \n       AffineConstraints<double> constraints;\n       SparsityPattern           sparsity_pattern;\n       SparseMatrix<double>      system_matrix;\n       Vector<double>            solution;\n       Vector<double>            system_rhs;\n   \n       TimerOutput timer;\n     };\n```\n\nIn the constructor, we set up the timer object to record wall times but be quiet during the normal execution. We will query it for timing details in the `PoissonProblem::run()` function. Furthermore, we select a relatively high polynomial degree of three for the finite element in use.\n\n```\n     template <int dim>\n     PoissonProblem<dim>::PoissonProblem()\n       : fe(3)\n       , dof_handler(triangulation)\n       , timer(std::cout, TimerOutput::never, TimerOutput::wall_times)\n     {}\n```\n\n### Grid creation and initialization of the manifolds\n\nThe next function presents the typical usage of [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html). The first step is to create the desired grid, which can be done by composition of two grids from [GridGenerator](namespaceGridGenerator.html). The inner ball mesh is simple enough: We run [GridGenerator::hyper\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403) centered at the origin with radius 0.5 (third function argument). The second mesh is more interesting and constructed as follows: We want to have a mesh that is spherical in the interior but flat on the outer surface. Furthermore, the mesh topology of the inner ball should be compatible with the outer grid in the sense that their vertices coincide so as to allow the two grid to be merged. The grid coming out of [GridGenerator::hyper\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) fulfills the requirements on the inner side in case it is created with \\(2d\\) coarse cells (6 coarse cells in 3d which we are going to use) – this is the same number of cells as there are boundary faces for the ball. For the outer surface, we use the fact that the 6 faces on the surface of the shell without a manifold attached would degenerate to the surface of a cube. What we are still missing is the radius of the outer shell boundary. Since we desire a cube of extent \\([-1, 1]\\) and the 6-cell shell puts its 8 outer vertices at the 8 opposing diagonals, we must translate the points \\((\\pm 1, \\pm 1, \\pm 1)\\) into a radius: Clearly, the radius must be \\(\\sqrt{d}\\) in \\(d\\) dimensions, i.e., \\(\\sqrt{3}\\) for the three-dimensional case we want to consider.\n\nThus, we have a plan: After creating the inner triangulation for the ball and the one for the outer shell, we merge those two grids but remove all manifolds that the functions in [GridGenerator](namespaceGridGenerator.html) may have set from the resulting triangulation, to ensure that we have full control over manifolds. In particular, we want additional points added on the boundary during refinement to follow a flat manifold description. To start the process of adding more appropriate manifold ids, we assign the manifold id 0 to all mesh entities (cells, faces, lines), which will later be associated with the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html). Then, we must identify the faces and lines that are along the sphere of radius 0.5 and mark them with a different manifold id, so as to then assign a [SphericalManifold](classSphericalManifold.html) to those. We will choose the manifold id of 1. Since we have thrown away all manifolds that pre-existed after calling [GridGenerator::hyper\\_ball()](namespaceGridGenerator.html#a533c4778cbc9bcbed365dcab42ca4418), we manually go through the cells of the mesh and all their faces. We have found a face on the sphere if all four vertices have a radius of 0.5, or, as we write in the program, have \\(r^2-0.25 \\approx 0\\). Note that we call `cell->face(f)->set_all_manifold_ids(1)` to set the manifold id both on the faces and the surrounding lines. Furthermore, we want to distinguish the cells inside the ball and outside the ball by a material id for visualization, corresponding to the picture in the introduction.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::create_grid()\n     {\n       Triangulation<dim> tria_inner;\n       GridGenerator::hyper_ball(tria_inner, Point<dim>(), 0.5);\n   \n       Triangulation<dim> tria_outer;\n       GridGenerator::hyper_shell(\n         tria_outer, Point<dim>(), 0.5, std::sqrt(dim), 2 * dim);\n   \n       GridGenerator::merge_triangulations(tria_inner, tria_outer, triangulation);\n   \n       triangulation.reset_all_manifolds();\n       triangulation.set_all_manifold_ids(0);\n   \n       for (const auto &cell : triangulation.cell_iterators())\n         {\n           for (const auto &face : cell->face_iterators())\n             {\n               bool face_at_sphere_boundary = true;\n               for (const auto v : face->vertex_indices())\n                 {\n                   if (std::abs(face->vertex(v).norm_square() - 0.25) > 1e-12)\n                     face_at_sphere_boundary = false;\n                 }\n               if (face_at_sphere_boundary)\n                 face->set_all_manifold_ids(1);\n             }\n           if (cell->center().norm_square() < 0.25)\n             cell->set_material_id(1);\n           else\n             cell->set_material_id(0);\n         }\n```\n\nWith all cells, faces and lines marked appropriately, we can attach the [Manifold](classManifold.html) objects to those numbers. The entities with manifold id 1 will get a spherical manifold, whereas the other entities, which have the manifold id 0, will be assigned the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html). As mentioned in the introduction, we must explicitly initialize the manifold with the current mesh using a call to [TransfiniteInterpolationManifold::initialize()](classTransfiniteInterpolationManifold.html#a34326a35d9ec4b6911d90c85c21847d8) in order to pick up the coarse mesh cells and the manifolds attached to the boundaries of those cells. We also note that the manifold objects we create locally in this function are allowed to go out of scope (as they do at the end of the function scope), because the [Triangulation](classTriangulation.html) object internally copies them.\n\nWith all manifolds attached, we will finally go about and refine the mesh a few times to create a sufficiently large test case.\n\n```\n       triangulation.set_manifold(1, SphericalManifold<dim>());\n   \n       TransfiniteInterpolationManifold<dim> transfinite_manifold;\n       transfinite_manifold.initialize(triangulation);\n       triangulation.set_manifold(0, transfinite_manifold);\n   \n       triangulation.refine_global(9 - 2 * dim);\n     }\n```\n\n### Setup of data structures\n\nThe following function is well-known from other tutorials in that it enumerates the degrees of freedom, creates a constraint object and sets up a sparse matrix for the linear system. The only thing worth mentioning is the fact that the function receives a reference to a mapping object that we then pass to the [VectorTools::interpolate\\_boundary\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) function to ensure that our boundary values are evaluated on the high-order mesh used for assembly. In the present example, it does not really matter because the outer surfaces are flat, but for curved outer cells this leads to more accurate approximation of the boundary values.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::setup_system(const Mapping<dim> &mapping)\n     {\n       dof_handler.distribute_dofs(fe);\n       std::cout << \"   Number of active cells:       \"\n                 << triangulation.n_global_active_cells() << std::endl;\n       std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n                 << std::endl;\n   \n       {\n         TimerOutput::Scope scope(timer, \"Compute constraints\");\n   \n         constraints.clear();\n   \n         DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n         VectorTools::interpolate_boundary_values(\n           mapping, dof_handler, 0, ExactSolution<dim>(), constraints);\n   \n         constraints.close();\n       }\n   \n       DynamicSparsityPattern dsp(dof_handler.n_dofs());\n       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n   \n       sparsity_pattern.copy_from(dsp);\n       system_matrix.reinit(sparsity_pattern);\n   \n       solution.reinit(dof_handler.n_dofs());\n       system_rhs.reinit(dof_handler.n_dofs());\n     }\n```\n\n### Assembly of the system matrix and right hand side\n\nThe function that assembles the linear system is also well known from the previous tutorial programs. One thing to note is that we set the number of quadrature points to the polynomial degree plus two, not the degree plus one as in most other tutorials. This is because we expect some extra accuracy as the mapping also involves a degree one more than the polynomials for the solution.\n\nThe only somewhat unusual code in the assembly is the way we compute the cell matrix. Rather than using three nested loop over the quadrature point index, the row, and the column of the matrix, we first collect the derivatives of the shape function, multiplied by the square root of the product of the coefficient and the integration factor `JxW` in a separate matrix `partial_matrix`. To compute the cell matrix, we then execute `cell_matrix = partial_matrix * transpose(partial_matrix)` in the line `partial_matrix.mTmult(cell_matrix, partial_matrix);`. To understand why this works, we realize that the matrix-matrix multiplication performs a summation over the columns of `partial_matrix`. If we denote the coefficient by \\(a(\\mathbf{x}\\_q)\\), the entries in the temporary matrix are \\(\\sqrt{\\text{det}(J) w\\_q a(x)} \\frac{\\partial \\varphi\\_i(\\boldsymbol\n\\xi\\_q)}{\\partial x\\_k}\\). If we take the product of the *i*th row with the *j*th column of that matrix, we compute a nested sum involving \\(\\sum\\_q \\sum\\_{k=1}^d \\sqrt{\\text{det}(J) w\\_q a(x)} \\frac{\\partial\n\\varphi\\_i(\\boldsymbol \\xi\\_q)}{\\partial x\\_k} \\sqrt{\\text{det}(J) w\\_q a(x)}\n\\frac{\\partial \\varphi\\_j(\\boldsymbol \\xi\\_q)}{\\partial x\\_k} = \\sum\\_q\n\\sum\\_{k=1}^d\\text{det}(J) w\\_q a(x)\\frac{\\partial \\varphi\\_i(\\boldsymbol\n\\xi\\_q)}{\\partial x\\_k} \\frac{\\partial \\varphi\\_j(\\boldsymbol\n\\xi\\_q)}{\\partial x\\_k}\\), which is exactly the terms needed for the bilinear form of the Laplace equation.\n\nThe reason for choosing this somewhat unusual scheme is due to the heavy work involved in computing the cell matrix for a relatively high polynomial degree in 3d. As we want to highlight the cost of the mapping in this tutorial program, we better do the assembly in an optimized way in order to not chase bottlenecks that have been solved by the community already. Matrix-matrix multiplication is one of the best optimized kernels in the HPC context, and the [FullMatrix::mTmult()](classFullMatrix.html#ac074fc1dc416f8cd75bb01d820e74aa0) function will call into those optimized BLAS functions. If the user has provided a good BLAS library when configuring deal.II (like OpenBLAS or Intel's MKL), the computation of the cell matrix will execute close to the processor's peak arithmetic performance. As a side note, we mention that despite an optimized matrix-matrix multiplication, the current strategy is sub-optimal in terms of complexity as the work to be done is proportional to \\((p+1)^9\\) operations for degree \\(p\\) (this also applies to the usual evaluation with [FEValues](classFEValues.html)). One could compute the cell matrix with \\(\\mathcal O((p+1)^7)\\) operations by utilizing the tensor product structure of the shape functions, as is done by the matrix-free framework in deal.II. We refer to [step-37](step_37.html) and the documentation of the tensor-product-aware evaluators [FEEvaluation](classFEEvaluation.html) for details on how an even more efficient cell matrix computation could be realized.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::assemble_system(const Mapping<dim> &mapping)\n     {\n       TimerOutput::Scope scope(timer, \"Assemble linear system\");\n   \n       const QGauss<dim> quadrature_formula(fe.degree + 2);\n       FEValues<dim>     fe_values(mapping,\n                               fe,\n                               quadrature_formula,\n                               update_values | update_gradients |\n                                 update_quadrature_points | update_JxW_values);\n   \n       const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n       Vector<double>     cell_rhs(dofs_per_cell);\n       FullMatrix<double> partial_matrix(dofs_per_cell, dim * n_q_points);\n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n   \n       for (const auto &cell : dof_handler.active_cell_iterators())\n         {\n           cell_rhs = 0.;\n           fe_values.reinit(cell);\n   \n           for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n             {\n               const double current_coefficient =\n                 coefficient(fe_values.quadrature_point(q_index));\n               for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                 {\n                   for (unsigned int d = 0; d < dim; ++d)\n                     partial_matrix(i, q_index * dim + d) =\n                       std::sqrt(fe_values.JxW(q_index) * current_coefficient) *\n                       fe_values.shape_grad(i, q_index)[d];\n                   cell_rhs(i) +=\n                     (fe_values.shape_value(i, q_index) * // phi_i(x_q)\n                      (-dim) *                            // f(x_q)\n                      fe_values.JxW(q_index));            // dx\n                 }\n             }\n   \n           partial_matrix.mTmult(cell_matrix, partial_matrix);\n   \n           cell->get_dof_indices(local_dof_indices);\n           constraints.distribute_local_to_global(\n             cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\n         }\n     }\n```\n\n### Solution of the linear system\n\nFor solving the linear system, we pick a simple Jacobi-preconditioned conjugate gradient solver, similar to the settings in the early tutorials.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::solve()\n     {\n       TimerOutput::Scope scope(timer, \"Solve linear system\");\n   \n       SolverControl            solver_control(1000, 1e-12);\n       SolverCG<Vector<double>> solver(solver_control);\n   \n       PreconditionJacobi<SparseMatrix<double>> preconditioner;\n       preconditioner.initialize(system_matrix);\n   \n       solver.solve(system_matrix, solution, system_rhs, preconditioner);\n       constraints.distribute(solution);\n   \n       std::cout << \"   Number of solver iterations:  \"\n                 << solver_control.last_step() << std::endl;\n     }\n```\n\n### Output of the solution and computation of errors\n\nIn the next function we do various post-processing steps with the solution, all of which involve the mapping in one way or the other.\n\nThe first operation we do is to write the solution as well as the material ids to a VTU file. This is similar to what was done in many other tutorial programs. The new ingredient presented in this tutorial program is that we want to ensure that the data written to the file used for visualization is actually a faithful representation of what is used internally by deal.II. That is because most of the visualization data formats only represent cells by their vertex coordinates, but have no way of representing the curved boundaries that are used in deal.II when using higher order mappings – in other words, what you see in the visualization tool is not actually what you are computing on. (The same, incidentally, is true when using higher order shape functions: Most visualization tools only render bilinear/trilinear representations. This is discussed in detail in [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646).)\n\nSo we need to ensure that a high-order representation is written to the file. We need to consider two particular topics. Firstly, we tell the [DataOut](classDataOut.html) object via the [DataOutBase::VtkFlags](structDataOutBase_1_1VtkFlags.html) that we intend to interpret the subdivisions of the elements as a high-order Lagrange polynomial rather than a collection of bilinear patches. Recent visualization programs, like ParaView version 5.5 or newer, can then render a high-order solution (see a [wiki page](https://github.com/dealii/dealii/wiki/Notes-on-visualizing-high-order-output) for more details). Secondly, we need to make sure that the mapping is passed to the [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646) method. Finally, the [DataOut](classDataOut.html) class only prints curved faces for *boundary* cells by default, so we need to ensure that also inner cells are printed in a curved representation via the mapping.\n\nNote\n:   As of 2023, Visit 3.3.3 can still not deal with higher-order cells. Rather, it simply reports that there is no data to show. To view the results of this program with Visit, you will want to comment out the line that sets `flags.write_higher_order_cells = true;`. On the other hand, Paraview is able to understand VTU files with higher order cells just fine.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::postprocess(const Mapping<dim> &mapping)\n     {\n       {\n         TimerOutput::Scope scope(timer, \"Write output\");\n   \n         DataOut<dim> data_out;\n   \n         DataOutBase::VtkFlags flags;\n         flags.write_higher_order_cells = true;\n         data_out.set_flags(flags);\n   \n         data_out.attach_dof_handler(dof_handler);\n         data_out.add_data_vector(solution, \"solution\");\n   \n         Vector<double> material_ids(triangulation.n_active_cells());\n         for (const auto &cell : triangulation.active_cell_iterators())\n           material_ids[cell->active_cell_index()] = cell->material_id();\n         data_out.add_data_vector(material_ids, \"material_ids\");\n   \n         data_out.build_patches(mapping,\n                                fe.degree,\n                                DataOut<dim>::curved_inner_cells);\n   \n         std::ofstream file(\n           (\"solution-\" +\n            std::to_string(triangulation.n_global_levels() - 10 + 2 * dim) +\n            \".vtu\")\n             .c_str());\n   \n         data_out.write_vtu(file);\n       }\n```\n\nThe next operation in the postprocessing function is to compute the \\(L\\_2\\) and \\(H^1\\) errors against the analytical solution. As the analytical solution is a quadratic polynomial, we expect a very accurate result at this point. If we were solving on a simple mesh with planar faces and a coefficient whose jumps are aligned with the faces between cells, then we would expect the numerical result to coincide with the analytical solution up to roundoff accuracy. However, since we are using deformed cells following a sphere, which are only tracked by polynomials of degree 4 (one more than the degree for the finite elements), we will see that there is an error around \\(10^{-7}\\). We could get more accuracy by increasing the polynomial degree or refining the mesh.\n\n```\n       {\n         TimerOutput::Scope scope(timer, \"Compute error norms\");\n   \n         Vector<double> norm_per_cell_p(triangulation.n_active_cells());\n   \n         VectorTools::integrate_difference(mapping,\n                                           dof_handler,\n                                           solution,\n                                           ExactSolution<dim>(),\n                                           norm_per_cell_p,\n                                           QGauss<dim>(fe.degree + 2),\n                                           VectorTools::L2_norm);\n         std::cout << \"   L2 error vs exact solution:   \"\n                   << norm_per_cell_p.l2_norm() << std::endl;\n   \n         VectorTools::integrate_difference(mapping,\n                                           dof_handler,\n                                           solution,\n                                           ExactSolution<dim>(),\n                                           norm_per_cell_p,\n                                           QGauss<dim>(fe.degree + 2),\n                                           VectorTools::H1_norm);\n         std::cout << \"   H1 error vs exact solution:   \"\n                   << norm_per_cell_p.l2_norm() << std::endl;\n       }\n```\n\nThe final post-processing operation we do here is to compute an error estimate with the [KellyErrorEstimator](classKellyErrorEstimator.html). We use the exact same settings as in the [step-6](step_6.html) tutorial program, except for the fact that we also hand in the mapping to ensure that errors are evaluated along the curved element, consistent with the remainder of the program. However, we do not really use the result here to drive a mesh adaptation step (that would refine the mesh around the material interface along the sphere), as the focus here is on the cost of this operation.\n\n```\n       {\n         TimerOutput::Scope scope(timer, \"Compute error estimator\");\n   \n         Vector<float> estimated_error_per_cell(triangulation.n_active_cells());\n         KellyErrorEstimator<dim>::estimate(\n           mapping,\n           dof_handler,\n           QGauss<dim - 1>(fe.degree + 1),\n           std::map<types::boundary_id, const Function<dim> *>(),\n           solution,\n           estimated_error_per_cell);\n         std::cout << \"   Max cell-wise error estimate: \"\n                   << estimated_error_per_cell.linfty_norm() << std::endl;\n       }\n     }\n```\n\n### The PoissonProblem::run() function\n\nFinally, we define the `run()` function that controls how we want to execute this program (which is called by the main() function in the usual way). We start by calling the `create_grid()` function that sets up our geometry with the appropriate manifolds. We then run two instances of a solver chain, starting from the setup of the equations, the assembly of the linear system, its solution with a simple iterative solver, and the postprocessing discussed above. The two instances differ in the way they use the mapping. The first uses a conventional [MappingQ](classMappingQ.html) mapping object which we initialize to a degree one more than we use for the finite element – after all, we expect the geometry representation to be the bottleneck as the analytic solution is only a quadratic polynomial. (In reality, things are interlinked to quite some extent because the evaluation of the polynomials in real coordinates involves the mapping of a higher-degree polynomials, which represent some smooth rational functions. As a consequence, higher-degree polynomials still pay off, so it does not make sense to increase the degree of the mapping further.) Once the first pass is completed, we let the timer print a summary of the compute times of the individual stages.\n\n```\n     template <int dim>\n     void PoissonProblem<dim>::run()\n     {\n       create_grid();\n   \n       {\n         std::cout << std::endl\n                   << \"====== Running with the basic MappingQ class ====== \"\n                   << std::endl\n                   << std::endl;\n   \n         MappingQ<dim> mapping(fe.degree + 1);\n         setup_system(mapping);\n         assemble_system(mapping);\n         solve();\n         postprocess(mapping);\n   \n         timer.print_summary();\n         timer.reset();\n       }\n```\n\nFor the second instance, we instead set up the [MappingQCache](classMappingQCache.html) class. Its use is very simple: After constructing it (with the degree, given that we want it to show the correct degree functionality in other contexts), we fill the cache via the [MappingQCache::initialize()](classMappingQCache.html#ab7c3ac515088ee08df64075954629314) function. At this stage, we specify which mapping we want to use (obviously, the same [MappingQ](classMappingQ.html) as previously in order to repeat the same computations) for the cache, and then run through the same functions again, now handing in the modified mapping. In the end, we again print the accumulated wall times since the reset to see how the times compare to the original setting.\n\n```\n       {\n         std::cout\n           << \"====== Running with the optimized MappingQCache class ====== \"\n           << std::endl\n           << std::endl;\n   \n         MappingQCache<dim> mapping(fe.degree + 1);\n         {\n           TimerOutput::Scope scope(timer, \"Initialize mapping cache\");\n           mapping.initialize(MappingQ<dim>(fe.degree + 1), triangulation);\n         }\n         std::cout << \"   Memory consumption cache:     \"\n                   << 1e-6 * mapping.memory_consumption() << \" MB\" << std::endl;\n   \n         setup_system(mapping);\n         assemble_system(mapping);\n         solve();\n         postprocess(mapping);\n   \n         timer.print_summary();\n       }\n     }\n   } // namespace Step65\n   \n   \n   \n   int main()\n   {\n     Step65::PoissonProblem<3> test_program;\n     test_program.run();\n     return 0;\n   }\n```\n\nResults\n=======\n\n### Program output\n\nIf we run the three-dimensional version of this program with polynomials of degree three, we get the following program output:\n\n```\n> make run\nScanning dependencies of target step-65\n[ 33%] Building CXX object CMakeFiles/step-65.dir/step-65.cc.o\n[ 66%] Linking CXX executable step-65\n[ 66%] Built target step-65\n[100%] Run step-65 with Release configuration\n \n====== Running with the basic MappingQ class ======\n \n   Number of active cells:       6656\n   Number of degrees of freedom: 181609\n   Number of solver iterations:  285\n   L2 error vs exact solution:   8.99339e-08\n   H1 error vs exact solution:   6.45341e-06\n   Max cell-wise error estimate: 0.00743406\n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |      49.4s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble linear system          |         1 |       5.8s |        12% |\n| Compute constraints             |         1 |     0.109s |      0.22% |\n| Compute error estimator         |         1 |      16.5s |        33% |\n| Compute error norms             |         1 |      9.11s |        18% |\n| Solve linear system             |         1 |      9.92s |        20% |\n| Write output                    |         1 |      4.85s |       9.8% |\n+---------------------------------+-----------+------------+------------+\n \n====== Running with the optimized MappingQCache class ======\n \n   Memory consumption cache:     22.9981 MB\n   Number of active cells:       6656\n   Number of degrees of freedom: 181609\n   Number of solver iterations:  285\n   L2 error vs exact solution:   8.99339e-08\n   H1 error vs exact solution:   6.45341e-06\n   Max cell-wise error estimate: 0.00743406\n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |      18.4s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble linear system          |         1 |      1.44s |       7.8% |\n| Compute constraints             |         1 |   0.00336s |         0% |\n| Compute error estimator         |         1 |     0.476s |       2.6% |\n| Compute error norms             |         1 |     0.505s |       2.7% |\n| Initialize mapping cache        |         1 |      4.96s |        27% |\n| Solve linear system             |         1 |      9.95s |        54% |\n| Write output                    |         1 |     0.875s |       4.8% |\n+---------------------------------+-----------+------------+------------+\n \n[100%] Built target run\n```\n\nBefore discussing the timings, we look at the memory consumption for the [MappingQCache](classMappingQCache.html) object: Our program prints that it utilizes 23 MB of memory. If we relate this number to the memory consumption of a single (solution or right hand side) vector, which is 1.5 MB (namely, 181,609 elements times 8 bytes per entry in double precision), or to the memory consumed by the system matrix and the sparsity pattern (which is 274 MB), we realize that it is not an overly heavy data structure, given its benefits.\n\nWith respect to the timers, we see a clear improvement in the overall run time of the program by a factor of 2.7. If we disregard the iterative solver, which is the same in both cases (and not optimal, given the simple preconditioner we use, and the fact that sparse matrix-vector products waste operations for cubic polynomials), the advantage is a factor of almost 5. This is pretty impressive for a linear stationary problem, and cost savings would indeed be much more prominent for time-dependent and nonlinear problems where assembly is called several times. If we look into the individual components, we get a clearer picture of what is going on and why the cache is so efficient: In the [MappingQ](classMappingQ.html) case, essentially every operation that involves a mapping take at least 5 seconds to run. The norm computation runs two [VectorTools::integrate\\_difference()](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b) functions, which each take almost 5 seconds. (The computation of constraints is cheaper because it only evaluates the mapping in cells at the boundary for the interpolation of boundary conditions.) If we compare these 5 seconds to the time it takes to fill the [MappingQCache](classMappingQCache.html), which is 5.2 seconds (for all cells, not just the active ones), it becomes obvious that the computation of the mapping support points dominates over everything else in the [MappingQ](classMappingQ.html) case. Perhaps the most striking result is the time for the error estimator, labeled \"Compute error\nestimator\", where the [MappingQ](classMappingQ.html) implementation takes 17.3 seconds and the [MappingQCache](classMappingQCache.html) variant less than 0.5 seconds. The reason why the former is so expensive (three times more expensive than the assembly, for instance) is that the error estimation involves evaluation of quantities over faces, where each face in the mesh requests additional points of the mapping that in turn go through the very expensive [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) class. As there are six faces per cell, this happens much more often than in assembly. Again, [MappingQCache](classMappingQCache.html) nicely eliminates the repeated evaluation, aggregating all the expensive steps involving the manifold in a single initialization call that gets repeatedly used.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2019 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Martin Kronbichler\n */\n \n \n \n#include <deal.II/base/timer.h>\n \n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_refinement.h>\n#include <deal.II/grid/manifold_lib.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/fe/mapping_q.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <fstream>\n \n#include <deal.II/fe/mapping_q_cache.h>\n \n \nnamespace Step65\n{\n using namespace dealii;\n \n \n \n template <int dim>\n class ExactSolution : public Function<dim>\n  {\n public:\n virtual double value(const Point<dim> &p,\n const unsigned int /*component*/ = 0) const override\n {\n if (p.norm_square() < 0.25)\n return p.norm_square();\n else\n return 0.1 * p.norm_square() + (0.25 - 0.025);\n    }\n \n virtual Tensor<1, dim>\n    gradient(const Point<dim> &p,\n const unsigned int /*component*/ = 0) const override\n {\n if (p.norm_square() < 0.25)\n return 2. * p;\n else\n return 0.2 * p;\n    }\n  };\n \n \n template <int dim>\n double coefficient(const Point<dim> &p)\n  {\n if (p.norm_square() < 0.25)\n return 0.5;\n else\n return 5.0;\n  }\n \n \n \n template <int dim>\n class PoissonProblem\n  {\n public:\n    PoissonProblem();\n void run();\n \n private:\n void create_grid();\n void setup_system(const Mapping<dim> &mapping);\n void assemble_system(const Mapping<dim> &mapping);\n void solve();\n void postprocess(const Mapping<dim> &mapping);\n \n Triangulation<dim> triangulation;\n const FE_Q<dim>    fe;\n DoFHandler<dim>    dof_handler;\n \n AffineConstraints<double> constraints;\n SparsityPattern           sparsity_pattern;\n SparseMatrix<double>      system_matrix;\n Vector<double>            solution;\n Vector<double>            system_rhs;\n \n TimerOutput timer;\n  };\n \n \n \n template <int dim>\n  PoissonProblem<dim>::PoissonProblem()\n    : fe(3)\n    , dof_handler(triangulation)\n    , timer(std::cout, TimerOutput::never, TimerOutput::wall_times)\n  {}\n \n \n \n template <int dim>\n void PoissonProblem<dim>::create_grid()\n  {\n Triangulation<dim> tria_inner;\n GridGenerator::hyper_ball(tria_inner, Point<dim>(), 0.5);\n \n Triangulation<dim> tria_outer;\n GridGenerator::hyper_shell(\n      tria_outer, Point<dim>(), 0.5, std::sqrt(dim), 2 * dim);\n \n GridGenerator::merge_triangulations(tria_inner, tria_outer, triangulation);\n \n triangulation.reset_all_manifolds();\n triangulation.set_all_manifold_ids(0);\n \n for (const auto &cell : triangulation.cell_iterators())\n      {\n for (const auto &face : cell->face_iterators())\n          {\n bool face_at_sphere_boundary = true;\n for (const auto v : face->vertex_indices())\n              {\n if (std::abs(face->vertex(v).norm_square() - 0.25) > 1e-12)\n                  face_at_sphere_boundary = false;\n              }\n if (face_at_sphere_boundary)\n              face->set_all_manifold_ids(1);\n          }\n if (cell->center().norm_square() < 0.25)\n          cell->set_material_id(1);\n else\n          cell->set_material_id(0);\n      }\n \n triangulation.set_manifold(1, SphericalManifold<dim>());\n \n TransfiniteInterpolationManifold<dim> transfinite_manifold;\n    transfinite_manifold.initialize(triangulation);\n triangulation.set_manifold(0, transfinite_manifold);\n \n triangulation.refine_global(9 - 2 * dim);\n  }\n \n \n \n template <int dim>\n void PoissonProblem<dim>::setup_system(const Mapping<dim> &mapping)\n  {\n    dof_handler.distribute_dofs(fe);\n    std::cout << \"   Number of active cells:       \"\n              << triangulation.n_global_active_cells() << std::endl;\n    std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\n              << std::endl;\n \n    {\n TimerOutput::Scope scope(timer, \"Compute constraints\");\n \n      constraints.clear();\n \n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n VectorTools::interpolate_boundary_values(\n        mapping, dof_handler, 0, ExactSolution<dim>(), constraints);\n \n      constraints.close();\n    }\n \n DynamicSparsityPattern dsp(dof_handler.n_dofs());\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\n \n    sparsity_pattern.copy_from(dsp);\n    system_matrix.reinit(sparsity_pattern);\n \n    solution.reinit(dof_handler.n_dofs());\n    system_rhs.reinit(dof_handler.n_dofs());\n  }\n \n \n template <int dim>\n void PoissonProblem<dim>::assemble_system(const Mapping<dim> &mapping)\n  {\n TimerOutput::Scope scope(timer, \"Assemble linear system\");\n \n const QGauss<dim> quadrature_formula(fe.degree + 2);\n FEValues<dim>     fe_values(mapping,\n                            fe,\n                            quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points | update_JxW_values);\n \n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n Vector<double>     cell_rhs(dofs_per_cell);\n FullMatrix<double> partial_matrix(dofs_per_cell, dim * n_q_points);\n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n      {\n        cell_rhs = 0.;\n        fe_values.reinit(cell);\n \n for (unsigned int q_index = 0; q_index < n_q_points; ++q_index)\n          {\n const double current_coefficient =\n              coefficient(fe_values.quadrature_point(q_index));\n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n              {\n for (unsigned int d = 0; d < dim; ++d)\n                  partial_matrix(i, q_index * dim + d) =\n std::sqrt(fe_values.JxW(q_index) * current_coefficient) *\n                    fe_values.shape_grad(i, q_index)[d];\n                cell_rhs(i) +=\n                  (fe_values.shape_value(i, q_index) * // phi_i(x_q)\n                   (-dim) *                            // f(x_q)\n                   fe_values.JxW(q_index));            // dx\n              }\n          }\n \n        partial_matrix.mTmult(cell_matrix, partial_matrix);\n \n        cell->get_dof_indices(local_dof_indices);\n        constraints.distribute_local_to_global(\n          cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\n      }\n  }\n \n \n \n template <int dim>\n void PoissonProblem<dim>::solve()\n  {\n TimerOutput::Scope scope(timer, \"Solve linear system\");\n \n SolverControl            solver_control(1000, 1e-12);\n SolverCG<Vector<double>> solver(solver_control);\n \n PreconditionJacobi<SparseMatrix<double>> preconditioner;\n    preconditioner.initialize(system_matrix);\n \n    solver.solve(system_matrix, solution, system_rhs, preconditioner);\n    constraints.distribute(solution);\n \n    std::cout << \"   Number of solver iterations:  \"\n              << solver_control.last_step() << std::endl;\n  }\n \n \n \n template <int dim>\n void PoissonProblem<dim>::postprocess(const Mapping<dim> &mapping)\n  {\n    {\n TimerOutput::Scope scope(timer, \"Write output\");\n \n DataOut<dim> data_out;\n \n DataOutBase::VtkFlags flags;\n      flags.write_higher_order_cells = true;\n      data_out.set_flags(flags);\n \n      data_out.attach_dof_handler(dof_handler);\n      data_out.add_data_vector(solution, \"solution\");\n \n Vector<double> material_ids(triangulation.n_active_cells());\n for (const auto &cell : triangulation.active_cell_iterators())\n        material_ids[cell->active_cell_index()] = cell->material_id();\n      data_out.add_data_vector(material_ids, \"material_ids\");\n \n      data_out.build_patches(mapping,\n                             fe.degree,\n DataOut<dim>::curved_inner_cells);\n \n      std::ofstream file(\n        (\"solution-\" +\n         std::to_string(triangulation.n_global_levels() - 10 + 2 * dim) +\n \".vtu\")\n          .c_str());\n \n      data_out.write_vtu(file);\n    }\n \n    {\n TimerOutput::Scope scope(timer, \"Compute error norms\");\n \n Vector<double> norm_per_cell_p(triangulation.n_active_cells());\n \n VectorTools::integrate_difference(mapping,\n                                        dof_handler,\n                                        solution,\n                                        ExactSolution<dim>(),\n                                        norm_per_cell_p,\n QGauss<dim>(fe.degree + 2),\n VectorTools::L2_norm);\n      std::cout << \"   L2 error vs exact solution:   \"\n                << norm_per_cell_p.l2_norm() << std::endl;\n \n VectorTools::integrate_difference(mapping,\n                                        dof_handler,\n                                        solution,\n                                        ExactSolution<dim>(),\n                                        norm_per_cell_p,\n QGauss<dim>(fe.degree + 2),\n VectorTools::H1_norm);\n      std::cout << \"   H1 error vs exact solution:   \"\n                << norm_per_cell_p.l2_norm() << std::endl;\n    }\n \n    {\n TimerOutput::Scope scope(timer, \"Compute error estimator\");\n \n Vector<float> estimated_error_per_cell(triangulation.n_active_cells());\n KellyErrorEstimator<dim>::estimate(\n        mapping,\n        dof_handler,\n QGauss<dim - 1>(fe.degree + 1),\n        std::map<types::boundary_id, const Function<dim> *>(),\n        solution,\n        estimated_error_per_cell);\n      std::cout << \"   Max cell-wise error estimate: \"\n                << estimated_error_per_cell.linfty_norm() << std::endl;\n    }\n  }\n \n \n \n template <int dim>\n void PoissonProblem<dim>::run()\n  {\n    create_grid();\n \n    {\n      std::cout << std::endl\n                << \"====== Running with the basic MappingQ class ====== \"\n                << std::endl\n                << std::endl;\n \n MappingQ<dim> mapping(fe.degree + 1);\n      setup_system(mapping);\n      assemble_system(mapping);\n      solve();\n      postprocess(mapping);\n \n      timer.print_summary();\n      timer.reset();\n    }\n \n    {\n      std::cout\n        << \"====== Running with the optimized MappingQCache class ====== \"\n        << std::endl\n        << std::endl;\n \n MappingQCache<dim> mapping(fe.degree + 1);\n      {\n TimerOutput::Scope scope(timer, \"Initialize mapping cache\");\n        mapping.initialize(MappingQ<dim>(fe.degree + 1), triangulation);\n      }\n      std::cout << \"   Memory consumption cache:     \"\n                << 1e-6 * mapping.memory_consumption() << \" MB\" << std::endl;\n \n      setup_system(mapping);\n      assemble_system(mapping);\n      solve();\n      postprocess(mapping);\n \n      timer.print_summary();\n    }\n  }\n} // namespace Step65\n \n \n \nint main()\n{\n  Step65::PoissonProblem<3> test_program;\n  test_program.run();\n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_66.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nA matrix-free geometric multigrid solver for a nonlinear problem.\nTutorial content :\nThis tutorial depends on [step-15](step_15.html), [step-37](step_37.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_66-Intro)    * [Problem formulation](#step_66-Problemformulation)* [Discretization with finite elements](#step_66-Discretizationwithfiniteelements)* [Numerical linear algebra](#step_66-Numericallinearalgebra)* [Triangulation](#step_66-Triangulation)- [The commented program](#step_66-CommProg)      * [Matrix-free JacobianOperator](#step_66-MatrixfreeJacobianOperator)        + [Evaluation of the old Newton step](#step_66-EvaluationoftheoldNewtonstep)+ [Nonlinear matrix-free operator application](#step_66-Nonlinearmatrixfreeoperatorapplication)+ [Diagonal of the JacobianOperator](#step_66-DiagonaloftheJacobianOperator)* [GelfandProblem class](#step_66-GelfandProblemclass)          + [GelfandProblem::make\\_grid](#step_66-GelfandProblemmake_grid)+ [GelfandProblem::setup\\_system](#step_66-GelfandProblemsetup_system)+ [GelfandProblem::evaluate\\_residual](#step_66-GelfandProblemevaluate_residual)+ [GelfandProblem::local\\_evaluate\\_residual](#step_66-GelfandProblemlocal_evaluate_residual)+ [GelfandProblem::assemble\\_rhs](#step_66-GelfandProblemassemble_rhs)+ [GelfandProblem::compute\\_residual](#step_66-GelfandProblemcompute_residual)+ [GelfandProblem::compute\\_update](#step_66-GelfandProblemcompute_update)+ [GelfandProblem::solve](#step_66-GelfandProblemsolve)+ [GelfandProblem::compute\\_solution\\_norm](#step_66-GelfandProblemcompute_solution_norm)+ [GelfandProblem::output\\_results](#step_66-GelfandProblemoutput_results)+ [GelfandProblem::run](#step_66-GelfandProblemrun)* [The `main` function](#step_66-Thecodemaincodefunction) | 1. [Results](#step_66-Results)    * [Program output](#step_66-Programoutput)* [Newton solver](#step_66-Newtonsolver)* [Possibilities for extensions](#step_66-Possibilitiesforextensions)          + [More sophisticated Newton iteration](#step_66-MoresophisticatedNewtoniteration)+ [Parallel scalability and thread parallelism](#step_66-Parallelscalabilityandthreadparallelism)+ [Comparison to matrix-based methods](#step_66-Comparisontomatrixbasedmethods)+ [Eigenvalue problem](#step_66-Eigenvalueproblem)- [The plain program](#step_66-PlainProg) |\n\n*This program was contributed by Fabian Castelli.*\n\n*A version of this code was presented and discussed in [[54]](citelist.html#CITEREF_castelli2021numerical) G.F. Castelli: Numerical Investigation of Cahn-Hilliard-Type Phase-Field Models for Battery Active Particles, PhD thesis, Karlsruhe Institute of Technology (KIT), 2021.*\n\n*Fabian Castelli acknowledges financial support by the German Research Foundation (DFG) through the Research Training Group 2218 SiMET – Simulation of mechano-electro-thermal processes in lithium-ion batteries, project number 281041241.*\n\n*Finally Fabian Castelli would like to thank Timo Heister for the encouragement and advice in writing this tutorial.*\n\nIntroduction\n============\n\nThe aim of this tutorial program is to demonstrate how to solve a nonlinear problem using Newton's method within the matrix-free framework. This tutorial combines several techniques already introduced in [step-15](step_15.html), [step-16](step_16.html), [step-37](step_37.html), [step-48](step_48.html) and others.\n\n### Problem formulation\n\nOn the unit circle \\(\\Omega = \\bigl\\{ x \\in \\mathbb{R}^2 : \\|x\\| \\leq 1 \\bigr\\}\\) we consider the following nonlinear elliptic boundary value problem subject to a homogeneous Dirichlet boundary condition: Find a function \\(u\\colon\\Omega\\to\\mathbb{R}\\) such that it holds:\n\n\\begin{align\\*}\n- \\Delta u &= \\exp(u) & \\quad & \\text{in } \\Omega,\\\\\nu &= 0 & \\quad & \\text{on } \\partial\\Omega.\n\\end{align\\*}\n\nThis problem is also called the *Gelfand problem* and is a typical example for problems from combustion theory, see for example [[18]](citelist.html#CITEREF_bebernes1989mathematical).\n\n### Discretization with finite elements\n\nAs usual, we first derive the weak formulation for this problem by multiplying with a smooth test function \\(v\\colon\\Omega\\to\\mathbb{R}\\) respecting the boundary condition and integrating over the domain \\(\\Omega\\). Integration by parts and putting the term from the right hand side to the left yields the weak formulation: Find a function \\(u\\colon\\Omega\\to\\mathbb{R}\\) such that for all test functions \\(v\\) it holds:\n\n\\begin{align\\*}\n\\int\\_\\Omega \\nabla v \\cdot \\nabla u \\,\\mathrm{d}x\n-\n\\int\\_\\Omega v \\exp(u) \\,\\mathrm{d}x\n=\n0.\n\\end{align\\*}\n\nChoosing the Lagrangian finite element space \\(V\\_h \\dealcoloneq\n\\bigl\\{ v \\in C(\\overline{\\Omega}) : v|\\_Q \\in \\mathbb{Q}\\_p \\text{ for all }\nQ \\in \\mathcal{T}\\_h \\bigr\\} \\cap H\\_0^1(\\Omega)\\), which directly incorporates the homogeneous Dirichlet boundary condition, we can define a basis \\(\\{\\varphi\\_i\\}\\_{i=1,\\dots,N}\\) and thus it suffices to test only with those basis functions. So the discrete problem reads as follows: Find \\(u\\_h\\in V\\_h\\) such that for all \\(i=1,\\dots,N\\) it holds:\n\n\\begin{align\\*}\nF(u\\_h)\n\\dealcoloneq\n\\int\\_\\Omega \\nabla \\varphi\\_i \\cdot \\nabla u\\_h \\,\\mathrm{d}x\n-\n\\int\\_\\Omega \\varphi\\_i \\exp(u\\_h) \\,\\mathrm{d}x \\stackrel{!}{=} 0.\n\\end{align\\*}\n\nAs each finite element function is a linear combination of the basis functions \\(\\{\\varphi\\_i\\}\\_{i=1,\\dots,N}\\), we can identify the finite element solution by a vector from \\(\\mathbb{R}^N\\) consisting of the unknown values in each degree of freedom (DOF). Thus, we define the nonlinear function \\(F\\colon\\mathbb{R}^N\\to\\mathbb{R}^N\\) representing the discrete nonlinear problem.\n\nTo solve this nonlinear problem we use Newton's method. So given an initial guess \\(u\\_h^0\\in V\\_h\\), which already fulfills the Dirichlet boundary condition, we determine a sequence of Newton steps \\(\\bigl( u\\_h^n \\bigr)\\_n\\) by successively applying the following scheme:\n\n\\begin{align\\*}\n&\\text{Solve for } s\\_h^n\\in V\\_h: \\quad & F'(u\\_h^n)[s\\_h^n] &= -F(u\\_h^n),\\\\\n&\\text{Update: } & u\\_h^{n+1} &= u\\_h^n + s\\_h^n.\n\\end{align\\*}\n\nSo in each Newton step we have to solve a linear problem \\(A\\,x = b\\), where the system matrix \\(A\\) is represented by the Jacobian \\(F'(u\\_h^n)[\\,\\cdot\\,]\\colon\\mathbb{R}^N\\to\\mathbb{R}^N\\) and the right hand side \\(b\\) by the negative residual \\(-F(u\\_h^n)\\). The solution vector \\(x\\) is in that case the Newton update of the \\(n\\)-th Newton step. Note, that we assume an initial guess \\(u\\_h^0\\), which already fulfills the Dirichlet boundary conditions of the problem formulation (in fact this could also be an inhomogeneous Dirichlet boundary condition) and thus the Newton updates \\(s\\_h\\) satisfy a homogeneous Dirichlet condition.\n\nUntil now we only tested with the basis functions, however, we can also represent any function of \\(V\\_h\\) as linear combination of basis functions. More mathematically this means, that every element of \\(V\\_h\\) can be identified with a vector \\(U\\in\\mathbb{R}^N\\) via the representation formula: \\(u\\_h = \\sum\\_{i=1}^N U\\_i \\varphi\\_i\\). So using this we can give an expression for the discrete Jacobian and the residual:\n\n\\begin{align\\*}\nA\\_{ij} = \\bigl( F'(u\\_h^n) \\bigr)\\_{ij}\n&=\n\\int\\_\\Omega \\nabla\\varphi\\_i \\cdot \\nabla \\varphi\\_j \\,\\mathrm{d} x\n-\n\\int\\_\\Omega \\varphi\\_i \\, \\exp( u\\_h^n ) \\varphi\\_j \\,\\mathrm{d} x,\\\\\nb\\_{i} = \\bigl( F(u\\_h^n) \\bigr)\\_{i}\n&=\n\\int\\_\\Omega \\nabla\\varphi\\_i \\cdot \\nabla u\\_h^n \\,\\mathrm{d} x\n-\n\\int\\_\\Omega \\varphi\\_i \\, \\exp( u\\_h^n ) \\,\\mathrm{d} x.\n\\end{align\\*}\n\nCompared to [step-15](step_15.html) we could also have formed the FrÃ©chet derivative of the nonlinear function corresponding to the strong formulation of the problem and discretized it afterwards. However, in the end we would get the same set of discrete equations.\n\n### Numerical linear algebra\n\nNote, how the system matrix, actually the Jacobian, depends on the previous Newton step \\(A = F'(u^n)\\). Hence we need to tell the function that computes the system matrix about the solution at the last Newton step. In an implementation with a classical `assemble_system()` function we would gather this information from the last Newton step during assembly by the use of the member functions [FEValuesBase::get\\_function\\_values()](classFEValuesBase.html#a33e437195106aee8e3ad88b2dd40d223) and [FEValuesBase::get\\_function\\_gradients()](classFEValuesBase.html#aa41921ba94d62a91fff93f3dfd51bb5a). This is how [step-15](step_15.html), for example, does things. The `assemble_system()` function would then look like:\n\n```\ntemplate <int dim>\nvoid GelfandProblem<dim>::assemble_system()\n{\n  system_matrix = 0;\n  system_rhs    = 0;\n \n const QGauss<dim> quadrature_formula(fe.degree + 1);\n FEValues<dim>     fe_values(fe,\n                          quadrature_formula,\n update_values | update_gradients | update_JxW_values);\n \n const unsigned int n_q_points    = fe_values.n_quadrature_points;\n const unsigned int dofs_per_cell = fe_values.dofs_per_cell;\n \n FullMatrix<double>                   cell_matrix(dofs_per_cell);\n Vector<double>                       cell_rhs(dofs_per_cell);\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n \n  std::vector<Tensor<1, dim>> newton_step_gradients(n_q_points);\n  std::vector<double>         newton_step_values(n_q_points);\n \n \n for (const auto &cell : dof_handler.active_cell_iterators())\n    {\n      cell_matrix = 0.0;\n      cell_rhs    = 0.0;\n \n      fe_values.reinit(cell);\n \n      fe_values.get_function_values(solution, newton_step_values);\n      fe_values.get_function_gradients(solution, newton_step_gradients);\n \n for (unsigned int q = 0; q < n_q_points; ++q)\n        {\n const double nonlinearity = std::exp(newton_step_values[q]);\n const double dx           = fe_values.JxW(q);\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n            {\n const double         phi_i      = fe_values.shape_value(i, q);\n const Tensor<1, dim> grad_phi_i = fe_values.shape_grad(i, q);\n \n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                {\n const double         phi_j      = fe_values.shape_value(j, q);\n const Tensor<1, dim> grad_phi_j = fe_values.shape_grad(j, q);\n \n                  cell_matrix(i, j) +=\n                    (grad_phi_i * grad_phi_j - phi_i * nonlinearity * phi_j) *\n                    dx;\n                }\n \n              cell_rhs(i) += (-grad_phi_i * newton_step_gradients[q] +\n                              phi_i * nonlinearity) *\n                             dx;\n            }\n        }\n \n      cell->get_dof_indices(local_dof_indices);\n \n      constraints.distribute_local_to_global(\n        cell_matrix, cell_rhs, local_dof_indices, system_matrix, system_rhs);\n    }\n}\n```\n\nSince we want to solve this problem without storing a matrix, we need to tell the matrix-free operator this information before we use it. Therefore in the derived class `JacobianOperator` we will implement a function called `evaluate_newton_step`, which will process the information of the last Newton step prior to the usage of the matrix-vector implementation. Furthermore we want to use a geometric multigrid (GMG) preconditioner for the linear solver, so in order to apply the multilevel operators we need to pass the last Newton step also to these operators. This is kind of a tricky task, since the vector containing the last Newton step has to be interpolated to all levels of the triangulation. In the code this task will be done by the function [MGTransferMatrixFree::interpolate\\_to\\_mg()](classMGTransferMatrixFree.html#a6d96b63fdd3c1a344a83ae43c7ed5a28). Note, a fundamental difference to the previous cases, where we set up and used a geometric multigrid preconditioner, is the fact, that we can reuse the [MGTransferMatrixFree](classMGTransferMatrixFree.html) object for the computation of all Newton steps. So we can save some work here by defining a class variable and using an already set up [MGTransferMatrixFree](classMGTransferMatrixFree.html) object `mg_transfer` that was initialized in the `setup_system()` function.\n\n```\ntemplate <int dim, int fe_degree>\nvoid GelfandProblem<dim, fe_degree>::compute_update()\n{\n TimerOutput::Scope t(computing_timer, \"compute update\");\n \n  solution.update_ghost_values();\n \n  system_matrix.evaluate_newton_step(solution);\n \n  mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\n \n \n // Set up options for the multilevel preconditioner\n // ...\n \n for (unsigned int level = 0; level < triangulation.n_global_levels(); ++level)\n    {\n      mg_matrices[level].evaluate_newton_step(mg_solution[level]);\n    }\n \n // Define the actual preconditioner\n // ...\n \n // Solve the linear system\n // ...\n}\n```\n\nThe function evaluating the nonlinearity works basically in the same way as the function `evaluate_coefficient` from [step-37](step_37.html) evaluating a coefficient function. The idea is to use an [FEEvaluation](classFEEvaluation.html) object to evaluate the Newton step and store the expression in a table for all cells and all quadrature points:\n\n```\ntemplate <int dim, int fe_degree, typename number>\nvoid JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\n const LinearAlgebra::distributed::Vector<number> &newton_step)\n{\n const unsigned int n_cells = this->data->n_cell_batches();\n \n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number> phi(*this->data);\n \n  nonlinear_values.reinit(n_cells, phi.n_q_points);\n \n for (unsigned int cell = 0; cell < n_cells; ++cell)\n    {\n      phi.reinit(cell);\n      phi.read_dof_values_plain(newton_step);\n      phi.evaluate(EvaluationFlags::values);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n        {\n          nonlinear_values(cell, q) = std::exp(phi.get_value(q));\n        }\n    }\n}\n```\n\n### Triangulation\n\nAs said in [step-37](step_37.html), the matrix-free method gets more efficient if we choose a higher order finite element space. Since we want to solve the problem on the \\(d\\)-dimensional unit ball, it would be good to have an appropriate boundary approximation to overcome convergence issues. For this reason we use an isoparametric approach with the [MappingQ](classMappingQ.html) class to recover the smooth boundary as well as the mapping for inner cells. In addition, to get a good triangulation in total we make use of the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html).\n\nThe commented program\n=====================\n\nFirst we include the typical headers of the deal.II library needed for this tutorial:\n\n```\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/timer.h>\n   #include <deal.II/base/vectorization.h>\n   \n   #include <deal.II/dofs/dof_accessor.h>\n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/mapping_q.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_out.h>\n   #include <deal.II/grid/manifold_lib.h>\n   #include <deal.II/grid/tria.h>\n   #include <deal.II/grid/tria_accessor.h>\n   #include <deal.II/grid/tria_iterator.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/precondition.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nIn particular, we need to include the headers for the matrix-free framework:\n\n```\n   #include <deal.II/matrix_free/fe_evaluation.h>\n   #include <deal.II/matrix_free/matrix_free.h>\n   #include <deal.II/matrix_free/operators.h>\n   #include <deal.II/matrix_free/tools.h>\n```\n\nAnd since we want to use a geometric multigrid preconditioner, we need also the multilevel headers:\n\n```\n   #include <deal.II/multigrid/mg_coarse.h>\n   #include <deal.II/multigrid/mg_constrained_dofs.h>\n   #include <deal.II/multigrid/mg_matrix.h>\n   #include <deal.II/multigrid/mg_smoother.h>\n   #include <deal.II/multigrid/mg_tools.h>\n   #include <deal.II/multigrid/mg_transfer_matrix_free.h>\n   #include <deal.II/multigrid/multigrid.h>\n```\n\nFinally some common C++ headers for in and output:\n\n```\n   #include <fstream>\n   #include <iostream>\n   \n   \n   \n   namespace Step66\n   {\n     using namespace dealii;\n```\n\n### Matrix-free JacobianOperator\n\nIn the beginning we define the matrix-free operator for the Jacobian. As a guideline we follow the tutorials [step-37](step_37.html) and [step-48](step_48.html), where the precise interface of the [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html) class was extensively documented.\n\nSince we want to use the Jacobian as system matrix and pass it to the linear solver as well as to the multilevel preconditioner classes, we derive the `JacobianOperator` class from the [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html) class, such that we have already the right interface. The two functions we need to override from the base class are the [MatrixFreeOperators::Base::apply\\_add()](classMatrixFreeOperators_1_1Base.html#abc81493aad390198580330cc99203b3c) and the [MatrixFreeOperators::Base::compute\\_diagonal()](classMatrixFreeOperators_1_1Base.html#a16d883c49c69eef468b39b2e991d8b0d) function. To allow preconditioning with float precision we define the number type as template argument.\n\nAs mentioned already in the introduction, we need to evaluate the Jacobian \\(F'\\) at the last Newton step \\(u\\_h^n\\) for the computation of the Newton update \\(s\\_h^n\\). To get the information of the last Newton step \\(u\\_h^n\\) we do pretty much the same as in [step-37](step_37.html), where we stored the values of a coefficient function in a table `nonlinear_values` once before we use the matrix-free operator. Instead of a function `evaluate_coefficient()`, we here implement a function `evaluate_newton_step()`.\n\nAs additional private member functions of the `JacobianOperator` we implement the `local_apply()` and the `local_compute_diagonal()` function. The first one is the actual worker function for the matrix-vector application, which we pass to the [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) in the `apply_add()` function. The later one is the worker function to compute the diagonal, which we pass to the [MatrixFreeTools::compute\\_diagonal()](namespaceMatrixFreeTools.html#aa6e7de0c62c2315141230cb171a151db) function.\n\nFor better readability of the source code we further define an alias for the [FEEvaluation](classFEEvaluation.html) object.\n\n```\n     template <int dim, int fe_degree, typename number>\n     class JacobianOperator\n       : public MatrixFreeOperators::\n           Base<dim, LinearAlgebra::distributed::Vector<number>>\n     {\n     public:\n       using value_type = number;\n   \n       using FECellIntegrator =\n         FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number>;\n   \n       JacobianOperator();\n   \n       virtual void clear() override;\n   \n       void evaluate_newton_step(\n         const LinearAlgebra::distributed::Vector<number> &newton_step);\n   \n       virtual void compute_diagonal() override;\n   \n     private:\n       virtual void apply_add(\n         LinearAlgebra::distributed::Vector<number>       &dst,\n         const LinearAlgebra::distributed::Vector<number> &src) const override;\n   \n       void\n       local_apply(const MatrixFree<dim, number>                    &data,\n                   LinearAlgebra::distributed::Vector<number>       &dst,\n                   const LinearAlgebra::distributed::Vector<number> &src,\n                   const std::pair<unsigned int, unsigned int> &cell_range) const;\n   \n       void local_compute_diagonal(FECellIntegrator &integrator) const;\n   \n       Table<2, VectorizedArray<number>> nonlinear_values;\n     };\n```\n\nThe constructor of the `JacobianOperator` just calls the constructor of the base class [MatrixFreeOperators::Base](classMatrixFreeOperators_1_1Base.html), which is itself derived from the [Subscriptor](classSubscriptor.html) class.\n\n```\n     template <int dim, int fe_degree, typename number>\n     JacobianOperator<dim, fe_degree, number>::JacobianOperator()\n       : MatrixFreeOperators::Base<dim,\n                                   LinearAlgebra::distributed::Vector<number>>()\n     {}\n```\n\nThe `clear()` function resets the table holding the values for the nonlinearity and call the `clear()` function of the base class.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::clear()\n     {\n       nonlinear_values.reinit(0, 0);\n       MatrixFreeOperators::Base<dim, LinearAlgebra::distributed::Vector<number>>::\n         clear();\n     }\n```\n\n#### Evaluation of the old Newton step\n\nThe following `evaluate_newton_step()` function is based on the `evaluate_coefficient()` function from [step-37](step_37.html). However, it does not evaluate a function object, but evaluates a vector representing a finite element function, namely the last Newton step needed for the Jacobian. Therefore we set up a [FEEvaluation](classFEEvaluation.html) object and evaluate the finite element function in the quadrature points with the [FEEvaluation::read\\_dof\\_values\\_plain()](classFEEvaluationBase.html#a5f7b105e45005ce2ed0dc8f265398768) and [FEEvaluation::evaluate()](classFEEvaluation.html#a710c252e9dccc0c4ce07044cac3bdd9b) functions. We store the evaluated values of the finite element function directly in the `nonlinear_values` table.\n\nThis will work well and in the `local_apply()` function we can use the values stored in the table to apply the matrix-vector product. However, we can also optimize the implementation of the Jacobian at this stage. We can directly evaluate the nonlinear function `std::exp(newton_step[q])` and store these values in the table. This skips all evaluations of the nonlinearity in each call of the `vmult()` function.\n\nNote that we need to manually call the functions to exchange the ghost data here, by calling [LinearAlgebra::distributed::Vector::update\\_ghost\\_values()](classLinearAlgebra_1_1distributed_1_1Vector.html#a2a6cb7d50e02022283af53c2ae14f878), to ensure all data from neighboring processes is available for evaluating the finite-element interpolation on cells. In the other functions of this tutorial program, [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) made sure to call this function. Note that we clear the ghost state again at the end of the function, in order to avoid mixing ghosted and non-ghosted vectors in other parts of the solver.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\n       const LinearAlgebra::distributed::Vector<number> &newton_step)\n     {\n       const unsigned int n_cells = this->data->n_cell_batches();\n       FECellIntegrator   phi(*this->data);\n   \n       newton_step.update_ghost_values();\n   \n       nonlinear_values.reinit(n_cells, phi.n_q_points);\n   \n       for (unsigned int cell = 0; cell < n_cells; ++cell)\n         {\n           phi.reinit(cell);\n           phi.read_dof_values_plain(newton_step);\n           phi.evaluate(EvaluationFlags::values);\n   \n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               nonlinear_values(cell, q) = std::exp(phi.get_value(q));\n             }\n         }\n       newton_step.zero_out_ghost_values();\n     }\n```\n\n#### Nonlinear matrix-free operator application\n\nNow in the `local_apply()` function, which actually implements the cell wise action of the system matrix, we can use the information of the last Newton step stored in the table `nonlinear_values`. The rest of this function is basically the same as in [step-37](step_37.html). We set up the [FEEvaluation](classFEEvaluation.html) object, gather and evaluate the values and gradients of the input vector `src`, submit the values and gradients according to the form of the Jacobian and finally call [FEEvaluation::integrate\\_scatter()](classFEEvaluation.html#a52265fb3ecb2b63388e1708ef395418f) to perform the cell integration and distribute the local contributions into the global vector  `dst`.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::local_apply(\n       const MatrixFree<dim, number>                    &data,\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src,\n       const std::pair<unsigned int, unsigned int>      &cell_range) const\n     {\n       FECellIntegrator phi(data);\n   \n       for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n         {\n           AssertDimension(nonlinear_values.size(0),\n                           phi.get_matrix_free().n_cell_batches());\n           AssertDimension(nonlinear_values.size(1), phi.n_q_points);\n   \n   \n           phi.reinit(cell);\n   \n           phi.gather_evaluate(src,\n                               EvaluationFlags::values |\n                                 EvaluationFlags::gradients);\n   \n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\n               phi.submit_gradient(phi.get_gradient(q), q);\n             }\n   \n           phi.integrate_scatter(EvaluationFlags::values |\n                                   EvaluationFlags::gradients,\n                                 dst);\n         }\n     }\n```\n\nNext we use [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) to perform the actual loop over all cells computing the cell contribution to the matrix-vector product.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::apply_add(\n       LinearAlgebra::distributed::Vector<number>       &dst,\n       const LinearAlgebra::distributed::Vector<number> &src) const\n     {\n       this->data->cell_loop(&JacobianOperator::local_apply, this, dst, src);\n     }\n```\n\n#### Diagonal of the JacobianOperator\n\nThe internal worker function `local_compute_diagonal()` for the computation of the diagonal is similar to the above worker function `local_apply()`. However, as major difference we do not read values from a input vector or distribute any local results to an output vector. Instead the only input argument is the used [FEEvaluation](classFEEvaluation.html) object.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::local_compute_diagonal(\n       FECellIntegrator &phi) const\n     {\n       AssertDimension(nonlinear_values.size(0),\n                       phi.get_matrix_free().n_cell_batches());\n       AssertDimension(nonlinear_values.size(1), phi.n_q_points);\n   \n       const unsigned int cell = phi.get_current_cell_index();\n   \n       phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n   \n       for (const unsigned int q : phi.quadrature_point_indices())\n         {\n           phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\n           phi.submit_gradient(phi.get_gradient(q), q);\n         }\n   \n       phi.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\n     }\n```\n\nFinally we override the [MatrixFreeOperators::Base::compute\\_diagonal()](classMatrixFreeOperators_1_1Base.html#a16d883c49c69eef468b39b2e991d8b0d) function of the base class of the `JacobianOperator`. Although the name of the function suggests just the computation of the diagonal, this function does a bit more. Because we only really need the inverse of the matrix diagonal elements for the Chebyshev smoother of the multigrid preconditioner, we compute the diagonal and store the inverse elements. Therefore we first initialize the `inverse_diagonal_entries`. Then we compute the diagonal by passing the worker function `local_compute_diagonal()` to the [MatrixFreeTools::compute\\_diagonal()](namespaceMatrixFreeTools.html#aa6e7de0c62c2315141230cb171a151db) function. In the end we loop over the diagonal and invert the elements by hand. Note, that during this loop we catch the constrained DOFs and set them manually to one.\n\n```\n     template <int dim, int fe_degree, typename number>\n     void JacobianOperator<dim, fe_degree, number>::compute_diagonal()\n     {\n       this->inverse_diagonal_entries.reset(\n         new DiagonalMatrix<LinearAlgebra::distributed::Vector<number>>());\n       LinearAlgebra::distributed::Vector<number> &inverse_diagonal =\n         this->inverse_diagonal_entries->get_vector();\n       this->data->initialize_dof_vector(inverse_diagonal);\n   \n       MatrixFreeTools::compute_diagonal(*this->data,\n                                         inverse_diagonal,\n                                         &JacobianOperator::local_compute_diagonal,\n                                         this);\n   \n       for (auto &diagonal_element : inverse_diagonal)\n         {\n           diagonal_element = (std::abs(diagonal_element) > 1.0e-10) ?\n                                (1.0 / diagonal_element) :\n                                1.0;\n         }\n     }\n```\n\n### GelfandProblem class\n\nAfter implementing the matrix-free operators we can now define the solver class for the *Gelfand problem*. This class is based on the common structure of all previous tutorial programs, in particular it is based on [step-15](step_15.html), solving also a nonlinear problem. Since we are using the matrix-free framework, we no longer need an assemble\\_system function any more, instead the information of the matrix is rebuilt in every call of the `vmult()` function. However, for the application of the Newton scheme we need to assemble the right hand side of the linearized problems and compute the residuals. Therefore, we implement an additional function `evaluate_residual()`, which we later call in the `assemble_rhs()` and the `compute_residual()` function. Finally, the typical `solve()` function here implements the Newton method, whereas the solution of the linearized system is computed in the function `compute_update()`. As the [MatrixFree](classMatrixFree.html) framework handles the polynomial degree of the Lagrangian finite element method as a template parameter, we declare it also as a template parameter for the problem solver class.\n\n```\n     template <int dim, int fe_degree>\n     class GelfandProblem\n     {\n     public:\n       GelfandProblem();\n   \n       void run();\n   \n     private:\n       void make_grid();\n   \n       void setup_system();\n   \n       void evaluate_residual(\n         LinearAlgebra::distributed::Vector<double>       &dst,\n         const LinearAlgebra::distributed::Vector<double> &src) const;\n   \n       void local_evaluate_residual(\n         const MatrixFree<dim, double>                    &data,\n         LinearAlgebra::distributed::Vector<double>       &dst,\n         const LinearAlgebra::distributed::Vector<double> &src,\n         const std::pair<unsigned int, unsigned int>      &cell_range) const;\n   \n       void assemble_rhs();\n   \n       double compute_residual(const double alpha);\n   \n       void compute_update();\n   \n       void solve();\n   \n       double compute_solution_norm() const;\n   \n       void output_results(const unsigned int cycle) const;\n```\n\nFor the parallel computation we define a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html). As the computational domain is a circle in 2d and a ball in 3d, we assign in addition to the [SphericalManifold](classSphericalManifold.html) for boundary cells a [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) object for the mapping of the inner cells, which takes care of the inner cells. In this example we use an isoparametric finite element approach and thus use the [MappingQ](classMappingQ.html) class. For further details you may read the detailed description of this class.\n\n```\n       parallel::distributed::Triangulation<dim> triangulation;\n       const MappingQ<dim>                       mapping;\n```\n\nAs usual we then define the Lagrangian finite elements [FE\\_Q](classFE__Q.html) and a [DoFHandler](classDoFHandler.html).\n\n```\n       const FE_Q<dim> fe;\n       DoFHandler<dim> dof_handler;\n```\n\nFor the linearized discrete system we define an [AffineConstraints](classAffineConstraints.html) objects and the `system_matrix`, which is in this example represented as a matrix-free operator.\n\n```\n       AffineConstraints<double> constraints;\n       using SystemMatrixType = JacobianOperator<dim, fe_degree, double>;\n       SystemMatrixType system_matrix;\n```\n\nThe multilevel object is also based on the matrix-free operator for the Jacobian. Since we need to evaluate the Jacobian with the last Newton step, we also need to evaluate the level operator with the last Newton step for the preconditioner. Thus in addition to `mg_matrices`, we also need a [MGLevelObject](classMGLevelObject.html) to store the interpolated solution vector on each level. As in [step-37](step_37.html) we use float precision for the preconditioner. Moreover, we define the [MGTransferMatrixFree](classMGTransferMatrixFree.html) object as a class variable, since we need to set it up only once when the triangulation has changed and can then use it again in each Newton step.\n\n```\n       MGConstrainedDoFs mg_constrained_dofs;\n       using LevelMatrixType = JacobianOperator<dim, fe_degree, float>;\n       MGLevelObject<LevelMatrixType>                           mg_matrices;\n       MGLevelObject<LinearAlgebra::distributed::Vector<float>> mg_solution;\n       MGTransferMatrixFree<dim, float>                         mg_transfer;\n```\n\nOf course we also need vectors holding the `solution`, the `newton_update` and the `system_rhs`. In that way we can always store the last Newton step in the solution vector and just add the update to get the next Newton step.\n\n```\n       LinearAlgebra::distributed::Vector<double> solution;\n       LinearAlgebra::distributed::Vector<double> newton_update;\n       LinearAlgebra::distributed::Vector<double> system_rhs;\n```\n\nFinally we have a variable for the number of iterations of the linear solver.\n\n```\n       unsigned int linear_iterations;\n```\n\nFor the output in programs running in parallel with MPI, we use the [ConditionalOStream](classConditionalOStream.html) class to avoid multiple output of the same data by different MPI ranks.\n\n```\n       ConditionalOStream pcout;\n```\n\nFinally for the time measurement we use a [TimerOutput](classTimerOutput.html) object, which prints the elapsed CPU and wall times for each function in a nicely formatted table after the program has finished.\n\n```\n       TimerOutput computing_timer;\n     };\n```\n\nThe constructor of the `GelfandProblem` initializes the class variables. In particular, we set up the multilevel support for the [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html), set the mapping degree equal to the finite element degree, initialize the [ConditionalOStream](classConditionalOStream.html) and tell the [TimerOutput](classTimerOutput.html) that we want to see the wall times only on demand.\n\n```\n     template <int dim, int fe_degree>\n     GelfandProblem<dim, fe_degree>::GelfandProblem()\n       : triangulation(MPI_COMM_WORLD,\n                       Triangulation<dim>::limit_level_difference_at_vertices,\n                       parallel::distributed::Triangulation<\n                         dim>::construct_multigrid_hierarchy)\n       , mapping(fe_degree)\n       , fe(fe_degree)\n       , dof_handler(triangulation)\n       , pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n       , computing_timer(MPI_COMM_WORLD,\n                         pcout,\n                         TimerOutput::never,\n                         TimerOutput::wall_times)\n     {}\n```\n\n#### GelfandProblem::make\\_grid\n\nAs the computational domain we use the `dim`-dimensional unit ball. We follow the instructions for the [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) class and also assign a [SphericalManifold](classSphericalManifold.html) for the boundary. Finally, we refine the initial mesh 3 - `dim` times globally.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::make_grid()\n     {\n       TimerOutput::Scope t(computing_timer, \"make grid\");\n   \n       SphericalManifold<dim>                boundary_manifold;\n       TransfiniteInterpolationManifold<dim> inner_manifold;\n   \n       GridGenerator::hyper_ball(triangulation);\n   \n       triangulation.set_all_manifold_ids(1);\n       triangulation.set_all_manifold_ids_on_boundary(0);\n   \n       triangulation.set_manifold(0, boundary_manifold);\n   \n       inner_manifold.initialize(triangulation);\n       triangulation.set_manifold(1, inner_manifold);\n   \n       triangulation.refine_global(3 - dim);\n     }\n```\n\n#### GelfandProblem::setup\\_system\n\nThe `setup_system()` function is quasi identical to the one in [step-37](step_37.html). The only differences are obviously the time measurement with only one [TimerOutput::Scope](classTimerOutput_1_1Scope.html) instead of measuring each part individually, and more importantly the initialization of the [MGLevelObject](classMGLevelObject.html) for the interpolated solution vector of the previous Newton step. Another important change is the setup of the [MGTransferMatrixFree](classMGTransferMatrixFree.html) object, which we can reuse in each Newton step as the `triangulation` will not be not changed.\n\nNote how we can use the same [MatrixFree](classMatrixFree.html) object twice, for the `JacobianOperator` and the multigrid preconditioner.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::setup_system()\n     {\n       TimerOutput::Scope t(computing_timer, \"setup system\");\n   \n       system_matrix.clear();\n       mg_matrices.clear_elements();\n   \n       dof_handler.distribute_dofs(fe);\n       dof_handler.distribute_mg_dofs();\n   \n       constraints.clear();\n       constraints.reinit(dof_handler.locally_owned_dofs(),\n                          DoFTools::extract_locally_relevant_dofs(dof_handler));\n       DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n       VectorTools::interpolate_boundary_values(dof_handler,\n                                                0,\n                                                Functions::ZeroFunction<dim>(),\n                                                constraints);\n       constraints.close();\n   \n       {\n         typename MatrixFree<dim, double>::AdditionalData additional_data;\n         additional_data.tasks_parallel_scheme =\n           MatrixFree<dim, double>::AdditionalData::partition_color;\n         additional_data.mapping_update_flags =\n           (update_values | update_gradients | update_JxW_values |\n            update_quadrature_points);\n         auto system_mf_storage = std::make_shared<MatrixFree<dim, double>>();\n         system_mf_storage->reinit(mapping,\n                                   dof_handler,\n                                   constraints,\n                                   QGauss<1>(fe.degree + 1),\n                                   additional_data);\n   \n         system_matrix.initialize(system_mf_storage);\n       }\n   \n       system_matrix.initialize_dof_vector(solution);\n       system_matrix.initialize_dof_vector(newton_update);\n       system_matrix.initialize_dof_vector(system_rhs);\n   \n   \n       const unsigned int nlevels = triangulation.n_global_levels();\n       mg_matrices.resize(0, nlevels - 1);\n       mg_solution.resize(0, nlevels - 1);\n   \n       const std::set<types::boundary_id> dirichlet_boundary_ids = {0};\n       mg_constrained_dofs.initialize(dof_handler);\n       mg_constrained_dofs.make_zero_boundary_constraints(dof_handler,\n                                                          dirichlet_boundary_ids);\n   \n       mg_transfer.initialize_constraints(mg_constrained_dofs);\n       mg_transfer.build(dof_handler);\n   \n       for (unsigned int level = 0; level < nlevels; ++level)\n         {\n           AffineConstraints<double> level_constraints(\n             dof_handler.locally_owned_mg_dofs(level),\n             DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\n   \n           for (const types::global_dof_index dof_index :\n                mg_constrained_dofs.get_boundary_indices(level))\n             level_constraints.constrain_dof_to_zero(dof_index);\n           level_constraints.close();\n   \n           typename MatrixFree<dim, float>::AdditionalData additional_data;\n           additional_data.tasks_parallel_scheme =\n             MatrixFree<dim, float>::AdditionalData::partition_color;\n           additional_data.mapping_update_flags =\n             (update_values | update_gradients | update_JxW_values |\n              update_quadrature_points);\n           additional_data.mg_level = level;\n           auto mg_mf_storage_level = std::make_shared<MatrixFree<dim, float>>();\n           mg_mf_storage_level->reinit(mapping,\n                                       dof_handler,\n                                       level_constraints,\n                                       QGauss<1>(fe.degree + 1),\n                                       additional_data);\n   \n           mg_matrices[level].initialize(mg_mf_storage_level,\n                                         mg_constrained_dofs,\n                                         level);\n           mg_matrices[level].initialize_dof_vector(mg_solution[level]);\n         }\n     }\n```\n\n#### GelfandProblem::evaluate\\_residual\n\nNext we implement a function which evaluates the nonlinear discrete residual for a given input vector ( \\(\\texttt{dst} = F(\\texttt{src})\\)). This function is then used for the assembly of the right hand side of the linearized system and later for the computation of the residual of the next Newton step to check if we already reached the error tolerance. As this function should not affect any class variable we define it as a constant function. Internally we exploit the fast finite element evaluation through the [FEEvaluation](classFEEvaluation.html) class and the [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7), similar to `apply_add()` function of the `JacobianOperator`.\n\nFirst we create a pointer to the [MatrixFree](classMatrixFree.html) object, which is stored in the `system_matrix`. Then we pass the worker function `local_evaluate_residual()` for the cell wise evaluation of the residual together with the input and output vector to the [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7). In addition, we enable the zero out of the output vector in the loop, which is more efficient than calling `dst = 0.0` separately before.\n\nNote that with this approach we do not have to take care about the MPI related data exchange, since all the bookkeeping is done by the [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7).\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::evaluate_residual(\n       LinearAlgebra::distributed::Vector<double>       &dst,\n       const LinearAlgebra::distributed::Vector<double> &src) const\n     {\n       auto matrix_free = system_matrix.get_matrix_free();\n   \n       matrix_free->cell_loop(\n         &GelfandProblem::local_evaluate_residual, this, dst, src, true);\n     }\n```\n\n#### GelfandProblem::local\\_evaluate\\_residual\n\nThis is the internal worker function for the evaluation of the residual. Essentially it has the same structure as the `local_apply()` function of the `JacobianOperator` and evaluates the residual for the input vector `src` on the given set of cells `cell_range`. The difference to the above mentioned `local_apply()` function is, that we split the [FEEvaluation::gather\\_evaluate()](classFEEvaluation.html#ab53d5c08f460cfe6c9830ac14a427115) function into [FEEvaluation::read\\_dof\\_values\\_plain()](classFEEvaluationBase.html#a5f7b105e45005ce2ed0dc8f265398768) and [FEEvaluation::evaluate()](classFEEvaluation.html#a710c252e9dccc0c4ce07044cac3bdd9b), since the input vector might have constrained DOFs.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::local_evaluate_residual(\n       const MatrixFree<dim, double>                    &data,\n       LinearAlgebra::distributed::Vector<double>       &dst,\n       const LinearAlgebra::distributed::Vector<double> &src,\n       const std::pair<unsigned int, unsigned int>      &cell_range) const\n     {\n       FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> phi(data);\n   \n       for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n         {\n           phi.reinit(cell);\n   \n           phi.read_dof_values_plain(src);\n           phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n   \n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               phi.submit_value(-std::exp(phi.get_value(q)), q);\n               phi.submit_gradient(phi.get_gradient(q), q);\n             }\n   \n           phi.integrate_scatter(EvaluationFlags::values |\n                                   EvaluationFlags::gradients,\n                                 dst);\n         }\n     }\n```\n\n#### GelfandProblem::assemble\\_rhs\n\nUsing the above function `evaluate_residual()` to evaluate the nonlinear residual, the assembly of the right hand side of the linearized system becomes now a very easy task. We just call the `evaluate_residual()` function and multiply the result with minus one.\n\nExperiences show that using the [FEEvaluation](classFEEvaluation.html) class is much faster than a classical implementation with [FEValues](classFEValues.html) and co.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::assemble_rhs()\n     {\n       TimerOutput::Scope t(computing_timer, \"assemble right hand side\");\n   \n       evaluate_residual(system_rhs, solution);\n   \n       system_rhs *= -1.0;\n     }\n```\n\n#### GelfandProblem::compute\\_residual\n\nAccording to [step-15](step_15.html) the following function computes the norm of the nonlinear residual for the solution \\(u\\_h^n + \\alpha s\\_h^n\\) with the help of the `evaluate_residual()` function. The Newton step length \\(\\alpha\\) becomes important if we would use an adaptive version of the Newton method. Then for example we would compute the residual for different step lengths and compare the residuals. However, for our problem the full Newton step with \\(\\alpha=1\\) is the best we can do. An adaptive version of Newton's method becomes interesting if we have no good initial value. Note that in theory Newton's method converges with quadratic order, but only if we have an appropriate initial value. For unsuitable initial values the Newton method diverges even with quadratic order. A common way is then to use a damped version \\(\\alpha<1\\) until the Newton step is good enough and the full Newton step can be performed. This was also discussed in [step-15](step_15.html).\n\n```\n     template <int dim, int fe_degree>\n     double GelfandProblem<dim, fe_degree>::compute_residual(const double alpha)\n     {\n       TimerOutput::Scope t(computing_timer, \"compute residual\");\n   \n       LinearAlgebra::distributed::Vector<double> residual;\n       LinearAlgebra::distributed::Vector<double> evaluation_point;\n   \n       system_matrix.initialize_dof_vector(residual);\n       system_matrix.initialize_dof_vector(evaluation_point);\n   \n       evaluation_point = solution;\n       if (alpha > 1e-12)\n         {\n           evaluation_point.add(alpha, newton_update);\n         }\n   \n       evaluate_residual(residual, evaluation_point);\n   \n       return residual.l2_norm();\n     }\n```\n\n#### GelfandProblem::compute\\_update\n\nIn order to compute the Newton updates in each Newton step we solve the linear system with the CG algorithm together with a geometric multigrid preconditioner. For this we first set up the [PreconditionMG](classPreconditionMG.html) object with a Chebyshev smoother like we did in [step-37](step_37.html).\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::compute_update()\n     {\n       TimerOutput::Scope t(computing_timer, \"compute update\");\n```\n\nWe remember that the Jacobian depends on the last Newton step stored in the solution vector. So we update the ghost values of the Newton step and pass it to the `JacobianOperator` to store the information.\n\n```\n       solution.update_ghost_values();\n   \n       system_matrix.evaluate_newton_step(solution);\n```\n\nNext we also have to pass the last Newton step to the multilevel operators. Therefore, we need to interpolate the Newton step to all levels of the triangulation. This is done with the [MGTransferMatrixFree::interpolate\\_to\\_mg()](classMGTransferMatrixFree.html#a6d96b63fdd3c1a344a83ae43c7ed5a28).\n\n```\n       mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\n```\n\nNow we can set up the preconditioner. We define the smoother and pass the interpolated vectors of the Newton step to the multilevel operators.\n\n```\n       using SmootherType =\n         PreconditionChebyshev<LevelMatrixType,\n                               LinearAlgebra::distributed::Vector<float>>;\n       mg::SmootherRelaxation<SmootherType,\n                              LinearAlgebra::distributed::Vector<float>>\n                                                            mg_smoother;\n       MGLevelObject<typename SmootherType::AdditionalData> smoother_data;\n       smoother_data.resize(0, triangulation.n_global_levels() - 1);\n       for (unsigned int level = 0; level < triangulation.n_global_levels();\n            ++level)\n         {\n           if (level > 0)\n             {\n               smoother_data[level].smoothing_range     = 15.;\n               smoother_data[level].degree              = 4;\n               smoother_data[level].eig_cg_n_iterations = 10;\n             }\n           else\n             {\n               smoother_data[0].smoothing_range = 1e-3;\n               smoother_data[0].degree          = numbers::invalid_unsigned_int;\n               smoother_data[0].eig_cg_n_iterations = mg_matrices[0].m();\n             }\n   \n           mg_matrices[level].evaluate_newton_step(mg_solution[level]);\n           mg_matrices[level].compute_diagonal();\n   \n           smoother_data[level].preconditioner =\n             mg_matrices[level].get_matrix_diagonal_inverse();\n         }\n       mg_smoother.initialize(mg_matrices, smoother_data);\n   \n       MGCoarseGridApplySmoother<LinearAlgebra::distributed::Vector<float>>\n         mg_coarse;\n       mg_coarse.initialize(mg_smoother);\n   \n       mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_matrix(\n         mg_matrices);\n   \n       MGLevelObject<MatrixFreeOperators::MGInterfaceOperator<LevelMatrixType>>\n         mg_interface_matrices;\n       mg_interface_matrices.resize(0, triangulation.n_global_levels() - 1);\n       for (unsigned int level = 0; level < triangulation.n_global_levels();\n            ++level)\n         {\n           mg_interface_matrices[level].initialize(mg_matrices[level]);\n         }\n       mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_interface(\n         mg_interface_matrices);\n   \n       Multigrid<LinearAlgebra::distributed::Vector<float>> mg(\n         mg_matrix, mg_coarse, mg_transfer, mg_smoother, mg_smoother);\n       mg.set_edge_matrices(mg_interface, mg_interface);\n   \n       PreconditionMG<dim,\n                      LinearAlgebra::distributed::Vector<float>,\n                      MGTransferMatrixFree<dim, float>>\n         preconditioner(dof_handler, mg, mg_transfer);\n```\n\nFinally we set up the [SolverControl](classSolverControl.html) and the [SolverCG](classSolverCG.html) to solve the linearized problem for the current Newton update. An important fact of the implementation of [SolverCG](classSolverCG.html) or also [SolverGMRES](classSolverGMRES.html) is, that the vector holding the solution of the linear system (here `newton_update`) can be used to pass a starting value. In order to start the iterative solver always with a zero vector we reset the `newton_update` explicitly before calling [SolverCG::solve()](classSolverCG.html#aa52469650d9b9ef2f4cb4884caeb0723). Afterwards we distribute the Dirichlet boundary conditions stored in `constraints` and store the number of iteration steps for the later output.\n\n```\n       SolverControl solver_control(100, 1.e-12);\n       SolverCG<LinearAlgebra::distributed::Vector<double>> cg(solver_control);\n   \n       newton_update = 0.0;\n   \n       cg.solve(system_matrix, newton_update, system_rhs, preconditioner);\n   \n       constraints.distribute(newton_update);\n   \n       linear_iterations = solver_control.last_step();\n```\n\nThen for bookkeeping we zero out the ghost values.\n\n```\n       solution.zero_out_ghost_values();\n     }\n```\n\n#### GelfandProblem::solve\n\nNow we implement the actual Newton solver for the nonlinear problem.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::solve()\n     {\n       TimerOutput::Scope t(computing_timer, \"solve\");\n```\n\nWe define a maximal number of Newton steps and tolerances for the convergence criterion. Usually, with good starting values, the Newton method converges in three to six steps, so maximal ten steps should be totally sufficient. As tolerances we use \\(\\|F(u^n\\_h)\\|<\\text{TOL}\\_f =\n10^{-12}\\) for the norm of the residual and \\(\\|s\\_h^n\\| < \\text{TOL}\\_x =\n10^{-10}\\) for the norm of the Newton update. This seems a bit over the top, but we will see that, for our example, we will achieve these tolerances after a few steps.\n\n```\n       const unsigned int itmax = 10;\n       const double       TOLf  = 1e-12;\n       const double       TOLx  = 1e-10;\n   \n   \n       Timer solver_timer;\n       solver_timer.start();\n```\n\nNow we start the actual Newton iteration.\n\n```\n       for (unsigned int newton_step = 1; newton_step <= itmax; ++newton_step)\n         {\n```\n\nWe assemble the right hand side of the linearized problem and compute the Newton update.\n\n```\n           assemble_rhs();\n           compute_update();\n```\n\nThen we compute the errors, namely the norm of the Newton update and the residual. Note that at this point one could incorporate a step size control for the Newton method by varying the input parameter \\(\\alpha\\) for the compute\\_residual function. However, here we just use \\(\\alpha\\) equal to one for a plain Newton iteration.\n\n```\n           const double ERRx = newton_update.l2_norm();\n           const double ERRf = compute_residual(1.0);\n```\n\nNext we advance the Newton step by adding the Newton update to the current Newton step.\n\n```\n           solution.add(1.0, newton_update);\n```\n\nA short output will inform us on the current Newton step.\n\n```\n           pcout << \"   Nstep \" << newton_step << \", errf = \" << ERRf\n                 << \", errx = \" << ERRx << \", it = \" << linear_iterations\n                 << std::endl;\n```\n\nAfter each Newton step we check the convergence criteria. If at least one of those is fulfilled we are done and end the loop. If we haven't found a satisfying solution after the maximal amount of Newton iterations, we inform the user about this shortcoming.\n\n```\n           if (ERRf < TOLf || ERRx < TOLx)\n             {\n               solver_timer.stop();\n   \n               pcout << \"Convergence step \" << newton_step << \" value \" << ERRf\n                     << \" (used wall time: \" << solver_timer.wall_time() << \" s)\"\n                     << std::endl;\n   \n               break;\n             }\n           else if (newton_step == itmax)\n             {\n               solver_timer.stop();\n               pcout << \"WARNING: No convergence of Newton's method after \"\n                     << newton_step << \" steps.\" << std::endl;\n   \n               break;\n             }\n         }\n     }\n```\n\n#### GelfandProblem::compute\\_solution\\_norm\n\nThe computation of the H1-seminorm of the solution can be done in the same way as in [step-59](step_59.html). We update the ghost values and use the function [VectorTools::integrate\\_difference()](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). In the end we gather all computations from all MPI ranks and return the norm.\n\n```\n     template <int dim, int fe_degree>\n     double GelfandProblem<dim, fe_degree>::compute_solution_norm() const\n     {\n       solution.update_ghost_values();\n   \n       Vector<float> norm_per_cell(triangulation.n_active_cells());\n   \n       VectorTools::integrate_difference(mapping,\n                                         dof_handler,\n                                         solution,\n                                         Functions::ZeroFunction<dim>(),\n                                         norm_per_cell,\n                                         QGauss<dim>(fe.degree + 2),\n                                         VectorTools::H1_seminorm);\n   \n       solution.zero_out_ghost_values();\n   \n       return VectorTools::compute_global_error(triangulation,\n                                                norm_per_cell,\n                                                VectorTools::H1_seminorm);\n     }\n```\n\n#### GelfandProblem::output\\_results\n\nWe generate the graphical output files in vtu format together with a pvtu master file at once by calling the [DataOut::write\\_vtu\\_with\\_pvtu\\_record()](classDataOutInterface.html#ae8163d7f2fab4dd25c0e7b8c40f0f746) function in the same way as in [step-37](step_37.html). In addition, as in [step-40](step_40.html), we query the [types::subdomain\\_id](namespacetypes.html#a198fcb9cfd43905f5c4f8c6ad7397330) of each cell and write the distribution of the triangulation among the MPI ranks into the output file. Finally, we generate the patches of the solution by calling [DataOut::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646). However, since we have a computational domain with a curved boundary, we additionally pass the `mapping` and the finite element degree as number of subdivision. But this is still not enough for the correct representation of the solution, for example in ParaView, because we attached a [TransfiniteInterpolationManifold](classTransfiniteInterpolationManifold.html) to the inner cells, which results in curved cells in the interior. Therefore we pass as third argument the [DataOut::curved\\_inner\\_cells](classDataOut.html#a1303b5d99f10f3fae984e7d406cfeb37ad8379a354d5bd6484471f6bf755cd111) option, such that also the inner cells use the corresponding manifold description to build the patches.\n\nNote that we could handle the higher order elements with the flag [DataOutBase::VtkFlags::write\\_higher\\_order\\_cells](structDataOutBase_1_1VtkFlags.html#aa9dd1830c0ff35a2431704c4d45453eb). However, due to the limited compatibility to previous version of ParaView and the missing support by VisIt, we left this option for a future version.\n\n```\n     template <int dim, int fe_degree>\n     void\n     GelfandProblem<dim, fe_degree>::output_results(const unsigned int cycle) const\n     {\n       if (triangulation.n_global_active_cells() > 1e6)\n         return;\n   \n       solution.update_ghost_values();\n   \n       DataOut<dim> data_out;\n       data_out.attach_dof_handler(dof_handler);\n       data_out.add_data_vector(solution, \"solution\");\n   \n       Vector<float> subdomain(triangulation.n_active_cells());\n       for (unsigned int i = 0; i < subdomain.size(); ++i)\n         {\n           subdomain(i) = triangulation.locally_owned_subdomain();\n         }\n       data_out.add_data_vector(subdomain, \"subdomain\");\n   \n       data_out.build_patches(mapping,\n                              fe.degree,\n                              DataOut<dim>::curved_inner_cells);\n   \n       DataOutBase::VtkFlags flags;\n       flags.compression_level = DataOutBase::CompressionLevel::best_speed;\n       data_out.set_flags(flags);\n       data_out.write_vtu_with_pvtu_record(\n         \"./\", \"solution_\" + std::to_string(dim) + \"d\", cycle, MPI_COMM_WORLD, 3);\n   \n       solution.zero_out_ghost_values();\n     }\n```\n\n#### GelfandProblem::run\n\nThe last missing function of the solver class for the *Gelfand problem* is the run function. In the beginning we print information about the system specifications and the finite element space we use. The problem is solved several times on a successively refined mesh.\n\n```\n     template <int dim, int fe_degree>\n     void GelfandProblem<dim, fe_degree>::run()\n     {\n       {\n         const unsigned int n_ranks =\n           Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD);\n         const unsigned int n_vect_doubles = VectorizedArray<double>::size();\n         const unsigned int n_vect_bits    = 8 * sizeof(double) * n_vect_doubles;\n   \n         std::string DAT_header = \"START DATE: \" + Utilities::System::get_date() +\n                                  \", TIME: \" + Utilities::System::get_time();\n         std::string MPI_header = \"Running with \" + std::to_string(n_ranks) +\n                                  \" MPI process\" + (n_ranks > 1 ? \"es\" : \"\");\n         std::string VEC_header =\n           \"Vectorization over \" + std::to_string(n_vect_doubles) +\n           \" doubles = \" + std::to_string(n_vect_bits) + \" bits (\" +\n           Utilities::System::get_current_vectorization_level() +\n           \"), VECTORIZATION_LEVEL=\" +\n           std::to_string(DEAL_II_COMPILER_VECTORIZATION_LEVEL);\n         std::string SOL_header = \"Finite element space: \" + fe.get_name();\n   \n         pcout << std::string(80, '=') << std::endl;\n         pcout << DAT_header << std::endl;\n         pcout << std::string(80, '-') << std::endl;\n   \n         pcout << MPI_header << std::endl;\n         pcout << VEC_header << std::endl;\n         pcout << SOL_header << std::endl;\n   \n         pcout << std::string(80, '=') << std::endl;\n       }\n   \n   \n       for (unsigned int cycle = 0; cycle < 9 - dim; ++cycle)\n         {\n           pcout << std::string(80, '-') << std::endl;\n           pcout << \"Cycle \" << cycle << std::endl;\n           pcout << std::string(80, '-') << std::endl;\n```\n\nThe first task in actually solving the problem is to generate or refine the triangulation.\n\n```\n           if (cycle == 0)\n             {\n               make_grid();\n             }\n           else\n             {\n               triangulation.refine_global(1);\n             }\n```\n\nNow we set up the system and solve the problem. These steps are accompanied by time measurement and textual output.\n\n```\n           Timer timer;\n   \n           pcout << \"Set up system...\" << std::endl;\n           setup_system();\n   \n           pcout << \"   Triangulation: \" << triangulation.n_global_active_cells()\n                 << \" cells\" << std::endl;\n           pcout << \"   DoFHandler:    \" << dof_handler.n_dofs() << \" DoFs\"\n                 << std::endl;\n           pcout << std::endl;\n   \n   \n           pcout << \"Solve using Newton's method...\" << std::endl;\n           solve();\n           pcout << std::endl;\n   \n   \n           timer.stop();\n           pcout << \"Time for setup+solve (CPU/Wall) \" << timer.cpu_time() << '/'\n                 << timer.wall_time() << \" s\" << std::endl;\n           pcout << std::endl;\n```\n\nAfter the problem was solved we compute the norm of the solution and generate the graphical output files.\n\n```\n           pcout << \"Output results...\" << std::endl;\n           const double norm = compute_solution_norm();\n           output_results(cycle);\n   \n           pcout << \"  H1 seminorm: \" << norm << std::endl;\n           pcout << std::endl;\n```\n\nFinally after each cycle we print the timing information.\n\n```\n           computing_timer.print_summary();\n           computing_timer.reset();\n         }\n     }\n   } // namespace Step66\n```\n\n### The `main` function\n\nAs typical for programs running in parallel with MPI we set up the MPI framework and disable shared-memory parallelization by limiting the number of threads to one. Finally to run the solver for the *Gelfand problem* we create an object of the `GelfandProblem` class and call the run function. Exemplarily we solve the problem once in 2d and once in 3d each with fourth-order Lagrangian finite elements.\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         using namespace Step66;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\n   \n         {\n           GelfandProblem<2, 4> gelfand_problem;\n           gelfand_problem.run();\n         }\n   \n         {\n           GelfandProblem<3, 4> gelfand_problem;\n           gelfand_problem.run();\n         }\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nThe aim of this tutorial step was to demonstrate the solution of a nonlinear PDE with the matrix-free framework.\n\n### Program output\n\nRunning the program on two processes in release mode via\n\n```\ncmake . && make release && make && mpirun -n 2 ./step-66\n```\n\ngives the following output on the console\n\n```\n================================================================================\nSTART DATE: 2021/5/18, TIME: 16:25:48\n--------------------------------------------------------------------------------\nRunning with 2 MPI processes\nVectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2\nFinite element space: FE_Q<2>(4)\n================================================================================\n--------------------------------------------------------------------------------\nCycle 0\n--------------------------------------------------------------------------------\nSet up system...\n Triangulation: 20 cells\n DoFHandler:    337 DoFs\n \nSolve using Newton's method...\n   Nstep 1, errf = 0.00380835, errx = 3.61904, it = 7\n   Nstep 2, errf = 3.80167e-06, errx = 0.104353, it = 6\n   Nstep 3, errf = 3.97939e-12, errx = 0.00010511, it = 4\n   Nstep 4, errf = 2.28859e-13, errx = 1.07726e-10, it = 1\nConvergence step 4 value 2.28859e-13 (used wall time: 0.0096409 s)\n \nTime for setup+solve (CPU/Wall) 0.015617/0.0156447 s\n \nOutput results...\n  H1 seminorm: 0.773426\n \n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |    0.0286s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| assemble right hand side        |         4 |  9.71e-05s |      0.34% |\n| compute residual                |         4 |  0.000137s |      0.48% |\n| compute update                  |         4 |   0.00901s |        32% |\n| make grid                       |         1 |   0.00954s |        33% |\n| setup system                    |         1 |   0.00585s |        20% |\n| solve                           |         1 |   0.00966s |        34% |\n+---------------------------------+-----------+------------+------------+\n \n.\n.\n.\n \n--------------------------------------------------------------------------------\nCycle 6\n--------------------------------------------------------------------------------\nSet up system...\n   Triangulation: 81920 cells\n   DoFHandler:    1311745 DoFs\n \nSolve using Newton's method...\n   Nstep 1, errf = 5.90478e-05, errx = 231.427, it = 9\n   Nstep 2, errf = 5.89991e-08, errx = 6.67102, it = 6\n   Nstep 3, errf = 4.28813e-13, errx = 0.0067188, it = 4\nConvergence step 3 value 4.28813e-13 (used wall time: 4.82953 s)\n \nTime for setup+solve (CPU/Wall) 6.25094/6.37174 s\n \nOutput results...\n  H1 seminorm: 0.773426\n \n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |      9.04s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| assemble right hand side        |         3 |    0.0827s |      0.91% |\n| compute residual                |         3 |    0.0909s |         1% |\n| compute update                  |         3 |      4.65s |        51% |\n| setup system                    |         1 |      1.54s |        17% |\n| solve                           |         1 |      4.83s |        53% |\n+---------------------------------+-----------+------------+------------+\n \n================================================================================\nSTART DATE: 2021/5/18, TIME: 16:26:00\n--------------------------------------------------------------------------------\nRunning with 2 MPI processes\nVectorization over 4 doubles = 256 bits (AVX), VECTORIZATION_LEVEL=2\nFinite element space: FE_Q<3>(4)\n================================================================================\n \n.\n.\n.\n \n--------------------------------------------------------------------------------\nCycle 5\n--------------------------------------------------------------------------------\nSet up system...\n Triangulation: 229376 cells\n DoFHandler:    14729857 DoFs\n \nSolve using Newton's method...\n   Nstep 1, errf = 6.30096e-06, errx = 481.74, it = 8\n   Nstep 2, errf = 4.25607e-10, errx = 4.14315, it = 6\n   Nstep 3, errf = 7.29563e-13, errx = 0.000321775, it = 2\nConvergence step 3 value 7.29563e-13 (used wall time: 133.793 s)\n \nTime for setup+solve (CPU/Wall) 226.809/232.615 s\n \nOutput results...\n  H1 seminorm: 0.588667\n \n \n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |       390s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| assemble right hand side        |         3 |      2.06s |      0.53% |\n| compute residual                |         3 |      2.46s |      0.63% |\n| compute update                  |         3 |       129s |        33% |\n| setup system                    |         1 |      98.8s |        25% |\n| solve                           |         1 |       134s |        34% |\n+---------------------------------+-----------+------------+------------+\n```\n\nWe show the solution for the two- and three-dimensional problem in the following figure.\n\n![Solution of the two-dimensional Gelfand problem.](images/steps/developer/step-66.solution-2d.png)\n\n![Solution of the three-dimensional Gelfand problem.](images/steps/developer/step-66.solution-3d.png)\n\n### Newton solver\n\nIn the program output above we find some interesting information about the Newton iterations. The terminal output in each refinement cycle presents detailed diagnostics of the Newton method, which show first of all the number of Newton steps and for each step the norm of the residual \\(\\|F(u\\_h^{n+1})\\|\\), the norm of the Newton update \\(\\|s\\_h^n\\|\\), and the number of CG iterations `it`.\n\nWe observe that for all cases the Newton method converges in approximately three to four steps, which shows the quadratic convergence of the Newton method with a full step length \\(\\alpha = 1\\). However, be aware that for a badly chosen initial guess \\(u\\_h^0\\), the Newton method will also diverge quadratically. Usually if you do not have an appropriate initial guess, you try a few damped Newton steps with a reduced step length \\(\\alpha < 1\\) until the Newton step is again in the quadratic convergence domain. This damping and relaxation of the Newton step length truly requires a more sophisticated implementation of the Newton method, which we designate to you as a possible extension of the tutorial.\n\nFurthermore, we see that the number of CG iterations is approximately constant with successive mesh refinements and an increasing number of DoFs. This is of course due to the geometric multigrid preconditioner and similar to the observations made in other tutorials that use this method, e.g., [step-16](step_16.html) and [step-37](step_37.html). Just to give an example, in the three-dimensional case after five refinements, we have approximately 14.7 million distributed DoFs with fourth-order Lagrangian finite elements, but the number of CG iterations is still less than ten.\n\nIn addition, there is one more very useful optimization that we applied and that should be mentioned here. In the `compute_update()` function we explicitly reset the vector holding the Newton update before passing it as the output vector to the solver. In that case we use a starting value of zero for the CG method, which is more suitable than the previous Newton update, the actual content of the `newton_update` before resetting, and thus reduces the number of CG iterations by a few steps.\n\n### Possibilities for extensions\n\nA couple of possible extensions are available concerning minor updates to the present code as well as a deeper numerical investigation of the Gelfand problem.\n\n#### More sophisticated Newton iteration\n\nBeside a step size controlled version of the Newton iteration as mentioned already in [step-15](step_15.html) (and actually implemented, with many more bells and whistles, in [step-77](step_77.html)), one could also implement a more flexible stopping criterion for the Newton iteration. For example one could replace the fixed tolerances for the residual `TOLf` and for the Newton updated `TOLx` and implement a mixed error control with a given absolute and relative tolerance, such that the Newton iteration exits with success as, e.g.,\n\n\\begin{align\\*}\n\\|F(u\\_h^{n+1})\\| \\leq \\texttt{RelTol} \\|u\\_h^{n+1}\\| + \\texttt{AbsTol}.\n\\end{align\\*}\n\nFor more advanced applications with many nonlinear systems to solve, for example at each time step for a time-dependent problem, it turns out that it is not necessary to set up and assemble the Jacobian anew at every single Newton step or even for each time step. Instead, the existing Jacobian from a previous step can be used for the Newton iteration. The Jacobian is then only rebuilt if, for example, the Newton iteration converges too slowly. Such an idea yields a [quasi-Newton method](https://en.wikipedia.org/wiki/Quasi-Newton_method). Admittedly, when using the matrix-free framework, the assembly of the Jacobian is omitted anyway, but with in this way one can try to optimize the reassembly of the geometric multigrid preconditioner. Remember that each time the solution from the old Newton step must be distributed to all levels and the mutligrid preconditioner must be reinitialized.\n\n#### Parallel scalability and thread parallelism\n\nIn the results section of [step-37](step_37.html) and others, the parallel scalability of the matrix-free framework on a large number of processors has already been demonstrated very impressively. In the nonlinear case we consider here, we note that one of the bottlenecks could become the transfer and evaluation of the matrix-free Jacobi operator and its multistage operators in the previous Newton step, since we need to transfer the old solution at all stages in each step. A first parallel scalability analysis in [[54]](citelist.html#CITEREF_castelli2021numerical) shows quite good strong scalability when the problem size is large enough. However, a more detailed analysis needs to be performed for reliable results. Moreover, the problem has been solved only with MPI so far, without using the possibilities of shared memory parallelization with threads. Therefore, for this example, you could try hybrid parallelization with MPI and threads, such as described in [step-48](step_48.html).\n\n#### Comparison to matrix-based methods\n\nAnalogously to [step-50](step_50.html) and the mentioned possible extension of [step-75](step_75.html), you can convince yourself which method is faster.\n\n#### Eigenvalue problem\n\nOne can consider the corresponding eigenvalue problem, which is called [Bratu problem](https://en.wikipedia.org/wiki/Liouville%E2%80%93Bratu%E2%80%93Gelfand_equation). For example, if we define a fixed eigenvalue \\(\\lambda\\in[0,6]\\), we can compute the corresponding discrete eigenfunction. You will notice that the number of Newton steps will increase with increasing \\(\\lambda\\). To reduce the number of Newton steps you can use the following trick: start from a certain \\(\\lambda\\), compute the eigenfunction, increase \\(\\lambda=\\lambda +\n\\delta\\_\\lambda\\), and then use the previous solution as an initial guess for the Newton iteration – this approach is called a \"continuation\nmethod\". In the end you can plot the \\(H^1(\\Omega)\\)-norm over the eigenvalue \\(\\lambda \\mapsto \\|u\\_h\\|\\_{H^1(\\Omega)}\\). What do you observe for further increasing \\(\\lambda>7\\)?\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2021 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Fabian Castelli, Karlsruhe Institute of Technology (KIT)\n */\n \n \n \n#include <deal.II/base/function.h>\n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/timer.h>\n#include <deal.II/base/vectorization.h>\n \n#include <deal.II/dofs/dof_accessor.h>\n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/mapping_q.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_out.h>\n#include <deal.II/grid/manifold_lib.h>\n#include <deal.II/grid/tria.h>\n#include <deal.II/grid/tria_accessor.h>\n#include <deal.II/grid/tria_iterator.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/precondition.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <deal.II/matrix_free/fe_evaluation.h>\n#include <deal.II/matrix_free/matrix_free.h>\n#include <deal.II/matrix_free/operators.h>\n#include <deal.II/matrix_free/tools.h>\n \n#include <deal.II/multigrid/mg_coarse.h>\n#include <deal.II/multigrid/mg_constrained_dofs.h>\n#include <deal.II/multigrid/mg_matrix.h>\n#include <deal.II/multigrid/mg_smoother.h>\n#include <deal.II/multigrid/mg_tools.h>\n#include <deal.II/multigrid/mg_transfer_matrix_free.h>\n#include <deal.II/multigrid/multigrid.h>\n \n \n#include <fstream>\n#include <iostream>\n \n \n \nnamespace Step66\n{\n using namespace dealii;\n \n \n \n \n template <int dim, int fe_degree, typename number>\n class JacobianOperator\n    : public MatrixFreeOperators::\n        Base<dim, LinearAlgebra::distributed::Vector<number>>\n  {\n public:\n using value_type = number;\n \n using FECellIntegrator =\n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, number>;\n \n    JacobianOperator();\n \n virtual void clear() override;\n \n void evaluate_newton_step(\n const LinearAlgebra::distributed::Vector<number> &newton_step);\n \n virtual void compute_diagonal() override;\n \n private:\n virtual void apply_add(\n LinearAlgebra::distributed::Vector<number>       &dst,\n const LinearAlgebra::distributed::Vector<number> &src) const override;\n \n void\n    local_apply(const MatrixFree<dim, number>                    &data,\n LinearAlgebra::distributed::Vector<number>       &dst,\n const LinearAlgebra::distributed::Vector<number> &src,\n const std::pair<unsigned int, unsigned int> &cell_range) const;\n \n void local_compute_diagonal(FECellIntegrator &integrator) const;\n \n Table<2, VectorizedArray<number>> nonlinear_values;\n  };\n \n \n \n template <int dim, int fe_degree, typename number>\n  JacobianOperator<dim, fe_degree, number>::JacobianOperator()\n    : MatrixFreeOperators::Base<dim,\n LinearAlgebra::distributed::Vector<number>>()\n  {}\n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::clear()\n  {\n    nonlinear_values.reinit(0, 0);\n MatrixFreeOperators::Base<dim, LinearAlgebra::distributed::Vector<number>>::\n      clear();\n  }\n \n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::evaluate_newton_step(\n const LinearAlgebra::distributed::Vector<number> &newton_step)\n  {\n const unsigned int n_cells = this->data->n_cell_batches();\n    FECellIntegrator   phi(*this->data);\n \n    newton_step.update_ghost_values();\n \n    nonlinear_values.reinit(n_cells, phi.n_q_points);\n \n for (unsigned int cell = 0; cell < n_cells; ++cell)\n      {\n        phi.reinit(cell);\n        phi.read_dof_values_plain(newton_step);\n        phi.evaluate(EvaluationFlags::values);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n            nonlinear_values(cell, q) = std::exp(phi.get_value(q));\n          }\n      }\n    newton_step.zero_out_ghost_values();\n  }\n \n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::local_apply(\n const MatrixFree<dim, number>                    &data,\n LinearAlgebra::distributed::Vector<number>       &dst,\n const LinearAlgebra::distributed::Vector<number> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const\n {\n    FECellIntegrator phi(data);\n \n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n      {\n AssertDimension(nonlinear_values.size(0),\n                        phi.get_matrix_free().n_cell_batches());\n AssertDimension(nonlinear_values.size(1), phi.n_q_points);\n \n \n        phi.reinit(cell);\n \n        phi.gather_evaluate(src,\n EvaluationFlags::values |\n EvaluationFlags::gradients);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n            phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\n            phi.submit_gradient(phi.get_gradient(q), q);\n          }\n \n        phi.integrate_scatter(EvaluationFlags::values |\n EvaluationFlags::gradients,\n                              dst);\n      }\n  }\n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::apply_add(\n LinearAlgebra::distributed::Vector<number>       &dst,\n const LinearAlgebra::distributed::Vector<number> &src) const\n {\n    this->data->cell_loop(&JacobianOperator::local_apply, this, dst, src);\n  }\n \n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::local_compute_diagonal(\n    FECellIntegrator &phi) const\n {\n AssertDimension(nonlinear_values.size(0),\n                    phi.get_matrix_free().n_cell_batches());\n AssertDimension(nonlinear_values.size(1), phi.n_q_points);\n \n const unsigned int cell = phi.get_current_cell_index();\n \n    phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n      {\n        phi.submit_value(-nonlinear_values(cell, q) * phi.get_value(q), q);\n        phi.submit_gradient(phi.get_gradient(q), q);\n      }\n \n    phi.integrate(EvaluationFlags::values | EvaluationFlags::gradients);\n  }\n \n \n \n template <int dim, int fe_degree, typename number>\n void JacobianOperator<dim, fe_degree, number>::compute_diagonal()\n  {\n    this->inverse_diagonal_entries.reset(\n new DiagonalMatrix<LinearAlgebra::distributed::Vector<number>>());\n LinearAlgebra::distributed::Vector<number> &inverse_diagonal =\n      this->inverse_diagonal_entries->get_vector();\n    this->data->initialize_dof_vector(inverse_diagonal);\n \n MatrixFreeTools::compute_diagonal(*this->data,\n                                      inverse_diagonal,\n                                      &JacobianOperator::local_compute_diagonal,\n this);\n \n for (auto &diagonal_element : inverse_diagonal)\n      {\n        diagonal_element = (std::abs(diagonal_element) > 1.0e-10) ?\n                             (1.0 / diagonal_element) :\n                             1.0;\n      }\n  }\n \n \n \n \n template <int dim, int fe_degree>\n class GelfandProblem\n  {\n public:\n    GelfandProblem();\n \n void run();\n \n private:\n void make_grid();\n \n void setup_system();\n \n void evaluate_residual(\n LinearAlgebra::distributed::Vector<double>       &dst,\n const LinearAlgebra::distributed::Vector<double> &src) const;\n \n void local_evaluate_residual(\n const MatrixFree<dim, double>                    &data,\n LinearAlgebra::distributed::Vector<double>       &dst,\n const LinearAlgebra::distributed::Vector<double> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const;\n \n void assemble_rhs();\n \n double compute_residual(const double alpha);\n \n void compute_update();\n \n void solve();\n \n double compute_solution_norm() const;\n \n void output_results(const unsigned int cycle) const;\n \n \n parallel::distributed::Triangulation<dim> triangulation;\n const MappingQ<dim>                       mapping;\n \n \n const FE_Q<dim> fe;\n DoFHandler<dim> dof_handler;\n \n \n AffineConstraints<double> constraints;\n using SystemMatrixType = JacobianOperator<dim, fe_degree, double>;\n    SystemMatrixType system_matrix;\n \n \n MGConstrainedDoFs mg_constrained_dofs;\n using LevelMatrixType = JacobianOperator<dim, fe_degree, float>;\n MGLevelObject<LevelMatrixType>                           mg_matrices;\n MGLevelObject<LinearAlgebra::distributed::Vector<float>> mg_solution;\n MGTransferMatrixFree<dim, float>                         mg_transfer;\n \n \n LinearAlgebra::distributed::Vector<double> solution;\n LinearAlgebra::distributed::Vector<double> newton_update;\n LinearAlgebra::distributed::Vector<double> system_rhs;\n \n \n unsigned int linear_iterations;\n \n \n ConditionalOStream pcout;\n \n \n TimerOutput computing_timer;\n  };\n \n \n \n template <int dim, int fe_degree>\n  GelfandProblem<dim, fe_degree>::GelfandProblem()\n    : triangulation(MPI_COMM_WORLD,\n Triangulation<dim>::limit_level_difference_at_vertices,\n parallel::distributed::Triangulation<\n                      dim>::construct_multigrid_hierarchy)\n    , mapping(fe_degree)\n    , fe(fe_degree)\n    , dof_handler(triangulation)\n    , pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n    , computing_timer(MPI_COMM_WORLD,\n                      pcout,\n TimerOutput::never,\n TimerOutput::wall_times)\n  {}\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::make_grid()\n  {\n TimerOutput::Scope t(computing_timer, \"make grid\");\n \n SphericalManifold<dim>                boundary_manifold;\n TransfiniteInterpolationManifold<dim> inner_manifold;\n \n GridGenerator::hyper_ball(triangulation);\n \n triangulation.set_all_manifold_ids(1);\n triangulation.set_all_manifold_ids_on_boundary(0);\n \n triangulation.set_manifold(0, boundary_manifold);\n \n    inner_manifold.initialize(triangulation);\n triangulation.set_manifold(1, inner_manifold);\n \n triangulation.refine_global(3 - dim);\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::setup_system()\n  {\n TimerOutput::Scope t(computing_timer, \"setup system\");\n \n    system_matrix.clear();\n    mg_matrices.clear_elements();\n \n    dof_handler.distribute_dofs(fe);\n    dof_handler.distribute_mg_dofs();\n \n    constraints.clear();\n    constraints.reinit(dof_handler.locally_owned_dofs(),\n DoFTools::extract_locally_relevant_dofs(dof_handler));\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\n VectorTools::interpolate_boundary_values(dof_handler,\n                                             0,\n Functions::ZeroFunction<dim>(),\n                                             constraints);\n    constraints.close();\n \n    {\n typename MatrixFree<dim, double>::AdditionalData additional_data;\n      additional_data.tasks_parallel_scheme =\n MatrixFree<dim, double>::AdditionalData::partition_color;\n      additional_data.mapping_update_flags =\n        (update_values | update_gradients | update_JxW_values |\n update_quadrature_points);\n auto system_mf_storage = std::make_shared<MatrixFree<dim, double>>();\n      system_mf_storage->reinit(mapping,\n                                dof_handler,\n                                constraints,\n QGauss<1>(fe.degree + 1),\n                                additional_data);\n \n      system_matrix.initialize(system_mf_storage);\n    }\n \n    system_matrix.initialize_dof_vector(solution);\n    system_matrix.initialize_dof_vector(newton_update);\n    system_matrix.initialize_dof_vector(system_rhs);\n \n \n const unsigned int nlevels = triangulation.n_global_levels();\n    mg_matrices.resize(0, nlevels - 1);\n    mg_solution.resize(0, nlevels - 1);\n \n const std::set<types::boundary_id> dirichlet_boundary_ids = {0};\n    mg_constrained_dofs.initialize(dof_handler);\n    mg_constrained_dofs.make_zero_boundary_constraints(dof_handler,\n                                                       dirichlet_boundary_ids);\n \n    mg_transfer.initialize_constraints(mg_constrained_dofs);\n    mg_transfer.build(dof_handler);\n \n for (unsigned int level = 0; level < nlevels; ++level)\n      {\n AffineConstraints<double> level_constraints(\n          dof_handler.locally_owned_mg_dofs(level),\n DoFTools::extract_locally_relevant_level_dofs(dof_handler, level));\n \n for (const types::global_dof_index dof_index :\n             mg_constrained_dofs.get_boundary_indices(level))\n          level_constraints.constrain_dof_to_zero(dof_index);\n        level_constraints.close();\n \n typename MatrixFree<dim, float>::AdditionalData additional_data;\n        additional_data.tasks_parallel_scheme =\n MatrixFree<dim, float>::AdditionalData::partition_color;\n        additional_data.mapping_update_flags =\n          (update_values | update_gradients | update_JxW_values |\n update_quadrature_points);\n        additional_data.mg_level = level;\n auto mg_mf_storage_level = std::make_shared<MatrixFree<dim, float>>();\n        mg_mf_storage_level->reinit(mapping,\n                                    dof_handler,\n                                    level_constraints,\n QGauss<1>(fe.degree + 1),\n                                    additional_data);\n \n        mg_matrices[level].initialize(mg_mf_storage_level,\n                                      mg_constrained_dofs,\n level);\n        mg_matrices[level].initialize_dof_vector(mg_solution[level]);\n      }\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::evaluate_residual(\n LinearAlgebra::distributed::Vector<double>       &dst,\n const LinearAlgebra::distributed::Vector<double> &src) const\n {\n auto matrix_free = system_matrix.get_matrix_free();\n \n    matrix_free->cell_loop(\n      &GelfandProblem::local_evaluate_residual, this, dst, src, true);\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::local_evaluate_residual(\n const MatrixFree<dim, double>                    &data,\n LinearAlgebra::distributed::Vector<double>       &dst,\n const LinearAlgebra::distributed::Vector<double> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const\n {\n FEEvaluation<dim, fe_degree, fe_degree + 1, 1, double> phi(data);\n \n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n      {\n        phi.reinit(cell);\n \n        phi.read_dof_values_plain(src);\n        phi.evaluate(EvaluationFlags::values | EvaluationFlags::gradients);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n            phi.submit_value(-std::exp(phi.get_value(q)), q);\n            phi.submit_gradient(phi.get_gradient(q), q);\n          }\n \n        phi.integrate_scatter(EvaluationFlags::values |\n EvaluationFlags::gradients,\n                              dst);\n      }\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::assemble_rhs()\n  {\n TimerOutput::Scope t(computing_timer, \"assemble right hand side\");\n \n    evaluate_residual(system_rhs, solution);\n \n    system_rhs *= -1.0;\n  }\n \n \n \n \n template <int dim, int fe_degree>\n double GelfandProblem<dim, fe_degree>::compute_residual(const double alpha)\n  {\n TimerOutput::Scope t(computing_timer, \"compute residual\");\n \n LinearAlgebra::distributed::Vector<double> residual;\n LinearAlgebra::distributed::Vector<double> evaluation_point;\n \n    system_matrix.initialize_dof_vector(residual);\n    system_matrix.initialize_dof_vector(evaluation_point);\n \n    evaluation_point = solution;\n if (alpha > 1e-12)\n      {\n        evaluation_point.add(alpha, newton_update);\n      }\n \n    evaluate_residual(residual, evaluation_point);\n \n return residual.l2_norm();\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::compute_update()\n  {\n TimerOutput::Scope t(computing_timer, \"compute update\");\n \n    solution.update_ghost_values();\n \n    system_matrix.evaluate_newton_step(solution);\n \n \n    mg_transfer.interpolate_to_mg(dof_handler, mg_solution, solution);\n \n \n using SmootherType =\n PreconditionChebyshev<LevelMatrixType,\n LinearAlgebra::distributed::Vector<float>>;\n mg::SmootherRelaxation<SmootherType,\n LinearAlgebra::distributed::Vector<float>>\n                                                         mg_smoother;\n MGLevelObject<typename SmootherType::AdditionalData> smoother_data;\n    smoother_data.resize(0, triangulation.n_global_levels() - 1);\n for (unsigned int level = 0; level < triangulation.n_global_levels();\n         ++level)\n      {\n if (level > 0)\n          {\n            smoother_data[level].smoothing_range     = 15.;\n            smoother_data[level].degree              = 4;\n            smoother_data[level].eig_cg_n_iterations = 10;\n          }\n else\n          {\n            smoother_data[0].smoothing_range = 1e-3;\n            smoother_data[0].degree          = numbers::invalid_unsigned_int;\n            smoother_data[0].eig_cg_n_iterations = mg_matrices[0].m();\n          }\n \n        mg_matrices[level].evaluate_newton_step(mg_solution[level]);\n        mg_matrices[level].compute_diagonal();\n \n        smoother_data[level].preconditioner =\n          mg_matrices[level].get_matrix_diagonal_inverse();\n      }\n    mg_smoother.initialize(mg_matrices, smoother_data);\n \n MGCoarseGridApplySmoother<LinearAlgebra::distributed::Vector<float>>\n      mg_coarse;\n    mg_coarse.initialize(mg_smoother);\n \n mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_matrix(\n      mg_matrices);\n \n MGLevelObject<MatrixFreeOperators::MGInterfaceOperator<LevelMatrixType>>\n      mg_interface_matrices;\n    mg_interface_matrices.resize(0, triangulation.n_global_levels() - 1);\n for (unsigned int level = 0; level < triangulation.n_global_levels();\n         ++level)\n      {\n        mg_interface_matrices[level].initialize(mg_matrices[level]);\n      }\n mg::Matrix<LinearAlgebra::distributed::Vector<float>> mg_interface(\n      mg_interface_matrices);\n \n Multigrid<LinearAlgebra::distributed::Vector<float>> mg(\n      mg_matrix, mg_coarse, mg_transfer, mg_smoother, mg_smoother);\n mg.set_edge_matrices(mg_interface, mg_interface);\n \n PreconditionMG<dim,\n LinearAlgebra::distributed::Vector<float>,\n MGTransferMatrixFree<dim, float>>\n      preconditioner(dof_handler, mg, mg_transfer);\n \n \n SolverControl solver_control(100, 1.e-12);\n SolverCG<LinearAlgebra::distributed::Vector<double>> cg(solver_control);\n \n    newton_update = 0.0;\n \n    cg.solve(system_matrix, newton_update, system_rhs, preconditioner);\n \n    constraints.distribute(newton_update);\n \n    linear_iterations = solver_control.last_step();\n \n \n    solution.zero_out_ghost_values();\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::solve()\n  {\n TimerOutput::Scope t(computing_timer, \"solve\");\n \n \n const unsigned int itmax = 10;\n const double       TOLf  = 1e-12;\n const double       TOLx  = 1e-10;\n \n \n Timer solver_timer;\n    solver_timer.start();\n \n \n for (unsigned int newton_step = 1; newton_step <= itmax; ++newton_step)\n      {\n        assemble_rhs();\n        compute_update();\n \n \n const double ERRx = newton_update.l2_norm();\n const double ERRf = compute_residual(1.0);\n \n \n        solution.add(1.0, newton_update);\n \n \n        pcout << \"   Nstep \" << newton_step << \", errf = \" << ERRf\n              << \", errx = \" << ERRx << \", it = \" << linear_iterations\n              << std::endl;\n \n \n if (ERRf < TOLf || ERRx < TOLx)\n          {\n            solver_timer.stop();\n \n            pcout << \"Convergence step \" << newton_step << \" value \" << ERRf\n                  << \" (used wall time: \" << solver_timer.wall_time() << \" s)\"\n                  << std::endl;\n \n break;\n          }\n else if (newton_step == itmax)\n          {\n            solver_timer.stop();\n            pcout << \"WARNING: No convergence of Newton's method after \"\n                  << newton_step << \" steps.\" << std::endl;\n \n break;\n          }\n      }\n  }\n \n \n \n \n template <int dim, int fe_degree>\n double GelfandProblem<dim, fe_degree>::compute_solution_norm() const\n {\n    solution.update_ghost_values();\n \n Vector<float> norm_per_cell(triangulation.n_active_cells());\n \n VectorTools::integrate_difference(mapping,\n                                      dof_handler,\n                                      solution,\n Functions::ZeroFunction<dim>(),\n                                      norm_per_cell,\n QGauss<dim>(fe.degree + 2),\n VectorTools::H1_seminorm);\n \n    solution.zero_out_ghost_values();\n \n return VectorTools::compute_global_error(triangulation,\n                                             norm_per_cell,\n VectorTools::H1_seminorm);\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void\n  GelfandProblem<dim, fe_degree>::output_results(const unsigned int cycle) const\n {\n if (triangulation.n_global_active_cells() > 1e6)\n return;\n \n    solution.update_ghost_values();\n \n DataOut<dim> data_out;\n    data_out.attach_dof_handler(dof_handler);\n    data_out.add_data_vector(solution, \"solution\");\n \n Vector<float> subdomain(triangulation.n_active_cells());\n for (unsigned int i = 0; i < subdomain.size(); ++i)\n      {\n        subdomain(i) = triangulation.locally_owned_subdomain();\n      }\n    data_out.add_data_vector(subdomain, \"subdomain\");\n \n    data_out.build_patches(mapping,\n                           fe.degree,\n DataOut<dim>::curved_inner_cells);\n \n DataOutBase::VtkFlags flags;\n    flags.compression_level = DataOutBase::CompressionLevel::best_speed;\n    data_out.set_flags(flags);\n    data_out.write_vtu_with_pvtu_record(\n \"./\", \"solution_\" + std::to_string(dim) + \"d\", cycle, MPI_COMM_WORLD, 3);\n \n    solution.zero_out_ghost_values();\n  }\n \n \n \n \n template <int dim, int fe_degree>\n void GelfandProblem<dim, fe_degree>::run()\n  {\n    {\n const unsigned int n_ranks =\n Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD);\n const unsigned int n_vect_doubles = VectorizedArray<double>::size();\n const unsigned int n_vect_bits    = 8 * sizeof(double) * n_vect_doubles;\n \n      std::string DAT_header = \"START DATE: \" + Utilities::System::get_date() +\n \", TIME: \" + Utilities::System::get_time();\n      std::string MPI_header = \"Running with \" + std::to_string(n_ranks) +\n \" MPI process\" + (n_ranks > 1 ? \"es\" : \"\");\n      std::string VEC_header =\n \"Vectorization over \" + std::to_string(n_vect_doubles) +\n \" doubles = \" + std::to_string(n_vect_bits) + \" bits (\" +\n Utilities::System::get_current_vectorization_level() +\n \"), VECTORIZATION_LEVEL=\" +\n        std::to_string(DEAL_II_COMPILER_VECTORIZATION_LEVEL);\n      std::string SOL_header = \"Finite element space: \" + fe.get_name();\n \n      pcout << std::string(80, '=') << std::endl;\n      pcout << DAT_header << std::endl;\n      pcout << std::string(80, '-') << std::endl;\n \n      pcout << MPI_header << std::endl;\n      pcout << VEC_header << std::endl;\n      pcout << SOL_header << std::endl;\n \n      pcout << std::string(80, '=') << std::endl;\n    }\n \n \n for (unsigned int cycle = 0; cycle < 9 - dim; ++cycle)\n      {\n        pcout << std::string(80, '-') << std::endl;\n        pcout << \"Cycle \" << cycle << std::endl;\n        pcout << std::string(80, '-') << std::endl;\n \n \n if (cycle == 0)\n          {\n            make_grid();\n          }\n else\n          {\n triangulation.refine_global(1);\n          }\n \n \n Timer timer;\n \n        pcout << \"Set up system...\" << std::endl;\n        setup_system();\n \n        pcout << \"   Triangulation: \" << triangulation.n_global_active_cells()\n              << \" cells\" << std::endl;\n        pcout << \"   DoFHandler:    \" << dof_handler.n_dofs() << \" DoFs\"\n              << std::endl;\n        pcout << std::endl;\n \n \n        pcout << \"Solve using Newton's method...\" << std::endl;\n        solve();\n        pcout << std::endl;\n \n \n        timer.stop();\n        pcout << \"Time for setup+solve (CPU/Wall) \" << timer.cpu_time() << '/'\n              << timer.wall_time() << \" s\" << std::endl;\n        pcout << std::endl;\n \n \n        pcout << \"Output results...\" << std::endl;\n const double norm = compute_solution_norm();\n        output_results(cycle);\n \n        pcout << \"  H1 seminorm: \" << norm << std::endl;\n        pcout << std::endl;\n \n \n        computing_timer.print_summary();\n        computing_timer.reset();\n      }\n  }\n} // namespace Step66\n \n \n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n using namespace Step66;\n \n Utilities::MPI::MPI_InitFinalize mpi_init(argc, argv, 1);\n \n      {\n        GelfandProblem<2, 4> gelfand_problem;\n        gelfand_problem.run();\n      }\n \n      {\n        GelfandProblem<3, 4> gelfand_problem;\n        gelfand_problem.run();\n      }\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_67.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSolving the Euler equations of compressible gas dynamics with an explicit time integrator and high-order discontinuous Galerkin methods based on matrix-free implementations.\nTutorial content :\nThis tutorial depends on [step-33](step_33.html), [step-48](step_48.html), [step-59](step_59.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_67-Intro)    * [The Euler equations](#step_67-TheEulerequations)* [High-order discontinuous Galerkin discretization](#step_67-HighorderdiscontinuousGalerkindiscretization)* [Explicit time integration](#step_67-Explicittimeintegration)* [Fast evaluation of integrals by matrix-free techniques](#step_67-Fastevaluationofintegralsbymatrixfreetechniques)* [Evaluation of the inverse mass matrix with matrix-free techniques](#step_67-Evaluationoftheinversemassmatrixwithmatrixfreetechniques)* [The test case](#step_67-Thetestcase)- [The commented program](#step_67-CommProg)      * [Equation data](#step_67-Equationdata)* [Low-storage explicit Runge—Kutta time integrators](#step_67-LowstorageexplicitRungeKuttatimeintegrators)* [Implementation of point-wise operations of the Euler equations](#step_67-ImplementationofpointwiseoperationsoftheEulerequations)* [The EulerOperation class](#step_67-TheEulerOperationclass)              + [Local evaluators](#step_67-Localevaluators)+ [The apply() and related functions](#step_67-Theapplyandrelatedfunctions)* [The EulerProblem class](#step_67-TheEulerProblemclass) | 1. [Results](#step_67-Results)    * [Program output](#step_67-Programoutput)* [Convergence rates for the analytical test case](#step_67-Convergenceratesfortheanalyticaltestcase)* [Results for flow in channel around cylinder in 2D](#step_67-Resultsforflowinchannelaroundcylinderin2D)* [Results for flow in channel around cylinder in 3D](#step_67-Resultsforflowinchannelaroundcylinderin3D)* [Possibilities for extensions](#step_67-Possibilitiesforextensions)              + [More advanced numerical flux functions and skew-symmetric formulations](#step_67-Moreadvancednumericalfluxfunctionsandskewsymmetricformulations)+ [Equipping the code for supersonic calculations](#step_67-Equippingthecodeforsupersoniccalculations)+ [Extension to the linearized Euler equations](#step_67-ExtensiontothelinearizedEulerequations)+ [Extension to the compressible Navier-Stokes equations](#step_67-ExtensiontothecompressibleNavierStokesequations)+ [Using cell-centric loops and shared memory](#step_67-Usingcellcentricloopsandsharedmemory)- [The plain program](#step_67-PlainProg) |\n\n*This program was contributed by Martin Kronbichler. Many ideas presented here are the result of common code development with Niklas Fehn, Katharina Kormann, Peter Munch, and Svenja Schoeder.*\n\n*This work was partly supported by the German Research Foundation (DFG) through the project \"High-order discontinuous Galerkin for the exa-scale\" (ExaDG) within the priority program \"Software for Exascale Computing\" (SPPEXA).*\n\nIntroduction\n============\n\nThis tutorial program solves the Euler equations of fluid dynamics using an explicit time integrator with the matrix-free framework applied to a high-order discontinuous Galerkin discretization in space. For details about the Euler system and an alternative implicit approach, we also refer to the [step-33](step_33.html) tutorial program. You might also want to look at [step-69](step_69.html) for an alternative approach to solving these equations.\n\n### The Euler equations\n\nThe Euler equations are a conservation law, describing the motion of a compressible inviscid gas,\n\n\\[\n\\frac{\\partial \\mathbf{w}}{\\partial t} + \\nabla \\cdot \\mathbf{F}(\\mathbf{w}) =\n\\mathbf{G}(\\mathbf w),\n\\]\n\nwhere the \\(d+2\\) components of the solution vector are \\(\\mathbf{w}=(\\rho, \\rho\nu\\_1,\\ldots,\\rho u\\_d,E)^{\\mathrm T}\\). Here, \\(\\rho\\) denotes the fluid density, \\({\\mathbf u}=(u\\_1,\\ldots, u\\_d)^\\mathrm T\\) the fluid velocity, and \\(E\\) the energy density of the gas. The velocity is not directly solved for, but rather the variable \\(\\rho \\mathbf{u}\\), the linear momentum (since this is the conserved quantity).\n\nThe Euler flux function, a \\((d+2)\\times d\\) matrix, is defined as\n\n\\[\n\\mathbf F(\\mathbf w)\n=\n\\begin{pmatrix}\n\\rho \\mathbf{u}\\\\\n\\rho \\mathbf{u} \\otimes \\mathbf{u} + \\mathbb{I}p\\\\\n(E+p)\\mathbf{u}\n\\end{pmatrix}\n\\]\n\nwith \\(\\mathbb{I}\\) the \\(d\\times d\\) identity matrix and \\(\\otimes\\) the outer product; its components denote the mass, momentum, and energy fluxes, respectively. The right hand side forcing is given by\n\n\\[\n\\mathbf G(\\mathbf w)\n=\n\\begin{pmatrix}\n0\\\\\n\\rho\\mathbf{g}\\\\\n\\rho \\mathbf{u} \\cdot \\mathbf{g}\n\\end{pmatrix},\n\\]\n\nwhere the vector \\(\\mathbf g\\) denotes the direction and magnitude of gravity. It could, however, also denote any other external force per unit mass that is acting on the fluid. (Think, for example, of the electrostatic forces exerted by an external electric field on charged particles.)\n\nThe three blocks of equations, the second involving \\(d\\) components, describe the conservation of mass, momentum, and energy. The pressure is not a solution variable but needs to be expressed through a \"closure relationship\" by the other variables; we here choose the relationship appropriate for a gas with molecules composed of two atoms, which at moderate temperatures is given by \\(p=(\\gamma - 1) \\left(E-\\frac 12 \\rho\n\\mathbf{u}\\cdot \\mathbf{u}\\right)\\) with the constant \\(\\gamma = 1.4\\).\n\n### High-order discontinuous Galerkin discretization\n\nFor spatial discretization, we use a high-order discontinuous Galerkin (DG) discretization, using a solution expansion of the form\n\n\\[\n\\mathbf{w}\\_h(\\mathbf{x}, t) =\n\\sum\\_{j=1}^{n\\_\\mathbf{dofs}} \\boldsymbol{\\varphi}\\_j(\\mathbf{x}) {w}\\_j(t).\n\\]\n\nHere, \\(\\boldsymbol{\\varphi}\\_j\\) denotes the \\(j\\)th basis function, written in vector form with separate shape functions for the different components and letting \\(w\\_j(t)\\) go through the density, momentum, and energy variables, respectively. In this form, the space dependence is contained in the shape functions and the time dependence in the unknown coefficients \\(w\\_j\\). As opposed to the continuous finite element method where some shape functions span across element boundaries, the shape functions are local to a single element in DG methods, with a discontinuity from one element to the next. The connection of the solution from one cell to its neighbors is instead imposed by the numerical fluxes specified below. This allows for some additional flexibility, for example to introduce directionality in the numerical method by, e.g., upwinding.\n\nDG methods are popular methods for solving problems of transport character because they combine low dispersion errors with controllable dissipation on barely resolved scales. This makes them particularly attractive for simulation in the field of fluid dynamics where a wide range of active scales needs to be represented and inadequately resolved features are prone to disturb the important well-resolved features. Furthermore, high-order DG methods are well-suited for modern hardware with the right implementation. At the same time, DG methods are no silver bullet. In particular when the solution develops discontinuities (shocks), as is typical for the Euler equations in some flow regimes, high-order DG methods tend to oscillatory solutions, like all high-order methods when not using flux- or slope-limiters. This is a consequence of [Godunov's theorem](https://en.wikipedia.org/wiki/Godunov%27s_theorem) that states that any total variation limited (TVD) scheme that is linear (like a basic DG discretization) can at most be first-order accurate. Put differently, since DG methods aim for higher order accuracy, they cannot be TVD on solutions that develop shocks. Even though some communities claim that the numerical flux in DG methods can control dissipation, this is of limited value unless **all** shocks in a problem align with cell boundaries. Any shock that passes through the interior of cells will again produce oscillatory components due to the high-order polynomials. In the finite element and DG communities, there exist a number of different approaches to deal with shocks, for example the introduction of artificial diffusion on troubled cells (using a troubled-cell indicator based e.g. on a modal decomposition of the solution), a switch to dissipative low-order finite volume methods on a subgrid, or the addition of some limiting procedures. Given the ample possibilities in this context, combined with the considerable implementation effort, we here refrain from the regime of the Euler equations with pronounced shocks, and rather concentrate on the regime of subsonic flows with wave-like phenomena. For a method that works well with shocks (but is more expensive per unknown), we refer to the [step-69](step_69.html) tutorial program.\n\nFor the derivation of the DG formulation, we multiply the Euler equations with test functions \\(\\mathbf{v}\\) and integrate over an individual cell \\(K\\), which gives\n\n\\[\n\\left(\\mathbf{v}, \\frac{\\partial \\mathbf{w}}{\\partial t}\\right)\\_{K}\n+ \\left(\\mathbf{v}, \\nabla \\cdot \\mathbf{F}(\\mathbf{w})\\right)\\_{K} =\n\\left(\\mathbf{v},\\mathbf{G}(\\mathbf w)\\right)\\_{K}.\n\\]\n\nWe then integrate the second term by parts, moving the divergence from the solution slot to the test function slot, and producing an integral over the element boundary:\n\n\\[\n\\left(\\mathbf{v}, \\frac{\\partial \\mathbf{w}}{\\partial t}\\right)\\_{K}\n- \\left(\\nabla \\mathbf{v}, \\mathbf{F}(\\mathbf{w})\\right)\\_{K}\n+ \\left<\\mathbf{v}, \\mathbf{n} \\cdot \\widehat{\\mathbf{F}}(\\mathbf{w})\n\\right>\\_{\\partial K} =\n\\left(\\mathbf{v},\\mathbf{G}(\\mathbf w)\\right)\\_{K}.\n\\]\n\nIn the surface integral, we have replaced the term \\(\\mathbf{F}(\\mathbf w)\\) by the term \\(\\widehat{\\mathbf{F}}(\\mathbf w)\\), the numerical flux. The role of the numerical flux is to connect the solution on neighboring elements and weakly impose continuity of the solution. This ensures that the global coupling of the PDE is reflected in the discretization, despite independent basis functions on the cells. The connectivity to the neighbor is included by defining the numerical flux as a function \\(\\widehat{\\mathbf{F}}(\\mathbf w^-,\n\\mathbf w^+)\\) of the solution from both sides of an interior face, \\(\\mathbf\nw^-\\) and \\(\\mathbf w^+\\). A basic property we require is that the numerical flux needs to be **conservative**. That is, we want all information (i.e., mass, momentum, and energy) that leaves a cell over a face to enter the neighboring cell in its entirety and vice versa. This can be expressed as \\(\\widehat{\\mathbf{F}}(\\mathbf w^-, \\mathbf w^+) =\n\\widehat{\\mathbf{F}}(\\mathbf w^+, \\mathbf w^-)\\), meaning that the numerical flux evaluates to the same result from either side. Combined with the fact that the numerical flux is multiplied by the unit outer normal vector on the face under consideration, which points in opposite direction from the two sides, we see that the conservation is fulfilled. An alternative point of view of the numerical flux is as a single-valued intermediate state that links the solution weakly from both sides.\n\nThere is a large number of numerical flux functions available, also called Riemann solvers. For the Euler equations, there exist so-called exact Riemann solvers – meaning that the states from both sides are combined in a way that is consistent with the Euler equations along a discontinuity – and approximate Riemann solvers, which violate some physical properties and rely on other mechanisms to render the scheme accurate overall. Approximate Riemann solvers have the advantage of being cheaper to compute. Most flux functions have their origin in the finite volume community, which are similar to DG methods with polynomial degree 0 within the cells (called volumes). As the volume integral of the Euler operator \\(\\mathbf{F}\\) would disappear for constant solution and test functions, the numerical flux must fully represent the physical operator, explaining why there has been a large body of research in that community. For DG methods, consistency is guaranteed by higher order polynomials within the cells, making the numerical flux less of an issue and usually affecting only the convergence rate, e.g., whether the solution converges as \\(\\mathcal O(h^p)\\), \\(\\mathcal O(h^{p+1/2})\\) or \\(\\mathcal\nO(h^{p+1})\\) in the \\(L\\_2\\) norm for polynomials of degree \\(p\\). The numerical flux can thus be seen as a mechanism to select more advantageous dissipation/dispersion properties or regarding the extremal eigenvalue of the discretized and linearized operator, which affect the maximal admissible time step size in explicit time integrators.\n\nIn this tutorial program, we implement two variants of fluxes that can be controlled via a switch in the program (of course, it would be easy to make them a run time parameter controlled via an input file). The first flux is the local Lax–Friedrichs flux\n\n\\[\n\\hat{\\mathbf{F}}(\\mathbf{w}^-,\\mathbf{w}^+) =\n\\frac{\\mathbf{F}(\\mathbf{w}^-)+\\mathbf{F}(\\mathbf{w}^+)}{2} +\n\\frac{\\lambda}{2}\\left[\\mathbf{w}^--\\mathbf{w}^+\\right]\\otimes\n\\mathbf{n^-}.\n\\]\n\nIn the original definition of the Lax–Friedrichs flux, a factor \\(\\lambda =\n\\max\\left(\\|\\mathbf{u}^-\\|+c^-, \\|\\mathbf{u}^+\\|+c^+\\right)\\) is used (corresponding to the maximal speed at which information is moving on the two sides of the interface), stating that the difference between the two states, \\([\\![\\mathbf{w}]\\!]\\) is penalized by the largest eigenvalue in the Euler flux, which is \\(\\|\\mathbf{u}\\|+c\\), where \\(c=\\sqrt{\\gamma p / \\rho}\\) is the speed of sound. In the implementation below, we modify the penalty term somewhat, given that the penalty is of approximate nature anyway. We use\n\n\\begin{align\\*}\n\\lambda\n&=\n\\frac{1}{2}\\max\\left(\\sqrt{\\|\\mathbf{u^-}\\|^2+(c^-)^2},\n\\sqrt{\\|\\mathbf{u}^+\\|^2+(c^+)^2}\\right)\n\\\\\n&=\n\\frac{1}{2}\\sqrt{\\max\\left(\\|\\mathbf{u^-}\\|^2+(c^-)^2,\n\\|\\mathbf{u}^+\\|^2+(c^+)^2\\right)}.\n\\end{align\\*}\n\nThe additional factor \\(\\frac 12\\) reduces the penalty strength (which results in a reduced negative real part of the eigenvalues, and thus increases the admissible time step size). Using the squares within the sums allows us to reduce the number of expensive square root operations, which is 4 for the original Lax–Friedrichs definition, to a single one. This simplification leads to at most a factor of 2 in the reduction of the parameter \\(\\lambda\\), since \\(\\|\\mathbf{u}\\|^2+c^2 \\leq\n\\|\\mathbf{u}\\|^2+2 c |\\mathbf{u}\\| + c^2 = \\left(\\|\\mathbf{u}\\|+c\\right)^2\n\\leq 2 \\left(\\|\\mathbf{u}\\|^2+c^2\\right)\\), with the last inequality following from Young's inequality.\n\nThe second numerical flux is one proposed by Harten, Lax and van Leer, called the HLL flux. It takes the different directions of propagation of the Euler equations into account, depending on the speed of sound. It utilizes some intermediate states \\(\\bar{\\mathbf{u}}\\) and \\(\\bar{c}\\) to define the two branches \\(s^\\mathrm{p} = \\max\\left(0, \\bar{\\mathbf{u}}\\cdot \\mathbf{n} +\n\\bar{c}\\right)\\) and \\(s^\\mathrm{n} = \\min\\left(0, \\bar{\\mathbf{u}}\\cdot\n\\mathbf{n} - \\bar{c}\\right)\\). From these branches, one then defines the flux\n\n\\[\n\\hat{\\mathbf{F}}(\\mathbf{w}^-,\\mathbf{w}^+) =\n\\frac{s^\\mathrm{p} \\mathbf{F}(\\mathbf{w}^-)-s^\\mathrm{n} \\mathbf{F}(\\mathbf{w}^+)}\n{s^\\mathrm p - s^\\mathrm{n} } +\n\\frac{s^\\mathrm{p} s^\\mathrm{n}}{s^\\mathrm{p}-s^\\mathrm{n}}\n\\left[\\mathbf{w}^--\\mathbf{w}^+\\right]\\otimes \\mathbf{n^-}.\n\\]\n\nRegarding the definition of the intermediate state \\(\\bar{\\mathbf{u}}\\) and \\(\\bar{c}\\), several variants have been proposed. The variant originally proposed uses a density-averaged definition of the velocity, \\(\\bar{\\mathbf{u}}\n= \\frac{\\sqrt{\\rho^-} \\mathbf{u}^- + \\sqrt{\\rho^+}\\mathbf{u}^+}{\\sqrt{\\rho^-}\n+ \\sqrt{\\rho^+}}\\). Since we consider the Euler equations without shocks, we simply use arithmetic means, \\(\\bar{\\mathbf{u}} = \\frac{\\mathbf{u}^- +\n\\mathbf{u}^+}{2}\\) and \\(\\bar{c} = \\frac{c^- + c^+}{2}\\), with \\(c^{\\pm} =\n\\sqrt{\\gamma p^{\\pm} / \\rho^{\\pm}}\\), in this tutorial program, and leave other variants to a possible extension. We also note that the HLL flux has been extended in the literature to the so-called HLLC flux, where C stands for the ability to represent contact discontinuities.\n\nAt the boundaries with no neighboring state \\(\\mathbf{w}^+\\) available, it is common practice to deduce suitable exterior values from the boundary conditions (see the general literature on DG methods for details). In this tutorial program, we consider three types of boundary conditions, namely **inflow boundary conditions** where all components are prescribed,\n\n\\[\n\\mathbf{w}^+ = \\begin{pmatrix} \\rho\\_\\mathrm{D}(t)\\\\\n(\\rho \\mathbf u)\\_{\\mathrm D}(t) \\\\ E\\_\\mathrm{D}(t)\\end{pmatrix} \\quad\n\\text{(Dirichlet)},\n\\]\n\n**subsonic outflow boundaries**, where we do not prescribe exterior solutions as the flow field is leaving the domain and use the interior values instead; we still need to prescribe the energy as there is one incoming characteristic left in the Euler flux,\n\n\\[\n\\mathbf{w}^+ = \\begin{pmatrix} \\rho^-\\\\\n(\\rho \\mathbf u)^- \\\\ E\\_\\mathrm{D}(t)\\end{pmatrix} \\quad\n\\text{(mixed Neumann/Dirichlet)},\n\\]\n\nand **wall boundary condition** which describe a no-penetration configuration:\n\n\\[\n\\mathbf{w}^+ = \\begin{pmatrix} \\rho^-\\\\\n(\\rho \\mathbf u)^- - 2 [(\\rho \\mathbf u)^-\\cdot \\mathbf n] \\mathbf{n}\n\\\\ E^-\\end{pmatrix}.\n\\]\n\nThe polynomial expansion of the solution is finally inserted to the weak form and test functions are replaced by the basis functions. This gives a discrete in space, continuous in time nonlinear system with a finite number of unknown coefficient values \\(w\\_j\\), \\(j=1,\\ldots,n\\_\\text{dofs}\\). Regarding the choice of the polynomial degree in the DG method, there is no consensus in literature as of 2019 as to what polynomial degrees are most efficient and the decision is problem-dependent. Higher order polynomials ensure better convergence rates and are thus superior for moderate to high accuracy requirements for **smooth** solutions. At the same time, the volume-to-surface ratio of where degrees of freedom are located, increases with higher degrees, and this makes the effect of the numerical flux weaker, typically reducing dissipation. However, in most of the cases the solution is not smooth, at least not compared to the resolution that can be afforded. This is true for example in incompressible fluid dynamics, compressible fluid dynamics, and the related topic of wave propagation. In this pre-asymptotic regime, the error is approximately proportional to the numerical resolution, and other factors such as dispersion errors or the dissipative behavior become more important. Very high order methods are often ruled out because they come with more restrictive CFL conditions measured against the number of unknowns, and they are also not as flexible when it comes to representing complex geometries. Therefore, polynomial degrees between two and six are most popular in practice, see e.g. the efficiency evaluation in [[85]](citelist.html#CITEREF_FehnWallKronbichler2019) and references cited therein.\n\n### Explicit time integration\n\nTo discretize in time, we slightly rearrange the weak form and sum over all cells:\n\n\\[\n\\sum\\_{K \\in \\mathcal T\\_h} \\left(\\boldsymbol{\\varphi}\\_i,\n\\frac{\\partial \\mathbf{w}}{\\partial t}\\right)\\_{K}\n=\n\\sum\\_{K\\in \\mathcal T\\_h}\n\\left[\n\\left(\\nabla \\boldsymbol{\\varphi}\\_i, \\mathbf{F}(\\mathbf{w})\\right)\\_{K}\n-\\left<\\boldsymbol{\\varphi}\\_i,\n\\mathbf{n} \\cdot \\widehat{\\mathbf{F}}(\\mathbf{w})\\right>\\_{\\partial K} +\n\\left(\\boldsymbol{\\varphi}\\_i,\\mathbf{G}(\\mathbf w)\\right)\\_{K}\n\\right],\n\\]\n\nwhere \\(\\boldsymbol{\\varphi}\\_i\\) runs through all basis functions with from 1 to \\(n\\_\\text{dofs}\\).\n\nWe now denote by \\(\\mathcal M\\) the [mass matrix](DEALGlossary.html#GlossMassMatrix) with entries \\(\\mathcal M\\_{ij} =\n\\sum\\_{K} \\left(\\boldsymbol{\\varphi}\\_i,\n\\boldsymbol{\\varphi}\\_j\\right)\\_K\\), and by\n\n\\[\n\\mathcal L\\_h(t,\\mathbf{w}\\_h) = \\left[\\sum\\_{K\\in \\mathcal T\\_h}\n\\left[\n\\left(\\nabla \\boldsymbol{\\varphi}\\_i, \\mathbf{F}(\\mathbf{w}\\_h)\\right)\\_{K}\n- \\left<\\boldsymbol{\\varphi}\\_i,\n\\mathbf{n} \\cdot \\widehat{\\mathbf{F}}(\\mathbf{w}\\_h)\\right>\\_{\\partial K}\n+ \\left(\\boldsymbol{\\varphi}\\_i,\\mathbf{G}(\\mathbf w\\_h)\\right)\\_{K}\n\\right]\\right]\\_{i=1,\\ldots,n\\_\\text{dofs}}.\n\\]\n\nthe operator evaluating the right-hand side of the Euler operator, given a function \\(\\mathbf{w}\\_h\\) associated with a global vector of unknowns and the finite element in use. This function \\(\\mathcal L\\_h\\) is explicitly time-dependent as the numerical flux evaluated at the boundary will involve time-dependent data \\(\\rho\\_\\mathrm{D}\\), \\((\\rho \\mathbf{u})\\_\\mathrm{D}\\), and \\(E\\_\\mathbf{D}\\) on some parts of the boundary, depending on the assignment of boundary conditions. With this notation, we can write the discrete in space, continuous in time system compactly as\n\n\\[\n\\mathcal M \\frac{\\partial \\mathbf{w}\\_h}{\\partial t} =\n\\mathcal L\\_h(t, \\mathbf{w}\\_h),\n\\]\n\nwhere we have taken the liberty to also denote the global solution vector by \\(\\mathbf{w}\\_h\\) (in addition to the corresponding finite element function). Equivalently, the system above has the form\n\n\\[\n\\frac{\\partial \\mathbf{w}\\_h}{\\partial t} =\n\\mathcal M^{-1} \\mathcal L\\_h(t, \\mathbf{w}\\_h).\n\\]\n\nFor hyperbolic systems discretized by high-order discontinuous Galerkin methods, explicit time integration of this system is very popular. This is due to the fact that the mass matrix \\(\\mathcal M\\) is block-diagonal (with each block corresponding to only variables of the same kind defined on the same cell) and thus easily inverted. In each time step – or stage of a Runge–Kutta scheme – one only needs to evaluate the differential operator once using the given data and subsequently apply the inverse of the mass matrix. For implicit time stepping, on the other hand, one would first have to linearize the equations and then iteratively solve the linear system, which involves several residual evaluations and at least a dozen applications of the linearized operator, as has been demonstrated in the [step-33](step_33.html) tutorial program.\n\nOf course, the simplicity of explicit time stepping comes with a price, namely conditional stability due to the so-called Courant–Friedrichs–Lewy (CFL) condition. It states that the time step cannot be larger than the fastest propagation of information by the discretized differential operator. In more modern terms, the speed of propagation corresponds to the largest eigenvalue in the discretized operator, and in turn depends on the mesh size, the polynomial degree \\(p\\) and the physics of the Euler operator, i.e., the eigenvalues of the linearization of \\(\\mathbf F(\\mathbf w)\\) with respect to \\(\\mathbf{w}\\). In this program, we set the time step as follows:\n\n\\[\n\\Delta t = \\frac{\\mathrm{Cr}}{p^{1.5}}\\left(\\frac{1}\n{\\max\\left[\\frac{\\|\\mathbf{u}\\|}{h\\_u} + \\frac{c}{h\\_c}\\right]}\\right),\n\\]\n\nwith the maximum taken over all quadrature points and all cells. The dimensionless number \\(\\mathrm{Cr}\\) denotes the Courant number and can be chosen up to a maximally stable number \\(\\mathrm{Cr}\\_\\text{max}\\), whose value depends on the selected time stepping method and its stability properties. The power \\(p^{1.5}\\) used for the polynomial scaling is heuristic and represents the closest fit for polynomial degrees between 1 and 8, see e.g. [[191]](citelist.html#CITEREF_SchoederKormann2018). In the limit of higher degrees, \\(p>10\\), a scaling of \\(p^2\\) is more accurate, related to the inverse estimates typically used for interior penalty methods. Regarding the *effective* mesh sizes \\(h\\_u\\) and \\(h\\_c\\) used in the formula, we note that the convective transport is directional. Thus an appropriate scaling is to use the element length in the direction of the velocity \\(\\mathbf u\\). The code below derives this scaling from the inverse of the Jacobian from the reference to real cell, i.e., we approximate \\(\\frac{\\|\\mathbf{u}\\|}{h\\_u} \\approx \\|J^{-1} \\mathbf\nu\\|\\_{\\infty}\\). The acoustic waves, instead, are isotropic in character, which is why we use the smallest feature size, represented by the smallest singular value of \\(J\\), for the acoustic scaling \\(h\\_c\\). Finally, we need to add the convective and acoustic limits, as the Euler equations can transport information with speed \\(\\|\\mathbf{u}\\|+c\\).\n\nIn this tutorial program, we use a specific variant of [explicit Runge–Kutta methods](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods), which in general use the following update procedure from the state \\(\\mathbf{w}\\_h^{n}\\) at time \\(t^n\\) to the new time \\(t^{n+1}\\) with \\(\\Delta t = t^{n+1}-t^n\\):\n\n\\[\n\\begin{aligned}\n\\mathbf{k}\\_1 &= \\mathcal M^{-1} \\mathcal L\\_h\\left(t^n, \\mathbf{w}\\_h^n\\right),\n\\\\\n\\mathbf{k}\\_2 &= \\mathcal M^{-1} \\mathcal L\\_h\\left(t^n+c\\_2\\Delta t,\n\\mathbf{w}\\_h^n + a\\_{21} \\Delta t \\mathbf{k}\\_1\\right),\n\\\\\n&\\vdots \\\\\n\\mathbf{k}\\_s &= \\mathcal M^{-1} \\mathcal L\\_h\\left(t^n+c\\_s\\Delta t,\n\\mathbf{w}\\_h^n + \\sum\\_{j=1}^{s-1} a\\_{sj} \\Delta t \\mathbf{k}\\_j\\right),\n\\\\\n\\mathbf{w}\\_h^{n+1} &= \\mathbf{w}\\_h^n + \\Delta t\\left(b\\_1 \\mathbf{k}\\_1 +\nb\\_2 \\mathbf{k}\\_2 + \\ldots + b\\_s \\mathbf{k}\\_s\\right).\n\\end{aligned}\n\\]\n\nThe vectors \\(\\mathbf{k}\\_i\\), \\(i=1,\\ldots,s\\), in an \\(s\\)-stage scheme are evaluations of the operator at some intermediate state and used to define the end-of-step value \\(\\mathbf{w}\\_h^{n+1}\\) via some linear combination. The scalar coefficients in this scheme, \\(c\\_i\\), \\(a\\_{ij}\\), and \\(b\\_j\\), are defined such that certain conditions are satisfied for higher order schemes, the most basic one being \\(c\\_i = \\sum\\_{j=1}^{i-1}a\\_{ij}\\). The parameters are typically collected in the form of a so-called [Butcher tableau](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Explicit_Runge%E2%80%93Kutta_methods) that collects all of the coefficients that define the scheme. For a five-stage scheme, it would look like this:\n\n\\[\n\\begin{array}{c|ccccc}\n0 \\\\\nc\\_2 & a\\_{21} \\\\\nc\\_3 & a\\_{31} & a\\_{32} \\\\\nc\\_4 & a\\_{41} & a\\_{42} & a\\_{43} \\\\\nc\\_5 & a\\_{51} & a\\_{52} & a\\_{53} & a\\_{54} \\\\\n\\hline\n& b\\_1 & b\\_2 & b\\_3 & b\\_4 & b\\_5\n\\end{array}\n\\]\n\nIn this tutorial program, we use a subset of explicit Runge–Kutta methods, so-called low-storage Runge–Kutta methods (LSRK), which assume additional structure in the coefficients. In the variant used by reference [[130]](citelist.html#CITEREF_KennedyCarpenterLewis2000), the assumption is to use Butcher tableaus of the form\n\n\\[\n\\begin{array}{c|ccccc}\n0 \\\\\nc\\_2 & a\\_1 \\\\\nc\\_3 & b\\_1 & a\\_2 \\\\\nc\\_4 & b\\_1 & b\\_2 & a\\_3 \\\\\nc\\_5 & b\\_1 & b\\_2 & b\\_3 & a\\_4 \\\\\n\\hline\n& b\\_1 & b\\_2 & b\\_3 & b\\_4 & b\\_5\n\\end{array}\n\\]\n\nWith such a definition, the update to \\(\\mathbf{w}\\_h^n\\) shares the storage with the information for the intermediate values \\(\\mathbf{k}\\_i\\). Starting with \\(\\mathbf{w}^{n+1}=\\mathbf{w}^n\\) and \\(\\mathbf{r}\\_1 = \\mathbf{w}^n\\), the update in each of the \\(s\\) stages simplifies to\n\n\\[\n\\begin{aligned}\n\\mathbf{k}\\_i &=\n\\mathcal M^{-1} \\mathcal L\\_h\\left(t^n+c\\_i\\Delta t, \\mathbf{r}\\_{i} \\right),\\\\\n\\mathbf{r}\\_{i+1} &= \\mathbf{w}\\_h^{n+1} + \\Delta t \\, a\\_i \\mathbf{k}\\_i,\\\\\n\\mathbf{w}\\_h^{n+1} &= \\mathbf{w}\\_h^{n+1} + \\Delta t \\, b\\_i \\mathbf{k}\\_i.\n\\end{aligned}\n\\]\n\nBesides the vector \\(\\mathbf w\\_h^{n+1}\\) that is successively updated, this scheme only needs two auxiliary vectors, namely the vector \\(\\mathbf{k}\\_i\\) to hold the evaluation of the differential operator, and the vector \\(\\mathbf{r}\\_i\\) that holds the right-hand side for the differential operator application. In subsequent stages \\(i\\), the values \\(\\mathbf{k}\\_i\\) and \\(\\mathbf{r}\\_i\\) can use the same storage.\n\nThe main advantages of low-storage variants are the reduced memory consumption on the one hand (if a very large number of unknowns must be fit in memory, holding all \\(\\mathbf{k}\\_i\\) to compute subsequent updates can be a limit already for \\(s\\) in between five and eight – recall that we are using an explicit scheme, so we do not need to store any matrices that are typically much larger than a few vectors), and the reduced memory access on the other. In this program, we are particularly interested in the latter aspect. Since cost of operator evaluation is only a small multiple of the cost of simply streaming the input and output vector from memory with the optimized matrix-free methods of deal.II, we must consider the cost of vector updates, and low-storage variants can deliver up to twice the throughput of conventional explicit Runge–Kutta methods for this reason, see e.g. the analysis in [[191]](citelist.html#CITEREF_SchoederKormann2018).\n\nBesides three variants for third, fourth and fifth order accuracy from the reference [[130]](citelist.html#CITEREF_KennedyCarpenterLewis2000), we also use a fourth-order accurate variant with seven stages that was optimized for acoustics setups from [[202]](citelist.html#CITEREF_TseliosSimos2007). Acoustic problems are one of the interesting aspects of the subsonic regime of the Euler equations where compressibility leads to the transmission of sound waves; often, one uses further simplifications of the linearized Euler equations around a background state or the acoustic wave equation around a fixed frame.\n\n### Fast evaluation of integrals by matrix-free techniques\n\nThe major ingredients used in this program are the fast matrix-free techniques we use to evaluate the operator \\(\\mathcal L\\_h\\) and the inverse mass matrix \\(\\mathcal M\\). Actually, the term *matrix-free* is a slight misnomer, because we are working with a nonlinear operator and do not linearize the operator that in turn could be represented by a matrix. However, fast evaluation of integrals has become popular as a replacement of sparse matrix-vector products, as shown in [step-37](step_37.html) and [step-59](step_59.html), and we have coined this infrastructure *matrix-free functionality* in deal.II for this reason. Furthermore, the inverse mass matrix is indeed applied in a matrix-free way, as detailed below.\n\nThe matrix-free infrastructure allows us to quickly evaluate the integrals in the weak forms. The ingredients are the fast interpolation from solution coefficients into values and derivatives at quadrature points, point-wise operations at quadrature points (where we implement the differential operator as derived above), as well as multiplication by all test functions and summation over quadrature points. The first and third component make use of sum factorization and have been extensively discussed in the [step-37](step_37.html) tutorial program for the cell integrals and [step-59](step_59.html) for the face integrals. The only difference is that we now deal with a system of \\(d+2\\) components, rather than the scalar systems in previous tutorial programs. In the code, all that changes is a template argument of the [FEEvaluation](classFEEvaluation.html) and [FEFaceEvaluation](classFEFaceEvaluation.html) classes, the one to set the number of components. The access to the vector is the same as before, all handled transparently by the evaluator. We also note that the variant with a single evaluator chosen in the code below is not the only choice – we could also have used separate evalators for the separate components \\(\\rho\\), \\(\\rho \\mathbf u\\), and \\(E\\); given that we treat all components similarly (also reflected in the way we state the equation as a vector system), this would be more complicated here. As before, the [FEEvaluation](classFEEvaluation.html) class provides explicit vectorization by combining the operations on several cells (and faces), involving data types called [VectorizedArray](classVectorizedArray.html). Since the arithmetic operations are overloaded for this type, we do not have to bother with it all that much, except for the evaluation of functions through the [Function](classFunction.html) interface, where we need to provide particular *vectorized* evaluations for several quadrature point locations at once.\n\nA more substantial change in this program is the operation at quadrature points: Here, the multi-component evaluators provide us with return types not discussed before. Whereas [FEEvaluation::get\\_value()](classFEEvaluationBase.html#aeecc76ffeff6b36816f6af20af1398a8) would return a scalar (more precisely, a [VectorizedArray](classVectorizedArray.html) type due to vectorization across cells) for the Laplacian of [step-37](step_37.html), it now returns a type that is `Tensor<1,dim+2,VectorizedArray<Number>>`. Likewise, the gradient type is now `Tensor<1,dim+2,Tensor<1,dim,VectorizedArray<Number>>>`, where the outer tensor collects the `dim+2` components of the Euler system, and the inner tensor the partial derivatives in the various directions. For example, the flux \\(\\mathbf{F}(\\mathbf{w})\\) of the Euler system is of this type. In order to reduce the amount of code we have to write for spelling out these types, we use the C++ `auto` keyword where possible.\n\nFrom an implementation point of view, the nonlinearity is not a big difficulty: It is introduced naturally as we express the terms of the Euler weak form, for example in the form of the momentum term \\(\\rho \\mathbf{u}\n\\otimes \\mathbf{u}\\). To obtain this expression, we first deduce the velocity \\(\\mathbf{u}\\) from the momentum variable \\(\\rho \\mathbf{u}\\). Given that \\(\\rho\n\\mathbf{u}\\) is represented as a \\(p\\)-degree polynomial, as is \\(\\rho\\), the velocity \\(\\mathbf{u}\\) is a rational expression in terms of the reference coordinates \\(\\hat{\\mathbf{x}}\\). As we perform the multiplication \\((\\rho\n\\mathbf{u})\\otimes \\mathbf{u}\\), we obtain an expression that is the ratio of two polynomials, with polynomial degree \\(2p\\) in the numerator and polynomial degree \\(p\\) in the denominator. Combined with the gradient of the test function, the integrand is of degree \\(3p\\) in the numerator and \\(p\\) in the denominator already for affine cells, i.e., for parallelograms/ parallelepipeds. For curved cells, additional polynomial and rational expressions appear when multiplying the integrand by the determinant of the Jacobian of the mapping. At this point, one usually needs to give up on insisting on exact integration, and take whatever accuracy the Gaussian (more precisely, Gauss–Legrende) quadrature provides. The situation is then similar to the one for the Laplace equation, where the integrand contains rational expressions on non-affince cells and is also only integrated approximately. As these formulas only integrate polynomials exactly, we have to live with the [variational crime](https://mathoverflow.net/questions/26018/what-are-variational-crimes-and-who-coined-the-term) in the form of an integration error.\n\nWhile inaccurate integration is usually tolerable for elliptic problems, for hyperbolic problems inexact integration causes some headache in the form of an effect called **aliasing**. The term comes from signal processing and expresses the situation of inappropriate, too coarse sampling. In terms of quadrature, the inappropriate sampling means that we use too few quadrature points compared to what would be required to accurately sample the variable-coefficient integrand. It has been shown in the DG literature that aliasing errors can introduce unphysical oscillations in the numerical solution for *barely* resolved simulations. The fact that aliasing mostly affects coarse resolutions – whereas finer meshes with the same scheme work fine – is not surprising because well-resolved simulations tend to be smooth on length-scales of a cell (i.e., they have small coefficients in the higher polynomial degrees that are missed by too few quadrature points, whereas the main solution contribution in the lower polynomial degrees is still well-captured – this is simply a consequence of Taylor's theorem). To address this topic, various approaches have been proposed in the DG literature. One technique is filtering which damps the solution components pertaining to higher polynomial degrees. As the chosen nodal basis is not hierarchical, this would mean to transform from the nodal basis into a hierarchical one (e.g., a modal one based on Legendre polynomials) where the contributions within a cell are split by polynomial degrees. In that basis, one could then multiply the solution coefficients associated with higher degrees by a small number, keep the lower ones intact (to not destroy consistency), and then transform back to the nodal basis. However, filters reduce the accuracy of the method. Another, in some sense simpler, strategy is to use more quadrature points to capture non-linear terms more accurately. Using more than \\(p+1\\) quadrature points per coordinate directions is sometimes called over-integration or consistent integration. The latter name is most common in the context of the incompressible Navier-Stokes equations, where the \\(\\mathbf{u}\\otimes \\mathbf{u}\\) nonlinearity results in polynomial integrands of degree \\(3p\\) (when also considering the test function), which can be integrated exactly with \\(\\textrm{floor}\\left(\\frac{3p}{2}\\right)+1\\) quadrature points per direction as long as the element geometry is affine. In the context of the Euler equations with non-polynomial integrands, the choice is less clear. Depending on the variation in the various variables both \\(\\textrm{floor}\\left(\\frac{3p}{2}\\right)+1\\) or \\(2p+1\\) points (integrating exactly polynomials of degree \\(3p\\) or \\(4p\\), respectively) are common.\n\nTo reflect this variability in the choice of quadrature in the program, we keep the number of quadrature points a variable to be specified just as the polynomial degree, and note that one would make different choices depending also on the flow configuration. The default choice is \\(p+2\\) points – a bit more than the minimum possible of \\(p+1\\) points. The [FEEvaluation](classFEEvaluation.html) and [FEFaceEvaluation](classFEFaceEvaluation.html) classes allow to seamlessly change the number of points by a template parameter, such that the program does not get more complicated because of that.\n\n### Evaluation of the inverse mass matrix with matrix-free techniques\n\nThe last ingredient is the evaluation of the inverse mass matrix \\(\\mathcal\nM^{-1}\\). In DG methods with explicit time integration, mass matrices are block-diagonal and thus easily inverted – one only needs to invert the diagonal blocks. However, given the fact that matrix-free evaluation of integrals is closer in cost to the access of the vectors only, even the application of a block-diagonal matrix (e.g. via an array of LU factors) would be several times more expensive than evaluation of \\(\\mathcal L\\_h\\) simply because just storing and loading matrices of size `dofs_per_cell` times `dofs_per_cell` for higher order finite elements repeatedly is expensive. As this is clearly undesirable, part of the community has moved to bases where the mass matrix is diagonal, for example the *L2*-orthogonal Legendre basis using hierarchical polynomials or Lagrange polynomials on the points of the Gaussian quadrature (which is just another way of utilizing Legendre information). While the diagonal property breaks down for deformed elements, the error made by taking a diagonal mass matrix and ignoring the rest (a variant of mass lumping, though not the one with an additional integration error as utilized in [step-48](step_48.html)) has been shown to not alter discretization accuracy. The Lagrange basis in the points of Gaussian quadrature is sometimes also referred to as a collocation setup, as the nodal points of the polynomials coincide (= are \"co-located\") with the points of quadrature, obviating some interpolation operations. Given the fact that we want to use more quadrature points for nonlinear terms in \\(\\mathcal L\\_h\\), however, the collocation property is lost. (More precisely, it is still used in [FEEvaluation](classFEEvaluation.html) and [FEFaceEvaluation](classFEFaceEvaluation.html) after a change of basis, see the matrix-free paper [[135]](citelist.html#CITEREF_KronbichlerKormann2019).)\n\nIn this tutorial program, we use the collocation idea for the application of the inverse mass matrix, but with a slight twist. Rather than using the collocation via Lagrange polynomials in the points of Gaussian quadrature, we prefer a conventional Lagrange basis in Gauss-Lobatto points as those make the evaluation of face integrals cheap. This is because for Gauss-Lobatto points, some of the node points are located on the faces of the cell and it is not difficult to show that on any given face, the only shape functions with non-zero values are exactly the ones whose node points are in fact located on that face. One could of course also use the Gauss-Lobatto quadrature (with some additional integration error) as was done in [step-48](step_48.html), but we do not want to sacrifice accuracy as these quadrature formulas are generally of lower order than the general Gauss quadrature formulas. Instead, we use an idea described in the reference [[139]](citelist.html#CITEREF_KronbichlerSchoeder2016) where it was proposed to change the basis for the sake of applying the inverse mass matrix. Let us denote by \\(S\\) the matrix of shape functions evaluated at quadrature points, with shape functions in the row of the matrix and quadrature points in columns. Then, the mass matrix on a cell \\(K\\) is given by\n\n\\[\n\\mathcal M^K = S J^K S^\\mathrm T.\n\\]\n\nHere, \\(J^K\\) is the diagonal matrix with the determinant of the Jacobian times the quadrature weight (JxW) as entries. The matrix \\(S\\) is constructed as the Kronecker product (tensor product) of one-dimensional matrices, e.g. in 3D as\n\n\\[\nS = S\\_{\\text{1D}}\\otimes S\\_{\\text{1D}}\\otimes S\\_{\\text{1D}},\n\\]\n\nwhich is the result of the basis functions being a tensor product of one-dimensional shape functions and the quadrature formula being the tensor product of 1D quadrature formulas. For the case that the number of polynomials equals the number of quadrature points, all matrices in \\(S J^K S^\\mathrm T\\) are square, and also the ingredients to \\(S\\) in the Kronecker product are square. Thus, one can invert each matrix to form the overall inverse,\n\n\\[\n\\left(\\mathcal M^K\\right)^{-1} = S\\_{\\text{1D}}^{-\\mathrm T}\\otimes\nS\\_{\\text{1D}}^{-\\mathrm T}\\otimes S\\_{\\text{1D}}^{-\\mathrm T}\n\\left(J^K\\right)^{-1}\nS\\_{\\text{1D}}^{-1}\\otimes S\\_{\\text{1D}}^{-1}\\otimes S\\_{\\text{1D}}^{-1}.\n\\]\n\nThis formula is of exactly the same structure as the steps in the forward evaluation of integrals with sum factorization techniques (i.e., the [FEEvaluation](classFEEvaluation.html) and [MatrixFree](classMatrixFree.html) framework of deal.II). Hence, we can utilize the same code paths with a different interpolation matrix, \\(S\\_{\\mathrm{1D}}^{-\\mathrm{T}}\\) rather than \\(S\\_{\\mathrm{1D}}\\).\n\nThe class [MatrixFreeOperators::CellwiseInverseMassMatrix](classMatrixFreeOperators_1_1CellwiseInverseMassMatrix.html) implements this operation: It changes from the basis contained in the finite element (in this case, [FE\\_DGQ](classFE__DGQ.html)) to the Lagrange basis in Gaussian quadrature points. Here, the inverse of a diagonal mass matrix can be evaluated, which is simply the inverse of the `JxW` factors (i.e., the quadrature weight times the determinant of the Jacobian from reference to real coordinates). Once this is done, we can change back to the standard nodal Gauss-Lobatto basis.\n\nThe advantage of this particular way of applying the inverse mass matrix is a cost similar to the forward application of a mass matrix, which is cheaper than the evaluation of the spatial operator \\(\\mathcal L\\_h\\) with over-integration and face integrals. (We will demonstrate this with detailed timing information in the [results section](#Results).) In fact, it is so cheap that it is limited by the bandwidth of reading the source vector, reading the diagonal, and writing into the destination vector on most modern architectures. The hardware used for the result section allows to do the computations at least twice as fast as the streaming of the vectors from memory.\n\n### The test case\n\nIn this tutorial program, we implement two test cases. The first case is a convergence test limited to two space dimensions. It runs a so-called isentropic vortex which is transported via a background flow field. The second case uses a more exciting setup: We start with a cylinder immersed in a channel, using the [GridGenerator::channel\\_with\\_cylinder()](namespaceGridGenerator.html#a9d0b8a34fe5ca58425aa1fcf0d6132f1) function. Here, we impose a subsonic initial field at Mach number of \\(\\mathrm{Ma}=0.307\\) with a constant velocity in \\(x\\) direction. At the top and bottom walls as well as at the cylinder, we impose a no-penetration (i.e., tangential flow) condition. This setup forces the flow to re-orient as compared to the initial condition, which results in a big sound wave propagating away from the cylinder. In upstream direction, the wave travels more slowly (as it has to move against the oncoming gas), including a discontinuity in density and pressure. In downstream direction, the transport is faster as sound propagation and fluid flow go in the same direction, which smears out the discontinuity somewhat. Once the sound wave hits the upper and lower walls, the sound is reflected back, creating some nice shapes as illustrated in the [results section](#Results) below.\n\nThe commented program\n=====================\n\nThe include files are similar to the previous matrix-free tutorial programs [step-37](step_37.html), [step-48](step_48.html), and [step-59](step_59.html)\n\n```\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/timer.h>\n   #include <deal.II/base/time_stepping.h>\n   #include <deal.II/base/utilities.h>\n   #include <deal.II/base/vectorization.h>\n   \n   #include <deal.II/distributed/tria.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   \n   #include <deal.II/fe/fe_dgq.h>\n   #include <deal.II/fe/fe_system.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/tria.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/la_parallel_vector.h>\n   \n   #include <deal.II/matrix_free/fe_evaluation.h>\n   #include <deal.II/matrix_free/matrix_free.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   \n   #include <fstream>\n   #include <iomanip>\n   #include <iostream>\n```\n\nThe following file includes the CellwiseInverseMassMatrix data structure that we will use for the mass matrix inversion, the only new include file for this tutorial program:\n\n```\n   #include <deal.II/matrix_free/operators.h>\n   \n   \n   \n   namespace Euler_DG\n   {\n     using namespace dealii;\n```\n\nSimilarly to the other matrix-free tutorial programs, we collect all parameters that control the execution of the program at the top of the file. Besides the dimension and polynomial degree we want to run with, we also specify a number of points in the Gaussian quadrature formula we want to use for the nonlinear terms in the Euler equations. Furthermore, we specify the time interval for the time-dependent problem, and implement two different test cases. The first one is an analytical solution in 2d, whereas the second is a channel flow around a cylinder as described in the introduction. Depending on the test case, we also change the final time up to which we run the simulation, and a variable `output_tick` that specifies in which intervals we want to write output (assuming that the tick is larger than the time step size).\n\n```\n     constexpr unsigned int testcase             = 0;\n     constexpr unsigned int dimension            = 2;\n     constexpr unsigned int n_global_refinements = 3;\n     constexpr unsigned int fe_degree            = 5;\n     constexpr unsigned int n_q_points_1d        = fe_degree + 2;\n   \n     using Number = double;\n   \n     constexpr double gamma       = 1.4;\n     constexpr double final_time  = testcase == 0 ? 10 : 2.0;\n     constexpr double output_tick = testcase == 0 ? 1 : 0.05;\n```\n\nNext off are some details of the time integrator, namely a Courant number that scales the time step size in terms of the formula \\(\\Delta t =\n\\text{Cr} n\\_\\text{stages} \\frac{h}{(p+1)^{1.5} (\\|\\mathbf{u} +\nc)\\_\\text{max}}\\), as well as a selection of a few low-storage Runge–Kutta methods. We specify the Courant number per stage of the Runge–Kutta scheme, as this gives a more realistic expression of the numerical cost for schemes of various numbers of stages.\n\n```\n     const double courant_number = 0.15 / std::pow(fe_degree, 1.5);\n     enum LowStorageRungeKuttaScheme\n     {\n       stage_3_order_3, /* Kennedy, Carpenter, Lewis, 2000 */\n       stage_5_order_4, /* Kennedy, Carpenter, Lewis, 2000 */\n       stage_7_order_4, /* Tselios, Simos, 2007 */\n       stage_9_order_5, /* Kennedy, Carpenter, Lewis, 2000 */\n     };\n     constexpr LowStorageRungeKuttaScheme lsrk_scheme = stage_5_order_4;\n```\n\nEventually, we select a detail of the spatial discretization, namely the numerical flux (Riemann solver) at the faces between cells. For this program, we have implemented a modified variant of the Lax–Friedrichs flux and the Harten–Lax–van Leer (HLL) flux.\n\n```\n     enum EulerNumericalFlux\n     {\n       lax_friedrichs_modified,\n       harten_lax_vanleer,\n     };\n     constexpr EulerNumericalFlux numerical_flux_type = lax_friedrichs_modified;\n```\n\n### Equation data\n\nWe now define a class with the exact solution for the test case 0 and one with a background flow field for test case 1 of the channel. Given that the Euler equations are a problem with \\(d+2\\) equations in \\(d\\) dimensions, we need to tell the [Function](classFunction.html) base class about the correct number of components.\n\n```\n     template <int dim>\n     class ExactSolution : public Function<dim>\n     {\n     public:\n       ExactSolution(const double time)\n         : Function<dim>(dim + 2, time)\n       {}\n   \n       virtual double value(const Point<dim>  &p,\n                            const unsigned int component = 0) const override;\n     };\n```\n\nAs far as the actual function implemented is concerned, the analytical test case is an isentropic vortex case (see e.g. the book by Hesthaven and Warburton, Example 6.1 in Section 6.6 on page 209) which fulfills the Euler equations with zero force term on the right hand side. Given that definition, we return either the density, the momentum, or the energy depending on which component is requested. Note that the original definition of the density involves the \\(\\frac{1}{\\gamma -1}\\)-th power of some expression. Since `std::pow()` has pretty slow implementations on some systems, we replace it by logarithm followed by exponentiation (of base 2), which is mathematically equivalent but usually much better optimized. This formula might lose accuracy in the last digits for very small numbers compared to `std::pow()`, but we are happy with it anyway, since small numbers map to data close to 1.\n\nFor the channel test case, we simply select a density of 1, a velocity of 0.4 in \\(x\\) direction and zero in the other directions, and an energy that corresponds to a speed of sound of 1.3 measured against the background velocity field, computed from the relation \\(E = \\frac{c^2}{\\gamma (\\gamma\n-1)} + \\frac 12 \\rho \\|u\\|^2\\).\n\n```\n     template <int dim>\n     double ExactSolution<dim>::value(const Point<dim>  &x,\n                                      const unsigned int component) const\n     {\n       const double t = this->get_time();\n   \n       switch (testcase)\n         {\n           case 0:\n             {\n               Assert(dim == 2, ExcNotImplemented());\n               const double beta = 5;\n   \n               Point<dim> x0;\n               x0[0] = 5.;\n               const double radius_sqr =\n                 (x - x0).norm_square() - 2. * (x[0] - x0[0]) * t + t * t;\n               const double factor =\n                 beta / (numbers::PI * 2) * std::exp(1. - radius_sqr);\n               const double density_log = std::log2(\n                 std::abs(1. - (gamma - 1.) / gamma * 0.25 * factor * factor));\n               const double density = std::exp2(density_log * (1. / (gamma - 1.)));\n               const double u       = 1. - factor * (x[1] - x0[1]);\n               const double v       = factor * (x[0] - t - x0[0]);\n   \n               if (component == 0)\n                 return density;\n               else if (component == 1)\n                 return density * u;\n               else if (component == 2)\n                 return density * v;\n               else\n                 {\n                   const double pressure =\n                     std::exp2(density_log * (gamma / (gamma - 1.)));\n                   return pressure / (gamma - 1.) +\n                          0.5 * (density * u * u + density * v * v);\n                 }\n             }\n   \n           case 1:\n             {\n               if (component == 0)\n                 return 1.;\n               else if (component == 1)\n                 return 0.4;\n               else if (component == dim + 1)\n                 return 3.097857142857143;\n               else\n                 return 0.;\n             }\n   \n           default:\n             DEAL_II_NOT_IMPLEMENTED();\n             return 0.;\n         }\n     }\n```\n\n### Low-storage explicit Runge–Kutta time integrators\n\nThe next few lines implement a few low-storage variants of Runge–Kutta methods. These methods have specific Butcher tableaux with coefficients \\(b\\_i\\) and \\(a\\_i\\) as shown in the introduction. As usual in Runge–Kutta method, we can deduce time steps, \\(c\\_i = \\sum\\_{j=1}^{i-2} b\\_i + a\\_{i-1}\\) from those coefficients. The main advantage of this kind of scheme is the fact that only two vectors are needed per stage, namely the accumulated part of the solution \\(\\mathbf{w}\\) (that will hold the solution \\(\\mathbf{w}^{n+1}\\) at the new time \\(t^{n+1}\\) after the last stage), the update vector \\(\\mathbf{r}\\_i\\) that gets evaluated during the stages, plus one vector \\(\\mathbf{k}\\_i\\) to hold the evaluation of the operator. Such a Runge–Kutta setup reduces the memory storage and memory access. As the memory bandwidth is often the performance-limiting factor on modern hardware when the evaluation of the differential operator is well-optimized, performance can be improved over standard time integrators. This is true also when taking into account that a conventional Runge–Kutta scheme might allow for slightly larger time steps as more free parameters allow for better stability properties.\n\nIn this tutorial programs, we concentrate on a few variants of low-storage schemes defined in the article by Kennedy, Carpenter, and Lewis (2000), as well as one variant described by Tselios and Simos (2007). There is a large series of other schemes available, which could be addressed by additional sets of coefficients or slightly different update formulas.\n\nWe define a single class for the four integrators, distinguished by the enum described above. To each scheme, we then fill the vectors for the \\(b\\_i\\) and \\(a\\_i\\) to the given variables in the class.\n\n```\n     class LowStorageRungeKuttaIntegrator\n     {\n     public:\n       LowStorageRungeKuttaIntegrator(const LowStorageRungeKuttaScheme scheme)\n       {\n         TimeStepping::runge_kutta_method lsrk;\n```\n\nFirst comes the three-stage scheme of order three by Kennedy et al. (2000). While its stability region is significantly smaller than for the other schemes, it only involves three stages, so it is very competitive in terms of the work per stage.\n\n```\n         switch (scheme)\n           {\n             case stage_3_order_3:\n               {\n                 lsrk = TimeStepping::LOW_STORAGE_RK_STAGE3_ORDER3;\n                 break;\n               }\n```\n\nThe next scheme is a five-stage scheme of order four, again defined in the paper by Kennedy et al. (2000).\n\n```\n             case stage_5_order_4:\n               {\n                 lsrk = TimeStepping::LOW_STORAGE_RK_STAGE5_ORDER4;\n                 break;\n               }\n```\n\nThe following scheme of seven stages and order four has been explicitly derived for acoustics problems. It is a balance of accuracy for imaginary eigenvalues among fourth order schemes, combined with a large stability region. Since DG schemes are dissipative among the highest frequencies, this does not necessarily translate to the highest possible time step per stage. In the context of the present tutorial program, the numerical flux plays a crucial role in the dissipation and thus also the maximal stable time step size. For the modified Lax–Friedrichs flux, this scheme is similar to the `stage_5_order_4` scheme in terms of step size per stage if only stability is considered, but somewhat less efficient for the HLL flux.\n\n```\n             case stage_7_order_4:\n               {\n                 lsrk = TimeStepping::LOW_STORAGE_RK_STAGE7_ORDER4;\n                 break;\n               }\n```\n\nThe last scheme included here is the nine-stage scheme of order five from Kennedy et al. (2000). It is the most accurate among the schemes used here, but the higher order of accuracy sacrifices some stability, so the step length normalized per stage is less than for the fourth order schemes.\n\n```\n             case stage_9_order_5:\n               {\n                 lsrk = TimeStepping::LOW_STORAGE_RK_STAGE9_ORDER5;\n                 break;\n               }\n   \n             default:\n               AssertThrow(false, ExcNotImplemented());\n           }\n         TimeStepping::LowStorageRungeKutta<\n           LinearAlgebra::distributed::Vector<Number>>\n           rk_integrator(lsrk);\n         rk_integrator.get_coefficients(ai, bi, ci);\n       }\n   \n       unsigned int n_stages() const\n       {\n         return bi.size();\n       }\n```\n\nThe main function of the time integrator is to go through the stages, evaluate the operator, prepare the \\(\\mathbf{r}\\_i\\) vector for the next evaluation, and update the solution vector \\(\\mathbf{w}\\). We hand off the work to the `pde_operator` involved in order to be able to merge the vector operations of the Runge–Kutta setup with the evaluation of the differential operator for better performance, so all we do here is to delegate the vectors and coefficients.\n\nWe separately call the operator for the first stage because we need slightly modified arguments there: We evaluate the solution from the old solution \\(\\mathbf{w}^n\\) rather than a \\(\\mathbf r\\_i\\) vector, so the first argument is `solution`. We here let the stage vector \\(\\mathbf{r}\\_i\\) also hold the temporary result of the evaluation, as it is not used otherwise. For all subsequent stages, we use the vector `vec_ki` as the second vector argument to store the result of the operator evaluation. Finally, when we are at the last stage, we must skip the computation of the vector \\(\\mathbf{r}\\_{s+1}\\) as there is no coefficient \\(a\\_s\\) available (nor will it be used).\n\n```\n       template <typename VectorType, typename Operator>\n       void perform_time_step(const Operator &pde_operator,\n                              const double    current_time,\n                              const double    time_step,\n                              VectorType     &solution,\n                              VectorType     &vec_ri,\n                              VectorType     &vec_ki) const\n       {\n         AssertDimension(ai.size() + 1, bi.size());\n   \n         pde_operator.perform_stage(current_time,\n                                    bi[0] * time_step,\n                                    ai[0] * time_step,\n                                    solution,\n                                    vec_ri,\n                                    solution,\n                                    vec_ri);\n   \n         for (unsigned int stage = 1; stage < bi.size(); ++stage)\n           {\n             const double c_i = ci[stage];\n             pde_operator.perform_stage(current_time + c_i * time_step,\n                                        bi[stage] * time_step,\n                                        (stage == bi.size() - 1 ?\n                                           0 :\n                                           ai[stage] * time_step),\n                                        vec_ri,\n                                        vec_ki,\n                                        solution,\n                                        vec_ri);\n           }\n       }\n   \n     private:\n       std::vector<double> bi;\n       std::vector<double> ai;\n       std::vector<double> ci;\n     };\n```\n\n### Implementation of point-wise operations of the Euler equations\n\nIn the following functions, we implement the various problem-specific operators pertaining to the Euler equations. Each function acts on the vector of conserved variables \\([\\rho, \\rho\\mathbf{u}, E]\\) that we hold in the solution vectors, and computes various derived quantities.\n\nFirst out is the computation of the velocity, that we derive from the momentum variable \\(\\rho \\mathbf{u}\\) by division by \\(\\rho\\). One thing to note here is that we decorate all those functions with the keyword `DEAL_II_ALWAYS_INLINE`. This is a special macro that maps to a compiler-specific keyword that tells the compiler to never create a function call for any of those functions, and instead move the implementation [inline](https://en.wikipedia.org/wiki/Inline_function) to where they are called. This is critical for performance because we call into some of those functions millions or billions of times: For example, we both use the velocity for the computation of the flux further down, but also for the computation of the pressure, and both of these places are evaluated at every quadrature point of every cell. Making sure these functions are inlined ensures not only that the processor does not have to execute a jump instruction into the function (and the corresponding return jump), but also that the compiler can re-use intermediate information from one function's context in code that comes after the place where the function was called. (We note that compilers are generally quite good at figuring out which functions to inline by themselves. Here is a place where compilers may or may not have figured it out by themselves but where we know for sure that inlining is a win.)\n\nAnother trick we apply is a separate variable for the inverse density \\(\\frac{1}{\\rho}\\). This enables the compiler to only perform a single division for the flux, despite the division being used at several places. As divisions are around ten to twenty times as expensive as multiplications or additions, avoiding redundant divisions is crucial for performance. We note that taking the inverse first and later multiplying with it is not equivalent to a division in floating point arithmetic due to roundoff effects, so the compiler is not allowed to exchange one way by the other with standard optimization flags. However, it is also not particularly difficult to write the code in the right way.\n\nTo summarize, the chosen strategy of always inlining and careful definition of expensive arithmetic operations allows us to write compact code without passing all intermediate results around, despite making sure that the code maps to excellent machine code.\n\n```\n     template <int dim, typename Number>\n     inline DEAL_II_ALWAYS_INLINE \n       Tensor<1, dim, Number>\n       euler_velocity(const Tensor<1, dim + 2, Number> &conserved_variables)\n     {\n       const Number inverse_density = Number(1.) / conserved_variables[0];\n   \n       Tensor<1, dim, Number> velocity;\n       for (unsigned int d = 0; d < dim; ++d)\n         velocity[d] = conserved_variables[1 + d] * inverse_density;\n   \n       return velocity;\n     }\n```\n\nThe next function computes the pressure from the vector of conserved variables, using the formula \\(p = (\\gamma - 1) \\left(E - \\frac 12 \\rho\n\\mathbf{u}\\cdot \\mathbf{u}\\right)\\). As explained above, we use the velocity from the `euler_velocity()` function. Note that we need to specify the first template argument `dim` here because the compiler is not able to deduce it from the arguments of the tensor, whereas the second argument (number type) can be automatically deduced.\n\n```\n     template <int dim, typename Number>\n     inline DEAL_II_ALWAYS_INLINE \n       Number\n       euler_pressure(const Tensor<1, dim + 2, Number> &conserved_variables)\n     {\n       const Tensor<1, dim, Number> velocity =\n         euler_velocity<dim>(conserved_variables);\n   \n       Number rho_u_dot_u = conserved_variables[1] * velocity[0];\n       for (unsigned int d = 1; d < dim; ++d)\n         rho_u_dot_u += conserved_variables[1 + d] * velocity[d];\n   \n       return (gamma - 1.) * (conserved_variables[dim + 1] - 0.5 * rho_u_dot_u);\n     }\n```\n\nHere is the definition of the Euler flux function, i.e., the definition of the actual equation. Given the velocity and pressure (that the compiler optimization will make sure are done only once), this is straight-forward given the equation stated in the introduction.\n\n```\n     template <int dim, typename Number>\n     inline DEAL_II_ALWAYS_INLINE \n       Tensor<1, dim + 2, Tensor<1, dim, Number>>\n       euler_flux(const Tensor<1, dim + 2, Number> &conserved_variables)\n     {\n       const Tensor<1, dim, Number> velocity =\n         euler_velocity<dim>(conserved_variables);\n       const Number pressure = euler_pressure<dim>(conserved_variables);\n   \n       Tensor<1, dim + 2, Tensor<1, dim, Number>> flux;\n       for (unsigned int d = 0; d < dim; ++d)\n         {\n           flux[0][d] = conserved_variables[1 + d];\n           for (unsigned int e = 0; e < dim; ++e)\n             flux[e + 1][d] = conserved_variables[e + 1] * velocity[d];\n           flux[d + 1][d] += pressure;\n           flux[dim + 1][d] =\n             velocity[d] * (conserved_variables[dim + 1] + pressure);\n         }\n   \n       return flux;\n     }\n```\n\nThis next function is a helper to simplify the implementation of the numerical flux, implementing the action of a tensor of tensors (with non-standard outer dimension of size `dim + 2`, so the standard overloads provided by deal.II's tensor classes do not apply here) with another tensor of the same inner dimension, i.e., a matrix-vector product.\n\n```\n     template <int n_components, int dim, typename Number>\n     inline DEAL_II_ALWAYS_INLINE \n       Tensor<1, n_components, Number>\n       operator*(const Tensor<1, n_components, Tensor<1, dim, Number>> &matrix,\n                 const Tensor<1, dim, Number>                          &vector)\n     {\n       Tensor<1, n_components, Number> result;\n       for (unsigned int d = 0; d < n_components; ++d)\n         result[d] = matrix[d] * vector;\n       return result;\n     }\n```\n\nThis function implements the numerical flux (Riemann solver). It gets the state from the two sides of an interface and the normal vector, oriented from the side of the solution \\(\\mathbf{w}^-\\) towards the solution \\(\\mathbf{w}^+\\). In finite volume methods which rely on piece-wise constant data, the numerical flux is the central ingredient as it is the only place where the physical information is entered. In DG methods, the numerical flux is less central due to the polynomials within the elements and the physical flux used there. As a result of higher-degree interpolation with consistent values from both sides in the limit of a continuous solution, the numerical flux can be seen as a control of the jump of the solution from both sides to weakly impose continuity. It is important to realize that a numerical flux alone cannot stabilize a high-order DG method in the presence of shocks, and thus any DG method must be combined with further shock-capturing techniques to handle those cases. In this tutorial, we focus on wave-like solutions of the Euler equations in the subsonic regime without strong discontinuities where our basic scheme is sufficient.\n\nNonetheless, the numerical flux is decisive in terms of the numerical dissipation of the overall scheme and influences the admissible time step size with explicit Runge–Kutta methods. We consider two choices, a modified Lax–Friedrichs scheme and the widely used Harten–Lax–van Leer (HLL) flux. For both variants, we first need to get the velocities and pressures from both sides of the interface and evaluate the physical Euler flux.\n\nFor the local Lax–Friedrichs flux, the definition is \\(\\hat{\\mathbf{F}}\n=\\frac{\\mathbf{F}(\\mathbf{w}^-)+\\mathbf{F}(\\mathbf{w}^+)}{2} +\n\\frac{\\lambda}{2}\\left[\\mathbf{w}^--\\mathbf{w}^+\\right]\\otimes\n\\mathbf{n^-}\\), where the factor \\(\\lambda =\n\\max\\left(\\|\\mathbf{u}^-\\|+c^-, \\|\\mathbf{u}^+\\|+c^+\\right)\\) gives the maximal wave speed and \\(c = \\sqrt{\\gamma p / \\rho}\\) is the speed of sound. Here, we choose two modifications of that expression for reasons of computational efficiency, given the small impact of the flux on the solution. For the above definition of the factor \\(\\lambda\\), we would need to take four square roots, two for the two velocity norms and two for the speed of sound on either side. The first modification is hence to rather use \\(\\sqrt{\\|\\mathbf{u}\\|^2+c^2}\\) as an estimate of the maximal speed (which is at most a factor of 2 away from the actual maximum, as shown in the introduction). This allows us to pull the square root out of the maximum and get away with a single square root computation. The second modification is to further relax on the parameter \\(\\lambda\\)—the smaller it is, the smaller the dissipation factor (which is multiplied by the jump in \\(\\mathbf{w}\\), which might result in a smaller or bigger dissipation in the end). This allows us to fit the spectrum into the stability region of the explicit Runge–Kutta integrator with bigger time steps. However, we cannot make dissipation too small because otherwise imaginary eigenvalues grow larger. Finally, the current conservative formulation is not energy-stable in the limit of \\(\\lambda\\to 0\\) as it is not skew-symmetric, and would need additional measures such as split-form DG schemes in that case.\n\nFor the HLL flux, we follow the formula from literature, introducing an additional weighting of the two states from Lax–Friedrichs by a parameter \\(s\\). It is derived from the physical transport directions of the Euler equations in terms of the current direction of velocity and sound speed. For the velocity, we here choose a simple arithmetic average which is sufficient for DG scenarios and moderate jumps in material parameters.\n\nSince the numerical flux is multiplied by the normal vector in the weak form, we multiply by the result by the normal vector for all terms in the equation. In these multiplications, the `operator*` defined above enables a compact notation similar to the mathematical definition.\n\nIn this and the following functions, we use variable suffixes `_m` and `_p` to indicate quantities derived from \\(\\mathbf{w}^-\\) and \\(\\mathbf{w}^+\\), i.e., values \"here\" and \"there\" relative to the current cell when looking at a neighbor cell.\n\n```\n     template <int dim, typename Number>\n     inline DEAL_II_ALWAYS_INLINE \n       Tensor<1, dim + 2, Number>\n       euler_numerical_flux(const Tensor<1, dim + 2, Number> &u_m,\n                            const Tensor<1, dim + 2, Number> &u_p,\n                            const Tensor<1, dim, Number>     &normal)\n     {\n       const auto velocity_m = euler_velocity<dim>(u_m);\n       const auto velocity_p = euler_velocity<dim>(u_p);\n   \n       const auto pressure_m = euler_pressure<dim>(u_m);\n       const auto pressure_p = euler_pressure<dim>(u_p);\n   \n       const auto flux_m = euler_flux<dim>(u_m);\n       const auto flux_p = euler_flux<dim>(u_p);\n   \n       switch (numerical_flux_type)\n         {\n           case lax_friedrichs_modified:\n             {\n               const auto lambda =\n                 0.5 * std::sqrt(std::max(velocity_p.norm_square() +\n                                            gamma * pressure_p * (1. / u_p[0]),\n                                          velocity_m.norm_square() +\n                                            gamma * pressure_m * (1. / u_m[0])));\n   \n               return 0.5 * (flux_m * normal + flux_p * normal) +\n                      0.5 * lambda * (u_m - u_p);\n             }\n   \n           case harten_lax_vanleer:\n             {\n               const auto avg_velocity_normal =\n                 0.5 * ((velocity_m + velocity_p) * normal);\n               const auto   avg_c = std::sqrt(std::abs(\n                 0.5 * gamma *\n                 (pressure_p * (1. / u_p[0]) + pressure_m * (1. / u_m[0]))));\n               const Number s_pos =\n                 std::max(Number(), avg_velocity_normal + avg_c);\n               const Number s_neg =\n                 std::min(Number(), avg_velocity_normal - avg_c);\n               const Number inverse_s = Number(1.) / (s_pos - s_neg);\n   \n               return inverse_s *\n                      ((s_pos * (flux_m * normal) - s_neg * (flux_p * normal)) -\n                       s_pos * s_neg * (u_m - u_p));\n             }\n   \n           default:\n             {\n               DEAL_II_NOT_IMPLEMENTED();\n               return {};\n             }\n         }\n     }\n```\n\nThis and the next function are helper functions to provide compact evaluation calls as multiple points get batched together via a [VectorizedArray](classVectorizedArray.html) argument (see the [step-37](step_37.html) tutorial for details). This function is used for the subsonic outflow boundary conditions where we need to set the energy component to a prescribed value. The next one requests the solution on all components and is used for inflow boundaries where all components of the solution are set.\n\n```\n     template <int dim, typename Number>\n     VectorizedArray<Number>\n     evaluate_function(const Function<dim>                       &function,\n                       const Point<dim, VectorizedArray<Number>> &p_vectorized,\n                       const unsigned int                         component)\n     {\n       VectorizedArray<Number> result;\n       for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n         {\n           Point<dim> p;\n           for (unsigned int d = 0; d < dim; ++d)\n             p[d] = p_vectorized[d][v];\n           result[v] = function.value(p, component);\n         }\n       return result;\n     }\n   \n   \n     template <int dim, typename Number, int n_components = dim + 2>\n     Tensor<1, n_components, VectorizedArray<Number>>\n     evaluate_function(const Function<dim>                       &function,\n                       const Point<dim, VectorizedArray<Number>> &p_vectorized)\n     {\n       AssertDimension(function.n_components, n_components);\n       Tensor<1, n_components, VectorizedArray<Number>> result;\n       for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n         {\n           Point<dim> p;\n           for (unsigned int d = 0; d < dim; ++d)\n             p[d] = p_vectorized[d][v];\n           for (unsigned int d = 0; d < n_components; ++d)\n             result[d][v] = function.value(p, d);\n         }\n       return result;\n     }\n```\n\n### The EulerOperation class\n\nThis class implements the evaluators for the Euler problem, in analogy to the `LaplaceOperator` class of [step-37](step_37.html) or [step-59](step_59.html). Since the present operator is non-linear and does not require a matrix interface (to be handed over to preconditioners), we skip the various `vmult` functions otherwise present in matrix-free operators and only implement an `apply` function as well as the combination of `apply` with the required vector updates for the low-storage Runge–Kutta time integrator mentioned above (called `perform_stage`). Furthermore, we have added three additional functions involving matrix-free routines, namely one to compute an estimate of the time step scaling (that is combined with the Courant number for the actual time step size) based on the velocity and speed of sound in the elements, one for the projection of solutions (specializing [VectorTools::project()](namespaceVectorTools.html#aeccf4e3a301c16ac028919bed74a68eb) for the DG case), and one to compute the errors against a possible analytical solution or norms against some background state.\n\nThe rest of the class is similar to other matrix-free tutorials. As discussed in the introduction, we provide a few functions to allow a user to pass in various forms of boundary conditions on different parts of the domain boundary marked by [types::boundary\\_id](namespacetypes.html#a10c23e1699231bd1fac0ebdd1890095d) variables, as well as possible body forces.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     class EulerOperator\n     {\n     public:\n       static constexpr unsigned int n_quadrature_points_1d = n_points_1d;\n   \n       EulerOperator(TimerOutput &timer_output);\n   \n       void reinit(const Mapping<dim>    &mapping,\n                   const DoFHandler<dim> &dof_handler);\n   \n       void set_inflow_boundary(const types::boundary_id       boundary_id,\n                                std::unique_ptr<Function<dim>> inflow_function);\n   \n       void set_subsonic_outflow_boundary(\n         const types::boundary_id       boundary_id,\n         std::unique_ptr<Function<dim>> outflow_energy);\n   \n       void set_wall_boundary(const types::boundary_id boundary_id);\n   \n       void set_body_force(std::unique_ptr<Function<dim>> body_force);\n   \n       void apply(const double                                      current_time,\n                  const LinearAlgebra::distributed::Vector<Number> &src,\n                  LinearAlgebra::distributed::Vector<Number>       &dst) const;\n   \n       void\n       perform_stage(const Number cur_time,\n                     const Number factor_solution,\n                     const Number factor_ai,\n                     const LinearAlgebra::distributed::Vector<Number> &current_ri,\n                     LinearAlgebra::distributed::Vector<Number>       &vec_ki,\n                     LinearAlgebra::distributed::Vector<Number>       &solution,\n                     LinearAlgebra::distributed::Vector<Number> &next_ri) const;\n   \n       void project(const Function<dim>                        &function,\n                    LinearAlgebra::distributed::Vector<Number> &solution) const;\n   \n       std::array<double, 3> compute_errors(\n         const Function<dim>                              &function,\n         const LinearAlgebra::distributed::Vector<Number> &solution) const;\n   \n       double compute_cell_transport_speed(\n         const LinearAlgebra::distributed::Vector<Number> &solution) const;\n   \n       void\n       initialize_vector(LinearAlgebra::distributed::Vector<Number> &vector) const;\n   \n     private:\n       MatrixFree<dim, Number> data;\n   \n       TimerOutput &timer;\n   \n       std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\n         inflow_boundaries;\n       std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\n                                      subsonic_outflow_boundaries;\n       std::set<types::boundary_id>   wall_boundaries;\n       std::unique_ptr<Function<dim>> body_force;\n   \n       void local_apply_inverse_mass_matrix(\n         const MatrixFree<dim, Number>                    &data,\n         LinearAlgebra::distributed::Vector<Number>       &dst,\n         const LinearAlgebra::distributed::Vector<Number> &src,\n         const std::pair<unsigned int, unsigned int>      &cell_range) const;\n   \n       void local_apply_cell(\n         const MatrixFree<dim, Number>                    &data,\n         LinearAlgebra::distributed::Vector<Number>       &dst,\n         const LinearAlgebra::distributed::Vector<Number> &src,\n         const std::pair<unsigned int, unsigned int>      &cell_range) const;\n   \n       void local_apply_face(\n         const MatrixFree<dim, Number>                    &data,\n         LinearAlgebra::distributed::Vector<Number>       &dst,\n         const LinearAlgebra::distributed::Vector<Number> &src,\n         const std::pair<unsigned int, unsigned int>      &face_range) const;\n   \n       void local_apply_boundary_face(\n         const MatrixFree<dim, Number>                    &data,\n         LinearAlgebra::distributed::Vector<Number>       &dst,\n         const LinearAlgebra::distributed::Vector<Number> &src,\n         const std::pair<unsigned int, unsigned int>      &face_range) const;\n     };\n   \n   \n   \n     template <int dim, int degree, int n_points_1d>\n     EulerOperator<dim, degree, n_points_1d>::EulerOperator(TimerOutput &timer)\n       : timer(timer)\n     {}\n```\n\nFor the initialization of the Euler operator, we set up the [MatrixFree](classMatrixFree.html) variable contained in the class. This can be done given a mapping to describe possible curved boundaries as well as a [DoFHandler](classDoFHandler.html) object describing the degrees of freedom. Since we use a discontinuous Galerkin discretization in this tutorial program where no constraints are imposed strongly on the solution field, we do not need to pass in an [AffineConstraints](classAffineConstraints.html) object and rather use a dummy for the construction. With respect to quadrature, we want to select two different ways of computing the underlying integrals: The first is a flexible one, based on a template parameter `n_points_1d` (that will be assigned the `n_q_points_1d` value specified at the top of this file). More accurate integration is necessary to avoid the aliasing problem due to the variable coefficients in the Euler operator. The second less accurate quadrature formula is a tight one based on `fe_degree+1` and needed for the inverse mass matrix. While that formula provides an exact inverse only on affine element shapes and not on deformed elements, it enables the fast inversion of the mass matrix by tensor product techniques, necessary to ensure optimal computational efficiency overall.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::reinit(\n       const Mapping<dim>    &mapping,\n       const DoFHandler<dim> &dof_handler)\n     {\n       const std::vector<const DoFHandler<dim> *> dof_handlers = {&dof_handler};\n       const AffineConstraints<double>            dummy;\n       const std::vector<const AffineConstraints<double> *> constraints = {&dummy};\n       const std::vector<Quadrature<1>> quadratures = {QGauss<1>(n_q_points_1d),\n                                                       QGauss<1>(fe_degree + 1)};\n   \n       typename MatrixFree<dim, Number>::AdditionalData additional_data;\n       additional_data.mapping_update_flags =\n         (update_gradients | update_JxW_values | update_quadrature_points |\n          update_values);\n       additional_data.mapping_update_flags_inner_faces =\n         (update_JxW_values | update_quadrature_points | update_normal_vectors |\n          update_values);\n       additional_data.mapping_update_flags_boundary_faces =\n         (update_JxW_values | update_quadrature_points | update_normal_vectors |\n          update_values);\n       additional_data.tasks_parallel_scheme =\n         MatrixFree<dim, Number>::AdditionalData::none;\n   \n       data.reinit(\n         mapping, dof_handlers, constraints, quadratures, additional_data);\n     }\n   \n   \n   \n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::initialize_vector(\n       LinearAlgebra::distributed::Vector<Number> &vector) const\n     {\n       data.initialize_dof_vector(vector);\n     }\n```\n\nThe subsequent four member functions are the ones that must be called from outside to specify the various types of boundaries. For an inflow boundary, we must specify all components in terms of density \\(\\rho\\), momentum \\(\\rho\n\\mathbf{u}\\) and energy \\(E\\). Given this information, we then store the function alongside the respective boundary id in a map member variable of this class. Likewise, we proceed for the subsonic outflow boundaries (where we request a function as well, which we use to retrieve the energy) and for wall (no-penetration) boundaries where we impose zero normal velocity (no function necessary, so we only request the boundary id). For the present DG code where boundary conditions are solely applied as part of the weak form (during time integration), the call to set the boundary conditions can appear both before or after the `reinit()` call to this class. This is different from continuous finite element codes where the boundary conditions determine the content of the [AffineConstraints](classAffineConstraints.html) object that is sent into [MatrixFree](classMatrixFree.html) for initialization, thus requiring to be set before the initialization of the matrix-free data structures.\n\nThe checks added in each of the four function are used to ensure that boundary conditions are mutually exclusive on the various parts of the boundary, i.e., that a user does not accidentally designate a boundary as both an inflow and say a subsonic outflow boundary.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::set_inflow_boundary(\n       const types::boundary_id       boundary_id,\n       std::unique_ptr<Function<dim>> inflow_function)\n     {\n       AssertThrow(subsonic_outflow_boundaries.find(boundary_id) ==\n                       subsonic_outflow_boundaries.end() &&\n                     wall_boundaries.find(boundary_id) == wall_boundaries.end(),\n                   ExcMessage(\"You already set the boundary with id \" +\n                              std::to_string(static_cast<int>(boundary_id)) +\n                              \" to another type of boundary before now setting \" +\n                              \"it as inflow\"));\n       AssertThrow(inflow_function->n_components == dim + 2,\n                   ExcMessage(\"Expected function with dim+2 components\"));\n   \n       inflow_boundaries[boundary_id] = std::move(inflow_function);\n     }\n   \n   \n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::set_subsonic_outflow_boundary(\n       const types::boundary_id       boundary_id,\n       std::unique_ptr<Function<dim>> outflow_function)\n     {\n       AssertThrow(inflow_boundaries.find(boundary_id) ==\n                       inflow_boundaries.end() &&\n                     wall_boundaries.find(boundary_id) == wall_boundaries.end(),\n                   ExcMessage(\"You already set the boundary with id \" +\n                              std::to_string(static_cast<int>(boundary_id)) +\n                              \" to another type of boundary before now setting \" +\n                              \"it as subsonic outflow\"));\n       AssertThrow(outflow_function->n_components == dim + 2,\n                   ExcMessage(\"Expected function with dim+2 components\"));\n   \n       subsonic_outflow_boundaries[boundary_id] = std::move(outflow_function);\n     }\n   \n   \n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::set_wall_boundary(\n       const types::boundary_id boundary_id)\n     {\n       AssertThrow(inflow_boundaries.find(boundary_id) ==\n                       inflow_boundaries.end() &&\n                     subsonic_outflow_boundaries.find(boundary_id) ==\n                       subsonic_outflow_boundaries.end(),\n                   ExcMessage(\"You already set the boundary with id \" +\n                              std::to_string(static_cast<int>(boundary_id)) +\n                              \" to another type of boundary before now setting \" +\n                              \"it as wall boundary\"));\n   \n       wall_boundaries.insert(boundary_id);\n     }\n   \n   \n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::set_body_force(\n       std::unique_ptr<Function<dim>> body_force)\n     {\n       AssertDimension(body_force->n_components, dim);\n   \n       this->body_force = std::move(body_force);\n     }\n```\n\n#### Local evaluators\n\nNow we proceed to the local evaluators for the Euler problem. The evaluators are relatively simple and follow what has been presented in [step-37](step_37.html), [step-48](step_48.html), or [step-59](step_59.html). The first notable difference is the fact that we use an [FEEvaluation](classFEEvaluation.html) with a non-standard number of quadrature points. Whereas we previously always set the number of quadrature points to equal the polynomial degree plus one (ensuring exact integration on affine element shapes), we now set the number quadrature points as a separate variable (e.g. the polynomial degree plus two or three halves of the polynomial degree) to more accurately handle nonlinear terms. Since the evaluator is fed with the appropriate loop lengths via the template argument and keeps the number of quadrature points in the whole cell in the variable [FEEvaluation::n\\_q\\_points](classFEEvaluation.html#a1b8934d6ae273d7b3f91994eddcad239), we now automatically operate on the more accurate formula without further changes.\n\nThe second difference is due to the fact that we are now evaluating a multi-component system, as opposed to the scalar systems considered previously. The matrix-free framework provides several ways to handle the multi-component case. The variant shown here utilizes an [FEEvaluation](classFEEvaluation.html) object with multiple components embedded into it, specified by the fourth template argument `dim + 2` for the components in the Euler system. As a consequence, the return type of [FEEvaluation::get\\_value()](classFEEvaluationBase.html#aeecc76ffeff6b36816f6af20af1398a8) is not a scalar any more (that would return a [VectorizedArray](classVectorizedArray.html) type, collecting data from several elements), but a [Tensor](classTensor.html) of `dim+2` components. The functionality is otherwise similar to the scalar case; it is handled by a template specialization of a base class, called FEEvaluationAccess. An alternative variant would have been to use several [FEEvaluation](classFEEvaluation.html) objects, a scalar one for the density, a vector-valued one with `dim` components for the momentum, and another scalar evaluator for the energy. To ensure that those components point to the correct part of the solution, the constructor of [FEEvaluation](classFEEvaluation.html) takes three optional integer arguments after the required [MatrixFree](classMatrixFree.html) field, namely the number of the [DoFHandler](classDoFHandler.html) for multi-DoFHandler systems (taking the first by default), the number of the quadrature point in case there are multiple [Quadrature](classQuadrature.html) objects (see more below), and as a third argument the component within a vector system. As we have a single vector for all components, we would go with the third argument, and set it to `0` for the density, `1` for the vector-valued momentum, and `dim+1` for the energy slot. [FEEvaluation](classFEEvaluation.html) then picks the appropriate subrange of the solution vector during [FEEvaluationBase::read\\_dof\\_values()](classFEEvaluationBase.html#aff4ac5c0f5afb445a2a5cf9a0715a2fe) and FEEvaluation::distributed\\_local\\_to\\_global() or the more compact [FEEvaluation::gather\\_evaluate()](classFEEvaluation.html#ab53d5c08f460cfe6c9830ac14a427115) and [FEEvaluation::integrate\\_scatter()](classFEEvaluation.html#a52265fb3ecb2b63388e1708ef395418f) calls.\n\nWhen it comes to the evaluation of the body force vector, we distinguish between two cases for efficiency reasons: In case we have a constant function (derived from [Functions::ConstantFunction](classFunctions_1_1ConstantFunction.html)), we can precompute the value outside the loop over quadrature points and simply use the value everywhere. For a more general function, we instead need to call the `evaluate_function()` method we provided above; this path is more expensive because we need to access the memory associated with the quadrature point data.\n\nThe rest follows the other tutorial programs. Since we have implemented all physics for the Euler equations in the separate `euler_flux()` function, all we have to do here is to call this function given the current solution evaluated at quadrature points, returned by `phi.get_value(q)`, and tell the [FEEvaluation](classFEEvaluation.html) object to queue the flux for testing it by the gradients of the shape functions (which is a [Tensor](classTensor.html) of outer `dim+2` components, each holding a tensor of `dim` components for the \\(x,y,z\\) component of the Euler flux). One final thing worth mentioning is the order in which we queue the data for testing by the value of the test function, `phi.submit_value()`, in case we are given an external function: We must do this after calling `phi.get_value(q)`, because `get_value()` (reading the solution) and `submit_value()` (queuing the value for multiplication by the test function and summation over quadrature points) access the same underlying data field. Here it would be easy to achieve also without temporary variable `w_q` since there is no mixing between values and gradients. For more complicated setups, one has to first copy out e.g. both the value and gradient at a quadrature point and then queue results again by [FEEvaluationBase::submit\\_value()](classFEEvaluationBase.html#a2c0efc6f70b305c0585001632063c98b) and [FEEvaluationBase::submit\\_gradient()](classFEEvaluationBase.html#a2a78655d119bd1bde992619c52b2d2f8).\n\nAs a final note, we mention that we do not use the first [MatrixFree](classMatrixFree.html) argument of this function, which is a call-back from [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf). The interfaces imposes the present list of arguments, but since we are in a member function where the [MatrixFree](classMatrixFree.html) object is already available as the `data` variable, we stick with that to avoid confusion.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::local_apply_cell(\n       const MatrixFree<dim, Number> &,\n       LinearAlgebra::distributed::Vector<Number>       &dst,\n       const LinearAlgebra::distributed::Vector<Number> &src,\n       const std::pair<unsigned int, unsigned int>      &cell_range) const\n     {\n       FEEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data);\n   \n       Tensor<1, dim, VectorizedArray<Number>> constant_body_force;\n       const Functions::ConstantFunction<dim> *constant_function =\n         dynamic_cast<Functions::ConstantFunction<dim> *>(body_force.get());\n   \n       if (constant_function)\n         constant_body_force = evaluate_function<dim, Number, dim>(\n           *constant_function, Point<dim, VectorizedArray<Number>>());\n   \n       for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n         {\n           phi.reinit(cell);\n           phi.gather_evaluate(src, EvaluationFlags::values);\n   \n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               const auto w_q = phi.get_value(q);\n               phi.submit_gradient(euler_flux<dim>(w_q), q);\n               if (body_force.get() != nullptr)\n                 {\n                   const Tensor<1, dim, VectorizedArray<Number>> force =\n                     constant_function ? constant_body_force :\n                                         evaluate_function<dim, Number, dim>(\n                                           *body_force, phi.quadrature_point(q));\n   \n                   Tensor<1, dim + 2, VectorizedArray<Number>> forcing;\n                   for (unsigned int d = 0; d < dim; ++d)\n                     forcing[d + 1] = w_q[0] * force[d];\n                   for (unsigned int d = 0; d < dim; ++d)\n                     forcing[dim + 1] += force[d] * w_q[d + 1];\n   \n                   phi.submit_value(forcing, q);\n                 }\n             }\n   \n           phi.integrate_scatter(((body_force.get() != nullptr) ?\n                                    EvaluationFlags::values :\n                                    EvaluationFlags::nothing) |\n                                   EvaluationFlags::gradients,\n                                 dst);\n         }\n     }\n```\n\nThe next function concerns the computation of integrals on interior faces, where we need evaluators from both cells adjacent to the face. We associate the variable `phi_m` with the solution component \\(\\mathbf{w}^-\\) and the variable `phi_p` with the solution component \\(\\mathbf{w}^+\\). We distinguish the two sides in the constructor of [FEFaceEvaluation](classFEFaceEvaluation.html) by the second argument, with `true` for the interior side and `false` for the exterior side, with interior and exterior denoting the orientation with respect to the normal vector.\n\nNote that the calls [FEFaceEvaluation::gather\\_evaluate()](classFEFaceEvaluation.html#a4ac53fde2eab227ef45c7d29a5ed33fe) and [FEFaceEvaluation::integrate\\_scatter()](classFEFaceEvaluation.html#a21c3b33147e4abc2b0ae787b6510ec04) combine the access to the vectors and the sum factorization parts. This combined operation not only saves a line of code, but also contains an important optimization: Given that we use a nodal basis in terms of the Lagrange polynomials in the points of the Gauss-Lobatto quadrature formula, only \\((p+1)^{d-1}\\) out of the \\((p+1)^d\\) basis functions evaluate to non-zero on each face. Thus, the evaluator only accesses the necessary data in the vector and skips the parts which are multiplied by zero. If we had first read the vector, we would have needed to load all data from the vector, as the call in isolation would not know what data is required in subsequent operations. If the subsequent [FEFaceEvaluation::evaluate()](classFEFaceEvaluation.html#a92f84b8ad276ca9866f30c6f789cf3a4) call requests values and derivatives, indeed all \\((p+1)^d\\) vector entries for each component are needed, as the normal derivative is nonzero for all basis functions.\n\nThe arguments to the evaluators as well as the procedure is similar to the cell evaluation. We again use the more accurate (over-)integration scheme due to the nonlinear terms, specified as the third template argument in the list. At the quadrature points, we then go to our free-standing function for the numerical flux. It receives the solution evaluated at quadrature points from both sides (i.e., \\(\\mathbf{w}^-\\) and \\(\\mathbf{w}^+\\)), as well as the normal vector onto the minus side. As explained above, the numerical flux is already multiplied by the normal vector from the minus side. We need to switch the sign because the boundary term comes with a minus sign in the weak form derived in the introduction. The flux is then queued for testing both on the minus sign and on the plus sign, with switched sign as the normal vector from the plus side is exactly opposed to the one from the minus side.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::local_apply_face(\n       const MatrixFree<dim, Number> &,\n       LinearAlgebra::distributed::Vector<Number>       &dst,\n       const LinearAlgebra::distributed::Vector<Number> &src,\n       const std::pair<unsigned int, unsigned int>      &face_range) const\n     {\n       FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi_m(data,\n                                                                         true);\n       FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi_p(data,\n                                                                         false);\n   \n       for (unsigned int face = face_range.first; face < face_range.second; ++face)\n         {\n           phi_p.reinit(face);\n           phi_p.gather_evaluate(src, EvaluationFlags::values);\n   \n           phi_m.reinit(face);\n           phi_m.gather_evaluate(src, EvaluationFlags::values);\n   \n           for (const unsigned int q : phi_m.quadrature_point_indices())\n             {\n               const auto numerical_flux =\n                 euler_numerical_flux<dim>(phi_m.get_value(q),\n                                           phi_p.get_value(q),\n                                           phi_m.normal_vector(q));\n               phi_m.submit_value(-numerical_flux, q);\n               phi_p.submit_value(numerical_flux, q);\n             }\n   \n           phi_p.integrate_scatter(EvaluationFlags::values, dst);\n           phi_m.integrate_scatter(EvaluationFlags::values, dst);\n         }\n     }\n```\n\nFor faces located at the boundary, we need to impose the appropriate boundary conditions. In this tutorial program, we implement four cases as mentioned above. (A fifth case, for supersonic outflow conditions is discussed in the \"Results\" section below.) The discontinuous Galerkin method imposes boundary conditions not as constraints, but only weakly. Thus, the various conditions are imposed by finding an appropriate *exterior* quantity \\(\\mathbf{w}^+\\) that is then handed to the numerical flux function also used for the interior faces. In essence, we \"pretend\" a state on the outside of the domain in such a way that if that were reality, the solution of the PDE would satisfy the boundary conditions we want.\n\nFor wall boundaries, we need to impose a no-normal-flux condition on the momentum variable, whereas we use a Neumann condition for the density and energy with \\(\\rho^+ = \\rho^-\\) and \\(E^+ = E^-\\). To achieve the no-normal flux condition, we set the exterior values to the interior values and subtract two times the velocity in wall-normal direction, i.e., in the direction of the normal vector.\n\nFor inflow boundaries, we simply set the given Dirichlet data \\(\\mathbf{w}\\_\\mathrm{D}\\) as a boundary value. An alternative would have been to use \\(\\mathbf{w}^+ = -\\mathbf{w}^- + 2 \\mathbf{w}\\_\\mathrm{D}\\), the so-called mirror principle.\n\nThe imposition of outflow is essentially a Neumann condition, i.e., setting \\(\\mathbf{w}^+ = \\mathbf{w}^-\\). For the case of subsonic outflow, we still need to impose a value for the energy, which we derive from the respective function. A special step is needed for the case of *backflow*, i.e., the case where there is a momentum flux into the domain on the Neumann portion. According to the literature (a fact that can be derived by appropriate energy arguments), we must switch to another variant of the flux on inflow parts, see Gravemeier, Comerford, Yoshihara, Ismail, Wall, \"A novel formulation for Neumann inflow\nconditions in biomechanics\", Int. J. Numer. Meth. Biomed. Eng., vol. 28 (2012). Here, the momentum term needs to be added once again, which corresponds to removing the flux contribution on the momentum variables. We do this in a post-processing step, and only for the case when we both are at an outflow boundary and the dot product between the normal vector and the momentum (or, equivalently, velocity) is negative. As we work on data of several quadrature points at once for SIMD vectorizations, we here need to explicitly loop over the array entries of the SIMD array.\n\nIn the implementation below, we check for the various types of boundaries at the level of quadrature points. Of course, we could also have moved the decision out of the quadrature point loop and treat entire faces as of the same kind, which avoids some map/set lookups in the inner loop over quadrature points. However, the loss of efficiency is hardly noticeable, so we opt for the simpler code here. Also note that the final `else` clause will catch the case when some part of the boundary was not assigned any boundary condition via `EulerOperator::set_..._boundary(...)`.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::local_apply_boundary_face(\n       const MatrixFree<dim, Number> &,\n       LinearAlgebra::distributed::Vector<Number>       &dst,\n       const LinearAlgebra::distributed::Vector<Number> &src,\n       const std::pair<unsigned int, unsigned int>      &face_range) const\n     {\n       FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data, true);\n   \n       for (unsigned int face = face_range.first; face < face_range.second; ++face)\n         {\n           phi.reinit(face);\n           phi.gather_evaluate(src, EvaluationFlags::values);\n   \n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               const auto w_m    = phi.get_value(q);\n               const auto normal = phi.normal_vector(q);\n   \n               auto rho_u_dot_n = w_m[1] * normal[0];\n               for (unsigned int d = 1; d < dim; ++d)\n                 rho_u_dot_n += w_m[1 + d] * normal[d];\n   \n               bool at_outflow = false;\n   \n               Tensor<1, dim + 2, VectorizedArray<Number>> w_p;\n               const auto boundary_id = data.get_boundary_id(face);\n               if (wall_boundaries.find(boundary_id) != wall_boundaries.end())\n                 {\n                   w_p[0] = w_m[0];\n                   for (unsigned int d = 0; d < dim; ++d)\n                     w_p[d + 1] = w_m[d + 1] - 2. * rho_u_dot_n * normal[d];\n                   w_p[dim + 1] = w_m[dim + 1];\n                 }\n               else if (inflow_boundaries.find(boundary_id) !=\n                        inflow_boundaries.end())\n                 w_p =\n                   evaluate_function(*inflow_boundaries.find(boundary_id)->second,\n                                     phi.quadrature_point(q));\n               else if (subsonic_outflow_boundaries.find(boundary_id) !=\n                        subsonic_outflow_boundaries.end())\n                 {\n                   w_p          = w_m;\n                   w_p[dim + 1] = evaluate_function(\n                     *subsonic_outflow_boundaries.find(boundary_id)->second,\n                     phi.quadrature_point(q),\n                     dim + 1);\n                   at_outflow = true;\n                 }\n               else\n                 AssertThrow(false,\n                             ExcMessage(\"Unknown boundary id, did \"\n                                        \"you set a boundary condition for \"\n                                        \"this part of the domain boundary?\"));\n   \n               auto flux = euler_numerical_flux<dim>(w_m, w_p, normal);\n   \n               if (at_outflow)\n                 for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n                   {\n                     if (rho_u_dot_n[v] < -1e-12)\n                       for (unsigned int d = 0; d < dim; ++d)\n                         flux[d + 1][v] = 0.;\n                   }\n   \n               phi.submit_value(-flux, q);\n             }\n   \n           phi.integrate_scatter(EvaluationFlags::values, dst);\n         }\n     }\n```\n\nThe next function implements the inverse mass matrix operation. The algorithms and rationale have been discussed extensively in the introduction, so we here limit ourselves to the technicalities of the [MatrixFreeOperators::CellwiseInverseMassMatrix](classMatrixFreeOperators_1_1CellwiseInverseMassMatrix.html) class. It does similar operations as the forward evaluation of the mass matrix, except with a different interpolation matrix, representing the inverse \\(S^{-1}\\) factors. These represent a change of basis from the specified basis (in this case, the Lagrange basis in the points of the Gauss–Lobatto quadrature formula) to the Lagrange basis in the points of the Gauss quadrature formula. In the latter basis, we can apply the inverse of the point-wise `JxW` factor, i.e., the quadrature weight times the determinant of the Jacobian of the mapping from reference to real coordinates. Once this is done, the basis is changed back to the nodal Gauss-Lobatto basis again. All of these operations are done by the `apply()` function below. What we need to provide is the local fields to operate on (which we extract from the global vector by an [FEEvaluation](classFEEvaluation.html) object) and write the results back to the destination vector of the mass matrix operation.\n\nOne thing to note is that we added two integer arguments (that are optional) to the constructor of [FEEvaluation](classFEEvaluation.html), the first being 0 (selecting among the [DoFHandler](classDoFHandler.html) in multi-DoFHandler systems; here, we only have one) and the second being 1 to make the quadrature formula selection. As we use the quadrature formula 0 for the over-integration of nonlinear terms, we use the formula 1 with the default \\(p+1\\) (or `fe_degree+1` in terms of the variable name) points for the mass matrix. This leads to square contributions to the mass matrix and ensures exact integration, as explained in the introduction.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::local_apply_inverse_mass_matrix(\n       const MatrixFree<dim, Number> &,\n       LinearAlgebra::distributed::Vector<Number>       &dst,\n       const LinearAlgebra::distributed::Vector<Number> &src,\n       const std::pair<unsigned int, unsigned int>      &cell_range) const\n     {\n       FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n       MatrixFreeOperators::CellwiseInverseMassMatrix<dim, degree, dim + 2, Number>\n         inverse(phi);\n   \n       for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n         {\n           phi.reinit(cell);\n           phi.read_dof_values(src);\n   \n           inverse.apply(phi.begin_dof_values(), phi.begin_dof_values());\n   \n           phi.set_dof_values(dst);\n         }\n     }\n```\n\n#### The apply() and related functions\n\nWe now come to the function which implements the evaluation of the Euler operator as a whole, i.e., \\(\\mathcal M^{-1} \\mathcal L(t, \\mathbf{w})\\), calling into the local evaluators presented above. The steps should be clear from the previous code. One thing to note is that we need to adjust the time in the functions we have associated with the various parts of the boundary, in order to be consistent with the equation in case the boundary data is time-dependent. Then, we call [MatrixFree::loop()](classMatrixFree.html#ab0fc4e60417ad475a106a6b875ad24cf) to perform the cell and face integrals, including the necessary ghost data exchange in the `src` vector. The seventh argument to the function, `true`, specifies that we want to zero the `dst` vector as part of the loop, before we start accumulating integrals into it. This variant is preferred over explicitly calling `dst = 0.;` before the loop as the zeroing operation is done on a subrange of the vector in parts that are written by the integrals nearby. This enhances data locality and allows for caching, saving one roundtrip of vector data to main memory and enhancing performance. The last two arguments to the loop determine which data is exchanged: Since we only access the values of the shape functions one faces, typical of first-order hyperbolic problems, and since we have a nodal basis with nodes at the reference element surface, we only need to exchange those parts. This again saves precious memory bandwidth.\n\nOnce the spatial operator \\(\\mathcal L\\) is applied, we need to make a second round and apply the inverse mass matrix. Here, we call [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) since only cell integrals appear. The cell loop is cheaper than the full loop as access only goes to the degrees of freedom associated with the locally owned cells, which is simply the locally owned degrees of freedom for DG discretizations. Thus, no ghost exchange is needed here.\n\nAround all these functions, we put timer scopes to record the computational time for statistics about the contributions of the various parts.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::apply(\n       const double                                      current_time,\n       const LinearAlgebra::distributed::Vector<Number> &src,\n       LinearAlgebra::distributed::Vector<Number>       &dst) const\n     {\n       {\n         TimerOutput::Scope t(timer, \"apply - integrals\");\n   \n         for (auto &i : inflow_boundaries)\n           i.second->set_time(current_time);\n         for (auto &i : subsonic_outflow_boundaries)\n           i.second->set_time(current_time);\n   \n         data.loop(&EulerOperator::local_apply_cell,\n                   &EulerOperator::local_apply_face,\n                   &EulerOperator::local_apply_boundary_face,\n                   this,\n                   dst,\n                   src,\n                   true,\n                   MatrixFree<dim, Number>::DataAccessOnFaces::values,\n                   MatrixFree<dim, Number>::DataAccessOnFaces::values);\n       }\n   \n       {\n         TimerOutput::Scope t(timer, \"apply - inverse mass\");\n   \n         data.cell_loop(&EulerOperator::local_apply_inverse_mass_matrix,\n                        this,\n                        dst,\n                        dst);\n       }\n     }\n```\n\nLet us move to the function that does an entire stage of a Runge–Kutta update. It calls EulerOperator::apply() followed by some updates to the vectors, namely `next_ri = solution + factor_ai * k_i` and `solution += factor_solution * k_i`. Rather than performing these steps through the vector interfaces, we here present an alternative strategy that is faster on cache-based architectures. As the memory consumed by the vectors is often much larger than what fits into caches, the data has to effectively come from the slow RAM memory. The situation can be improved by loop fusion, i.e., performing both the updates to `next_ki` and `solution` within a single sweep. In that case, we would read the two vectors `rhs` and `solution` and write into `next_ki` and `solution`, compared to at least 4 reads and two writes in the baseline case. Here, we go one step further and perform the loop immediately when the mass matrix inversion has finished on a part of the vector. [MatrixFree::cell\\_loop()](classMatrixFree.html#abc204ec41ead1b5060f47ef3a5a066d7) provides a mechanism to attach an `std::function` both before the loop over cells first touches a vector entry (which we do not use here, but is e.g. used for zeroing the vector) and a second `std::function` to be called after the loop last touches an entry. The callback is in form of a range over the given vector (in terms of the local index numbering in the MPI universe) that can be addressed by `local_element()` functions.\n\nFor this second callback, we create a lambda that works on a range and write the respective update on this range. Ideally, we would add the `DEAL_II_OPENMP_SIMD_PRAGMA` before the local loop to suggest to the compiler to SIMD parallelize this loop (which means in practice that we ensure that there is no overlap, also called aliasing, between the index ranges of the pointers we use inside the loops). It turns out that at the time of this writing, GCC 7.2 fails to compile an OpenMP pragma inside a lambda function, so we comment this pragma out below. If your compiler is newer, you should be able to uncomment these lines again.\n\nNote that we select a different code path for the last Runge–Kutta stage when we do not need to update the `next_ri` vector. This strategy gives a considerable speedup. Whereas the inverse mass matrix and vector updates take more than 60% of the computational time with default vector updates on a 40-core machine, the percentage is around 35% with the more optimized variant. In other words, this is a speedup of around a third.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::perform_stage(\n       const Number                                      current_time,\n       const Number                                      factor_solution,\n       const Number                                      factor_ai,\n       const LinearAlgebra::distributed::Vector<Number> &current_ri,\n       LinearAlgebra::distributed::Vector<Number>       &vec_ki,\n       LinearAlgebra::distributed::Vector<Number>       &solution,\n       LinearAlgebra::distributed::Vector<Number>       &next_ri) const\n     {\n       {\n         TimerOutput::Scope t(timer, \"rk_stage - integrals L_h\");\n   \n         for (auto &i : inflow_boundaries)\n           i.second->set_time(current_time);\n         for (auto &i : subsonic_outflow_boundaries)\n           i.second->set_time(current_time);\n   \n         data.loop(&EulerOperator::local_apply_cell,\n                   &EulerOperator::local_apply_face,\n                   &EulerOperator::local_apply_boundary_face,\n                   this,\n                   vec_ki,\n                   current_ri,\n                   true,\n                   MatrixFree<dim, Number>::DataAccessOnFaces::values,\n                   MatrixFree<dim, Number>::DataAccessOnFaces::values);\n       }\n   \n   \n       {\n         TimerOutput::Scope t(timer, \"rk_stage - inv mass + vec upd\");\n         data.cell_loop(\n           &EulerOperator::local_apply_inverse_mass_matrix,\n           this,\n           next_ri,\n           vec_ki,\n           std::function<void(const unsigned int, const unsigned int)>(),\n           [&](const unsigned int start_range, const unsigned int end_range) {\n             const Number ai = factor_ai;\n             const Number bi = factor_solution;\n             if (ai == Number())\n               {\n                 /* DEAL_II_OPENMP_SIMD_PRAGMA */\n                 for (unsigned int i = start_range; i < end_range; ++i)\n                   {\n                     const Number k_i          = next_ri.local_element(i);\n                     const Number sol_i        = solution.local_element(i);\n                     solution.local_element(i) = sol_i + bi * k_i;\n                   }\n               }\n             else\n               {\n                 /* DEAL_II_OPENMP_SIMD_PRAGMA */\n                 for (unsigned int i = start_range; i < end_range; ++i)\n                   {\n                     const Number k_i          = next_ri.local_element(i);\n                     const Number sol_i        = solution.local_element(i);\n                     solution.local_element(i) = sol_i + bi * k_i;\n                     next_ri.local_element(i)  = sol_i + ai * k_i;\n                   }\n               }\n           });\n       }\n     }\n```\n\nHaving discussed the implementation of the functions that deal with advancing the solution by one time step, let us now move to functions that implement other, ancillary operations. Specifically, these are functions that compute projections, evaluate errors, and compute the speed of information transport on a cell.\n\nThe first of these functions is essentially equivalent to [VectorTools::project()](namespaceVectorTools.html#aeccf4e3a301c16ac028919bed74a68eb), just much faster because it is specialized for DG elements where there is no need to set up and solve a linear system, as each element has independent basis functions. The reason why we show the code here, besides a small speedup of this non-critical operation, is that it shows additional functionality provided by [MatrixFreeOperators::CellwiseInverseMassMatrix](classMatrixFreeOperators_1_1CellwiseInverseMassMatrix.html).\n\nThe projection operation works as follows: If we denote the matrix of shape functions evaluated at quadrature points by \\(S\\), the projection on cell \\(K\\) is an operation of the form \\(\\underbrace{S J^K S^\\mathrm\nT}\\_{\\mathcal M^K} \\mathbf{w}^K = S J^K\n\\tilde{\\mathbf{w}}(\\mathbf{x}\\_q)\\_{q=1:n\\_q}\\), where \\(J^K\\) is the diagonal matrix containing the determinant of the Jacobian times the quadrature weight (JxW), \\(\\mathcal M^K\\) is the cell-wise mass matrix, and \\(\\tilde{\\mathbf{w}}(\\mathbf{x}\\_q)\\_{q=1:n\\_q}\\) is the evaluation of the field to be projected onto quadrature points. (In reality the matrix \\(S\\) has additional structure through the tensor product, as explained in the introduction.) This system can now equivalently be written as \\(\\mathbf{w}^K = \\left(S J^K S^\\mathrm T\\right)^{-1} S J^K\n\\tilde{\\mathbf{w}}(\\mathbf{x}\\_q)\\_{q=1:n\\_q} = S^{-\\mathrm T}\n\\left(J^K\\right)^{-1} S^{-1} S J^K\n\\tilde{\\mathbf{w}}(\\mathbf{x}\\_q)\\_{q=1:n\\_q}\\). Now, the term \\(S^{-1} S\\) and then \\(\\left(J^K\\right)^{-1} J^K\\) cancel, resulting in the final expression \\(\\mathbf{w}^K = S^{-\\mathrm T}\n\\tilde{\\mathbf{w}}(\\mathbf{x}\\_q)\\_{q=1:n\\_q}\\). This operation is implemented by [MatrixFreeOperators::CellwiseInverseMassMatrix::transform\\_from\\_q\\_points\\_to\\_basis()](classMatrixFreeOperators_1_1CellwiseInverseMassMatrix.html#a5e95a87a9c63b321c77c72b8d762b760). The name is derived from the fact that this projection is simply the multiplication by \\(S^{-\\mathrm T}\\), a basis change from the nodal basis in the points of the Gaussian quadrature to the given finite element basis. Note that we call [FEEvaluation::set\\_dof\\_values()](classFEEvaluationBase.html#aea17b9ce958683ef4a01401d2cc9fcfd) to write the result into the vector, overwriting previous content, rather than accumulating the results as typical in integration tasks – we can do this because every vector entry has contributions from only a single cell for discontinuous Galerkin discretizations.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     void EulerOperator<dim, degree, n_points_1d>::project(\n       const Function<dim>                        &function,\n       LinearAlgebra::distributed::Vector<Number> &solution) const\n     {\n       FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n       MatrixFreeOperators::CellwiseInverseMassMatrix<dim, degree, dim + 2, Number>\n         inverse(phi);\n       solution.zero_out_ghost_values();\n       for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n           for (const unsigned int q : phi.quadrature_point_indices())\n             phi.submit_dof_value(evaluate_function(function,\n                                                    phi.quadrature_point(q)),\n                                  q);\n           inverse.transform_from_q_points_to_basis(dim + 2,\n                                                    phi.begin_dof_values(),\n                                                    phi.begin_dof_values());\n           phi.set_dof_values(solution);\n         }\n     }\n```\n\nThe next function again repeats functionality also provided by the deal.II library, namely [VectorTools::integrate\\_difference()](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). We here show the explicit code to highlight how the vectorization across several cells works and how to accumulate results via that interface: Recall that each *lane* of the vectorized array holds data from a different cell. By the loop over all cell batches that are owned by the current MPI process, we could then fill a [VectorizedArray](classVectorizedArray.html) of results; to obtain a global sum, we would need to further go on and sum across the entries in the SIMD array. However, such a procedure is not stable as the SIMD array could in fact not hold valid data for all its lanes. This happens when the number of locally owned cells is not a multiple of the SIMD width. To avoid invalid data, we must explicitly skip those invalid lanes when accessing the data. While one could imagine that we could make it work by simply setting the empty lanes to zero (and thus, not contribute to a sum), the situation is more complicated than that: What if we were to compute a velocity out of the momentum? Then, we would need to divide by the density, which is zero – the result would consequently be NaN and contaminate the result. This trap is avoided by accumulating the results from the valid SIMD range as we loop through the cell batches, using the function [MatrixFree::n\\_active\\_entries\\_per\\_cell\\_batch()](classMatrixFree.html#a1d516071d20e633dc9efcadb7852ce15) to give us the number of lanes with valid data. It equals [VectorizedArray::size()](classVectorizedArrayBase.html#acda344ca9dd9fa932986816a8201b507) on most cells, but can be less on the last cell batch if the number of cells has a remainder compared to the SIMD width.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     std::array<double, 3> EulerOperator<dim, degree, n_points_1d>::compute_errors(\n       const Function<dim>                              &function,\n       const LinearAlgebra::distributed::Vector<Number> &solution) const\n     {\n       TimerOutput::Scope t(timer, \"compute errors\");\n       double             errors_squared[3] = {};\n       FEEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data, 0, 0);\n   \n       for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n           phi.gather_evaluate(solution, EvaluationFlags::values);\n           VectorizedArray<Number> local_errors_squared[3] = {};\n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               const auto error =\n                 evaluate_function(function, phi.quadrature_point(q)) -\n                 phi.get_value(q);\n               const auto JxW = phi.JxW(q);\n   \n               local_errors_squared[0] += error[0] * error[0] * JxW;\n               for (unsigned int d = 0; d < dim; ++d)\n                 local_errors_squared[1] += (error[d + 1] * error[d + 1]) * JxW;\n               local_errors_squared[2] += (error[dim + 1] * error[dim + 1]) * JxW;\n             }\n           for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\n                ++v)\n             for (unsigned int d = 0; d < 3; ++d)\n               errors_squared[d] += local_errors_squared[d][v];\n         }\n   \n       Utilities::MPI::sum(errors_squared, MPI_COMM_WORLD, errors_squared);\n   \n       std::array<double, 3> errors;\n       for (unsigned int d = 0; d < 3; ++d)\n         errors[d] = std::sqrt(errors_squared[d]);\n   \n       return errors;\n     }\n```\n\nThis final function of the EulerOperator class is used to estimate the transport speed, scaled by the mesh size, that is relevant for setting the time step size in the explicit time integrator. In the Euler equations, there are two speeds of transport, namely the convective velocity \\(\\mathbf{u}\\) and the propagation of sound waves with sound speed \\(c = \\sqrt{\\gamma p/\\rho}\\) relative to the medium moving at velocity \\(\\mathbf u\\).\n\nIn the formula for the time step size, we are interested not by these absolute speeds, but by the amount of time it takes for information to cross a single cell. For information transported along with the medium, \\(\\mathbf u\\) is scaled by the mesh size, so an estimate of the maximal velocity can be obtained by computing \\(\\|J^{-\\mathrm T} \\mathbf{u}\\|\\_\\infty\\), where \\(J\\) is the Jacobian of the transformation from real to the reference domain. Note that [FEEvaluationBase::inverse\\_jacobian()](classFEEvaluationData.html#a62582767128bf5712e13ac30bb8cf5f4) returns the inverse and transpose Jacobian, representing the metric term from real to reference coordinates, so we do not need to transpose it again. We store this limit in the variable `convective_limit` in the code below.\n\nThe sound propagation is isotropic, so we need to take mesh sizes in any direction into account. The appropriate mesh size scaling is then given by the minimal singular value of \\(J\\) or, equivalently, the maximal singular value of \\(J^{-1}\\). Note that one could approximate this quantity by the minimal distance between vertices of a cell when ignoring curved cells. To get the maximal singular value of the Jacobian, the general strategy would be some LAPACK function. Since all we need here is an estimate, we can avoid the hassle of decomposing a tensor of [VectorizedArray](classVectorizedArray.html) numbers into several matrices and go into an (expensive) eigenvalue function without vectorization, and instead use a few iterations (five in the code below) of the power method applied to \\(J^{-1}J^{-\\mathrm T}\\). The speed of convergence of this method depends on the ratio of the largest to the next largest eigenvalue and the initial guess, which is the vector of all ones. This might suggest that we get slow convergence on cells close to a cube shape where all lengths are almost the same. However, this slow convergence means that the result will sit between the two largest singular values, which both are close to the maximal value anyway. In all other cases, convergence will be quick. Thus, we can merely hardcode 5 iterations here and be confident that the result is good.\n\n```\n     template <int dim, int degree, int n_points_1d>\n     double EulerOperator<dim, degree, n_points_1d>::compute_cell_transport_speed(\n       const LinearAlgebra::distributed::Vector<Number> &solution) const\n     {\n       TimerOutput::Scope t(timer, \"compute transport speed\");\n       Number             max_transport = 0;\n       FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n   \n       for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n         {\n           phi.reinit(cell);\n           phi.gather_evaluate(solution, EvaluationFlags::values);\n           VectorizedArray<Number> local_max = 0.;\n           for (const unsigned int q : phi.quadrature_point_indices())\n             {\n               const auto solution = phi.get_value(q);\n               const auto velocity = euler_velocity<dim>(solution);\n               const auto pressure = euler_pressure<dim>(solution);\n   \n               const auto inverse_jacobian = phi.inverse_jacobian(q);\n               const auto convective_speed = inverse_jacobian * velocity;\n               VectorizedArray<Number> convective_limit = 0.;\n               for (unsigned int d = 0; d < dim; ++d)\n                 convective_limit =\n                   std::max(convective_limit, std::abs(convective_speed[d]));\n   \n               const auto speed_of_sound =\n                 std::sqrt(gamma * pressure * (1. / solution[0]));\n   \n               Tensor<1, dim, VectorizedArray<Number>> eigenvector;\n               for (unsigned int d = 0; d < dim; ++d)\n                 eigenvector[d] = 1.;\n               for (unsigned int i = 0; i < 5; ++i)\n                 {\n                   eigenvector = transpose(inverse_jacobian) *\n                                 (inverse_jacobian * eigenvector);\n                   VectorizedArray<Number> eigenvector_norm = 0.;\n                   for (unsigned int d = 0; d < dim; ++d)\n                     eigenvector_norm =\n                       std::max(eigenvector_norm, std::abs(eigenvector[d]));\n                   eigenvector /= eigenvector_norm;\n                 }\n               const auto jac_times_ev   = inverse_jacobian * eigenvector;\n               const auto max_eigenvalue = std::sqrt(\n                 (jac_times_ev * jac_times_ev) / (eigenvector * eigenvector));\n               local_max =\n                 std::max(local_max,\n                          max_eigenvalue * speed_of_sound + convective_limit);\n             }\n```\n\nSimilarly to the previous function, we must make sure to accumulate speed only on the valid cells of a cell batch.\n\n```\n           for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\n                ++v)\n             max_transport = std::max(max_transport, local_max[v]);\n         }\n   \n       max_transport = Utilities::MPI::max(max_transport, MPI_COMM_WORLD);\n   \n       return max_transport;\n     }\n```\n\n### The EulerProblem class\n\nThis class combines the EulerOperator class with the time integrator and the usual global data structures such as [FiniteElement](classFiniteElement.html) and [DoFHandler](classDoFHandler.html), to actually run the simulations of the Euler problem.\n\nThe member variables are a triangulation, a finite element, a mapping (to create high-order curved surfaces, see e.g. [step-10](step_10.html)), and a [DoFHandler](classDoFHandler.html) to describe the degrees of freedom. In addition, we keep an instance of the EulerOperator described above around, which will do all heavy lifting in terms of integrals, and some parameters for time integration like the current time or the time step size.\n\nFurthermore, we use a PostProcessor instance to write some additional information to the output file, in similarity to what was done in [step-33](step_33.html). The interface of the [DataPostprocessor](classDataPostprocessor.html) class is intuitive, requiring us to provide information about what needs to be evaluated (typically only the values of the solution, except for the Schlieren plot that we only enable in 2d where it makes sense), and the names of what gets evaluated. Note that it would also be possible to extract most information by calculator tools within visualization programs such as ParaView, but it is so much more convenient to do it already when writing the output.\n\n```\n     template <int dim>\n     class EulerProblem\n     {\n     public:\n       EulerProblem();\n   \n       void run();\n   \n     private:\n       void make_grid_and_dofs();\n   \n       void output_results(const unsigned int result_number);\n   \n       LinearAlgebra::distributed::Vector<Number> solution;\n   \n       ConditionalOStream pcout;\n   \n   #ifdef DEAL_II_WITH_P4EST\n       parallel::distributed::Triangulation<dim> triangulation;\n   #else\n       Triangulation<dim> triangulation;\n   #endif\n   \n       const FESystem<dim> fe;\n       MappingQ<dim>       mapping;\n       DoFHandler<dim>     dof_handler;\n   \n       TimerOutput timer;\n   \n       EulerOperator<dim, fe_degree, n_q_points_1d> euler_operator;\n   \n       double time, time_step;\n   \n       class Postprocessor : public DataPostprocessor<dim>\n       {\n       public:\n         Postprocessor();\n   \n         virtual void evaluate_vector_field(\n           const DataPostprocessorInputs::Vector<dim> &inputs,\n           std::vector<Vector<double>> &computed_quantities) const override;\n   \n         virtual std::vector<std::string> get_names() const override;\n   \n         virtual std::vector<\n           DataComponentInterpretation::DataComponentInterpretation>\n         get_data_component_interpretation() const override;\n   \n         virtual UpdateFlags get_needed_update_flags() const override;\n   \n       private:\n         const bool do_schlieren_plot;\n       };\n     };\n   \n   \n   \n     template <int dim>\n     EulerProblem<dim>::Postprocessor::Postprocessor()\n       : do_schlieren_plot(dim == 2)\n     {}\n```\n\nFor the main evaluation of the field variables, we first check that the lengths of the arrays equal the expected values (the lengths `2*dim+4` or `2*dim+5` are derived from the sizes of the names we specify in the get\\_names() function below). Then we loop over all evaluation points and fill the respective information: First we fill the primal solution variables of density \\(\\rho\\), momentum \\(\\rho \\mathbf{u}\\) and energy \\(E\\), then we compute the derived velocity \\(\\mathbf u\\), the pressure \\(p\\), the speed of sound \\(c=\\sqrt{\\gamma p / \\rho}\\), as well as the Schlieren plot showing \\(s = |\\nabla \\rho|^2\\) in case it is enabled. (See [step-69](step_69.html) for another example where we create a Schlieren plot.)\n\n```\n     template <int dim>\n     void EulerProblem<dim>::Postprocessor::evaluate_vector_field(\n       const DataPostprocessorInputs::Vector<dim> &inputs,\n       std::vector<Vector<double>>                &computed_quantities) const\n     {\n       const unsigned int n_evaluation_points = inputs.solution_values.size();\n   \n       if (do_schlieren_plot == true)\n         Assert(inputs.solution_gradients.size() == n_evaluation_points,\n                ExcInternalError());\n   \n       Assert(computed_quantities.size() == n_evaluation_points,\n              ExcInternalError());\n       Assert(inputs.solution_values[0].size() == dim + 2, ExcInternalError());\n       Assert(computed_quantities[0].size() ==\n                dim + 2 + (do_schlieren_plot == true ? 1 : 0),\n              ExcInternalError());\n   \n       for (unsigned int p = 0; p < n_evaluation_points; ++p)\n         {\n           Tensor<1, dim + 2> solution;\n           for (unsigned int d = 0; d < dim + 2; ++d)\n             solution[d] = inputs.solution_values[p](d);\n   \n           const double         density  = solution[0];\n           const Tensor<1, dim> velocity = euler_velocity<dim>(solution);\n           const double         pressure = euler_pressure<dim>(solution);\n   \n           for (unsigned int d = 0; d < dim; ++d)\n             computed_quantities[p](d) = velocity[d];\n           computed_quantities[p](dim)     = pressure;\n           computed_quantities[p](dim + 1) = std::sqrt(gamma * pressure / density);\n   \n           if (do_schlieren_plot == true)\n             computed_quantities[p](dim + 2) =\n               inputs.solution_gradients[p][0] * inputs.solution_gradients[p][0];\n         }\n     }\n   \n   \n   \n     template <int dim>\n     std::vector<std::string> EulerProblem<dim>::Postprocessor::get_names() const\n     {\n       std::vector<std::string> names;\n       for (unsigned int d = 0; d < dim; ++d)\n         names.emplace_back(\"velocity\");\n       names.emplace_back(\"pressure\");\n       names.emplace_back(\"speed_of_sound\");\n   \n       if (do_schlieren_plot == true)\n         names.emplace_back(\"schlieren_plot\");\n   \n       return names;\n     }\n```\n\nFor the interpretation of quantities, we have scalar density, energy, pressure, speed of sound, and the Schlieren plot, and vectors for the momentum and the velocity.\n\n```\n     template <int dim>\n     std::vector<DataComponentInterpretation::DataComponentInterpretation>\n     EulerProblem<dim>::Postprocessor::get_data_component_interpretation() const\n     {\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         interpretation;\n       for (unsigned int d = 0; d < dim; ++d)\n         interpretation.push_back(\n           DataComponentInterpretation::component_is_part_of_vector);\n       interpretation.push_back(DataComponentInterpretation::component_is_scalar);\n       interpretation.push_back(DataComponentInterpretation::component_is_scalar);\n   \n       if (do_schlieren_plot == true)\n         interpretation.push_back(\n           DataComponentInterpretation::component_is_scalar);\n   \n       return interpretation;\n     }\n```\n\nWith respect to the necessary update flags, we only need the values for all quantities but the Schlieren plot, which is based on the density gradient.\n\n```\n     template <int dim>\n     UpdateFlags EulerProblem<dim>::Postprocessor::get_needed_update_flags() const\n     {\n       if (do_schlieren_plot == true)\n         return update_values | update_gradients;\n       else\n         return update_values;\n     }\n```\n\nThe constructor for this class is unsurprising: We set up a parallel triangulation based on the `MPI_COMM_WORLD` communicator, a vector finite element with `dim+2` components for density, momentum, and energy, a high-order mapping of the same degree as the underlying finite element, and initialize the time and time step to zero.\n\n```\n     template <int dim>\n     EulerProblem<dim>::EulerProblem()\n       : pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n   #ifdef DEAL_II_WITH_P4EST\n       , triangulation(MPI_COMM_WORLD)\n   #endif\n       , fe(FE_DGQ<dim>(fe_degree) ^ (dim + 2))\n       , mapping(fe_degree)\n       , dof_handler(triangulation)\n       , timer(pcout, TimerOutput::never, TimerOutput::wall_times)\n       , euler_operator(timer)\n       , time(0)\n       , time_step(0)\n     {}\n```\n\nAs a mesh, this tutorial program implements two options, depending on the global variable `testcase`: For the analytical variant (`testcase==0`), the domain is \\((0, 10) \\times (-5, 5)\\), with Dirichlet boundary conditions (inflow) all around the domain. For `testcase==1`, we set the domain to a cylinder in a rectangular box, derived from the flow past cylinder testcase for incompressible viscous flow by Schäfer and Turek (1996). Here, we have a larger variety of boundaries. The inflow part at the left of the channel is given the inflow type, for which we choose a constant inflow profile, whereas we set a subsonic outflow at the right. For the boundary around the cylinder (boundary id equal to 2) as well as the channel walls (boundary id equal to 3) we use the wall boundary type, which is no-normal flow. Furthermore, for the 3d cylinder we also add a gravity force in vertical direction. Having the base mesh in place (including the manifolds set by [GridGenerator::channel\\_with\\_cylinder()](namespaceGridGenerator.html#a9d0b8a34fe5ca58425aa1fcf0d6132f1)), we can then perform the specified number of global refinements, create the unknown numbering from the [DoFHandler](classDoFHandler.html), and hand the [DoFHandler](classDoFHandler.html) and [Mapping](classMapping.html \"Abstract base class for mapping classes.\") objects to the initialization of the EulerOperator.\n\n```\n     template <int dim>\n     void EulerProblem<dim>::make_grid_and_dofs()\n     {\n       switch (testcase)\n         {\n           case 0:\n             {\n               Point<dim> lower_left;\n               for (unsigned int d = 1; d < dim; ++d)\n                 lower_left[d] = -5;\n   \n               Point<dim> upper_right;\n               upper_right[0] = 10;\n               for (unsigned int d = 1; d < dim; ++d)\n                 upper_right[d] = 5;\n   \n               GridGenerator::hyper_rectangle(triangulation,\n                                              lower_left,\n                                              upper_right);\n               triangulation.refine_global(2);\n   \n               euler_operator.set_inflow_boundary(\n                 0, std::make_unique<ExactSolution<dim>>(0));\n   \n               break;\n             }\n   \n           case 1:\n             {\n               GridGenerator::channel_with_cylinder(\n                 triangulation, 0.03, 1, 0, true);\n   \n               euler_operator.set_inflow_boundary(\n                 0, std::make_unique<ExactSolution<dim>>(0));\n               euler_operator.set_subsonic_outflow_boundary(\n                 1, std::make_unique<ExactSolution<dim>>(0));\n   \n               euler_operator.set_wall_boundary(2);\n               euler_operator.set_wall_boundary(3);\n   \n               if (dim == 3)\n                 euler_operator.set_body_force(\n                   std::make_unique<Functions::ConstantFunction<dim>>(\n                     std::vector<double>({0., 0., -0.2})));\n   \n               break;\n             }\n   \n           default:\n             DEAL_II_NOT_IMPLEMENTED();\n         }\n   \n       triangulation.refine_global(n_global_refinements);\n   \n       dof_handler.distribute_dofs(fe);\n   \n       euler_operator.reinit(mapping, dof_handler);\n       euler_operator.initialize_vector(solution);\n```\n\nIn the following, we output some statistics about the problem. Because we often end up with quite large numbers of cells or degrees of freedom, we would like to print them with a comma to separate each set of three digits. This can be done via \"locales\", although the way this works is not particularly intuitive. [step-32](step_32.html) explains this in slightly more detail.\n\n```\n       std::locale s = pcout.get_stream().getloc();\n       pcout.get_stream().imbue(std::locale(\"\"));\n       pcout << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n             << \" ( = \" << (dim + 2) << \" [vars] x \"\n             << triangulation.n_global_active_cells() << \" [cells] x \"\n             << Utilities::pow(fe_degree + 1, dim) << \" [dofs/cell/var] )\"\n             << std::endl;\n       pcout.get_stream().imbue(s);\n     }\n```\n\nFor output, we first let the Euler operator compute the errors of the numerical results. More precisely, we compute the error against the analytical result for the analytical solution case, whereas we compute the deviation against the background field with constant density and energy and constant velocity in \\(x\\) direction for the second test case.\n\nThe next step is to create output. This is similar to what is done in [step-33](step_33.html): We let the postprocessor defined above control most of the output, except for the primal field that we write directly. For the analytical solution test case, we also perform another projection of the analytical solution and print the difference between that field and the numerical solution. Once we have defined all quantities to be written, we build the patches for output. Similarly to [step-65](step_65.html), we create a high-order VTK output by setting the appropriate flag, which enables us to visualize fields of high polynomial degrees. Finally, we call the `DataOutInterface::write_vtu_in_parallel()` function to write the result to the given file name. This function uses special MPI parallel write facilities, which are typically more optimized for parallel file systems than the standard library's `std::ofstream` variants used in most other tutorial programs. A particularly nice feature of the `write_vtu_in_parallel()` function is the fact that it can combine output from all MPI ranks into a single file, making it unnecessary to have a central record of all such files (namely, the \"pvtu\" file).\n\nFor parallel programs, it is often instructive to look at the partitioning of cells among processors. To this end, one can pass a vector of numbers to [DataOut::add\\_data\\_vector()](classDataOut__DoFData.html#ac43d3b1f6e67424f36e474627fe8e401) that contains as many entries as the current processor has active cells; these numbers should then be the rank of the processor that owns each of these cells. Such a vector could, for example, be obtained from [GridTools::get\\_subdomain\\_association()](namespaceGridTools.html#ac41d959ae1723a898b616c3320241ffe). On the other hand, on each MPI process, [DataOut](classDataOut.html) will only read those entries that correspond to locally owned cells, and these of course all have the same value: namely, the rank of the current process. What is in the remaining entries of the vector doesn't actually matter, and so we can just get away with a cheap trick: We just fill *all* values of the vector we give to [DataOut::add\\_data\\_vector()](classDataOut__DoFData.html#ac43d3b1f6e67424f36e474627fe8e401) with the rank of the current MPI process. The key is that on each process, only the entries corresponding to the locally owned cells will be read, ignoring the (wrong) values in other entries. The fact that every process submits a vector in which the correct subset of entries is correct is all that is necessary.\n\nNote\n:   As of 2023, Visit 3.3.3 can still not deal with higher-order cells. Rather, it simply reports that there is no data to show. To view the results of this program with Visit, you will want to comment out the line that sets `flags.write_higher_order_cells = true;`. On the other hand, Paraview is able to understand VTU files with higher order cells just fine.\n\n```\n     template <int dim>\n     void EulerProblem<dim>::output_results(const unsigned int result_number)\n     {\n       const std::array<double, 3> errors =\n         euler_operator.compute_errors(ExactSolution<dim>(time), solution);\n       const std::string quantity_name = testcase == 0 ? \"error\" : \"norm\";\n   \n       pcout << \"Time:\" << std::setw(8) << std::setprecision(3) << time\n             << \", dt: \" << std::setw(8) << std::setprecision(2) << time_step\n             << \", \" << quantity_name << \" rho: \" << std::setprecision(4)\n             << std::setw(10) << errors[0] << \", rho * u: \" << std::setprecision(4)\n             << std::setw(10) << errors[1] << \", energy:\" << std::setprecision(4)\n             << std::setw(10) << errors[2] << std::endl;\n   \n       {\n         TimerOutput::Scope t(timer, \"output\");\n   \n         Postprocessor postprocessor;\n         DataOut<dim>  data_out;\n   \n         DataOutBase::VtkFlags flags;\n         flags.write_higher_order_cells = true;\n         data_out.set_flags(flags);\n   \n         data_out.attach_dof_handler(dof_handler);\n         {\n           std::vector<std::string> names;\n           names.emplace_back(\"density\");\n           for (unsigned int d = 0; d < dim; ++d)\n             names.emplace_back(\"momentum\");\n           names.emplace_back(\"energy\");\n   \n           std::vector<DataComponentInterpretation::DataComponentInterpretation>\n             interpretation;\n           interpretation.push_back(\n             DataComponentInterpretation::component_is_scalar);\n           for (unsigned int d = 0; d < dim; ++d)\n             interpretation.push_back(\n               DataComponentInterpretation::component_is_part_of_vector);\n           interpretation.push_back(\n             DataComponentInterpretation::component_is_scalar);\n   \n           data_out.add_data_vector(dof_handler, solution, names, interpretation);\n         }\n         data_out.add_data_vector(solution, postprocessor);\n   \n         LinearAlgebra::distributed::Vector<Number> reference;\n         if (testcase == 0 && dim == 2)\n           {\n             reference.reinit(solution);\n             euler_operator.project(ExactSolution<dim>(time), reference);\n             reference.sadd(-1., 1, solution);\n             std::vector<std::string> names;\n             names.emplace_back(\"error_density\");\n             for (unsigned int d = 0; d < dim; ++d)\n               names.emplace_back(\"error_momentum\");\n             names.emplace_back(\"error_energy\");\n   \n             std::vector<DataComponentInterpretation::DataComponentInterpretation>\n               interpretation;\n             interpretation.push_back(\n               DataComponentInterpretation::component_is_scalar);\n             for (unsigned int d = 0; d < dim; ++d)\n               interpretation.push_back(\n                 DataComponentInterpretation::component_is_part_of_vector);\n             interpretation.push_back(\n               DataComponentInterpretation::component_is_scalar);\n   \n             data_out.add_data_vector(dof_handler,\n                                      reference,\n                                      names,\n                                      interpretation);\n           }\n   \n         Vector<double> mpi_owner(triangulation.n_active_cells());\n         mpi_owner = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\n         data_out.add_data_vector(mpi_owner, \"owner\");\n   \n         data_out.build_patches(mapping,\n                                fe.degree,\n                                DataOut<dim>::curved_inner_cells);\n   \n         const std::string filename =\n           \"solution_\" + Utilities::int_to_string(result_number, 3) + \".vtu\";\n         data_out.write_vtu_in_parallel(filename, MPI_COMM_WORLD);\n       }\n     }\n```\n\nThe EulerProblem::run() function puts all pieces together. It starts off by calling the function that creates the mesh and sets up data structures, and then initializing the time integrator and the two temporary vectors of the low-storage integrator. We call these vectors `rk_register_1` and `rk_register_2`, and use the first vector to represent the quantity \\(\\mathbf{r}\\_i\\) and the second one for \\(\\mathbf{k}\\_i\\) in the formulas for the Runge–Kutta scheme outlined in the introduction. Before we start the time loop, we compute the time step size by the `EulerOperator::compute_cell_transport_speed()` function. For reasons of comparison, we compare the result obtained there with the minimal mesh size and print them to screen. For velocities and speeds of sound close to unity as in this tutorial program, the predicted effective mesh size will be close, but they could vary if scaling were different.\n\n```\n     template <int dim>\n     void EulerProblem<dim>::run()\n     {\n       {\n         const unsigned int n_vect_number = VectorizedArray<Number>::size();\n         const unsigned int n_vect_bits   = 8 * sizeof(Number) * n_vect_number;\n   \n         pcout << \"Running with \"\n               << Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD)\n               << \" MPI processes\" << std::endl;\n         pcout << \"Vectorization over \" << n_vect_number << ' '\n               << (std::is_same_v<Number, double> ? \"doubles\" : \"floats\") << \" = \"\n               << n_vect_bits << \" bits (\"\n               << Utilities::System::get_current_vectorization_level() << ')'\n               << std::endl;\n       }\n   \n       make_grid_and_dofs();\n   \n       const LowStorageRungeKuttaIntegrator integrator(lsrk_scheme);\n   \n       LinearAlgebra::distributed::Vector<Number> rk_register_1;\n       LinearAlgebra::distributed::Vector<Number> rk_register_2;\n       rk_register_1.reinit(solution);\n       rk_register_2.reinit(solution);\n   \n       euler_operator.project(ExactSolution<dim>(time), solution);\n   \n       double min_vertex_distance = std::numeric_limits<double>::max();\n       for (const auto &cell : triangulation.active_cell_iterators())\n         if (cell->is_locally_owned())\n           min_vertex_distance =\n             std::min(min_vertex_distance, cell->minimum_vertex_distance());\n       min_vertex_distance =\n         Utilities::MPI::min(min_vertex_distance, MPI_COMM_WORLD);\n   \n       time_step = courant_number * integrator.n_stages() /\n                   euler_operator.compute_cell_transport_speed(solution);\n       pcout << \"Time step size: \" << time_step\n             << \", minimal h: \" << min_vertex_distance\n             << \", initial transport scaling: \"\n             << 1. / euler_operator.compute_cell_transport_speed(solution)\n             << std::endl\n             << std::endl;\n   \n       output_results(0);\n```\n\nNow we are ready to start the time loop, which we run until the time has reached the desired end time. Every 5 time steps, we compute a new estimate for the time step – since the solution is nonlinear, it is most effective to adapt the value during the course of the simulation. In case the Courant number was chosen too aggressively, the simulation will typically blow up with time step NaN, so that is easy to detect here. One thing to note is that roundoff errors might propagate to the leading digits due to an interaction of slightly different time step selections that in turn lead to slightly different solutions. To decrease this sensitivity, it is common practice to round or truncate the time step size to a few digits, e.g. 3 in this case. In case the current time is near the prescribed 'tick' value for output (e.g. 0.02), we also write the output. After the end of the time loop, we summarize the computation by printing some statistics, which is mostly done by the [TimerOutput::print\\_wall\\_time\\_statistics()](classTimerOutput.html#a643e162e90b44601a29f15a198b5f0b6) function.\n\n```\n       unsigned int timestep_number = 0;\n   \n       while (time < final_time - 1e-12)\n         {\n           ++timestep_number;\n           if (timestep_number % 5 == 0)\n             time_step =\n               courant_number * integrator.n_stages() /\n               Utilities::truncate_to_n_digits(\n                 euler_operator.compute_cell_transport_speed(solution), 3);\n   \n           {\n             TimerOutput::Scope t(timer, \"rk time stepping total\");\n             integrator.perform_time_step(euler_operator,\n                                          time,\n                                          time_step,\n                                          solution,\n                                          rk_register_1,\n                                          rk_register_2);\n           }\n   \n           time += time_step;\n   \n           if (static_cast<int>(time / output_tick) !=\n                 static_cast<int>((time - time_step) / output_tick) ||\n               time >= final_time - 1e-12)\n             output_results(\n               static_cast<unsigned int>(std::round(time / output_tick)));\n         }\n   \n       timer.print_wall_time_statistics(MPI_COMM_WORLD);\n       pcout << std::endl;\n     }\n   \n   } // namespace Euler_DG\n```\n\nThe main() function is not surprising and follows what was done in all previous MPI programs: As we run an MPI program, we need to call `MPI_Init()` and `MPI_Finalize()`, which we do through the [Utilities::MPI::MPI\\_InitFinalize](classUtilities_1_1MPI_1_1MPI__InitFinalize.html) data structure. Note that we run the program only with MPI, and set the thread count to 1.\n\n```\n   int main(int argc, char **argv)\n   {\n     using namespace Euler_DG;\n     using namespace dealii;\n   \n     Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n   \n     try\n       {\n         EulerProblem<dimension> euler_problem;\n         euler_problem.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\n### Program output\n\nRunning the program with the default settings on a machine with 40 processes produces the following output:\n\n```\nRunning with 40 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 147,456 ( = 4 [vars] x 1,024 [cells] x 36 [dofs/cell/var] )\nTime step size: 0.00689325, minimal h: 0.3125, initial transport scaling: 0.102759\n \nTime:       0, dt:   0.0069, error rho:   2.76e-07, rho * u:  1.259e-06, energy: 2.987e-06\nTime:    1.01, dt:   0.0069, error rho:   1.37e-06, rho * u:  2.252e-06, energy: 4.153e-06\nTime:    2.01, dt:   0.0069, error rho:  1.561e-06, rho * u:   2.43e-06, energy: 4.493e-06\nTime:    3.01, dt:   0.0069, error rho:  1.714e-06, rho * u:  2.591e-06, energy: 4.762e-06\nTime:    4.01, dt:   0.0069, error rho:  1.843e-06, rho * u:  2.625e-06, energy: 4.985e-06\nTime:    5.01, dt:   0.0069, error rho:  1.496e-06, rho * u:  1.961e-06, energy: 4.142e-06\nTime:       6, dt:   0.0083, error rho:  1.007e-06, rho * u:  7.119e-07, energy: 2.972e-06\nTime:       7, dt:   0.0095, error rho:  9.096e-07, rho * u:  3.786e-07, energy: 2.626e-06\nTime:       8, dt:   0.0096, error rho:  8.439e-07, rho * u:  3.338e-07, energy:  2.43e-06\nTime:       9, dt:   0.0096, error rho:  7.822e-07, rho * u:  2.984e-07, energy: 2.248e-06\nTime:      10, dt:   0.0096, error rho:  7.231e-07, rho * u:  2.666e-07, energy: 2.074e-06\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              |     2.249s    30 |     2.249s |     2.249s     8 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        11 |  0.008066s    13 |   0.00952s |   0.01041s    20 |\n| compute transport speed       |       258 |   0.01012s    13 |   0.05392s |   0.08574s    25 |\n| output                        |        11 |    0.9597s    13 |    0.9613s |    0.9623s     6 |\n| rk time stepping total        |      1283 |    0.9827s    25 |     1.015s |      1.06s    13 |\n| rk_stage - integrals L_h      |      6415 |    0.8803s    26 |    0.9198s |    0.9619s    14 |\n| rk_stage - inv mass + vec upd |      6415 |   0.05677s    15 |   0.06487s |   0.07597s    13 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThe program output shows that all errors are small. This is due to the fact that we use a relatively fine mesh of \\(32^2\\) cells with polynomials of degree 5 for a solution that is smooth. An interesting pattern shows for the time step size: whereas it is 0.0069 up to time 5, it increases to 0.0096 for later times. The step size increases once the vortex with some motion on top of the speed of sound (and thus faster propagation) leaves the computational domain between times 5 and 6.5. After that point, the flow is simply uniform in the same direction, and the maximum velocity of the gas is reduced compared to the previous state where the uniform velocity was overlaid by the vortex. Our time step formula recognizes this effect.\n\nThe final block of output shows detailed information about the timing of individual parts of the programs; it breaks this down by showing the time taken by the fastest and the slowest processor, and the average time – this is often useful in very large computations to find whether there are processors that are consistently overheated (and consequently are throttling their clock speed) or consistently slow for other reasons. The summary shows that 1283 time steps have been performed in 1.02 seconds (looking at the average time among all MPI processes), while the output of 11 files has taken additional 0.96 seconds. Broken down per time step and into the five Runge–Kutta stages, the compute time per evaluation is 0.16 milliseconds. This high performance is typical of matrix-free evaluators and a reason why explicit time integration is very competitive against implicit solvers, especially for large-scale simulations. The breakdown of computational times at the end of the program run shows that the evaluation of integrals in \\(\\mathcal L\\_h\\) contributes with around 0.92 seconds and the application of the inverse mass matrix with 0.06 seconds. Furthermore, the estimation of the transport speed for the time step size computation contributes with another 0.05 seconds of compute time.\n\nIf we use three more levels of global refinement and 9.4 million DoFs in total, the final statistics are as follows (for the modified Lax–Friedrichs flux, \\(p=5\\), and the same system of 40 cores of dual-socket Intel Xeon Gold 6230):\n\n```\n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              |     244.9s    12 |     244.9s |     244.9s    34 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        11 |    0.4239s    12 |    0.4318s |    0.4408s     9 |\n| compute transport speed       |      2053 |     3.962s    12 |     6.727s |     10.12s     7 |\n| output                        |        11 |     30.35s    12 |     30.36s |     30.37s     9 |\n| rk time stepping total        |     10258 |     201.7s     7 |     205.1s |     207.8s    12 |\n| rk_stage - integrals L_h      |     51290 |     121.3s     6 |     126.6s |     136.3s    16 |\n| rk_stage - inv mass + vec upd |     51290 |     66.19s    16 |     77.52s |     81.84s    10 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nPer time step, the solver now takes 0.02 seconds, about 25 times as long as for the small problem with 147k unknowns. Given that the problem involves 64 times as many unknowns, the increase in computing time is not surprising. Since we also do 8 times as many time steps, the compute time should in theory increase by a factor of 512. The actual increase is 205 s / 1.02 s = 202. This is because the small problem size cannot fully utilize the 40 cores due to communication overhead. This becomes clear if we look into the details of the operations done per time step. The evaluation of the differential operator \\(\\mathcal L\\_h\\) with nearest neighbor communication goes from 0.92 seconds to 127 seconds, i.e., it increases with a factor of 138. On the other hand, the cost for application of the inverse mass matrix and the vector updates, which do not need to communicate between the MPI processes at all, has increased by a factor of 1195. The increase is more than the theoretical factor of 512 because the operation is limited by the bandwidth from RAM memory for the larger size while for the smaller size, all vectors fit into the caches of the CPU. The numbers show that the mass matrix evaluation and vector update part consume almost 40% of the time spent by the Runge–Kutta stages – despite using a low-storage Runge–Kutta integrator and merging of vector operations! And despite using over-integration for the \\(\\mathcal L\\_h\\) operator. For simpler differential operators and more expensive time integrators, the proportion spent in the mass matrix and vector update part can also reach 70%. If we compute a throughput number in terms of DoFs processed per second and Runge–Kutta stage, we obtain\n\n\\[ \\text{throughput} =\n\\frac{n\\_\\mathrm{time steps} n\\_\\mathrm{stages}\nn\\_\\mathrm{dofs}}{t\\_\\mathrm{compute}} = \\frac{10258 \\cdot 5 \\cdot\n9.4\\,\\text{MDoFs}}{205s} = 2360\\, \\text{MDoFs/s} \\]\n\nThis throughput number is very high, given that simply copying one vector to another one runs at only around 10,000 MDoFs/s.\n\nIf we go to the next-larger size with 37.7 million DoFs, the overall simulation time is 2196 seconds, with 1978 seconds spent in the time stepping. The increase in run time is a factor of 9.3 for the L\\_h operator (1179 versus 127 seconds) and a factor of 10.3 for the inverse mass matrix and vector updates (797 vs 77.5 seconds). The reason for this non-optimal increase in run time can be traced back to cache effects on the given hardware (with 40 MB of L2 cache and 55 MB of L3 cache): While not all of the relevant data fits into caches for 9.4 million DoFs (one vector takes 75 MB and we have three vectors plus some additional data in [MatrixFree](classMatrixFree.html)), there is capacity for one and a half vector nonetheless. Given that modern caches are more sophisticated than the naive least-recently-used strategy (where we would have little re-use as the data is used in a streaming-like fashion), we can assume that a sizeable fraction of data can indeed be delivered from caches for the 9.4 million DoFs case. For the larger case, even with optimal caching less than 10 percent of data would fit into caches, with an associated loss in performance.\n\n### Convergence rates for the analytical test case\n\nFor the modified Lax–Friedrichs flux and measuring the error in the momentum variable, we obtain the following convergence table (the rates are very similar for the density and energy variables):\n\n|  | *p*=2 | | | *p*=3 | | | *p*=5 | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| n\\_cells | n\\_dofs | error mom | rate | n\\_dofs | error mom | rate | n\\_dofs | error mom | rate |\n| 16 |  |  |  |  |  |  | 2,304 | 1.373e-01 |  |\n| 64 |  |  |  | 4,096 | 9.130e-02 |  | 9,216 | 8.899e-03 | 3.94 |\n| 256 | 9,216 | 5.577e-02 |  | 16,384 | 7.381e-03 | 3.64 | 36,864 | 2.082e-04 | 5.42 |\n| 1024 | 36,864 | 4.724e-03 | 3.56 | 65,536 | 3.072e-04 | 4.59 | 147,456 | 2.625e-06 | 6.31 |\n| 4096 | 147,456 | 6.205e-04 | 2.92 | 262,144 | 1.880e-05 | 4.03 | 589,824 | 3.268e-08 | 6.33 |\n| 16,384 | 589,824 | 8.279e-05 | 2.91 | 1,048,576 | 1.224e-06 | 3.94 | 2,359,296 | 9.252e-10 | 5.14 |\n| 65,536 | 2,359,296 | 1.105e-05 | 2.91 | 4,194,304 | 7.871e-08 | 3.96 | 9,437,184 | 1.369e-10 | 2.77 |\n| 262,144 | 9,437,184 | 1.615e-06 | 2.77 | 16,777,216 | 4.961e-09 | 3.99 | 37,748,736 | 7.091e-11 | 0.95 |\n\nIf we switch to the Harten-Lax-van Leer flux, the results are as follows:\n\n|  | *p*=2 | | | *p*=3 | | | *p*=5 | | |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| n\\_cells | n\\_dofs | error mom | rate | n\\_dofs | error mom | rate | n\\_dofs | error mom | rate |\n| 16 |  |  |  |  |  |  | 2,304 | 1.339e-01 |  |\n| 64 |  |  |  | 4,096 | 9.037e-02 |  | 9,216 | 8.849e-03 | 3.92 |\n| 256 | 9,216 | 4.204e-02 |  | 16,384 | 9.143e-03 | 3.31 | 36,864 | 2.501e-04 | 5.14 |\n| 1024 | 36,864 | 4.913e-03 | 3.09 | 65,536 | 3.257e-04 | 4.81 | 147,456 | 3.260e-06 | 6.26 |\n| 4096 | 147,456 | 7.862e-04 | 2.64 | 262,144 | 1.588e-05 | 4.36 | 589,824 | 2.953e-08 | 6.79 |\n| 16,384 | 589,824 | 1.137e-04 | 2.79 | 1,048,576 | 9.400e-07 | 4.08 | 2,359,296 | 4.286e-10 | 6.11 |\n| 65,536 | 2,359,296 | 1.476e-05 | 2.95 | 4,194,304 | 5.799e-08 | 4.02 | 9,437,184 | 2.789e-11 | 3.94 |\n| 262,144 | 9,437,184 | 2.038e-06 | 2.86 | 16,777,216 | 3.609e-09 | 4.01 | 37,748,736 | 5.730e-11 | -1.04 |\n\nThe tables show that we get optimal \\(\\mathcal O\\left(h^{p+1}\\right)\\) convergence rates for both numerical fluxes. The errors are slightly smaller for the Lax–Friedrichs flux for \\(p=2\\), but the picture is reversed for \\(p=3\\); in any case, the differences on this testcase are relatively small.\n\nFor \\(p=5\\), we reach the roundoff accuracy of \\(10^{-11}\\) with both fluxes on the finest grids. Also note that the errors are absolute with a domain length of \\(10^2\\), so relative errors are below \\(10^{-12}\\). The HLL flux is somewhat better for the highest degree, which is due to a slight inaccuracy of the Lax–Friedrichs flux: The Lax–Friedrichs flux sets a Dirichlet condition on the solution that leaves the domain, which results in a small artificial reflection, which is accentuated for the Lax–Friedrichs flux. Apart from that, we see that the influence of the numerical flux is minor, as the polynomial part inside elements is the main driver of the accucary. The limited influence of the flux also has consequences when trying to approach more challenging setups with the higher-order DG setup: Taking for example the parameters and grid of [step-33](step_33.html), we get oscillations (which in turn make density negative and make the solution explode) with both fluxes once the high-mass part comes near the boundary, as opposed to the low-order finite volume case ( \\(p=0\\)). Thus, any case that leads to shocks in the solution necessitates some form of limiting or artificial dissipation. For another alternative, see the [step-69](step_69.html) tutorial program.\n\n### Results for flow in channel around cylinder in 2D\n\nFor the test case of the flow around a cylinder in a channel, we need to change the first code line to\n\n```\nconstexpr unsigned int testcase = 1;\n```\n\nThis test case starts with a background field of a constant velocity of Mach number 0.31 and a constant initial density; the flow will have to go around an obstacle in the form of a cylinder. Since we impose a no-penetration condition on the cylinder walls, the flow that initially impinges head-on onto to cylinder has to rearrange, which creates a big sound wave. The following pictures show the pressure at times 0.1, 0.25, 0.5, and 1.0 (top left to bottom right) for the 2D case with 5 levels of global refinement, using 102,400 cells with polynomial degree of 5 and 14.7 million degrees of freedom over all 4 solution variables. We clearly see the discontinuity that propagates slowly in the upstream direction and more quickly in downstream direction in the first snapshot at time 0.1. At time 0.25, the sound wave has reached the top and bottom walls and reflected back to the interior. From the different distances of the reflected waves from lower and upper walls we can see the slight asymmetry of the Schäfer-Turek test case represented by [GridGenerator::channel\\_with\\_cylinder()](namespaceGridGenerator.html#a9d0b8a34fe5ca58425aa1fcf0d6132f1) with somewhat more space above the cylinder compared to below. At later times, the picture is more chaotic with many sound waves all over the place.\n\n|  |  |\n| --- | --- |\n|  |  |\n|  |  |\n\nThe next picture shows an elevation plot of the pressure at time 1.0 looking from the channel inlet towards the outlet at the same resolution – here, we can see the large number of reflections. In the figure, two types of waves are visible. The larger-amplitude waves correspond to various reflections that happened as the initial discontinuity hit the walls, whereas the small-amplitude waves of size similar to the elements correspond to numerical artifacts. They have their origin in the finite resolution of the scheme and appear as the discontinuity travels through elements with high-order polynomials. This effect can be cured by increasing resolution. Apart from this effect, the rich wave structure is the result of the transport accuracy of the high-order DG method.\n\n![](images/steps/developer/step-67.pressure_elevated.jpg)\n\nIf we run the program with degree 2 and 6 levels of global refinements (410k cells, 14.7M unknowns), we get the following evolution of the pressure (elevation plot, colored by the value of the density):\n\nWith 2 levels of global refinement with 1,600 cells, the mesh and its partitioning on 40 MPI processes looks as follows:\n\n![](images/steps/developer/step-67.grid-owner.png)\n\nWhen we run the code with 4 levels of global refinements on 40 cores, we get the following output:\n\n```\nRunning with 40 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 3,686,400 ( = 4 [vars] x 25,600 [cells] x 36 [dofs/cell/var] )\nTime step size: 7.39876e-05, minimal h: 0.001875, initial transport scaling: 0.00110294\n \nTime:       0, dt:  7.4e-05, norm rho:   4.17e-16, rho * u:  1.629e-16, energy: 1.381e-15\nTime:    0.05, dt:  6.3e-05, norm rho:    0.02075, rho * u:    0.03801, energy:   0.08772\nTime:     0.1, dt:  5.9e-05, norm rho:    0.02211, rho * u:    0.04515, energy:   0.08953\nTime:    0.15, dt:  5.7e-05, norm rho:    0.02261, rho * u:    0.04592, energy:   0.08967\nTime:     0.2, dt:  5.8e-05, norm rho:    0.02058, rho * u:    0.04361, energy:   0.08222\nTime:    0.25, dt:  5.9e-05, norm rho:    0.01695, rho * u:    0.04203, energy:   0.06873\nTime:     0.3, dt:  5.9e-05, norm rho:    0.01653, rho * u:     0.0401, energy:   0.06604\nTime:    0.35, dt:  5.7e-05, norm rho:    0.01774, rho * u:    0.04264, energy:    0.0706\n \n...\n \nTime:    1.95, dt:  5.8e-05, norm rho:    0.01488, rho * u:    0.03923, energy:   0.05185\nTime:       2, dt:  5.7e-05, norm rho:    0.01432, rho * u:    0.03969, energy:   0.04889\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              |     273.6s    13 |     273.6s |     273.6s     0 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        41 |   0.01112s    35 |    0.0672s |    0.1337s     0 |\n| compute transport speed       |      6914 |     5.422s    35 |     15.96s |     29.99s     1 |\n| output                        |        41 |     37.24s    35 |      37.3s |     37.37s     0 |\n| rk time stepping total        |     34564 |     205.4s     1 |     219.5s |     230.1s    35 |\n| rk_stage - integrals L_h      |    172820 |     153.6s     1 |     164.9s |     175.6s    27 |\n| rk_stage - inv mass + vec upd |    172820 |     47.13s    13 |     53.09s |     64.05s    33 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThe norms shown here for the various quantities are the deviations \\(\\rho'\\), \\((\\rho u)'\\), and \\(E'\\) against the background field (namely, the initial condition). The distribution of run time is overall similar as in the previous test case. The only slight difference is the larger proportion of time spent in \\(\\mathcal L\\_h\\) as compared to the inverse mass matrix and vector updates. This is because the geometry is deformed and the matrix-free framework needs to load additional arrays for the geometry from memory that are compressed in the affine mesh case.\n\nIncreasing the number of global refinements to 5, the output becomes:\n\n```\nRunning with 40 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 14,745,600 ( = 4 [vars] x 102,400 [cells] x 36 [dofs/cell/var] )\n \n...\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              |      2693s    32 |      2693s |      2693s    23 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        41 |   0.04537s    32 |     0.173s |    0.3489s     0 |\n| compute transport speed       |     13858 |     40.75s    32 |     85.99s |     149.8s     0 |\n| output                        |        41 |     153.8s    32 |     153.9s |     154.1s     0 |\n| rk time stepping total        |     69284 |      2386s     0 |      2450s |      2496s    32 |\n| rk_stage - integrals L_h      |    346420 |      1365s    32 |      1574s |      1718s    19 |\n| rk_stage - inv mass + vec upd |    346420 |     722.5s    10 |     870.7s |      1125s    32 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThe effect on performance is similar to the analytical test case – in theory, computation times should increase by a factor of 8, but we actually see an increase by a factor of 11 for the time steps (219.5 seconds versus 2450 seconds). This can be traced back to caches, with the small case mostly fitting in caches. An interesting effect, typical of programs with a mix of local communication (integrals \\(\\mathcal L\\_h\\)) and global communication (computation of transport speed) with some load imbalance, can be observed by looking at the MPI ranks that encounter the minimal and maximal time of different phases, respectively. Rank 0 reports the fastest throughput for the \"rk time stepping\ntotal\" part. At the same time, it appears to be slowest for the \"compute\ntransport speed\" part, almost a factor of 2 slower than the average and almost a factor of 4 compared to the faster rank. Since the latter involves global communication, we can attribute the slowness in this part to the fact that the local Runge–Kutta stages have advanced more quickly on this rank and need to wait until the other processors catch up. At this point, one can wonder about the reason for this imbalance: The number of cells is almost the same on all MPI processes. However, the matrix-free framework is faster on affine and Cartesian cells located towards the outlet of the channel, to which the lower MPI ranks are assigned. On the other hand, rank 32, which reports the highest run time for the Runga–Kutta stages, owns the curved cells near the cylinder, for which no data compression is possible. To improve throughput, we could assign different weights to different cell types when partitioning the [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) object, or even measure the run time for a few time steps and try to rebalance then.\n\nThe throughput per Runge–Kutta stage can be computed to 2085 MDoFs/s for the 14.7 million DoFs test case over the 346,000 Runge–Kutta stages, slightly slower than the Cartesian mesh throughput of 2360 MDoFs/s reported above.\n\nFinally, if we add one additional refinement, we record the following output:\n\n```\nRunning with 40 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 58,982,400 ( = 4 [vars] x 409,600 [cells] x 36 [dofs/cell/var] )\n \n...\n \nTime:    1.95, dt:  1.4e-05, norm rho:    0.01488, rho * u:    0.03923, energy:   0.05183\nTime:       2, dt:  1.4e-05, norm rho:    0.01431, rho * u:    0.03969, energy:   0.04887\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              | 2.166e+04s    26 | 2.166e+04s | 2.166e+04s    24 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        41 |    0.1758s    30 |     0.672s |     1.376s     1 |\n| compute transport speed       |     27748 |     321.3s    34 |     678.8s |      1202s     1 |\n| output                        |        41 |     616.3s    32 |     616.4s |     616.4s    34 |\n| rk time stepping total        |    138733 | 1.983e+04s     1 | 2.036e+04s | 2.072e+04s    34 |\n| rk_stage - integrals L_h      |    693665 | 1.052e+04s    32 | 1.248e+04s | 1.387e+04s    19 |\n| rk_stage - inv mass + vec upd |    693665 |      6404s    10 |      7868s | 1.018e+04s    32 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThe \"rk time stepping total\" part corresponds to a throughput of 2010 MDoFs/s. The overall run time to perform 139k time steps is 20k seconds (5.7 hours) or 7 time steps per second – not so bad for having nearly 60 million unknowns. More throughput can be achieved by adding more cores to the computation.\n\n### Results for flow in channel around cylinder in 3D\n\nSwitching the channel test case to 3D with 3 global refinements, the output is\n\n```\nRunning with 40 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 221,184,000 ( = 5 [vars] x 204,800 [cells] x 216 [dofs/cell/var] )\n \n...\n \nTime:    1.95, dt:  0.00011, norm rho:    0.01131, rho * u:    0.03056, energy:   0.04091\nTime:       2, dt:  0.00011, norm rho:     0.0119, rho * u:    0.03142, energy:   0.04425\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              | 1.734e+04s     4 | 1.734e+04s | 1.734e+04s    38 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        41 |    0.6551s    34 |     3.216s |     7.281s     0 |\n| compute transport speed       |      3546 |       160s    34 |     393.2s |     776.9s     0 |\n| output                        |        41 |      1350s    34 |      1353s |      1357s     0 |\n| rk time stepping total        |     17723 | 1.519e+04s     0 | 1.558e+04s | 1.582e+04s    34 |\n| rk_stage - integrals L_h      |     88615 | 1.005e+04s    32 | 1.126e+04s |  1.23e+04s    11 |\n| rk_stage - inv mass + vec upd |     88615 |      3056s    11 |      4322s |      5759s    32 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThe physics are similar to the 2D case, with a slight motion in the z direction due to the gravitational force. The throughput per Runge–Kutta stage in this case is\n\n\\[\n\\text{throughput} = \\frac{n\\_\\mathrm{time steps} n\\_\\mathrm{stages}\nn\\_\\mathrm{dofs}}{t\\_\\mathrm{compute}} =\n\\frac{17723 \\cdot 5 \\cdot 221.2\\,\\text{M}}{15580s} = 1258\\, \\text{MDoFs/s}.\n\\]\n\nThe throughput is lower than in 2D because the computation of the \\(\\mathcal L\\_h\\) term is more expensive. This is due to over-integration with `degree+2` points and the larger fraction of face integrals (worse volume-to-surface ratio) with more expensive flux computations. If we only consider the inverse mass matrix and vector update part, we record a throughput of 4857 MDoFs/s for the 2D case of the isentropic vortex with 37.7 million unknowns, whereas the 3D case runs with 4535 MDoFs/s. The performance is similar because both cases are in fact limited by the memory bandwidth.\n\nIf we go to four levels of global refinement, we need to increase the number of processes to fit everything in memory – the computation needs around 350 GB of RAM memory in this case. Also, the time it takes to complete 35k time steps becomes more tolerable by adding additional resources. We therefore use 6 nodes with 40 cores each, resulting in a computation with 240 MPI processes:\n\n```\nRunning with 240 MPI processes\nVectorization over 8 doubles = 512 bits (AVX512)\nNumber of degrees of freedom: 1,769,472,000 ( = 5 [vars] x 1,638,400 [cells] x 216 [dofs/cell/var] )\n \n...\n \nTime:    1.95, dt:  5.6e-05, norm rho:    0.01129, rho * u:     0.0306, energy:   0.04086\nTime:       2, dt:  5.6e-05, norm rho:    0.01189, rho * u:    0.03145, energy:   0.04417\n \n+-------------------------------------------+------------------+------------+------------------+\n| Total wallclock time elapsed              | 5.396e+04s   151 | 5.396e+04s | 5.396e+04s     0 |\n|                                           |                  |                               |\n| Section                       | no. calls |   min time  rank |   avg time |   max time  rank |\n+-------------------------------------------+------------------+------------+------------------+\n| compute errors                |        41 |     2.632s   178 |     7.221s |     16.56s     0 |\n| compute transport speed       |      7072 |       714s   193 |      1553s |      3351s     0 |\n| output                        |        41 |      8065s   176 |      8070s |      8079s     0 |\n| rk time stepping total        |     35350 |  4.25e+04s     0 |  4.43e+04s | 4.515e+04s   193 |\n| rk_stage - integrals L_h      |    176750 | 2.936e+04s   134 | 3.222e+04s |  3.67e+04s    99 |\n| rk_stage - inv mass + vec upd |    176750 |      7004s    99 | 1.207e+04s |  1.55e+04s   132 |\n+-------------------------------------------+------------------+------------+------------------+\n```\n\nThis simulation had nearly 2 billion unknowns – quite a large computation indeed, and still only needed around 1.5 seconds per time step.\n\n### Possibilities for extensions\n\nThe code presented here straight-forwardly extends to adaptive meshes, given appropriate indicators for setting the refinement flags. Large-scale adaptivity of a similar solver in the context of the acoustic wave equation has been achieved by the [exwave project](https://github.com/kronbichler/exwave). However, in the present context, the benefits of adaptivity are often limited to early times and effects close to the origin of sound waves, as the waves eventually reflect and diffract. This leads to steep gradients all over the place, similar to turbulent flow, and a more or less globally refined mesh.\n\nAnother topic that we did not discuss in the results section is a comparison of different time integration schemes. The program provides four variants of low-storage Runga–Kutta integrators that each have slightly different accuracy and stability behavior. Among the schemes implemented here, the higher-order ones provide additional accuracy but come with slightly lower efficiency in terms of step size per stage before they violate the CFL condition. An interesting extension would be to compare the low-storage variants proposed here with standard Runge–Kutta integrators or to use vector operations that are run separate from the mass matrix operation and compare performance.\n\n#### More advanced numerical flux functions and skew-symmetric formulations\n\nAs mentioned in the introduction, the modified Lax–Friedrichs flux and the HLL flux employed in this program are only two variants of a large body of numerical fluxes available in the literature on the Euler equations. One example is the HLLC flux (Harten-Lax-van Leer-Contact) flux which adds the effect of rarefaction waves missing in the HLL flux, or the Roe flux. As mentioned in the introduction, the effect of numerical fluxes on high-order DG schemes is debatable (unlike for the case of low-order discretizations).\n\nA related improvement to increase the stability of the solver is to also consider the spatial integral terms. A shortcoming in the rather naive implementation used above is the fact that the energy conservation of the original Euler equations (in the absence of shocks) only holds up to a discretization error. If the solution is under-resolved, the discretization error can give rise to an increase in the numerical energy and eventually render the discretization unstable. This is because of the inexact numerical integration of the terms in the Euler equations, which both contain rational nonlinearities and higher-degree content from curved cells. A way out of this dilemma are so-called skew-symmetric formulations, see [[95]](citelist.html#CITEREF_Gassner2013) for a simple variant. Skew symmetry means that switching the role of the solution \\(\\mathbf{w}\\) and test functions \\(\\mathbf{v}\\) in the weak form produces the exact negative of the original quantity, apart from some boundary terms. In the discrete setting, the challenge is to keep this skew symmetry also when the integrals are only computed approximately (in the continuous case, skew-symmetry is a consequence of integration by parts). Skew-symmetric numerical schemes balance spatial derivatives in the conservative form \\((\\nabla \\mathbf v, \\mathbf{F}(\\mathbf w))\\_{K}\\) with contributions in the convective form \\((\\mathbf v, \\tilde{\\mathbf{F}}(\\mathbf w)\\nabla\n\\mathbf{w})\\_{K}\\) for some \\(\\tilde{\\mathbf{F}}\\). The precise terms depend on the equation and the integration formula, and can in some cases by understood by special skew-symmetric finite difference schemes.\n\nTo get started, interested readers could take a look at <https://github.com/kronbichler/advection_miniapp>, where a skew-symmetric DG formulation is implemented with deal.II for a simple advection equation.\n\n#### Equipping the code for supersonic calculations\n\nAs mentioned in the introduction, the solution to the Euler equations develops shocks as the Mach number increases, which require additional mechanisms to stabilize the scheme, e.g. in the form of limiters. The main challenge besides actually implementing the limiter or artificial viscosity approach would be to load-balance the computations, as the additional computations involved for limiting the oscillations in troubled cells would make them more expensive than the plain DG cells without limiting. Furthermore, additional numerical fluxes that better cope with the discontinuities would also be an option.\n\nOne ingredient also necessary for supersonic flows are appropriate boundary conditions. As opposed to the subsonic outflow boundaries discussed in the introduction and implemented in the program, all characteristics are outgoing for supersonic outflow boundaries, so we do not want to prescribe any external data,\n\n\\[\n\\mathbf{w}^+ = \\mathbf{w}^- = \\begin{pmatrix} \\rho^-\\\\\n(\\rho \\mathbf u)^- \\\\ E^-\\end{pmatrix} \\quad\n\\text{(Neumann)}.\n\\]\n\nIn the code, we would simply add the additional statement\n\n```\nelse if (supersonic_outflow_boundaries.find(boundary_id) !=\n         supersonic_outflow_boundaries.end())\n  {\n    w_p        = w_m;\n    at_outflow = true;\n  }\n```\n\nin the `local_apply_boundary_face()` function.\n\n#### Extension to the linearized Euler equations\n\nWhen the interest with an Euler solution is mostly in the propagation of sound waves, it often makes sense to linearize the Euler equations around a background state, i.e., a given density, velocity and energy (or pressure) field, and only compute the change against these fields. This is the setting of the wide field of aeroacoustics. Even though the resolution requirements are sometimes considerably reduced, implementation gets somewhat more complicated as the linearization gives rise to additional terms. From a code perspective, in the operator evaluation we also need to equip the code with the state to linearize against. This information can be provided either by analytical functions (that are evaluated in terms of the position of the quadrature points) or by a vector similar to the solution. Based on that vector, we would create an additional [FEEvaluation](classFEEvaluation.html) object to read from it and provide the values of the field at quadrature points. If the background velocity is zero and the density is constant, the linearized Euler equations further simplify and can equivalently be written in the form of the acoustic wave equation.\n\nA challenge in the context of sound propagation is often the definition of boundary conditions, as the computational domain needs to be of finite size, whereas the actual simulation often spans an infinite (or at least much larger) physical domain. Conventional Dirichlet or Neumann boundary conditions give rise to reflections of the sound waves that eventually propagate back to the region of interest and spoil the solution. Therefore, various variants of non-reflecting boundary conditions or sponge layers, often in the form of [perfectly matched layers](https://en.wikipedia.org/wiki/Perfectly_matched_layer) – where the solution is damped without reflection – are common.\n\n#### Extension to the compressible Navier-Stokes equations\n\nThe solver presented in this tutorial program can also be extended to the compressible Navier–Stokes equations by adding viscous terms, as described in [[85]](citelist.html#CITEREF_FehnWallKronbichler2019). To keep as much of the performance obtained here despite the additional cost of elliptic terms, e.g. via an interior penalty method, one can switch the basis from [FE\\_DGQ](classFE__DGQ.html) to [FE\\_DGQHermite](classFE__DGQHermite.html) like in the [step-59](step_59.html) tutorial program.\n\n#### Using cell-centric loops and shared memory\n\nIn this tutorial, we used face-centric loops. Here, cell and face integrals are treated in separate loops, resulting in multiple writing accesses into the result vector, which is relatively expensive on modern hardware since writing operations generally result also in an implicit read operation. Element-centric loops, on the other hand, are processing a cell and in direct succession processing all its 2d faces. Although this kind of loop implies that fluxes have to be computed twice (for each side of an interior face), the fact that the result vector has to accessed only once might - and the fact that the resulting algorithm is free of race-conditions and as such perfectly suitable for shared memory - already give a performance boost. If you are interested in these advanced topics, you can take a look at [step-76](step_76.html) where we take the present tutorial and modify it so that we can use these features.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2020 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Author: Martin Kronbichler, 2020\n */\n \n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/function.h>\n#include <deal.II/base/timer.h>\n#include <deal.II/base/time_stepping.h>\n#include <deal.II/base/utilities.h>\n#include <deal.II/base/vectorization.h>\n \n#include <deal.II/distributed/tria.h>\n \n#include <deal.II/dofs/dof_handler.h>\n \n#include <deal.II/fe/fe_dgq.h>\n#include <deal.II/fe/fe_system.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/tria.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/la_parallel_vector.h>\n \n#include <deal.II/matrix_free/fe_evaluation.h>\n#include <deal.II/matrix_free/matrix_free.h>\n \n#include <deal.II/numerics/data_out.h>\n \n#include <fstream>\n#include <iomanip>\n#include <iostream>\n \n#include <deal.II/matrix_free/operators.h>\n \n \n \nnamespace Euler_DG\n{\n using namespace dealii;\n \n constexpr unsigned int testcase             = 0;\n constexpr unsigned int dimension            = 2;\n constexpr unsigned int n_global_refinements = 3;\n constexpr unsigned int fe_degree            = 5;\n constexpr unsigned int n_q_points_1d        = fe_degree + 2;\n \n using Number = double;\n \n constexpr double gamma       = 1.4;\n constexpr double final_time  = testcase == 0 ? 10 : 2.0;\n constexpr double output_tick = testcase == 0 ? 1 : 0.05;\n \n const double courant_number = 0.15 / std::pow(fe_degree, 1.5);\n enum LowStorageRungeKuttaScheme\n  {\n    stage_3_order_3, /* Kennedy, Carpenter, Lewis, 2000 */\n    stage_5_order_4, /* Kennedy, Carpenter, Lewis, 2000 */\n    stage_7_order_4, /* Tselios, Simos, 2007 */\n    stage_9_order_5, /* Kennedy, Carpenter, Lewis, 2000 */\n  };\n constexpr LowStorageRungeKuttaScheme lsrk_scheme = stage_5_order_4;\n \n enum EulerNumericalFlux\n  {\n    lax_friedrichs_modified,\n    harten_lax_vanleer,\n  };\n constexpr EulerNumericalFlux numerical_flux_type = lax_friedrichs_modified;\n \n \n \n \n template <int dim>\n class ExactSolution : public Function<dim>\n  {\n public:\n    ExactSolution(const double time)\n      : Function<dim>(dim + 2, time)\n    {}\n \n virtual double value(const Point<dim>  &p,\n const unsigned int component = 0) const override;\n  };\n \n \n \n template <int dim>\n double ExactSolution<dim>::value(const Point<dim>  &x,\n const unsigned int component) const\n {\n const double t = this->get_time();\n \n switch (testcase)\n      {\n case 0:\n          {\n Assert(dim == 2, ExcNotImplemented());\n const double beta = 5;\n \n Point<dim> x0;\n            x0[0] = 5.;\n const double radius_sqr =\n              (x - x0).norm_square() - 2. * (x[0] - x0[0]) * t + t * t;\n const double factor =\n              beta / (numbers::PI * 2) * std::exp(1. - radius_sqr);\n const double density_log = std::log2(\n std::abs(1. - (gamma - 1.) / gamma * 0.25 * factor * factor));\n const double density = std::exp2(density_log * (1. / (gamma - 1.)));\n const double u       = 1. - factor * (x[1] - x0[1]);\n const double v       = factor * (x[0] - t - x0[0]);\n \n if (component == 0)\n return density;\n else if (component == 1)\n return density * u;\n else if (component == 2)\n return density * v;\n else\n              {\n const double pressure =\n                  std::exp2(density_log * (gamma / (gamma - 1.)));\n return pressure / (gamma - 1.) +\n                       0.5 * (density * u * u + density * v * v);\n              }\n          }\n \n case 1:\n          {\n if (component == 0)\n return 1.;\n else if (component == 1)\n return 0.4;\n else if (component == dim + 1)\n return 3.097857142857143;\n else\n return 0.;\n          }\n \n default:\n DEAL_II_NOT_IMPLEMENTED();\n return 0.;\n      }\n  }\n \n \n \n \n class LowStorageRungeKuttaIntegrator\n  {\n public:\n    LowStorageRungeKuttaIntegrator(const LowStorageRungeKuttaScheme scheme)\n    {\n TimeStepping::runge_kutta_method lsrk;\n switch (scheme)\n        {\n case stage_3_order_3:\n            {\n              lsrk = TimeStepping::LOW_STORAGE_RK_STAGE3_ORDER3;\n break;\n            }\n \n case stage_5_order_4:\n            {\n              lsrk = TimeStepping::LOW_STORAGE_RK_STAGE5_ORDER4;\n break;\n            }\n \n case stage_7_order_4:\n            {\n              lsrk = TimeStepping::LOW_STORAGE_RK_STAGE7_ORDER4;\n break;\n            }\n \n case stage_9_order_5:\n            {\n              lsrk = TimeStepping::LOW_STORAGE_RK_STAGE9_ORDER5;\n break;\n            }\n \n default:\n AssertThrow(false, ExcNotImplemented());\n        }\n TimeStepping::LowStorageRungeKutta<\n LinearAlgebra::distributed::Vector<Number>>\n        rk_integrator(lsrk);\n      rk_integrator.get_coefficients(ai, bi, ci);\n    }\n \n unsigned int n_stages() const\n {\n return bi.size();\n    }\n \n template <typename VectorType, typename Operator>\n void perform_time_step(const Operator &pde_operator,\n const double    current_time,\n const double    time_step,\n                           VectorType     &solution,\n                           VectorType     &vec_ri,\n                           VectorType     &vec_ki) const\n {\n AssertDimension(ai.size() + 1, bi.size());\n \n      pde_operator.perform_stage(current_time,\n                                 bi[0] * time_step,\n                                 ai[0] * time_step,\n                                 solution,\n                                 vec_ri,\n                                 solution,\n                                 vec_ri);\n \n for (unsigned int stage = 1; stage < bi.size(); ++stage)\n        {\n const double c_i = ci[stage];\n          pde_operator.perform_stage(current_time + c_i * time_step,\n                                     bi[stage] * time_step,\n                                     (stage == bi.size() - 1 ?\n                                        0 :\n                                        ai[stage] * time_step),\n                                     vec_ri,\n                                     vec_ki,\n                                     solution,\n                                     vec_ri);\n        }\n    }\n \n private:\n    std::vector<double> bi;\n    std::vector<double> ai;\n    std::vector<double> ci;\n  };\n \n \n \n \n template <int dim, typename Number>\n inline DEAL_II_ALWAYS_INLINE \n Tensor<1, dim, Number>\n    euler_velocity(const Tensor<1, dim + 2, Number> &conserved_variables)\n  {\n const Number inverse_density = Number(1.) / conserved_variables[0];\n \n Tensor<1, dim, Number> velocity;\n for (unsigned int d = 0; d < dim; ++d)\n      velocity[d] = conserved_variables[1 + d] * inverse_density;\n \n return velocity;\n  }\n \n template <int dim, typename Number>\n inline DEAL_II_ALWAYS_INLINE \n    Number\n    euler_pressure(const Tensor<1, dim + 2, Number> &conserved_variables)\n  {\n const Tensor<1, dim, Number> velocity =\n      euler_velocity<dim>(conserved_variables);\n \n    Number rho_u_dot_u = conserved_variables[1] * velocity[0];\n for (unsigned int d = 1; d < dim; ++d)\n      rho_u_dot_u += conserved_variables[1 + d] * velocity[d];\n \n return (gamma - 1.) * (conserved_variables[dim + 1] - 0.5 * rho_u_dot_u);\n  }\n \n template <int dim, typename Number>\n inline DEAL_II_ALWAYS_INLINE \n Tensor<1, dim + 2, Tensor<1, dim, Number>>\n    euler_flux(const Tensor<1, dim + 2, Number> &conserved_variables)\n  {\n const Tensor<1, dim, Number> velocity =\n      euler_velocity<dim>(conserved_variables);\n const Number pressure = euler_pressure<dim>(conserved_variables);\n \n Tensor<1, dim + 2, Tensor<1, dim, Number>> flux;\n for (unsigned int d = 0; d < dim; ++d)\n      {\n        flux[0][d] = conserved_variables[1 + d];\n for (unsigned int e = 0; e < dim; ++e)\n          flux[e + 1][d] = conserved_variables[e + 1] * velocity[d];\n        flux[d + 1][d] += pressure;\n        flux[dim + 1][d] =\n          velocity[d] * (conserved_variables[dim + 1] + pressure);\n      }\n \n return flux;\n  }\n \n template <int n_components, int dim, typename Number>\n inline DEAL_II_ALWAYS_INLINE \n Tensor<1, n_components, Number>\n operator*(const Tensor<1, n_components, Tensor<1, dim, Number>> &matrix,\n const Tensor<1, dim, Number>                          &vector)\n  {\n Tensor<1, n_components, Number> result;\n for (unsigned int d = 0; d < n_components; ++d)\n      result[d] = matrix[d] * vector;\n return result;\n  }\n \n template <int dim, typename Number>\n inline DEAL_II_ALWAYS_INLINE \n Tensor<1, dim + 2, Number>\n    euler_numerical_flux(const Tensor<1, dim + 2, Number> &u_m,\n const Tensor<1, dim + 2, Number> &u_p,\n const Tensor<1, dim, Number>     &normal)\n  {\n const auto velocity_m = euler_velocity<dim>(u_m);\n const auto velocity_p = euler_velocity<dim>(u_p);\n \n const auto pressure_m = euler_pressure<dim>(u_m);\n const auto pressure_p = euler_pressure<dim>(u_p);\n \n const auto flux_m = euler_flux<dim>(u_m);\n const auto flux_p = euler_flux<dim>(u_p);\n \n switch (numerical_flux_type)\n      {\n case lax_friedrichs_modified:\n          {\n const auto lambda =\n              0.5 * std::sqrt(std::max(velocity_p.norm_square() +\n                                         gamma * pressure_p * (1. / u_p[0]),\n                                       velocity_m.norm_square() +\n                                         gamma * pressure_m * (1. / u_m[0])));\n \n return 0.5 * (flux_m * normal + flux_p * normal) +\n                   0.5 * lambda * (u_m - u_p);\n          }\n \n case harten_lax_vanleer:\n          {\n const auto avg_velocity_normal =\n              0.5 * ((velocity_m + velocity_p) * normal);\n const auto   avg_c = std::sqrt(std::abs(\n              0.5 * gamma *\n              (pressure_p * (1. / u_p[0]) + pressure_m * (1. / u_m[0]))));\n const Number s_pos =\n std::max(Number(), avg_velocity_normal + avg_c);\n const Number s_neg =\n std::min(Number(), avg_velocity_normal - avg_c);\n const Number inverse_s = Number(1.) / (s_pos - s_neg);\n \n return inverse_s *\n                   ((s_pos * (flux_m * normal) - s_neg * (flux_p * normal)) -\n                    s_pos * s_neg * (u_m - u_p));\n          }\n \n default:\n          {\n DEAL_II_NOT_IMPLEMENTED();\n return {};\n          }\n      }\n  }\n \n \n \n template <int dim, typename Number>\n VectorizedArray<Number>\n  evaluate_function(const Function<dim>                       &function,\n const Point<dim, VectorizedArray<Number>> &p_vectorized,\n const unsigned int                         component)\n  {\n VectorizedArray<Number> result;\n for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n      {\n Point<dim> p;\n for (unsigned int d = 0; d < dim; ++d)\n          p[d] = p_vectorized[d][v];\n        result[v] = function.value(p, component);\n      }\n return result;\n  }\n \n \n template <int dim, typename Number, int n_components = dim + 2>\n Tensor<1, n_components, VectorizedArray<Number>>\n  evaluate_function(const Function<dim>                       &function,\n const Point<dim, VectorizedArray<Number>> &p_vectorized)\n  {\n AssertDimension(function.n_components, n_components);\n Tensor<1, n_components, VectorizedArray<Number>> result;\n for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n      {\n Point<dim> p;\n for (unsigned int d = 0; d < dim; ++d)\n          p[d] = p_vectorized[d][v];\n for (unsigned int d = 0; d < n_components; ++d)\n          result[d][v] = function.value(p, d);\n      }\n return result;\n  }\n \n \n \n \n template <int dim, int degree, int n_points_1d>\n class EulerOperator\n  {\n public:\n static constexpr unsigned int n_quadrature_points_1d = n_points_1d;\n \n    EulerOperator(TimerOutput &timer_output);\n \n void reinit(const Mapping<dim>    &mapping,\n const DoFHandler<dim> &dof_handler);\n \n void set_inflow_boundary(const types::boundary_id       boundary_id,\n                             std::unique_ptr<Function<dim>> inflow_function);\n \n void set_subsonic_outflow_boundary(\n const types::boundary_id       boundary_id,\n      std::unique_ptr<Function<dim>> outflow_energy);\n \n void set_wall_boundary(const types::boundary_id boundary_id);\n \n void set_body_force(std::unique_ptr<Function<dim>> body_force);\n \n void apply(const double                                      current_time,\n const LinearAlgebra::distributed::Vector<Number> &src,\n LinearAlgebra::distributed::Vector<Number>       &dst) const;\n \n void\n    perform_stage(const Number cur_time,\n const Number factor_solution,\n const Number factor_ai,\n const LinearAlgebra::distributed::Vector<Number> &current_ri,\n LinearAlgebra::distributed::Vector<Number>       &vec_ki,\n LinearAlgebra::distributed::Vector<Number>       &solution,\n LinearAlgebra::distributed::Vector<Number> &next_ri) const;\n \n void project(const Function<dim>                        &function,\n LinearAlgebra::distributed::Vector<Number> &solution) const;\n \n    std::array<double, 3> compute_errors(\n const Function<dim>                              &function,\n const LinearAlgebra::distributed::Vector<Number> &solution) const;\n \n double compute_cell_transport_speed(\n const LinearAlgebra::distributed::Vector<Number> &solution) const;\n \n void\n    initialize_vector(LinearAlgebra::distributed::Vector<Number> &vector) const;\n \n private:\n MatrixFree<dim, Number> data;\n \n TimerOutput &timer;\n \n    std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\n      inflow_boundaries;\n    std::map<types::boundary_id, std::unique_ptr<Function<dim>>>\n                                   subsonic_outflow_boundaries;\n    std::set<types::boundary_id>   wall_boundaries;\n    std::unique_ptr<Function<dim>> body_force;\n \n void local_apply_inverse_mass_matrix(\n const MatrixFree<dim, Number>                    &data,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const;\n \n void local_apply_cell(\n const MatrixFree<dim, Number>                    &data,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const;\n \n void local_apply_face(\n const MatrixFree<dim, Number>                    &data,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &face_range) const;\n \n void local_apply_boundary_face(\n const MatrixFree<dim, Number>                    &data,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &face_range) const;\n  };\n \n \n \n template <int dim, int degree, int n_points_1d>\n  EulerOperator<dim, degree, n_points_1d>::EulerOperator(TimerOutput &timer)\n    : timer(timer)\n  {}\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::reinit(\n const Mapping<dim>    &mapping,\n const DoFHandler<dim> &dof_handler)\n  {\n const std::vector<const DoFHandler<dim> *> dof_handlers = {&dof_handler};\n const AffineConstraints<double>            dummy;\n const std::vector<const AffineConstraints<double> *> constraints = {&dummy};\n const std::vector<Quadrature<1>> quadratures = {QGauss<1>(n_q_points_1d),\n QGauss<1>(fe_degree + 1)};\n \n typename MatrixFree<dim, Number>::AdditionalData additional_data;\n    additional_data.mapping_update_flags =\n      (update_gradients | update_JxW_values | update_quadrature_points |\n update_values);\n    additional_data.mapping_update_flags_inner_faces =\n      (update_JxW_values | update_quadrature_points | update_normal_vectors |\n update_values);\n    additional_data.mapping_update_flags_boundary_faces =\n      (update_JxW_values | update_quadrature_points | update_normal_vectors |\n update_values);\n    additional_data.tasks_parallel_scheme =\n MatrixFree<dim, Number>::AdditionalData::none;\n \n    data.reinit(\n      mapping, dof_handlers, constraints, quadratures, additional_data);\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::initialize_vector(\n LinearAlgebra::distributed::Vector<Number> &vector) const\n {\n    data.initialize_dof_vector(vector);\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::set_inflow_boundary(\n const types::boundary_id       boundary_id,\n    std::unique_ptr<Function<dim>> inflow_function)\n  {\n AssertThrow(subsonic_outflow_boundaries.find(boundary_id) ==\n                    subsonic_outflow_boundaries.end() &&\n                  wall_boundaries.find(boundary_id) == wall_boundaries.end(),\n                ExcMessage(\"You already set the boundary with id \" +\n                           std::to_string(static_cast<int>(boundary_id)) +\n \" to another type of boundary before now setting \" +\n \"it as inflow\"));\n AssertThrow(inflow_function->n_components == dim + 2,\n                ExcMessage(\"Expected function with dim+2 components\"));\n \n    inflow_boundaries[boundary_id] = std::move(inflow_function);\n  }\n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::set_subsonic_outflow_boundary(\n const types::boundary_id       boundary_id,\n    std::unique_ptr<Function<dim>> outflow_function)\n  {\n AssertThrow(inflow_boundaries.find(boundary_id) ==\n                    inflow_boundaries.end() &&\n                  wall_boundaries.find(boundary_id) == wall_boundaries.end(),\n                ExcMessage(\"You already set the boundary with id \" +\n                           std::to_string(static_cast<int>(boundary_id)) +\n \" to another type of boundary before now setting \" +\n \"it as subsonic outflow\"));\n AssertThrow(outflow_function->n_components == dim + 2,\n                ExcMessage(\"Expected function with dim+2 components\"));\n \n    subsonic_outflow_boundaries[boundary_id] = std::move(outflow_function);\n  }\n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::set_wall_boundary(\n const types::boundary_id boundary_id)\n  {\n AssertThrow(inflow_boundaries.find(boundary_id) ==\n                    inflow_boundaries.end() &&\n                  subsonic_outflow_boundaries.find(boundary_id) ==\n                    subsonic_outflow_boundaries.end(),\n                ExcMessage(\"You already set the boundary with id \" +\n                           std::to_string(static_cast<int>(boundary_id)) +\n \" to another type of boundary before now setting \" +\n \"it as wall boundary\"));\n \n    wall_boundaries.insert(boundary_id);\n  }\n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::set_body_force(\n    std::unique_ptr<Function<dim>> body_force)\n  {\n AssertDimension(body_force->n_components, dim);\n \n    this->body_force = std::move(body_force);\n  }\n \n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::local_apply_cell(\n const MatrixFree<dim, Number> &,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const\n {\n FEEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data);\n \n Tensor<1, dim, VectorizedArray<Number>> constant_body_force;\n const Functions::ConstantFunction<dim> *constant_function =\n dynamic_cast<Functions::ConstantFunction<dim> *>(body_force.get());\n \n if (constant_function)\n      constant_body_force = evaluate_function<dim, Number, dim>(\n        *constant_function, Point<dim, VectorizedArray<Number>>());\n \n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n      {\n        phi.reinit(cell);\n        phi.gather_evaluate(src, EvaluationFlags::values);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n const auto w_q = phi.get_value(q);\n            phi.submit_gradient(euler_flux<dim>(w_q), q);\n if (body_force.get() != nullptr)\n              {\n const Tensor<1, dim, VectorizedArray<Number>> force =\n                  constant_function ? constant_body_force :\n                                      evaluate_function<dim, Number, dim>(\n                                        *body_force, phi.quadrature_point(q));\n \n Tensor<1, dim + 2, VectorizedArray<Number>> forcing;\n for (unsigned int d = 0; d < dim; ++d)\n                  forcing[d + 1] = w_q[0] * force[d];\n for (unsigned int d = 0; d < dim; ++d)\n                  forcing[dim + 1] += force[d] * w_q[d + 1];\n \n                phi.submit_value(forcing, q);\n              }\n          }\n \n        phi.integrate_scatter(((body_force.get() != nullptr) ?\n EvaluationFlags::values :\n EvaluationFlags::nothing) |\n EvaluationFlags::gradients,\n                              dst);\n      }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::local_apply_face(\n const MatrixFree<dim, Number> &,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &face_range) const\n {\n FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi_m(data,\n true);\n FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi_p(data,\n false);\n \n for (unsigned int face = face_range.first; face < face_range.second; ++face)\n      {\n        phi_p.reinit(face);\n        phi_p.gather_evaluate(src, EvaluationFlags::values);\n \n        phi_m.reinit(face);\n        phi_m.gather_evaluate(src, EvaluationFlags::values);\n \n for (const unsigned int q : phi_m.quadrature_point_indices())\n          {\n const auto numerical_flux =\n              euler_numerical_flux<dim>(phi_m.get_value(q),\n                                        phi_p.get_value(q),\n                                        phi_m.normal_vector(q));\n            phi_m.submit_value(-numerical_flux, q);\n            phi_p.submit_value(numerical_flux, q);\n          }\n \n        phi_p.integrate_scatter(EvaluationFlags::values, dst);\n        phi_m.integrate_scatter(EvaluationFlags::values, dst);\n      }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::local_apply_boundary_face(\n const MatrixFree<dim, Number> &,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &face_range) const\n {\n FEFaceEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data, true);\n \n for (unsigned int face = face_range.first; face < face_range.second; ++face)\n      {\n        phi.reinit(face);\n        phi.gather_evaluate(src, EvaluationFlags::values);\n \n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n const auto w_m    = phi.get_value(q);\n const auto normal = phi.normal_vector(q);\n \n auto rho_u_dot_n = w_m[1] * normal[0];\n for (unsigned int d = 1; d < dim; ++d)\n              rho_u_dot_n += w_m[1 + d] * normal[d];\n \n bool at_outflow = false;\n \n Tensor<1, dim + 2, VectorizedArray<Number>> w_p;\n const auto boundary_id = data.get_boundary_id(face);\n if (wall_boundaries.find(boundary_id) != wall_boundaries.end())\n              {\n                w_p[0] = w_m[0];\n for (unsigned int d = 0; d < dim; ++d)\n                  w_p[d + 1] = w_m[d + 1] - 2. * rho_u_dot_n * normal[d];\n                w_p[dim + 1] = w_m[dim + 1];\n              }\n else if (inflow_boundaries.find(boundary_id) !=\n                     inflow_boundaries.end())\n              w_p =\n                evaluate_function(*inflow_boundaries.find(boundary_id)->second,\n                                  phi.quadrature_point(q));\n else if (subsonic_outflow_boundaries.find(boundary_id) !=\n                     subsonic_outflow_boundaries.end())\n              {\n                w_p          = w_m;\n                w_p[dim + 1] = evaluate_function(\n                  *subsonic_outflow_boundaries.find(boundary_id)->second,\n                  phi.quadrature_point(q),\n                  dim + 1);\n                at_outflow = true;\n              }\n else\n AssertThrow(false,\n                          ExcMessage(\"Unknown boundary id, did \"\n \"you set a boundary condition for \"\n \"this part of the domain boundary?\"));\n \n auto flux = euler_numerical_flux<dim>(w_m, w_p, normal);\n \n if (at_outflow)\n for (unsigned int v = 0; v < VectorizedArray<Number>::size(); ++v)\n                {\n if (rho_u_dot_n[v] < -1e-12)\n for (unsigned int d = 0; d < dim; ++d)\n                      flux[d + 1][v] = 0.;\n                }\n \n            phi.submit_value(-flux, q);\n          }\n \n        phi.integrate_scatter(EvaluationFlags::values, dst);\n      }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::local_apply_inverse_mass_matrix(\n const MatrixFree<dim, Number> &,\n LinearAlgebra::distributed::Vector<Number>       &dst,\n const LinearAlgebra::distributed::Vector<Number> &src,\n const std::pair<unsigned int, unsigned int>      &cell_range) const\n {\n FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n MatrixFreeOperators::CellwiseInverseMassMatrix<dim, degree, dim + 2, Number>\n      inverse(phi);\n \n for (unsigned int cell = cell_range.first; cell < cell_range.second; ++cell)\n      {\n        phi.reinit(cell);\n        phi.read_dof_values(src);\n \n        inverse.apply(phi.begin_dof_values(), phi.begin_dof_values());\n \n        phi.set_dof_values(dst);\n      }\n  }\n \n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::apply(\n const double                                      current_time,\n const LinearAlgebra::distributed::Vector<Number> &src,\n LinearAlgebra::distributed::Vector<Number>       &dst) const\n {\n    {\n TimerOutput::Scope t(timer, \"apply - integrals\");\n \n for (auto &i : inflow_boundaries)\n        i.second->set_time(current_time);\n for (auto &i : subsonic_outflow_boundaries)\n        i.second->set_time(current_time);\n \n      data.loop(&EulerOperator::local_apply_cell,\n                &EulerOperator::local_apply_face,\n                &EulerOperator::local_apply_boundary_face,\n this,\n                dst,\n                src,\n true,\n MatrixFree<dim, Number>::DataAccessOnFaces::values,\n MatrixFree<dim, Number>::DataAccessOnFaces::values);\n    }\n \n    {\n TimerOutput::Scope t(timer, \"apply - inverse mass\");\n \n      data.cell_loop(&EulerOperator::local_apply_inverse_mass_matrix,\n this,\n                     dst,\n                     dst);\n    }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::perform_stage(\n const Number                                      current_time,\n const Number                                      factor_solution,\n const Number                                      factor_ai,\n const LinearAlgebra::distributed::Vector<Number> &current_ri,\n LinearAlgebra::distributed::Vector<Number>       &vec_ki,\n LinearAlgebra::distributed::Vector<Number>       &solution,\n LinearAlgebra::distributed::Vector<Number>       &next_ri) const\n {\n    {\n TimerOutput::Scope t(timer, \"rk_stage - integrals L_h\");\n \n for (auto &i : inflow_boundaries)\n        i.second->set_time(current_time);\n for (auto &i : subsonic_outflow_boundaries)\n        i.second->set_time(current_time);\n \n      data.loop(&EulerOperator::local_apply_cell,\n                &EulerOperator::local_apply_face,\n                &EulerOperator::local_apply_boundary_face,\n this,\n                vec_ki,\n                current_ri,\n true,\n MatrixFree<dim, Number>::DataAccessOnFaces::values,\n MatrixFree<dim, Number>::DataAccessOnFaces::values);\n    }\n \n \n    {\n TimerOutput::Scope t(timer, \"rk_stage - inv mass + vec upd\");\n      data.cell_loop(\n        &EulerOperator::local_apply_inverse_mass_matrix,\n this,\n        next_ri,\n        vec_ki,\n        std::function<void(const unsigned int, const unsigned int)>(),\n        [&](const unsigned int start_range, const unsigned int end_range) {\n const Number ai = factor_ai;\n const Number bi = factor_solution;\n if (ai == Number())\n            {\n /* DEAL_II_OPENMP_SIMD_PRAGMA */\n for (unsigned int i = start_range; i < end_range; ++i)\n                {\n const Number k_i          = next_ri.local_element(i);\n const Number sol_i        = solution.local_element(i);\n                  solution.local_element(i) = sol_i + bi * k_i;\n                }\n            }\n else\n            {\n /* DEAL_II_OPENMP_SIMD_PRAGMA */\n for (unsigned int i = start_range; i < end_range; ++i)\n                {\n const Number k_i          = next_ri.local_element(i);\n const Number sol_i        = solution.local_element(i);\n                  solution.local_element(i) = sol_i + bi * k_i;\n                  next_ri.local_element(i)  = sol_i + ai * k_i;\n                }\n            }\n        });\n    }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n void EulerOperator<dim, degree, n_points_1d>::project(\n const Function<dim>                        &function,\n LinearAlgebra::distributed::Vector<Number> &solution) const\n {\n FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n MatrixFreeOperators::CellwiseInverseMassMatrix<dim, degree, dim + 2, Number>\n      inverse(phi);\n    solution.zero_out_ghost_values();\n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n      {\n        phi.reinit(cell);\n for (const unsigned int q : phi.quadrature_point_indices())\n          phi.submit_dof_value(evaluate_function(function,\n                                                 phi.quadrature_point(q)),\n                               q);\n        inverse.transform_from_q_points_to_basis(dim + 2,\n                                                 phi.begin_dof_values(),\n                                                 phi.begin_dof_values());\n        phi.set_dof_values(solution);\n      }\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n  std::array<double, 3> EulerOperator<dim, degree, n_points_1d>::compute_errors(\n const Function<dim>                              &function,\n const LinearAlgebra::distributed::Vector<Number> &solution) const\n {\n TimerOutput::Scope t(timer, \"compute errors\");\n double             errors_squared[3] = {};\n FEEvaluation<dim, degree, n_points_1d, dim + 2, Number> phi(data, 0, 0);\n \n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n      {\n        phi.reinit(cell);\n        phi.gather_evaluate(solution, EvaluationFlags::values);\n VectorizedArray<Number> local_errors_squared[3] = {};\n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n const auto error =\n              evaluate_function(function, phi.quadrature_point(q)) -\n              phi.get_value(q);\n const auto JxW = phi.JxW(q);\n \n            local_errors_squared[0] += error[0] * error[0] * JxW;\n for (unsigned int d = 0; d < dim; ++d)\n              local_errors_squared[1] += (error[d + 1] * error[d + 1]) * JxW;\n            local_errors_squared[2] += (error[dim + 1] * error[dim + 1]) * JxW;\n          }\n for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\n             ++v)\n for (unsigned int d = 0; d < 3; ++d)\n            errors_squared[d] += local_errors_squared[d][v];\n      }\n \n Utilities::MPI::sum(errors_squared, MPI_COMM_WORLD, errors_squared);\n \n    std::array<double, 3> errors;\n for (unsigned int d = 0; d < 3; ++d)\n      errors[d] = std::sqrt(errors_squared[d]);\n \n return errors;\n  }\n \n \n \n template <int dim, int degree, int n_points_1d>\n double EulerOperator<dim, degree, n_points_1d>::compute_cell_transport_speed(\n const LinearAlgebra::distributed::Vector<Number> &solution) const\n {\n TimerOutput::Scope t(timer, \"compute transport speed\");\n    Number             max_transport = 0;\n FEEvaluation<dim, degree, degree + 1, dim + 2, Number> phi(data, 0, 1);\n \n for (unsigned int cell = 0; cell < data.n_cell_batches(); ++cell)\n      {\n        phi.reinit(cell);\n        phi.gather_evaluate(solution, EvaluationFlags::values);\n VectorizedArray<Number> local_max = 0.;\n for (const unsigned int q : phi.quadrature_point_indices())\n          {\n const auto solution = phi.get_value(q);\n const auto velocity = euler_velocity<dim>(solution);\n const auto pressure = euler_pressure<dim>(solution);\n \n const auto inverse_jacobian = phi.inverse_jacobian(q);\n const auto convective_speed = inverse_jacobian * velocity;\n VectorizedArray<Number> convective_limit = 0.;\n for (unsigned int d = 0; d < dim; ++d)\n              convective_limit =\n std::max(convective_limit, std::abs(convective_speed[d]));\n \n const auto speed_of_sound =\n std::sqrt(gamma * pressure * (1. / solution[0]));\n \n Tensor<1, dim, VectorizedArray<Number>> eigenvector;\n for (unsigned int d = 0; d < dim; ++d)\n              eigenvector[d] = 1.;\n for (unsigned int i = 0; i < 5; ++i)\n              {\n                eigenvector = transpose(inverse_jacobian) *\n                              (inverse_jacobian * eigenvector);\n VectorizedArray<Number> eigenvector_norm = 0.;\n for (unsigned int d = 0; d < dim; ++d)\n                  eigenvector_norm =\n std::max(eigenvector_norm, std::abs(eigenvector[d]));\n                eigenvector /= eigenvector_norm;\n              }\n const auto jac_times_ev   = inverse_jacobian * eigenvector;\n const auto max_eigenvalue = std::sqrt(\n              (jac_times_ev * jac_times_ev) / (eigenvector * eigenvector));\n            local_max =\n std::max(local_max,\n                       max_eigenvalue * speed_of_sound + convective_limit);\n          }\n \n for (unsigned int v = 0; v < data.n_active_entries_per_cell_batch(cell);\n             ++v)\n          max_transport = std::max(max_transport, local_max[v]);\n      }\n \n    max_transport = Utilities::MPI::max(max_transport, MPI_COMM_WORLD);\n \n return max_transport;\n  }\n \n \n \n \n template <int dim>\n class EulerProblem\n  {\n public:\n    EulerProblem();\n \n void run();\n \n private:\n void make_grid_and_dofs();\n \n void output_results(const unsigned int result_number);\n \n LinearAlgebra::distributed::Vector<Number> solution;\n \n ConditionalOStream pcout;\n \n#ifdef DEAL_II_WITH_P4EST\n parallel::distributed::Triangulation<dim> triangulation;\n#else\n Triangulation<dim> triangulation;\n#endif\n \n const FESystem<dim> fe;\n MappingQ<dim>       mapping;\n DoFHandler<dim>     dof_handler;\n \n TimerOutput timer;\n \n    EulerOperator<dim, fe_degree, n_q_points_1d> euler_operator;\n \n double time, time_step;\n \n class Postprocessor : public DataPostprocessor<dim>\n    {\n public:\n      Postprocessor();\n \n virtual void evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n        std::vector<Vector<double>> &computed_quantities) const override;\n \n virtual std::vector<std::string> get_names() const override;\n \n virtual std::vector<\n DataComponentInterpretation::DataComponentInterpretation>\n      get_data_component_interpretation() const override;\n \n virtual UpdateFlags get_needed_update_flags() const override;\n \n private:\n const bool do_schlieren_plot;\n    };\n  };\n \n \n \n template <int dim>\n  EulerProblem<dim>::Postprocessor::Postprocessor()\n    : do_schlieren_plot(dim == 2)\n  {}\n \n \n \n template <int dim>\n void EulerProblem<dim>::Postprocessor::evaluate_vector_field(\n const DataPostprocessorInputs::Vector<dim> &inputs,\n    std::vector<Vector<double>>                &computed_quantities) const\n {\n const unsigned int n_evaluation_points = inputs.solution_values.size();\n \n if (do_schlieren_plot == true)\n Assert(inputs.solution_gradients.size() == n_evaluation_points,\n             ExcInternalError());\n \n Assert(computed_quantities.size() == n_evaluation_points,\n           ExcInternalError());\n Assert(inputs.solution_values[0].size() == dim + 2, ExcInternalError());\n Assert(computed_quantities[0].size() ==\n             dim + 2 + (do_schlieren_plot == true ? 1 : 0),\n           ExcInternalError());\n \n for (unsigned int p = 0; p < n_evaluation_points; ++p)\n      {\n Tensor<1, dim + 2> solution;\n for (unsigned int d = 0; d < dim + 2; ++d)\n          solution[d] = inputs.solution_values[p](d);\n \n const double         density  = solution[0];\n const Tensor<1, dim> velocity = euler_velocity<dim>(solution);\n const double         pressure = euler_pressure<dim>(solution);\n \n for (unsigned int d = 0; d < dim; ++d)\n          computed_quantities[p](d) = velocity[d];\n        computed_quantities[p](dim)     = pressure;\n        computed_quantities[p](dim + 1) = std::sqrt(gamma * pressure / density);\n \n if (do_schlieren_plot == true)\n          computed_quantities[p](dim + 2) =\n            inputs.solution_gradients[p][0] * inputs.solution_gradients[p][0];\n      }\n  }\n \n \n \n template <int dim>\n  std::vector<std::string> EulerProblem<dim>::Postprocessor::get_names() const\n {\n    std::vector<std::string> names;\n for (unsigned int d = 0; d < dim; ++d)\n      names.emplace_back(\"velocity\");\n    names.emplace_back(\"pressure\");\n    names.emplace_back(\"speed_of_sound\");\n \n if (do_schlieren_plot == true)\n      names.emplace_back(\"schlieren_plot\");\n \n return names;\n  }\n \n \n \n template <int dim>\n  std::vector<DataComponentInterpretation::DataComponentInterpretation>\n  EulerProblem<dim>::Postprocessor::get_data_component_interpretation() const\n {\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      interpretation;\n for (unsigned int d = 0; d < dim; ++d)\n      interpretation.push_back(\n DataComponentInterpretation::component_is_part_of_vector);\n    interpretation.push_back(DataComponentInterpretation::component_is_scalar);\n    interpretation.push_back(DataComponentInterpretation::component_is_scalar);\n \n if (do_schlieren_plot == true)\n      interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n return interpretation;\n  }\n \n \n \n template <int dim>\n UpdateFlags EulerProblem<dim>::Postprocessor::get_needed_update_flags() const\n {\n if (do_schlieren_plot == true)\n return update_values | update_gradients;\n else\n return update_values;\n  }\n \n \n \n template <int dim>\n  EulerProblem<dim>::EulerProblem()\n    : pcout(std::cout, Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n#ifdef DEAL_II_WITH_P4EST\n    , triangulation(MPI_COMM_WORLD)\n#endif\n    , fe(FE_DGQ<dim>(fe_degree) ^ (dim + 2))\n    , mapping(fe_degree)\n    , dof_handler(triangulation)\n    , timer(pcout, TimerOutput::never, TimerOutput::wall_times)\n    , euler_operator(timer)\n    , time(0)\n    , time_step(0)\n  {}\n \n \n \n template <int dim>\n void EulerProblem<dim>::make_grid_and_dofs()\n  {\n switch (testcase)\n      {\n case 0:\n          {\n Point<dim> lower_left;\n for (unsigned int d = 1; d < dim; ++d)\n              lower_left[d] = -5;\n \n Point<dim> upper_right;\n            upper_right[0] = 10;\n for (unsigned int d = 1; d < dim; ++d)\n              upper_right[d] = 5;\n \n GridGenerator::hyper_rectangle(triangulation,\n                                           lower_left,\n                                           upper_right);\n triangulation.refine_global(2);\n \n            euler_operator.set_inflow_boundary(\n              0, std::make_unique<ExactSolution<dim>>(0));\n \n break;\n          }\n \n case 1:\n          {\n GridGenerator::channel_with_cylinder(\n triangulation, 0.03, 1, 0, true);\n \n            euler_operator.set_inflow_boundary(\n              0, std::make_unique<ExactSolution<dim>>(0));\n            euler_operator.set_subsonic_outflow_boundary(\n              1, std::make_unique<ExactSolution<dim>>(0));\n \n            euler_operator.set_wall_boundary(2);\n            euler_operator.set_wall_boundary(3);\n \n if (dim == 3)\n              euler_operator.set_body_force(\n                std::make_unique<Functions::ConstantFunction<dim>>(\n                  std::vector<double>({0., 0., -0.2})));\n \n break;\n          }\n \n default:\n DEAL_II_NOT_IMPLEMENTED();\n      }\n \n triangulation.refine_global(n_global_refinements);\n \n    dof_handler.distribute_dofs(fe);\n \n    euler_operator.reinit(mapping, dof_handler);\n    euler_operator.initialize_vector(solution);\n \n    std::locale s = pcout.get_stream().getloc();\n    pcout.get_stream().imbue(std::locale(\"\"));\n    pcout << \"Number of degrees of freedom: \" << dof_handler.n_dofs()\n          << \" ( = \" << (dim + 2) << \" [vars] x \"\n          << triangulation.n_global_active_cells() << \" [cells] x \"\n          << Utilities::pow(fe_degree + 1, dim) << \" [dofs/cell/var] )\"\n          << std::endl;\n    pcout.get_stream().imbue(s);\n  }\n \n \n \n template <int dim>\n void EulerProblem<dim>::output_results(const unsigned int result_number)\n  {\n const std::array<double, 3> errors =\n      euler_operator.compute_errors(ExactSolution<dim>(time), solution);\n const std::string quantity_name = testcase == 0 ? \"error\" : \"norm\";\n \n    pcout << \"Time:\" << std::setw(8) << std::setprecision(3) << time\n          << \", dt: \" << std::setw(8) << std::setprecision(2) << time_step\n          << \", \" << quantity_name << \" rho: \" << std::setprecision(4)\n          << std::setw(10) << errors[0] << \", rho * u: \" << std::setprecision(4)\n          << std::setw(10) << errors[1] << \", energy:\" << std::setprecision(4)\n          << std::setw(10) << errors[2] << std::endl;\n \n    {\n TimerOutput::Scope t(timer, \"output\");\n \n      Postprocessor postprocessor;\n DataOut<dim>  data_out;\n \n DataOutBase::VtkFlags flags;\n      flags.write_higher_order_cells = true;\n      data_out.set_flags(flags);\n \n      data_out.attach_dof_handler(dof_handler);\n      {\n        std::vector<std::string> names;\n        names.emplace_back(\"density\");\n for (unsigned int d = 0; d < dim; ++d)\n          names.emplace_back(\"momentum\");\n        names.emplace_back(\"energy\");\n \n        std::vector<DataComponentInterpretation::DataComponentInterpretation>\n          interpretation;\n        interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n for (unsigned int d = 0; d < dim; ++d)\n          interpretation.push_back(\n DataComponentInterpretation::component_is_part_of_vector);\n        interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n        data_out.add_data_vector(dof_handler, solution, names, interpretation);\n      }\n      data_out.add_data_vector(solution, postprocessor);\n \n LinearAlgebra::distributed::Vector<Number> reference;\n if (testcase == 0 && dim == 2)\n        {\n          reference.reinit(solution);\n          euler_operator.project(ExactSolution<dim>(time), reference);\n          reference.sadd(-1., 1, solution);\n          std::vector<std::string> names;\n          names.emplace_back(\"error_density\");\n for (unsigned int d = 0; d < dim; ++d)\n            names.emplace_back(\"error_momentum\");\n          names.emplace_back(\"error_energy\");\n \n          std::vector<DataComponentInterpretation::DataComponentInterpretation>\n            interpretation;\n          interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n for (unsigned int d = 0; d < dim; ++d)\n            interpretation.push_back(\n DataComponentInterpretation::component_is_part_of_vector);\n          interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n          data_out.add_data_vector(dof_handler,\n                                   reference,\n                                   names,\n                                   interpretation);\n        }\n \n Vector<double> mpi_owner(triangulation.n_active_cells());\n      mpi_owner = Utilities::MPI::this_mpi_process(MPI_COMM_WORLD);\n      data_out.add_data_vector(mpi_owner, \"owner\");\n \n      data_out.build_patches(mapping,\n                             fe.degree,\n DataOut<dim>::curved_inner_cells);\n \n const std::string filename =\n \"solution_\" + Utilities::int_to_string(result_number, 3) + \".vtu\";\n      data_out.write_vtu_in_parallel(filename, MPI_COMM_WORLD);\n    }\n  }\n \n \n \n template <int dim>\n void EulerProblem<dim>::run()\n  {\n    {\n const unsigned int n_vect_number = VectorizedArray<Number>::size();\n const unsigned int n_vect_bits   = 8 * sizeof(Number) * n_vect_number;\n \n      pcout << \"Running with \"\n            << Utilities::MPI::n_mpi_processes(MPI_COMM_WORLD)\n            << \" MPI processes\" << std::endl;\n      pcout << \"Vectorization over \" << n_vect_number << ' '\n            << (std::is_same_v<Number, double> ? \"doubles\" : \"floats\") << \" = \"\n            << n_vect_bits << \" bits (\"\n            << Utilities::System::get_current_vectorization_level() << ')'\n            << std::endl;\n    }\n \n    make_grid_and_dofs();\n \n const LowStorageRungeKuttaIntegrator integrator(lsrk_scheme);\n \n LinearAlgebra::distributed::Vector<Number> rk_register_1;\n LinearAlgebra::distributed::Vector<Number> rk_register_2;\n    rk_register_1.reinit(solution);\n    rk_register_2.reinit(solution);\n \n    euler_operator.project(ExactSolution<dim>(time), solution);\n \n double min_vertex_distance = std::numeric_limits<double>::max();\n for (const auto &cell : triangulation.active_cell_iterators())\n      if (cell->is_locally_owned())\n        min_vertex_distance =\n std::min(min_vertex_distance, cell->minimum_vertex_distance());\n    min_vertex_distance =\n Utilities::MPI::min(min_vertex_distance, MPI_COMM_WORLD);\n \n    time_step = courant_number * integrator.n_stages() /\n                euler_operator.compute_cell_transport_speed(solution);\n    pcout << \"Time step size: \" << time_step\n          << \", minimal h: \" << min_vertex_distance\n          << \", initial transport scaling: \"\n          << 1. / euler_operator.compute_cell_transport_speed(solution)\n          << std::endl\n          << std::endl;\n \n    output_results(0);\n \n unsigned int timestep_number = 0;\n \n while (time < final_time - 1e-12)\n      {\n        ++timestep_number;\n if (timestep_number % 5 == 0)\n          time_step =\n            courant_number * integrator.n_stages() /\n Utilities::truncate_to_n_digits(\n              euler_operator.compute_cell_transport_speed(solution), 3);\n \n        {\n TimerOutput::Scope t(timer, \"rk time stepping total\");\n          integrator.perform_time_step(euler_operator,\n                                       time,\n                                       time_step,\n                                       solution,\n                                       rk_register_1,\n                                       rk_register_2);\n        }\n \n        time += time_step;\n \n if (static_cast<int>(time / output_tick) !=\n static_cast<int>((time - time_step) / output_tick) ||\n            time >= final_time - 1e-12)\n          output_results(\n static_cast<unsigned int>(std::round(time / output_tick)));\n      }\n \n    timer.print_wall_time_statistics(MPI_COMM_WORLD);\n    pcout << std::endl;\n  }\n \n} // namespace Euler_DG\n \n \n \nint main(int argc, char **argv)\n{\n using namespace Euler_DG;\n using namespace dealii;\n \n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n \n try\n    {\n      EulerProblem<dimension> euler_problem;\n      euler_problem.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_68.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nSimulation of the motion of massless tracer particles in a vortical flow. Parallel simulation of the advection of particles with load balancing.\nTutorial content :\nThis tutorial depends on [step-19](step_19.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_68-Intro)    * [Simulation of the motion of massless tracer particles in a vortical flow](#step_68-Simulationofthemotionofmasslesstracerparticlesinavorticalflow)* [Particles in deal.II](#step_68-ParticlesindealII)* [Challenges related to distributed particle simulations](#step_68-Challengesrelatedtodistributedparticlesimulations)          + [Parallel particle generation](#step_68-Parallelparticlegeneration)+ [Particle exchange](#step_68-Particleexchange)+ [Balancing mesh and particle load](#step_68-Balancingmeshandparticleload)* [The testcase](#step_68-Thetestcase)- [The commented program](#step_68-CommProg)      * [Include files](#step_68-Includefiles)* [Run-time parameter handling](#step_68-Runtimeparameterhandling)* [The `ParticleTracking` class declaration](#step_68-ThecodeParticleTrackingcodeclassdeclaration)* [The `PatricleTracking` class implementation](#step_68-ThecodePatricleTrackingcodeclassimplementation)              + [Constructor](#step_68-Constructor)+ [Cell weight](#step_68-Cellweight)+ [Particles generation](#step_68-Particlesgeneration)+ [Background DOFs and interpolation](#step_68-BackgroundDOFsandinterpolation)+ [Time integration of the trajectories](#step_68-Timeintegrationofthetrajectories)+ [Data output](#step_68-Dataoutput)+ [Running the simulation](#step_68-Runningthesimulation)* [The main() function](#step_68-Themainfunction) | 1. [Results](#step_68-Results)    * [Motion of the particles](#step_68-Motionoftheparticles) * [Dynamic load balancing](#step_68-Dynamicloadbalancing) * [Possibilities for extensions](#step_68-Possibilitiesforextensions)- [The plain program](#step_68-PlainProg) |\n\n*This program was contributed by Bruno Blais (Polytechnique MontrÃ©al), Toni El Geitani Nehme (Polytechnique MontrÃ©al), Rene GassmÃ¶ller (University of California Davis), and Peter Munch (Technical University of Munich and Helmholtz-Zentrum Geesthacht). Bruno Blais was supported by NSERC Discovery grant RGPIN-2020-04510, by Compute Canada and Calcul QuÃ©bec.*\n\nIntroduction\n============\n\n### Simulation of the motion of massless tracer particles in a vortical flow\n\n[Particles](namespaceParticles.html) play an important part in numerical models for a large number of applications. [Particles](namespaceParticles.html) are routinely used as massless tracers to visualize the dynamic of a transient flow. They can also play an intrinsic role as part of a more complex finite element model, as is the case for the Particle-In-Cell (PIC) method [[93]](citelist.html#CITEREF_GLHPW2018) or they can even be used to simulate the motion of granular matter, as in the Discrete Element Method (DEM) [[33]](citelist.html#CITEREF_Blais2019). In the case of DEM, the resulting model is not related to the finite element method anymore, but just leads to a system of ordinary differential equation which describes the motion of the particles and the dynamic of their collisions. All of these models can be built using deal.II's particle handling capabilities.\n\nIn the present step, we use particles as massless tracers to illustrate the dynamic of a vortical flow. Since the particles are massless tracers, the position of each particle \\(i\\) is described by the following ordinary differential equation (ODE):\n\n\\[\n\\frac{d \\textbf{x}\\_i}{dt} =\\textbf{u}(\\textbf{x}\\_i)\n\\]\n\nwhere \\(\\textbf{x}\\_i\\) is the position of particle \\(i\\) and \\(\\textbf{u}(\\textbf{x}\\_i)\\) the flow velocity at its position. In the present step, this ODE is solved using the explicit Euler method. The resulting scheme is:\n\n\\[\n\\textbf{x}\\_{i}^{n+1} = \\textbf{x}\\_{i}^{n} + \\Delta t \\; \\textbf{u}(\\textbf{x}\\_{i}^{n})\n\\]\n\nwhere \\(\\textbf{x}\\_{i}^{n+1}\\) and \\(\\textbf{x}\\_{i}^{n}\\) are the position of particle \\(i\\) at time \\(t+\\Delta t\\) and \\(t\\), respectively and where \\(\\Delta t\\) is the time step. In the present step, the velocity at the location of particles is obtained in two different fashions:\n\n* By evaluating the velocity function at the location of the particles;\n* By evaluating the velocity function on a background triangulation and, using a finite element support, interpolating at the position of the particle.\n\nThe first approach is not practical, since the velocity profile is generally not known analytically. The second approach, based on interpolating a solution at the position of the particles, mimics exactly what would be done in a realistic computational fluid dynamic simulation, and this follows the way we have also evaluated the finite element solution at particle locations in [step-19](step_19.html). In this step, we illustrate both strategies.\n\nWe note that much greater accuracy could be obtained by using a fourth order Runge-Kutta method or another appropriate scheme for the time integration of the motion of the particles. Implementing a more advanced time-integration scheme would be a straightforward extension of this step.\n\n### [Particles](namespaceParticles.html) in deal.II\n\nIn deal.II, [Particles::Particle](classParticles_1_1Particle.html) are very simple and flexible entities that can be used to build PIC, DEM or any type of particle-based models. [Particles](namespaceParticles.html) have a location in real space, a location in the reference space of the element in which they are located and a unique ID. In the majority of cases, simulations that include particles require a significant number of them. Thus, it becomes interesting to handle all particles through an entity which agglomerates all particles. In deal.II, this is achieved through the use of the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class.\n\nBy default, particles do not have a diameter, a mass or any other physical properties which we would generally expect of physical particles. However, through a ParticleHandler, particles have access to a [Particles::PropertyPool](classParticles_1_1PropertyPool.html). This PropertyPool is an array which can be used to store an arbitrary number of properties associated with the particles. Consequently, users can build their own particle solver and attribute the desired properties to the particles (e.g., mass, charge, diameter, temperature, etc.). In the present tutorial, this is used to store the value of the fluid velocity and the process id to which the particles belong.\n\n### Challenges related to distributed particle simulations\n\nAlthough the present step is not computationally intensive, simulations that include many particles can be computationally demanding and require parallelization. The present step showcases the distributed parallel capabilities of deal.II for particles. In general, there are three main challenges that specifically arise in parallel distributed simulations that include particles:\n\n* Generating the particles on the distributed triangulation;\n* Exchanging the particles that leave local domains between the processors;\n* Load balancing the simulation so that every processor has a similar computational load. These challenges and their solution in deal.II have been discussed in more detail in [[93]](citelist.html#CITEREF_GLHPW2018), but we will summarize them below.\n\nThere are of course also questions on simply setting up a code that uses particles. These have largely already been addressed in [step-19](step_19.html). Some more advanced techniques will also be discussed in [step-70](step_70.html).\n\n#### Parallel particle generation\n\nGenerating distributed particles in a scalable way is not straightforward since the processor to which they belong must first be identified before the cell in which they are located is found. deal.II provides numerous capabilities to generate particles through the Particles::Generator namespace. Some of these particle generators create particles only on the locally owned subdomain. For example, [Particles::Generators::regular\\_reference\\_locations()](namespaceParticles_1_1Generators.html#aa208979db87fa6cbd1563bf2cc5c4bac) creates particles at the same reference locations within each cell of the local subdomain and [Particles::Generators::probabilistic\\_locations()](namespaceParticles_1_1Generators.html#a0dc34529399792726fea6706d3b2e533) uses a globally defined probability density function to determine how many and where to generate particles locally.\n\nIn other situations, such as the present step, particles must be generated at specific locations on cells that may be owned only by a subset of the processors. In most of these situations, the insertion of the particles is done for a very limited number of time-steps and, consequently, does not constitute a large portion of the computational cost. For these occasions, deal.II provides convenient [Particles::Generators](namespaceParticles_1_1Generators.html) that can globally insert the particles even if the particle is not located in a cell owned by the parallel process on which the call to create the particle is initiated. The generators first locate on which subdomain the particles are situated, identify in which cell they are located and exchange the necessary information among the processors to ensure that the particle is generated with the right properties. Consequently, this type of particle generation can be communication intensive. The [Particles::Generators::dof\\_support\\_points](namespaceParticles_1_1Generators.html#a7da221c4d1c77276fdd0b607c2f8e933) and the [Particles::Generators::quadrature\\_points](namespaceParticles_1_1Generators.html#a5b2b3978a6847a08d7dc8b628e82aa82) generate particles using a triangulation and the points of an associated [DoFHandler](classDoFHandler.html) or quadrature respectively. The triangulation that is used to generate the particles can be the same triangulation that is used for the background mesh, in which case these functions are very similar to the [Particles::Generators::regular\\_reference\\_locations()](namespaceParticles_1_1Generators.html#aa208979db87fa6cbd1563bf2cc5c4bac) function described in the previous paragraph. However, the triangulation used to generate particles can also be different (non-matching) from the triangulation of the background grid, which is useful to generate particles in particular shapes (as in this example), or to transfer information between two different computational grids (as in [step-70](step_70.html)). Furthermore, the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class provides the [Particles::ParticleHandler::insert\\_global\\_particles()](classParticles_1_1ParticleHandler.html#a969e872fca93e8f5609b8bfea3739d04) function which enables the global insertion of particles from a vector of arbitrary points and a global vector of bounding boxes. In the present step, we use the [Particles::Generators::quadrature\\_points()](namespaceParticles_1_1Generators.html#a5b2b3978a6847a08d7dc8b628e82aa82) function on a non-matching triangulation to insert particles located at positions in the shape of a disk.\n\n#### Particle exchange\n\nAs particles move around in parallel distributed computations they may leave the locally owned subdomain and need to be transferred to their new owner processes. This situation can arise in two very different ways: First, if the previous owning process knows the new owner of the particles that were lost (for example because the particles moved from the locally owned cell of one processor into an adjacent ghost cells of a distributed triangulation) then the transfer can be handled efficiently as a point-to-point communication between each process and the new owners. This transfer happens automatically whenever particles are sorted into their new cells. Secondly, the previous owner may not know to which process the particle has moved. In this case the particle is discarded by default, as a global search for the owner can be expensive. [step-19](step_19.html) shows how such a discarded particle can still be collected, interpreted, and potentially reinserted by the user. In the present example we prevent the second case by imposing a CFL criterion on the timestep to ensure particles will at most move into the ghost layer of the local process and can therefore be send to neighboring processes automatically.\n\n#### Balancing mesh and particle load\n\nThe last challenge that arises in parallel distributed computations using particles is to balance the computational load between work that is done on the grid, for example solving the finite-element problem, and the work that is done on the particles, for example advecting the particles or computing the forces between particles or between particles and grid. By default, for example in [step-40](step_40.html), deal.II distributes the background mesh as evenly as possible between the available processes, that is it balances the number of cells on each process. However, if some cells own many more particles than other cells, or if the particles of one cell are much more computationally expensive than the particles in other cells, then this problem no longer scales efficiently (for a discussion of what we consider \"scalable\" programs, see [this glossary entry](DEALGlossary.html#GlossParallelScaling)). Thus, we have to apply a form of \"load balancing\", which means we estimate the computational load that is associated with each cell and its particles. Repartitioning the mesh then accounts for this combined computational load instead of the simplified assumption of the number of cells [[93]](citelist.html#CITEREF_GLHPW2018).\n\nIn this section we only discussed the particle-specific challenges in distributed computation. Parallel challenges that particles share with finite-element solutions (parallel output, data transfer during mesh refinement) can be addressed with the solutions found for finite-element problems already discussed in other examples.\n\n### The testcase\n\nIn the present step, we use particles as massless tracers to illustrate the dynamics of a particular vortical flow: the Rayleigh–Kothe vortex. This flow pattern is generally used as a complex test case for interface tracking methods (e.g., volume-of-fluid and level set approaches) since it leads to strong rotation and elongation of the fluid [[32]](citelist.html#CITEREF_Blais2013).\n\nThe stream function \\(\\Psi\\) of this Rayleigh-Kothe vortex is defined as:\n\n\\[\n\\Psi = \\frac{1}{\\pi} \\sin^2 (\\pi x) \\sin^2 (\\pi y) \\cos \\left( \\pi \\frac{t}{T} \\right)\n\\]\n\nwhere \\(T\\) is half the period of the flow. The velocity profile in 2D ( \\(\\textbf{u}=[u,v]^T\\)) is :\n\n\\begin{eqnarray\\*}\nu &=& - \\frac{\\partial\\Psi}{\\partial y} = -2 \\sin^2 (\\pi x) \\sin (\\pi y) \\cos (\\pi y) \\cos \\left( \\pi \\frac{t}{T} \\right)\\\\\nv &=& \\frac{\\partial\\Psi}{\\partial x} = 2 \\cos(\\pi x) \\sin(\\pi x) \\sin^2 (\\pi y) \\cos \\left( \\pi \\frac{t}{T} \\right)\n\\end{eqnarray\\*}\n\nThe velocity profile is illustrated in the following animation:\n\nIt can be seen that this velocity reverses periodically due to the term \\(\\cos \\left( \\pi \\frac{t}{T} \\right)\\) and that material will end up at its starting position after every period of length \\(t=2T\\). We will run this tutorial program for exactly one period and compare the final particle location to the initial location to illustrate this flow property. This example uses the testcase to produce two models that handle the particles slightly differently. The first model prescribes the exact analytical velocity solution as the velocity for each particle. Therefore in this model there is no error in the assigned velocity to the particles, and any deviation of particle positions from the analytical position at a given time results from the error in solving the equation of motion for the particle inexactly, using a time stepping method. In the second model the analytical velocity field is first interpolated to a finite-element vector space (to simulate the case that the velocity was obtained from solving a finite-element problem, in the same way as the ODE for each particle in [step-19](step_19.html) depends on a finite element solution). This finite-element \"solution\" is then evaluated at the locations of the particles to solve their equation of motion. The difference between the two cases allows to assess whether the chosen finite-element space is sufficiently accurate to advect the particles with the optimal convergence rate of the chosen particle advection scheme, a question that is important in practice to determine the accuracy of the combined algorithm (see e.g. [[94]](citelist.html#CITEREF_Gassmoller2019)).\n\nThe commented program\n=====================\n\n### Include files\n\n```\n   #include <deal.II/base/bounding_box.h>\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/discrete_time.h>\n   #include <deal.II/base/function_lib.h>\n   #include <deal.II/base/mpi.h>\n   #include <deal.II/base/parameter_acceptor.h>\n   #include <deal.II/base/timer.h>\n   \n   #include <deal.II/distributed/solution_transfer.h>\n   #include <deal.II/distributed/tria.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/mapping_q1.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_tools.h>\n   \n   #include <deal.II/lac/la_parallel_vector.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nFrom the following include file we import the ParticleHandler class that allows you to manage a collection of particles (objects of type [Particles::Particle](classParticles_1_1Particle.html)), representing a collection of points with some attached properties (e.g., an id) floating on a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html). The methods and classes in the namespace [Particles](namespaceParticles.html) allows one to easily implement Particle-In-Cell methods and particle tracing on distributed triangulations:\n\n```\n   #include <deal.II/particles/particle_handler.h>\n```\n\nWe import the particles generator which allow us to insert the particles. In the present step, the particle are globally inserted using a non-matching hyper-shell triangulation:\n\n```\n   #include <deal.II/particles/generators.h>\n```\n\nSince the particles do not form a triangulation, they have their own specific [DataOut](classDataOut.html) class which will enable us to write them to commonly used parallel vtu format (or any number of other file formats):\n\n```\n   #include <deal.II/particles/data_out.h>\n   \n   #include <cmath>\n   #include <iostream>\n   \n   \n   \n   namespace Step68\n   {\n     using namespace dealii;\n```\n\n### Run-time parameter handling\n\nSimilarly to what is done in [step-60](step_60.html), we set up a class that holds all the parameters of our problem and derive it from the [ParameterAcceptor](classParameterAcceptor.html) class to simplify the management and creation of parameter files.\n\nThe [ParameterAcceptor](classParameterAcceptor.html) paradigm requires all parameters to be writable by the [ParameterAcceptor](classParameterAcceptor.html) methods. In order to avoid bugs that would be very difficult to track down (such as writing things like `if (time = 0)` instead of `if(time == 0)`), we declare all the parameters in an external class, which is initialized before the actual `ParticleTracking` class, and pass it to the main class as a `const` reference.\n\nThe constructor of the class is responsible for the connection between the members of this class and the corresponding entries in the [ParameterHandler](classParameterHandler.html). Thanks to the use of the [ParameterHandler::add\\_parameter()](classParameterHandler.html#a04b75c02037d19fd7fd781785fcefc79) method, this connection is trivial, but requires all members of this class to be writable.\n\n```\n     class ParticleTrackingParameters : public ParameterAcceptor\n     {\n     public:\n       ParticleTrackingParameters();\n```\n\nThis class consists largely of member variables that describe the details of the particle tracking simulation and its discretization. The following parameters are about where output should written to, the spatial discretization of the velocity (the default is \\(Q\\_1\\)), the time step and the output interval (how many time steps should elapse before we generate graphical output again):\n\n```\n       std::string output_directory = \"./\";\n   \n       unsigned int velocity_degree      = 1;\n       double       time_step            = 0.002;\n       double       final_time           = 4.0;\n       unsigned int output_interval      = 10;\n       unsigned int repartition_interval = 5;\n```\n\nWe allow every grid to be refined independently. In this tutorial, no physics is resolved on the fluid grid, and its velocity is calculated analytically.\n\n```\n       unsigned int fluid_refinement              = 4;\n       unsigned int particle_insertion_refinement = 3;\n     };\n```\n\nThere remains the task of declaring what run-time parameters we can accept in input files. Since we have a very limited number of parameters, all parameters are declared in the same section.\n\n```\n     ParticleTrackingParameters::ParticleTrackingParameters()\n       : ParameterAcceptor(\"Particle Tracking Problem/\")\n     {\n       add_parameter(\n         \"Velocity degree\", velocity_degree, \"\", prm, Patterns::Integer(1));\n   \n       add_parameter(\"Output interval\",\n                     output_interval,\n                     \"Iteration interval between which output results are written\",\n                     prm,\n                     Patterns::Integer(1));\n   \n       add_parameter(\"Repartition interval\",\n                     repartition_interval,\n                     \"Iteration interval at which the mesh is load balanced\",\n                     prm,\n                     Patterns::Integer(1));\n   \n       add_parameter(\"Output directory\", output_directory);\n   \n       add_parameter(\"Time step\", time_step, \"\", prm, Patterns::Double());\n   \n       add_parameter(\"Final time\",\n                     final_time,\n                     \"End time of the simulation\",\n                     prm,\n                     Patterns::Double());\n   \n       add_parameter(\"Fluid refinement\",\n                     fluid_refinement,\n                     \"Refinement level of the fluid domain\",\n                     prm,\n                     Patterns::Integer(0));\n   \n       add_parameter(\n         \"Particle insertion refinement\",\n         particle_insertion_refinement,\n         \"Refinement of the volumetric mesh used to insert the particles\",\n         prm,\n         Patterns::Integer(0));\n     }\n```\n\n### The `ParticleTracking` class declaration\n\nWe are now ready to introduce the main class of our tutorial program.\n\n```\n     template <int dim>\n     class ParticleTracking\n     {\n     public:\n       ParticleTracking(const ParticleTrackingParameters &par,\n                        const bool                        interpolated_velocity);\n       void run();\n   \n     private:\n```\n\nThis function is responsible for the initial generation of the particles on top of the background grid.\n\n```\n       void generate_particles();\n```\n\nWhen the velocity profile is interpolated to the position of the particles, it must first be stored using degrees of freedom. Consequently, as is the case for other parallel case (e.g. [step-40](step_40.html)) we initialize the degrees of freedom on the background grid.\n\n```\n       void setup_background_dofs();\n```\n\nIn one of the test cases, the function is mapped to the background grid and a finite element interpolation is used to calculate the velocity at the particle location. This function calculates the value of the function at the support point of the triangulation.\n\n```\n       void interpolate_function_to_field();\n```\n\nThe next two functions are responsible for carrying out step of explicit Euler time integration for the cases where the velocity field is interpolated at the positions of the particles or calculated analytically, respectively.\n\n```\n       void euler_step_interpolated(const double dt);\n       void euler_step_analytical(const double dt);\n```\n\nThe `cell_weight()` function indicates to the triangulation how much computational work is expected to happen on this cell, and consequently how the domain needs to be partitioned so that every MPI rank receives a roughly equal amount of work (potentially not an equal number of cells). While the function is called from the outside, it is connected to the corresponding signal from inside this class, therefore it can be `private`.\n\n```\n       unsigned int cell_weight(\n         const typename parallel::distributed::Triangulation<dim>::cell_iterator\n                         &cell,\n         const CellStatus status) const;\n```\n\nThe following two functions are responsible for outputting the simulation results for the particles and for the velocity profile on the background mesh, respectively.\n\n```\n       void output_particles(const unsigned int it);\n       void output_background(const unsigned int it);\n```\n\nThe private members of this class are similar to other parallel deal.II examples. The parameters are stored as a `const` member. It is important to note that we keep the `Vortex` class as a member since its time must be modified as the simulation proceeds.\n\n```\n       const ParticleTrackingParameters &par;\n   \n       MPI_Comm                                  mpi_communicator;\n       parallel::distributed::Triangulation<dim> background_triangulation;\n       Particles::ParticleHandler<dim>           particle_handler;\n   \n       DoFHandler<dim>                            fluid_dh;\n       const FESystem<dim>                        fluid_fe;\n       MappingQ1<dim>                             mapping;\n       LinearAlgebra::distributed::Vector<double> velocity_field;\n   \n       Functions::RayleighKotheVortex<dim> velocity;\n   \n       ConditionalOStream pcout;\n   \n       bool interpolated_velocity;\n     };\n```\n\n### The `PatricleTracking` class implementation\n\n#### Constructor\n\nThe constructors and destructors are rather trivial. They are very similar to what is done in [step-40](step_40.html). We set the processors we want to work on to all machines available (`MPI_COMM_WORLD`) and initialize the `pcout` variable to only allow processor zero to output anything to the standard output.\n\n```\n     template <int dim>\n     ParticleTracking<dim>::ParticleTracking(const ParticleTrackingParameters &par,\n                                             const bool interpolated_velocity)\n       : par(par)\n       , mpi_communicator(MPI_COMM_WORLD)\n       , background_triangulation(mpi_communicator)\n       , fluid_dh(background_triangulation)\n       , fluid_fe(FE_Q<dim>(par.velocity_degree) ^ dim)\n       , velocity(4.0)\n       , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n       , interpolated_velocity(interpolated_velocity)\n   \n     {}\n```\n\n#### Cell weight\n\nThis function is the key component that allow us to dynamically balance the computational load for this example. The function attributes a weight to every cell that represents the computational work on this cell. Here the majority of work is expected to happen on the particles, therefore the return value of this function (representing \"work for this cell\") is calculated based on the number of particles in the current cell. The function is connected to the `weight` signal inside the triangulation, and will be called once per cell, whenever the triangulation repartitions the domain between ranks (the connection is created inside the generate\\_particles() function of this class).\n\n```\n     template <int dim>\n     unsigned int ParticleTracking<dim>::cell_weight(\n       const typename parallel::distributed::Triangulation<dim>::cell_iterator\n                       &cell,\n       const CellStatus status) const\n     {\n```\n\nFirst, we introduce a base weight that will be assigned to every cell.\n\n```\n       const unsigned int base_weight = 1;\n```\n\nThe following variable then determines how important particle work is compared to cell work. We set the weight per particle much higher to indicate that the particle load is the only one that is important to distribute the cells in this example. The optimal value of this number depends on the application and can range from 0 (cheap particle operations, expensive cell operations) to much larger than the base weight of 1 (expensive particle operations, cheap cell operations, like presumed in this example).\n\n```\n       const unsigned int particle_weight = 10;\n```\n\nThis example does not use adaptive refinement, therefore every cell should have the status `CellStatus::cell_will_persist`. However this function can also be used to distribute load during refinement, therefore we consider refined or coarsened cells as well.\n\n```\n       unsigned int n_particles_in_cell = 0;\n       switch (status)\n         {\n           case CellStatus::cell_will_persist:\n           case CellStatus::cell_will_be_refined:\n             n_particles_in_cell = particle_handler.n_particles_in_cell(cell);\n             break;\n   \n           case CellStatus::cell_invalid:\n             break;\n   \n           case CellStatus::children_will_be_coarsened:\n             for (const auto &child : cell->child_iterators())\n               n_particles_in_cell += particle_handler.n_particles_in_cell(child);\n             break;\n   \n           default:\n             DEAL_II_ASSERT_UNREACHABLE();\n         }\n   \n       return base_weight + particle_weight * n_particles_in_cell;\n     }\n```\n\n#### [Particles](namespaceParticles.html) generation\n\nThis function generates the tracer particles and the background triangulation on which these particles evolve.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::generate_particles()\n     {\n```\n\nWe create a hyper cube triangulation which we globally refine. This triangulation covers the full trajectory of the particles.\n\n```\n       GridGenerator::hyper_cube(background_triangulation, 0, 1);\n       background_triangulation.refine_global(par.fluid_refinement);\n```\n\nIn order to consider the particles when repartitioning the triangulation the algorithm needs to know how much weight to assign to each cell (how many particles are in there).\n\nWe attach a weight function to the signal inside [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html). This signal will be called every time the repartition() function is called. This connection only needs to be created once, so we might as well have set it up in the constructor of this class, but for the purpose of this example we want to group the particle related instructions.\n\n```\n       background_triangulation.signals.weight.connect(\n         [&](const typename parallel::distributed::Triangulation<\n               dim>::cell_iterator &cell,\n             const CellStatus       status) -> unsigned int {\n           return this->cell_weight(cell, status);\n         });\n```\n\nThis initializes the background triangulation where the particles are living and the number of properties of the particles.\n\n```\n       particle_handler.initialize(background_triangulation, mapping, 1 + dim);\n```\n\nWe create a particle triangulation which is solely used to generate the points which will be used to insert the particles. This triangulation is a hyper shell which is offset from the center of the simulation domain. This will be used to generate a disk filled with particles which will allow an easy monitoring of the motion due to the vortex.\n\n```\n       Point<dim> center;\n       center[0] = 0.5;\n       center[1] = 0.75;\n       if (dim == 3)\n         center[2] = 0.5;\n   \n       const double outer_radius = 0.15;\n       const double inner_radius = 0.01;\n   \n       parallel::distributed::Triangulation<dim> particle_triangulation(\n         MPI_COMM_WORLD);\n   \n       GridGenerator::hyper_shell(\n         particle_triangulation, center, inner_radius, outer_radius, 6);\n       particle_triangulation.refine_global(par.particle_insertion_refinement);\n```\n\nWe generate the necessary bounding boxes for the particles generator. These bounding boxes are required to quickly identify in which process's subdomain the inserted particle lies, and which cell owns it.\n\n```\n       const auto my_bounding_box = GridTools::compute_mesh_predicate_bounding_box(\n         background_triangulation, IteratorFilters::LocallyOwnedCell());\n       const auto global_bounding_boxes =\n         Utilities::MPI::all_gather(MPI_COMM_WORLD, my_bounding_box);\n```\n\nWe generate an empty vector of properties. We will attribute the properties to the particles once they are generated.\n\n```\n       std::vector<std::vector<double>> properties(\n         particle_triangulation.n_locally_owned_active_cells(),\n         std::vector<double>(dim + 1, 0.));\n```\n\nWe generate the particles at the position of a single point quadrature. Consequently, one particle will be generated at the centroid of each cell.\n\n```\n       Particles::Generators::quadrature_points(particle_triangulation,\n                                                QMidpoint<dim>(),\n                                                global_bounding_boxes,\n                                                particle_handler,\n                                                mapping,\n                                                properties);\n   \n       pcout << \"Number of particles inserted: \"\n             << particle_handler.n_global_particles() << std::endl;\n     }\n```\n\n#### Background DOFs and interpolation\n\nThis function sets up the background degrees of freedom used for the velocity interpolation and allocates the field vector where the entire solution of the velocity field is stored.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::setup_background_dofs()\n     {\n       fluid_dh.distribute_dofs(fluid_fe);\n       const IndexSet locally_owned_dofs = fluid_dh.locally_owned_dofs();\n       const IndexSet locally_relevant_dofs =\n         DoFTools::extract_locally_relevant_dofs(fluid_dh);\n   \n       velocity_field.reinit(locally_owned_dofs,\n                             locally_relevant_dofs,\n                             mpi_communicator);\n     }\n```\n\nThis function takes care of interpolating the vortex velocity field to the field vector. This is achieved rather easily by using the [VectorTools::interpolate()](namespaceVectorTools.html#a35950c839da51812962d41ee4075b3b8) function.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::interpolate_function_to_field()\n     {\n       velocity_field.zero_out_ghost_values();\n       VectorTools::interpolate(mapping, fluid_dh, velocity, velocity_field);\n       velocity_field.update_ghost_values();\n     }\n```\n\n#### Time integration of the trajectories\n\nWe integrate the particle trajectories using an analytically defined velocity field. This demonstrates a relatively trivial usage of the particles.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::euler_step_analytical(const double dt)\n     {\n       const unsigned int this_mpi_rank =\n         Utilities::MPI::this_mpi_process(mpi_communicator);\n       Vector<double> particle_velocity(dim);\n```\n\nLooping over all particles in the domain using a particle iterator\n\n```\n       for (auto &particle : particle_handler)\n         {\n```\n\nWe calculate the velocity of the particles using their current location.\n\n```\n           Point<dim> &particle_location = particle.get_location();\n           velocity.vector_value(particle_location, particle_velocity);\n```\n\nThis updates the position of the particles and sets the old position equal to the new position of the particle.\n\n```\n           for (int d = 0; d < dim; ++d)\n             particle_location[d] += particle_velocity[d] * dt;\n```\n\nWe store the processor id (a scalar) and the particle velocity (a vector) in the particle properties. In this example, this is done purely for visualization purposes.\n\n```\n           ArrayView<double> properties = particle.get_properties();\n           for (int d = 0; d < dim; ++d)\n             properties[d] = particle_velocity[d];\n           properties[dim] = this_mpi_rank;\n         }\n     }\n```\n\nIn contrast to the previous function in this function we integrate the particle trajectories by interpolating the value of the velocity field at the degrees of freedom to the position of the particles. This is achieved using the [FEPointEvaluation](classFEPointEvaluation.html) object.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::euler_step_interpolated(const double dt)\n     {\n       Vector<double> local_dof_values(fluid_fe.dofs_per_cell);\n   \n       FEPointEvaluation<dim, dim> evaluator(mapping, fluid_fe, update_values);\n       std::vector<Point<dim>>     particle_positions;\n```\n\nWe loop over all the local particles. Although this could be achieved directly by looping over all the cells, this would force us to loop over numerous cells which do not contain particles. Rather, we loop over all the particles, but, we get the reference of the cell in which the particle lies and then loop over all particles within that cell. This enables us to gather the values of the velocity out of the `velocity_field` vector once and use them for all particles that lie within the cell.\n\n```\n       auto particle = particle_handler.begin();\n       while (particle != particle_handler.end())\n         {\n           const auto cell = particle->get_surrounding_cell();\n           const auto dh_cell =\n             typename DoFHandler<dim>::cell_iterator(*cell, &fluid_dh);\n   \n           dh_cell->get_dof_values(velocity_field, local_dof_values);\n```\n\nNext, compute the velocity at the particle locations by evaluating the finite element solution at the position of the particles. This is achieved using [FEPointEvaluation](classFEPointEvaluation.html) object.\n\n```\n           const auto pic = particle_handler.particles_in_cell(cell);\n           Assert(pic.begin() == particle, ExcInternalError());\n           particle_positions.clear();\n           for (auto &p : pic)\n             particle_positions.push_back(p.get_reference_location());\n   \n           evaluator.reinit(cell, particle_positions);\n           evaluator.evaluate(make_array_view(local_dof_values),\n                              EvaluationFlags::values);\n```\n\nWe move the particles using the interpolated velocity field\n\n```\n           for (unsigned int particle_index = 0; particle != pic.end();\n                ++particle, ++particle_index)\n             {\n               Point<dim>           &particle_location = particle->get_location();\n               const Tensor<1, dim> &particle_velocity =\n                 evaluator.get_value(particle_index);\n               particle_location += particle_velocity * dt;\n```\n\nAgain, we store the particle velocity and the processor id in the particle properties for visualization purposes.\n\n```\n               ArrayView<double> properties = particle->get_properties();\n               for (int d = 0; d < dim; ++d)\n                 properties[d] = particle_velocity[d];\n   \n               properties[dim] =\n                 Utilities::MPI::this_mpi_process(mpi_communicator);\n             }\n         }\n     }\n```\n\n#### Data output\n\nThe next two functions take care of writing both the particles and the background mesh to vtu with a pvtu record. This ensures that the simulation results can be visualized when the simulation is launched in parallel.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::output_particles(const unsigned int it)\n     {\n       Particles::DataOut<dim, dim> particle_output;\n   \n       std::vector<std::string> solution_names(dim, \"velocity\");\n       solution_names.emplace_back(\"process_id\");\n   \n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           dim, DataComponentInterpretation::component_is_part_of_vector);\n       data_component_interpretation.push_back(\n         DataComponentInterpretation::component_is_scalar);\n   \n       particle_output.build_patches(particle_handler,\n                                     solution_names,\n                                     data_component_interpretation);\n       const std::string output_folder(par.output_directory);\n       const std::string file_name(interpolated_velocity ?\n                                     \"interpolated-particles\" :\n                                     \"analytical-particles\");\n   \n       pcout << \"Writing particle output file: \" << file_name << '-' << it\n             << std::endl;\n   \n       particle_output.write_vtu_with_pvtu_record(\n         output_folder, file_name, it, mpi_communicator, 6);\n     }\n   \n   \n   \n     template <int dim>\n     void ParticleTracking<dim>::output_background(const unsigned int it)\n     {\n       std::vector<std::string> solution_names(dim, \"velocity\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           dim, DataComponentInterpretation::component_is_part_of_vector);\n   \n       DataOut<dim> data_out;\n```\n\nAttach the solution data to data\\_out object\n\n```\n       data_out.attach_dof_handler(fluid_dh);\n       data_out.add_data_vector(velocity_field,\n                                solution_names,\n                                DataOut<dim>::type_dof_data,\n                                data_component_interpretation);\n       Vector<float> subdomain(background_triangulation.n_active_cells());\n       for (unsigned int i = 0; i < subdomain.size(); ++i)\n         subdomain(i) = background_triangulation.locally_owned_subdomain();\n       data_out.add_data_vector(subdomain, \"subdomain\");\n   \n       data_out.build_patches(mapping);\n   \n       const std::string output_folder(par.output_directory);\n       const std::string file_name(\"background\");\n   \n       pcout << \"Writing background field file: \" << file_name << '-' << it\n             << std::endl;\n   \n       data_out.write_vtu_with_pvtu_record(\n         output_folder, file_name, it, mpi_communicator, 6);\n     }\n```\n\n#### Running the simulation\n\nThis function orchestrates the entire simulation. It is very similar to the other time dependent tutorial programs – take [step-21](step_21.html) or [step-26](step_26.html) as an example. Note that we use the [DiscreteTime](classDiscreteTime.html) class to monitor the time, the time-step and the step-number. This function is relatively straightforward.\n\n```\n     template <int dim>\n     void ParticleTracking<dim>::run()\n     {\n       DiscreteTime discrete_time(0, par.final_time, par.time_step);\n   \n       generate_particles();\n   \n       pcout << \"Repartitioning triangulation after particle generation\"\n             << std::endl;\n   \n       particle_handler.prepare_for_coarsening_and_refinement();\n       background_triangulation.repartition();\n       particle_handler.unpack_after_coarsening_and_refinement();\n```\n\nWe set the initial property of the particles by doing an explicit Euler iteration with a time-step of 0 both in the case of the analytical and the interpolated approach.\n\n```\n       if (interpolated_velocity)\n         {\n           setup_background_dofs();\n           interpolate_function_to_field();\n           euler_step_interpolated(0.);\n         }\n       else\n         euler_step_analytical(0.);\n   \n       output_particles(discrete_time.get_step_number());\n       if (interpolated_velocity)\n         output_background(discrete_time.get_step_number());\n```\n\nThe particles are advected by looping over time.\n\n```\n       while (!discrete_time.is_at_end())\n         {\n           discrete_time.advance_time();\n           velocity.set_time(discrete_time.get_previous_time());\n   \n           if ((discrete_time.get_step_number() % par.repartition_interval) == 0)\n             {\n               particle_handler.prepare_for_coarsening_and_refinement();\n               background_triangulation.repartition();\n               particle_handler.unpack_after_coarsening_and_refinement();\n   \n               if (interpolated_velocity)\n                 setup_background_dofs();\n             }\n   \n           if (interpolated_velocity)\n             {\n               interpolate_function_to_field();\n               euler_step_interpolated(discrete_time.get_previous_step_size());\n             }\n           else\n             euler_step_analytical(discrete_time.get_previous_step_size());\n```\n\nAfter the particles have been moved, it is necessary to identify in which cell they now reside. This is achieved by calling `sort_particles_into_subdomains_and_cells`\n\n```\n           particle_handler.sort_particles_into_subdomains_and_cells();\n   \n           if ((discrete_time.get_step_number() % par.output_interval) == 0)\n             {\n               output_particles(discrete_time.get_step_number());\n               if (interpolated_velocity)\n                 output_background(discrete_time.get_step_number());\n             }\n         }\n     }\n   \n   } // namespace Step68\n```\n\n### The main() function\n\nThe remainder of the code, the `main()` function, is standard. We note that we run the particle tracking with the analytical velocity and the interpolated velocity and produce both results\n\n```\n   int main(int argc, char *argv[])\n   {\n     using namespace Step68;\n     using namespace dealii;\n     deallog.depth_console(1);\n   \n     try\n       {\n         Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n   \n         std::string prm_file;\n         if (argc > 1)\n           prm_file = argv[1];\n         else\n           prm_file = \"parameters.prm\";\n   \n         ParticleTrackingParameters par;\n         ParameterAcceptor::initialize(prm_file);\n         {\n           Step68::ParticleTracking<2> particle_tracking(par, false);\n           particle_tracking.run();\n         }\n         {\n           Step68::ParticleTracking<2> particle_tracking(par, true);\n           particle_tracking.run();\n         }\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nThe directory in which this program is run contains an example parameter file by default. If you do not specify a parameter file as an argument on the command line, the program will try to read the file \"parameters.prm\" by default, and will execute the code.\n\nOn any number of cores, the simulation output will look like:\n\n```\nbash@f$ mpirun -np 4 ./step-68 parameters.prm\nNumber of particles inserted: 606\nRepartitioning triangulation after particle generation\nWriting particle output file: analytical-particles-0\nWriting particle output file: analytical-particles-10\nWriting particle output file: analytical-particles-20\nWriting particle output file: analytical-particles-30\n...\nNumber of particles inserted: 606\nRepartitioning triangulation after particle generation\nWriting particle output file: interpolated-particles-0\nWriting background field file: background-0\nWriting particle output file: interpolated-particles-10\nWriting background field file: background-10\nWriting particle output file: interpolated-particles-20\nWriting background field file: background-20\nWriting particle output file: interpolated-particles-30\nWriting background field file: background-30\n...\nWriting particle output file: interpolated-particles-1980\nWriting background field file: background-1980\nWriting particle output file: interpolated-particles-1990\nWriting background field file: background-1990\nWriting particle output file: interpolated-particles-2000\nWriting background field file: background-2000\n```\n\nWe note that, by default, the simulation runs the particle tracking with an analytical velocity for 2000 iterations, then restarts from the beginning and runs the particle tracking with velocity interpolation for the same duration. The results are written every 10th iteration.\n\n### Motion of the particles\n\nThe following animation displays the trajectory of the particles as they are advected by the flow field. We see that after the complete duration of the flow, the particle go back to their initial configuration as is expected.\n\n### Dynamic load balancing\n\nThe following animation shows the impact of dynamic load balancing. We clearly see that the subdomains adapt themselves to balance the number of particles per subdomain. However, a perfect load balancing is not reached, in part due to the coarseness of the background mesh.\n\n### Possibilities for extensions\n\nThis program highlights some of the main capabilities for handling particles in deal.II, notably their capacity to be used in distributed parallel simulations. However, this step could be extended in numerous manners:\n\n* High-order time integration (for example using a Runge-Kutta 4 method) could be used to increase the accuracy or allow for larger time-step sizes with the same accuracy.\n* The full equation of motion (with inertia) could be solved for the particles. In this case the particles would need to have additional properties such as their mass, as in [step-19](step_19.html), and if one wanted to also consider interactions with the fluid, their diameter.\n* Coupling to a flow solver. This step could be straightforwardly coupled to any parallel program in which the Stokes ([step-32](step_32.html), [step-70](step_70.html)) or the Navier-Stokes equations are solved (e.g., [step-57](step_57.html)).\n* Computing the difference in final particle positions between the two models would allow to quantify the influence of the interpolation error on particle motion.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2020 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Bruno Blais, Toni El Geitani Nehme, Rene Gassmoeller, Peter Munch\n */\n \n \n#include <deal.II/base/bounding_box.h>\n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/discrete_time.h>\n#include <deal.II/base/function_lib.h>\n#include <deal.II/base/mpi.h>\n#include <deal.II/base/parameter_acceptor.h>\n#include <deal.II/base/timer.h>\n \n#include <deal.II/distributed/solution_transfer.h>\n#include <deal.II/distributed/tria.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/mapping_q1.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_tools.h>\n \n#include <deal.II/lac/la_parallel_vector.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <deal.II/particles/particle_handler.h>\n \n#include <deal.II/particles/generators.h>\n \n#include <deal.II/particles/data_out.h>\n \n#include <cmath>\n#include <iostream>\n \n \n \nnamespace Step68\n{\n using namespace dealii;\n \n \n class ParticleTrackingParameters : public ParameterAcceptor\n  {\n public:\n    ParticleTrackingParameters();\n \n    std::string output_directory = \"./\";\n \n unsigned int velocity_degree      = 1;\n double       time_step            = 0.002;\n double       final_time           = 4.0;\n unsigned int output_interval      = 10;\n unsigned int repartition_interval = 5;\n \n unsigned int fluid_refinement              = 4;\n unsigned int particle_insertion_refinement = 3;\n  };\n \n \n \n  ParticleTrackingParameters::ParticleTrackingParameters()\n    : ParameterAcceptor(\"Particle Tracking Problem/\")\n  {\n    add_parameter(\n \"Velocity degree\", velocity_degree, \"\", prm, Patterns::Integer(1));\n \n    add_parameter(\"Output interval\",\n                  output_interval,\n \"Iteration interval between which output results are written\",\n                  prm,\n Patterns::Integer(1));\n \n    add_parameter(\"Repartition interval\",\n                  repartition_interval,\n \"Iteration interval at which the mesh is load balanced\",\n                  prm,\n Patterns::Integer(1));\n \n    add_parameter(\"Output directory\", output_directory);\n \n    add_parameter(\"Time step\", time_step, \"\", prm, Patterns::Double());\n \n    add_parameter(\"Final time\",\n                  final_time,\n \"End time of the simulation\",\n                  prm,\n Patterns::Double());\n \n    add_parameter(\"Fluid refinement\",\n                  fluid_refinement,\n \"Refinement level of the fluid domain\",\n                  prm,\n Patterns::Integer(0));\n \n    add_parameter(\n \"Particle insertion refinement\",\n      particle_insertion_refinement,\n \"Refinement of the volumetric mesh used to insert the particles\",\n      prm,\n Patterns::Integer(0));\n  }\n \n \n \n \n template <int dim>\n class ParticleTracking\n  {\n public:\n    ParticleTracking(const ParticleTrackingParameters &par,\n const bool                        interpolated_velocity);\n void run();\n \n private:\n void generate_particles();\n \n void setup_background_dofs();\n \n void interpolate_function_to_field();\n \n void euler_step_interpolated(const double dt);\n void euler_step_analytical(const double dt);\n \n unsigned int cell_weight(\n const typename parallel::distributed::Triangulation<dim>::cell_iterator\n                      &cell,\n const CellStatus status) const;\n \n void output_particles(const unsigned int it);\n void output_background(const unsigned int it);\n \n \n const ParticleTrackingParameters &par;\n \n MPI_Comm                                  mpi_communicator;\n parallel::distributed::Triangulation<dim> background_triangulation;\n Particles::ParticleHandler<dim>           particle_handler;\n \n DoFHandler<dim>                            fluid_dh;\n const FESystem<dim>                        fluid_fe;\n MappingQ1<dim>                             mapping;\n LinearAlgebra::distributed::Vector<double> velocity_field;\n \n Functions::RayleighKotheVortex<dim> velocity;\n \n ConditionalOStream pcout;\n \n bool interpolated_velocity;\n  };\n \n \n \n \n \n \n template <int dim>\n  ParticleTracking<dim>::ParticleTracking(const ParticleTrackingParameters &par,\n const bool interpolated_velocity)\n    : par(par)\n    , mpi_communicator(MPI_COMM_WORLD)\n    , background_triangulation(mpi_communicator)\n    , fluid_dh(background_triangulation)\n    , fluid_fe(FE_Q<dim>(par.velocity_degree) ^ dim)\n    , velocity(4.0)\n    , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n    , interpolated_velocity(interpolated_velocity)\n \n  {}\n \n \n \n \n template <int dim>\n unsigned int ParticleTracking<dim>::cell_weight(\n const typename parallel::distributed::Triangulation<dim>::cell_iterator\n                    &cell,\n const CellStatus status) const\n {\n const unsigned int base_weight = 1;\n \n const unsigned int particle_weight = 10;\n \n unsigned int n_particles_in_cell = 0;\n switch (status)\n      {\n case CellStatus::cell_will_persist:\n case CellStatus::cell_will_be_refined:\n          n_particles_in_cell = particle_handler.n_particles_in_cell(cell);\n break;\n \n case CellStatus::cell_invalid:\n break;\n \n case CellStatus::children_will_be_coarsened:\n for (const auto &child : cell->child_iterators())\n            n_particles_in_cell += particle_handler.n_particles_in_cell(child);\n break;\n \n default:\n DEAL_II_ASSERT_UNREACHABLE();\n      }\n \n return base_weight + particle_weight * n_particles_in_cell;\n  }\n \n \n \n \n template <int dim>\n void ParticleTracking<dim>::generate_particles()\n  {\n GridGenerator::hyper_cube(background_triangulation, 0, 1);\n    background_triangulation.refine_global(par.fluid_refinement);\n \n    background_triangulation.signals.weight.connect(\n      [&](const typename parallel::distributed::Triangulation<\n            dim>::cell_iterator &cell,\n const CellStatus       status) -> unsigned int {\n return this->cell_weight(cell, status);\n      });\n \n    particle_handler.initialize(background_triangulation, mapping, 1 + dim);\n \n Point<dim> center;\n center[0] = 0.5;\n center[1] = 0.75;\n if (dim == 3)\n center[2] = 0.5;\n \n const double outer_radius = 0.15;\n const double inner_radius = 0.01;\n \n parallel::distributed::Triangulation<dim> particle_triangulation(\n      MPI_COMM_WORLD);\n \n GridGenerator::hyper_shell(\n      particle_triangulation, center, inner_radius, outer_radius, 6);\n    particle_triangulation.refine_global(par.particle_insertion_refinement);\n \n const auto my_bounding_box = GridTools::compute_mesh_predicate_bounding_box(\n      background_triangulation, IteratorFilters::LocallyOwnedCell());\n const auto global_bounding_boxes =\n Utilities::MPI::all_gather(MPI_COMM_WORLD, my_bounding_box);\n \n    std::vector<std::vector<double>> properties(\n      particle_triangulation.n_locally_owned_active_cells(),\n      std::vector<double>(dim + 1, 0.));\n \n Particles::Generators::quadrature_points(particle_triangulation,\n QMidpoint<dim>(),\n                                             global_bounding_boxes,\n                                             particle_handler,\n                                             mapping,\n                                             properties);\n \n    pcout << \"Number of particles inserted: \"\n          << particle_handler.n_global_particles() << std::endl;\n  }\n \n \n \n \n template <int dim>\n void ParticleTracking<dim>::setup_background_dofs()\n  {\n    fluid_dh.distribute_dofs(fluid_fe);\n const IndexSet locally_owned_dofs = fluid_dh.locally_owned_dofs();\n const IndexSet locally_relevant_dofs =\n DoFTools::extract_locally_relevant_dofs(fluid_dh);\n \n    velocity_field.reinit(locally_owned_dofs,\n                          locally_relevant_dofs,\n                          mpi_communicator);\n  }\n \n \n \n template <int dim>\n void ParticleTracking<dim>::interpolate_function_to_field()\n  {\n    velocity_field.zero_out_ghost_values();\n VectorTools::interpolate(mapping, fluid_dh, velocity, velocity_field);\n    velocity_field.update_ghost_values();\n  }\n \n \n \n \n template <int dim>\n void ParticleTracking<dim>::euler_step_analytical(const double dt)\n  {\n const unsigned int this_mpi_rank =\n Utilities::MPI::this_mpi_process(mpi_communicator);\n Vector<double> particle_velocity(dim);\n \n for (auto &particle : particle_handler)\n      {\n Point<dim> &particle_location = particle.get_location();\n        velocity.vector_value(particle_location, particle_velocity);\n \n for (int d = 0; d < dim; ++d)\n          particle_location[d] += particle_velocity[d] * dt;\n \n ArrayView<double> properties = particle.get_properties();\n for (int d = 0; d < dim; ++d)\n          properties[d] = particle_velocity[d];\n        properties[dim] = this_mpi_rank;\n      }\n  }\n \n \n \n template <int dim>\n void ParticleTracking<dim>::euler_step_interpolated(const double dt)\n  {\n Vector<double> local_dof_values(fluid_fe.dofs_per_cell);\n \n FEPointEvaluation<dim, dim> evaluator(mapping, fluid_fe, update_values);\n    std::vector<Point<dim>>     particle_positions;\n \n auto particle = particle_handler.begin();\n while (particle != particle_handler.end())\n      {\n const auto cell = particle->get_surrounding_cell();\n const auto dh_cell =\n typename DoFHandler<dim>::cell_iterator(*cell, &fluid_dh);\n \n        dh_cell->get_dof_values(velocity_field, local_dof_values);\n \n const auto pic = particle_handler.particles_in_cell(cell);\n Assert(pic.begin() == particle, ExcInternalError());\n        particle_positions.clear();\n for (auto &p : pic)\n          particle_positions.push_back(p.get_reference_location());\n \n        evaluator.reinit(cell, particle_positions);\n        evaluator.evaluate(make_array_view(local_dof_values),\n EvaluationFlags::values);\n \n for (unsigned int particle_index = 0; particle != pic.end();\n             ++particle, ++particle_index)\n          {\n Point<dim>           &particle_location = particle->get_location();\n const Tensor<1, dim> &particle_velocity =\n              evaluator.get_value(particle_index);\n            particle_location += particle_velocity * dt;\n \n ArrayView<double> properties = particle->get_properties();\n for (int d = 0; d < dim; ++d)\n              properties[d] = particle_velocity[d];\n \n            properties[dim] =\n Utilities::MPI::this_mpi_process(mpi_communicator);\n          }\n      }\n  }\n \n \n \n \n template <int dim>\n void ParticleTracking<dim>::output_particles(const unsigned int it)\n  {\n Particles::DataOut<dim, dim> particle_output;\n \n    std::vector<std::string> solution_names(dim, \"velocity\");\n    solution_names.emplace_back(\"process_id\");\n \n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        dim, DataComponentInterpretation::component_is_part_of_vector);\n    data_component_interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n    particle_output.build_patches(particle_handler,\n                                  solution_names,\n                                  data_component_interpretation);\n const std::string output_folder(par.output_directory);\n const std::string file_name(interpolated_velocity ?\n \"interpolated-particles\" :\n \"analytical-particles\");\n \n    pcout << \"Writing particle output file: \" << file_name << '-' << it\n          << std::endl;\n \n    particle_output.write_vtu_with_pvtu_record(\n      output_folder, file_name, it, mpi_communicator, 6);\n  }\n \n \n \n template <int dim>\n void ParticleTracking<dim>::output_background(const unsigned int it)\n  {\n    std::vector<std::string> solution_names(dim, \"velocity\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        dim, DataComponentInterpretation::component_is_part_of_vector);\n \n DataOut<dim> data_out;\n \n    data_out.attach_dof_handler(fluid_dh);\n    data_out.add_data_vector(velocity_field,\n                             solution_names,\n DataOut<dim>::type_dof_data,\n                             data_component_interpretation);\n Vector<float> subdomain(background_triangulation.n_active_cells());\n for (unsigned int i = 0; i < subdomain.size(); ++i)\n      subdomain(i) = background_triangulation.locally_owned_subdomain();\n    data_out.add_data_vector(subdomain, \"subdomain\");\n \n    data_out.build_patches(mapping);\n \n const std::string output_folder(par.output_directory);\n const std::string file_name(\"background\");\n \n    pcout << \"Writing background field file: \" << file_name << '-' << it\n          << std::endl;\n \n    data_out.write_vtu_with_pvtu_record(\n      output_folder, file_name, it, mpi_communicator, 6);\n  }\n \n \n \n \n template <int dim>\n void ParticleTracking<dim>::run()\n  {\n DiscreteTime discrete_time(0, par.final_time, par.time_step);\n \n    generate_particles();\n \n    pcout << \"Repartitioning triangulation after particle generation\"\n          << std::endl;\n \n    particle_handler.prepare_for_coarsening_and_refinement();\n    background_triangulation.repartition();\n    particle_handler.unpack_after_coarsening_and_refinement();\n \n if (interpolated_velocity)\n      {\n        setup_background_dofs();\n        interpolate_function_to_field();\n        euler_step_interpolated(0.);\n      }\n else\n      euler_step_analytical(0.);\n \n    output_particles(discrete_time.get_step_number());\n if (interpolated_velocity)\n      output_background(discrete_time.get_step_number());\n \n while (!discrete_time.is_at_end())\n      {\n        discrete_time.advance_time();\n        velocity.set_time(discrete_time.get_previous_time());\n \n if ((discrete_time.get_step_number() % par.repartition_interval) == 0)\n          {\n            particle_handler.prepare_for_coarsening_and_refinement();\n            background_triangulation.repartition();\n            particle_handler.unpack_after_coarsening_and_refinement();\n \n if (interpolated_velocity)\n              setup_background_dofs();\n          }\n \n if (interpolated_velocity)\n          {\n            interpolate_function_to_field();\n            euler_step_interpolated(discrete_time.get_previous_step_size());\n          }\n else\n          euler_step_analytical(discrete_time.get_previous_step_size());\n \n        particle_handler.sort_particles_into_subdomains_and_cells();\n \n if ((discrete_time.get_step_number() % par.output_interval) == 0)\n          {\n            output_particles(discrete_time.get_step_number());\n if (interpolated_velocity)\n              output_background(discrete_time.get_step_number());\n          }\n      }\n  }\n \n} // namespace Step68\n \n \n \n \nint main(int argc, char *argv[])\n{\n using namespace Step68;\n using namespace dealii;\n deallog.depth_console(1);\n \n try\n    {\n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n \n      std::string prm_file;\n if (argc > 1)\n        prm_file = argv[1];\n else\n        prm_file = \"parameters.prm\";\n \n      ParticleTrackingParameters par;\n ParameterAcceptor::initialize(prm_file);\n      {\n        Step68::ParticleTracking<2> particle_tracking(par, false);\n        particle_tracking.run();\n      }\n      {\n        Step68::ParticleTracking<2> particle_tracking(par, true);\n        particle_tracking.run();\n      }\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_69.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nHyperbolic conservation laws: a first-order guaranteed maximum wavespeed method for the compressible Euler equations. Explicit time stepping.\nTutorial content :\nThis tutorial depends on [step-33](step_33.html), [step-40](step_40.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_69-Intro)    * [Euler's equations of gas dynamics](#step_69-Eulersequationsofgasdynamics)      + [Solution theory](#step_69-Solutiontheory)+ [Variational versus collocation-type discretizations](#step_69-Variationalversuscollocationtypediscretizations)* [Description of the scheme](#step_69-Descriptionofthescheme) * [Stable boundary conditions and conservation properties.](#step_69-Stableboundaryconditionsandconservationproperties)- [The commented program](#step_69-CommProg)      * [Include files](#step_69-Includefiles)* [Class template declarations](#step_69-Classtemplatedeclarations)          + [The `Discretization` class](#step_69-ThecodeDiscretizationcodeclass)+ [The `OfflineData` class](#step_69-ThecodeOfflineDatacodeclass)+ [The `ProblemDescription` class](#step_69-ThecodeProblemDescriptioncodeclass)+ [The `InitialValues` class](#step_69-ThecodeInitialValuescodeclass)+ [The `%TimeStepping` class](#step_69-ThecodeTimeSteppingcodeclass)+ [The `SchlierenPostprocessor` class](#step_69-ThecodeSchlierenPostprocessorcodeclass)+ [The `MainLoop` class](#step_69-ThecodeMainLoopcodeclass)* [Implementation](#step_69-Implementation)            + [Grid generation, setup of data structures](#step_69-Gridgenerationsetupofdatastructures)+ [Assembly of offline matrices](#step_69-Assemblyofofflinematrices)+ [Translation to local index ranges](#step_69-Translationtolocalindexranges)+ [Equation of state and approximate Riemann solver](#step_69-EquationofstateandapproximateRiemannsolver)+ [Initial values](#step_69-Initialvalues)+ [The Forward Euler step](#step_69-TheForwardEulerstep)+ [Schlieren postprocessing](#step_69-Schlierenpostprocessing)+ [The main loop](#step_69-Themainloop)                            - [Resume](#step_69-Resume)- [Output and checkpointing](#step_69-Outputandcheckpointing) | 1. [Results](#step_69-Results)    * [Possibilities for extensions](#step_69-Possibilitiesforextensions)- [The plain program](#step_69-PlainProg) |\n\n *This program was contributed by Matthias Maier (Texas A&M University), and Ignacio Tomas (Sandia National Laboratories \\(^{\\!\\dagger}\\)).*\n\n\\(^\\dagger\\)*Sandia National Laboratories is a multimission laboratory managed and operated by National Technology & Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of Honeywell International Inc., for the U.S. Department of Energy's National Nuclear Security Administration under contract DE-NA0003525. This document describes objective technical results and analysis. Any subjective views or opinions that might be expressed in the paper do not necessarily represent the views of the U.S. Department of Energy or the United States Government.*\n\nNote\n:   This tutorial step implements a first-order accurate *guaranteed maximum wavespeed method* based on a first-order *graph viscosity* for solving Euler's equations of gas dynamics [[106]](citelist.html#CITEREF_GuermondPopov2016). As such it is presented primarily for educational purposes. For actual research computations you might want to consider exploring a corresponding [high-performance implementation of a second-order accurate scheme](https://github.com/conservation-laws/ryujin) that uses *convex limiting* techniques, and strong stability-preserving (SSP) time integration, see [[107]](citelist.html#CITEREF_GuermondEtAl2018) ([website](https://conservation-laws.org/)).\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.3698223](https://zenodo.org/badge/DOI/10.5281/zenodo.3698223.svg)](https://doi.org/10.5281/zenodo.3698223)\n\nIntroduction\n============\n\nThis tutorial presents a first-order scheme for solving compressible Euler's equations that is based on three ingredients: a *collocation*-type discretization of Euler's equations in the context of finite elements; a graph-viscosity stabilization based on a *guaranteed* upper bound of the local wave speed; and explicit time-stepping. As such, the ideas and techniques presented in this tutorial step are drastically different from those used in [step-33](step_33.html), which focuses on the use of automatic differentiation. From a programming perspective this tutorial will focus on a number of techniques found in large-scale computations: hybrid thread-MPI parallelization; efficient local numbering of degrees of freedom; concurrent post-processing and write-out of results using worker threads; as well as checkpointing and restart.\n\nIt should be noted that first-order schemes in the context of hyperbolic conservation laws require prohibitively many degrees of freedom to resolve certain key features of the simulated fluid, and thus, typically only serve as elementary building blocks in higher-order schemes [[107]](citelist.html#CITEREF_GuermondEtAl2018). However, we hope that the reader still finds the tutorial step to be a good starting point (in particular with respect to the programming techniques) before jumping into full research codes such as the second-order scheme discussed in [[107]](citelist.html#CITEREF_GuermondEtAl2018).\n\n### Euler's equations of gas dynamics\n\nThe compressible Euler's equations of gas dynamics are written in conservative form as follows:\n\n\\begin{align}\n\\mathbf{u}\\_t + \\text{div} \\, \\mathbb{f}(\\mathbf{u}) = \\boldsymbol{0} ,\n\\end{align}\n\nwhere \\(\\mathbf{u}(\\textbf{x},t):\\mathbb{R}^{d} \\times \\mathbb{R}\n\\rightarrow \\mathbb{R}^{d+2}\\), and \\(\\mathbb{f}(\\mathbf{u}):\\mathbb{R}^{d+2}\n\\rightarrow \\mathbb{R}^{(d+2) \\times d}\\), and \\(d \\geq 1\\) is the space dimension. We say that \\(\\mathbf{u} \\in \\mathbb{R}^{d+2}\\) is the state and \\(\\mathbb{f}(\\mathbf{u}) \\in \\mathbb{R}^{(d+2) \\times d}\\) is the flux of the system. In the case of Euler's equations the state is given by \\(\\textbf{u} = [\\rho, \\textbf{m}^\\top,E]^{\\top}\\): where \\(\\rho \\in \\mathbb{R}^+\\) denotes the density, \\(\\textbf{m} \\in \\mathbb{R}^d\\) is the momentum, and \\(E\n\\in \\mathbb{R}^+\\) is the total energy of the system. The flux of the system \\(\\mathbb{f}(\\mathbf{u})\\) is defined as\n\n\\begin{align\\*}\n\\mathbb{f}(\\textbf{u})\n=\n\\begin{bmatrix}\n\\textbf{m}^\\top \\\\\n\\rho^{-1} \\textbf{m} \\otimes \\textbf{m} + \\mathbb{I} p\\\\\n\\tfrac{\\textbf{m}^\\top}{\\rho} (E + p)\n\\end{bmatrix},\n\\end{align\\*}\n\nwhere \\(\\mathbb{I} \\in \\mathbb{R}^{d \\times d}\\) is the identity matrix and \\(\\otimes\\) denotes the tensor product. Here, we have introduced the pressure \\(p\\) that, in general, is defined by a closed-form equation of state. In this tutorial we limit the discussion to the class of polytropic ideal gases for which the pressure is given by\n\n\\begin{align\\*}\np = p(\\textbf{u}) := (\\gamma -1) \\Big(E -\n\\tfrac{|\\textbf{m}|^2}{2\\,\\rho}\n\\Big),\n\\end{align\\*}\n\nwhere the factor \\(\\gamma \\in (1,5/3]\\) denotes the [ratio of specific heats](https://en.wikipedia.org/wiki/Heat_capacity_ratio).\n\n#### Solution theory\n\nHyperbolic conservation laws, such as\n\n\\begin{align\\*}\n\\mathbf{u}\\_t + \\text{div} \\, \\mathbb{f}(\\mathbf{u}) = \\boldsymbol{0},\n\\end{align\\*}\n\npose a significant challenge with respect to solution theory. An evident observation is that rewriting the equation in variational form and testing with the solution itself does not lead to an energy estimate because the pairing \\(\\langle \\text{div} \\, \\mathbb{f}(\\mathbf{u}), \\mathbf{u}\\rangle\\) (understood as the \\(L^2(\\Omega)\\) inner product or duality pairing) is not guaranteed to be non-negative. Notions such as energy-stability or \\(L^2(\\Omega)\\)-stability are (in general) meaningless in this context.\n\nHistorically, the most fruitful step taken in order to deepen the understanding of hyperbolic conservation laws was to assume that the solution is formally defined as \\(\\mathbf{u} := \\lim\\_{\\epsilon \\rightarrow\n0^+} \\mathbf{u}^{\\epsilon}\\) where \\(\\mathbf{u}^{\\epsilon}\\) is the solution of the parabolic regularization\n\n\\begin{align}\n\\mathbf{u}\\_t^{\\epsilon} + \\text{div} \\, \\mathbb{f}(\\mathbf{u}^{\\epsilon})\n- {\\epsilon} \\Delta \\mathbf{u}^{\\epsilon} = 0.\n\\end{align}\n\nSuch solutions, which are understood as the solution recovered in the zero-viscosity limit, are often referred to as *viscosity solutions*. (This is, because physically \\(\\epsilon\\) can be understood as related to the viscosity of the fluid, i.e., a quantity that indicates the amount of friction neighboring gas particles moving at different speeds exert on each other. The Euler equations themselves are derived under the assumption of no friction, but can physically be expected to describe the limiting case of vanishing friction or viscosity.) Global existence and uniqueness of such solutions is an open issue. However, we know at least that if such viscosity solutions exists they have to satisfy the constraint \\(\\textbf{u}(\\mathbf{x},t) \\in \\mathcal{B}\\) for all \\(\\mathbf{x} \\in \\Omega\\) and \\(t \\geq 0\\) where\n\n\\begin{align}\n\\mathcal{B} = \\big\\{ \\textbf{u} =\n[\\rho, \\textbf{m}^\\top,E]^{\\top} \\in \\mathbb{R}^{d+2} \\, \\big |\n\\\n\\rho > 0 \\, ,\n\\\n\\ E - \\tfrac{|\\textbf{m}|^2}{2 \\rho} > 0 \\, ,\n\\\ns(\\mathbf{u}) \\geq \\min\\_{x \\in \\Omega} s(\\mathbf{u}\\_0(\\mathbf{x}))\n\\big\\}.\n\\end{align}\n\nHere, \\(s(\\mathbf{u})\\) denotes the specific entropy\n\n\\begin{align}\ns(\\mathbf{u}) = \\ln \\Big(\\frac{p(\\mathbf{u})}{\\rho^{\\gamma}}\\Big).\n\\end{align}\n\nWe will refer to \\(\\mathcal{B}\\) as the invariant set of Euler's equations. In other words, a state \\(\\mathbf{u}(\\mathbf{x},t)\\in\\mathcal{B}\\) obeys positivity of the density, positivity of the internal energy, and a local minimum principle on the specific entropy. This condition is a simplified version of a class of pointwise stability constraints satisfied by the exact (viscosity) solution. By pointwise we mean that the constraint has to be satisfied at every point of the domain, not just in an averaged (integral, or high order moments) sense.\n\nIn context of a numerical approximation, a violation of such a constraint has dire consequences: it almost surely leads to catastrophic failure of the numerical scheme, loss of hyperbolicity, and overall, loss of well-posedness of the (discrete) problem. It would also mean that we have computed something that can not be interpreted physically. (For example, what are we to make of a computed solution with a negative density?) In the following we will formulate a scheme that ensures that the discrete approximation of \\(\\mathbf{u}(\\mathbf{x},t)\\) remains in \\(\\mathcal{B}\\).\n\n#### Variational versus collocation-type discretizations\n\nFollowing [step-9](step_9.html), [step-12](step_12.html), [step-33](step_33.html), and [step-67](step_67.html), at this point it might look tempting to base a discretization of Euler's equations on a (semi-discrete) variational formulation:\n\n\\begin{align\\*}\n(\\partial\\_t\\mathbf{u}\\_{h},\\textbf{v}\\_h)\\_{L^2(\\Omega)}\n- ( \\mathbb{f}(\\mathbf{u}\\_{h}) ,\\text{grad} \\, \\textbf{v}\\_{h})\\_{L^2(\\Omega)}\n+ s\\_h(\\mathbf{u}\\_{h},\\textbf{v}\\_h)\\_{L^2(\\Omega)} = \\boldsymbol{0}\n\\quad\\forall \\textbf{v}\\_h \\in \\mathbb{V}\\_h.\n\\end{align\\*}\n\nHere, \\(\\mathbb{V}\\_h\\) is an appropriate finite element space, and \\(s\\_h(\\cdot,\\cdot)\\_{L^2(\\Omega)}\\) is some linear stabilization method (possibly complemented with some ad-hoc shock-capturing technique, see for instance Chapter 5 of [[82]](citelist.html#CITEREF_GuermondErn2004) and references therein). Most time-dependent discretization approaches described in the deal.II tutorials are based on such a (semi-discrete) variational approach. Fundamentally, from an analysis perspective, variational discretizations are conceived to provide some notion of global (integral) stability, meaning an estimate of the form\n\n\\begin{align\\*}\n|\\!|\\!| \\mathbf{u}\\_{h}(t) |\\!|\\!| \\leq |\\!|\\!| \\mathbf{u}\\_{h}(0) |\\!|\\!|\n\\end{align\\*}\n\nholds true, where \\(|\\!|\\!| \\cdot |\\!|\\!| \\) could represent the \\(L^2(\\Omega)\\)-norm or, more generally, some discrete (possibly mesh dependent) energy-norm. Variational discretizations of hyperbolic conservation laws have been very popular since the mid eighties, in particular combined with SUPG-type stabilization and/or upwinding techniques (see the early work of [[46]](citelist.html#CITEREF_Brooks1982) and [[123]](citelist.html#CITEREF_Johnson1986)). They have proven to be some of the best approaches for simulations in the subsonic shockless regime and similarly benign situations.\n\nHowever, in the transonic and supersonic regimes, and shock-hydrodynamics applications the use of variational schemes might be questionable. In fact, at the time of this writing, most shock-hydrodynamics codes are still firmly grounded on finite volume methods. The main reason for failure of variational schemes in such extreme regimes is the lack of pointwise stability. This stems from the fact that *a priori* bounds on integrated quantities (e.g. integrals of moments) have in general no implications on pointwise properties of the solution. While some of these problems might be alleviated by the (perpetual) chase of the right shock capturing scheme, finite difference-like and finite volume schemes still have an edge in many regards.\n\nIn this tutorial step we therefore depart from variational schemes. We will present a completely algebraic formulation (with the flavor of a collocation-type scheme) that preserves constraints pointwise, i.e.,\n\n\\begin{align\\*}\n\\textbf{u}\\_h(\\mathbf{x}\\_i,t) \\in \\mathcal{B}\n\\;\\text{at every node}\\;\\mathbf{x}\\_i\\;\\text{of the mesh}.\n\\end{align\\*}\n\nContrary to finite difference/volume schemes, the scheme implemented in this step maximizes the use of finite element software infrastructure, works on any mesh, in any space dimension, and is theoretically guaranteed to always work, all the time, no exception. This illustrates that deal.II can be used far beyond the context of variational schemes in Hilbert spaces and that a large number of classes, topics, and namespaces from deal.II can be adapted for such a purpose.\n\n### Description of the scheme\n\nLet \\(\\mathbb{V}\\_h\\) be scalar-valued finite dimensional space spanned by a basis \\(\\{\\phi\\_i\\}\\_{i \\in \\mathcal{V}}\\) where: \\(\\phi\\_i:\\Omega \\rightarrow\n\\mathbb{R}\\) and \\(\\mathcal{V}\\) is the set of all indices (nonnegative integers) identifying each scalar Degree of Freedom (DOF) in the mesh. Therefore a scalar finite element functional \\(u\\_h \\in \\mathbb{V}\\_h\\) can be written as \\(u\\_h = \\sum\\_{i \\in \\mathcal{V}} U\\_i \\phi\\_i\\) with \\(U\\_i \\in\n\\mathbb{R}\\). We introduce the notation for vector-valued approximation spaces \\(\\pmb{\\mathbb{V}}\\_h := \\{\\mathbb{V}\\_h\\}^{d+2}\\). Let \\(\\mathbf{u}\\_h\n\\in \\pmb{\\mathbb{V}}\\_h\\), then it can be written as \\(\\mathbf{u}\\_h = \\sum\\_{i\n\\in \\mathcal{V}} \\mathbf{U}\\_i \\phi\\_i\\) where \\(\\mathbf{U}\\_i \\in\n\\mathbb{R}^{d+2}\\) and \\(\\phi\\_i\\) is a scalar-valued shape function.\n\nNote\n:   We purposely refrain from using vector-valued finite element spaces in our notation. Vector-valued finite element spaces are natural for variational formulations of PDE systems (e.g. Navier-Stokes). In such context, the interactions that have to be computed describe *interactions between DOFs*: with proper renumbering of the vector-valued [DoFHandler](classDoFHandler.html) (i.e. initialized with an [FESystem](classFESystem.html)) it is possible to compute the block-matrices (required in order to advance the solution) with relative ease. However, the interactions that have to be computed in the context of time-explicit collocation-type schemes (such as finite differences and/or the scheme presented in this tutorial) can be better described as *interactions between nodes* (not between DOFs). In addition, in our case we do not solve a linear equation in order to advance the solution. This leaves very little reason to use vector-valued finite element spaces both in theory and/or practice.\n\nWe will use the usual Lagrange finite elements: let \\(\\{\\mathbf{x}\\_i\\}\\_{i \\in\n\\mathcal{V}}\\) denote the set of all support points (see [this glossary entry](DEALGlossary.html#GlossSupport)), where \\(\\mathbf{x}\\_i \\in \\mathbb{R}^d\\). Then each index \\(i \\in\n\\mathcal{V}\\) uniquely identifies a support point \\(\\mathbf{x}\\_i\\), as well as a scalar-valued shape function \\(\\phi\\_i\\). With this notation at hand we can define the (explicit time stepping) scheme as:\n\n\\begin{align\\*}\nm\\_i \\frac{\\mathbf{U}\\_i^{n+1} - \\mathbf{U}\\_i^{n}}{\\tau}\n+ \\sum\\_{j \\in \\mathcal{I}(i)} \\mathbb{f}(\\mathbf{U}\\_j^{n})\\cdot\n\\mathbf{c}\\_{ij} - \\sum\\_{j \\in \\mathcal{I}(i)}\nd\\_{ij} \\mathbf{U}\\_j^{n} = \\boldsymbol{0} \\, ,\n\\end{align\\*}\n\nwhere\n\n* \\(m\\_i \\dealcoloneq \\int\\_{\\Omega} \\phi\\_i \\, \\mathrm{d}\\mathbf{x}\\) is the [lumped](DEALGlossary.html#GlossLumpedMassMatrix) [mass matrix](DEALGlossary.html#GlossMassMatrix)\n* \\(\\tau\\) is the time step size\n* \\(\\mathbf{c}\\_{ij} \\dealcoloneq \\int\\_{\\Omega} \\nabla\\phi\\_j\\phi\\_i \\,\n  \\mathrm{d}\\mathbf{x}\\) (note that \\(\\mathbf{c}\\_{ij}\\in \\mathbb{R}^d\\)) is a vector-valued matrix that was used to approximate the divergence of the flux in a weak sense.\n* \\(\\mathcal{I}(i) \\dealcoloneq \\{j \\in \\mathcal{V} \\ | \\ \\mathbf{c}\\_{ij}\n  \\not \\equiv \\boldsymbol{0}\\} \\cup \\{i\\}\\) is the adjacency list containing all degrees of freedom coupling to the index \\(i\\). In other words \\(\\mathcal{I}(i)\\) contains all nonzero column indices for row index i. \\(\\mathcal{I}(i)\\) will also be called a \"stencil\".\n* \\(\\mathbb{f}(\\mathbf{U}\\_j^{n})\\) is the flux \\(\\mathbb{f}\\) of the hyperbolic system evaluated for the state \\(\\mathbf{U}\\_j^{n}\\) associated with support point \\(\\mathbf{x}\\_j\\).\n* \\(d\\_{ij} \\dealcoloneq \\max \\{ \\lambda\\_{\\text{max}}\n  (\\mathbf{U}\\_i^{n},\\mathbf{U}\\_j^{n}, \\textbf{n}\\_{ij}),\n  \\lambda\\_{\\text{max}} (\\mathbf{U}\\_j^{n}, \\mathbf{U}\\_i^{n},\n  \\textbf{n}\\_{ji}) \\} \\|\\mathbf{c}\\_{ij}\\|\\) if \\(i \\not = j\\) is the so called *graph viscosity*. The graph viscosity serves as a stabilization term, it is somewhat the discrete counterpart of \\(\\epsilon \\Delta \\mathbf{u}\\) that appears in the notion of viscosity solution described above. We will base our construction of \\(d\\_{ij}\\) on an estimate of the maximal local wavespeed \\(\\lambda\\_{\\text{max}}\\) that will be explained in detail in a moment.\n* the diagonal entries of the viscosity matrix are defined as \\(d\\_{ii} = - \\sum\\_{j \\in \\mathcal{I}(i)\\backslash \\{i\\}} d\\_{ij}\\).\n* \\(\\textbf{n}\\_{ij} = \\frac{\\mathbf{c}\\_{ij}}{ \\|\\mathbf{c}\\_{ij}\\| }\\) is a normalization of the \\(\\textbf{c}\\_{ij}\\) matrix that enters the approximate Riemann solver with which we compute an the approximations \\(\\lambda\\_{\\text{max}}\\) on the local wavespeed. (This will be explained further down below).\n\nThe definition of \\(\\lambda\\_{\\text{max}} (\\mathbf{U},\\mathbf{V},\n\\textbf{n})\\) is far from trivial and we will postpone the precise definition in order to focus first on some algorithmic and implementation questions. We note that\n\n* \\(m\\_i\\) and \\(\\mathbf{c}\\_{ij}\\) do not evolve in time (provided we keep the discretization fixed). It thus makes sense to assemble these matrices/vectors once in a so called *offline computation* and reuse them in every time step. They are part of what we are going to call off-line data.\n* At every time step we have to evaluate \\(\\mathbb{f}(\\mathbf{U}\\_j^{n})\\) and \\(d\\_{ij} \\dealcoloneq \\max \\{ \\lambda\\_{\\text{max}}\n  (\\mathbf{U}\\_i^{n},\\mathbf{U}\\_j^{n}, \\textbf{n}\\_{ij}),\n  \\lambda\\_{\\text{max}} (\\mathbf{U}\\_j^{n}, \\mathbf{U}\\_i^{n},\n  \\textbf{n}\\_{ji}) \\} \\|\\mathbf{c}\\_{ij}\\| \\), which will constitute the bulk of the computational cost.\n\nConsider the following pseudo-code, illustrating a possible straight forward strategy for computing the solution \\(\\textbf{U}^{n+1}\\) at a new time \\(t\\_{n+1} = t\\_n + \\tau\\_n\\) given a known state \\(\\textbf{U}^{n}\\) at time \\(t\\_n\\):\n\n\\begin{align\\*}\n&\\textbf{for } i \\in \\mathcal{V} \\\\\n&\\ \\ \\ \\ \\{\\mathbf{c}\\_{ij}\\}\\_{j \\in \\mathcal{I}(i)} \\leftarrow\n\\mathtt{gather\\\\_cij\\\\_vectors} (\\textbf{c}, \\mathcal{I}(i)) \\\\\n&\\ \\ \\ \\ \\{\\textbf{U}\\_j^n\\}\\_{j \\in \\mathcal{I}(i)} \\leftarrow\n\\mathtt{gather\\\\_state\\\\_vectors} (\\textbf{U}^n, \\mathcal{I}(i)) \\\\\n&\\ \\ \\ \\ \\ \\textbf{U}\\_i^{n+1} \\leftarrow \\mathbf{U}\\_i^{n} \\\\\n&\\ \\ \\ \\ \\textbf{for } j \\in \\mathcal{I}(i)\\backslash\\{i\\} \\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\texttt{compute } d\\_{ij} \\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\texttt{compute } \\mathbb{f}(\\mathbf{U}\\_j^{n}) \\\\\n&\\ \\ \\ \\ \\ \\ \\ \\ \\textbf{U}\\_i^{n+1} \\leftarrow \\textbf{U}\\_i^{n+1} - \\frac{\\tau\\_n}{m\\_i}\n\\mathbb{f}(\\mathbf{U}\\_j^{n})\\cdot \\mathbf{c}\\_{ij} + d\\_{ij} \\mathbf{U}\\_j^{n} \\\\\n&\\ \\ \\ \\ \\textbf{end} \\\\\n&\\ \\ \\ \\ \\mathtt{scatter\\\\_updated\\\\_state} (\\textbf{U}\\_i^{n+1}) \\\\\n&\\textbf{end}\n\\end{align\\*}\n\nWe note here that:\n\n* This \"assembly\" does not require any form of quadrature or cell-loops.\n* Here \\(\\textbf{c}\\) and \\(\\textbf{U}^n\\) are a global matrix and a global vector containing all the vectors \\(\\mathbf{c}\\_{ij}\\) and all the states \\(\\mathbf{U}\\_j^n\\) respectively.\n* \\(\\mathtt{gather\\\\_cij\\\\_vectors}\\), \\(\\mathtt{gather\\\\_state\\\\_vectors}\\), and \\(\\mathtt{scatter\\\\_updated\\\\_state}\\) are hypothetical implementations that either collect (from) or write (into) global matrices and vectors.\n* If we assume a Cartesian mesh in two space dimensions, first-order polynomial space \\(\\mathbb{Q}^1\\), and that \\(\\mathbf{x}\\_i\\) is an interior node (i.e. \\(\\mathbf{x}\\_i\\) is not on the boundary of the domain) then: \\(\\{\\textbf{U}\\_j^n\\}\\_{j \\in \\mathcal{I}(i)}\\) should contain nine state vector elements (i.e. all the states in the patch/macro element associated to the shape function \\(\\phi\\_i\\)). This is one of the major differences with the usual cell-based loop where the gather functionality (encoded in [FEValuesBase<dim, spacedim>.get\\_function\\_values()](classFEValuesBase.html#a33e437195106aee8e3ad88b2dd40d223) in the case of deal.II) only collects values for the local cell (just a subset of the patch).\n\nThe actual implementation will deviate from above code in one key aspect: the time-step size \\(\\tau\\) has to be chosen subject to a CFL condition\n\n\\begin{align\\*}\n\\tau\\_n = c\\_{\\text{cfl}}\\,\\min\\_{\ni\\in\\mathcal{V}}\\left(\\frac{m\\_i}{-2\\,d\\_{ii}^{n}}\\right),\n\\end{align\\*}\n\nwhere \\(0<c\\_{\\text{cfl}}\\le1\\) is a chosen constant. This will require to compute all \\(d\\_{ij}\\) in a separate step prior to actually performing above update. The core principle remains unchanged, though: we do not loop over cells but rather over all edges of the sparsity graph.\n\nNote\n:   It is not uncommon to encounter such fully-algebraic schemes (i.e. no bilinear forms, no cell loops, and no quadrature) outside of the finite element community in the wider CFD community. There is a rich history of application of this kind of schemes, also called *edge-based* or *graph-based* finite element schemes (see for instance [[147]](citelist.html#CITEREF_Rainald2008) for a historical overview). However, it is important to highlight that the algebraic structure of the scheme (presented in this tutorial) and the node-loops are not just a performance gimmick. Actually, the structure of this scheme was born out of theoretical necessity: the proof of pointwise stability of the scheme hinges on the specific algebraic structure of the scheme. In addition, it is not possible to compute the algebraic viscosities \\(d\\_{ij}\\) using cell-loops since they depend nonlinearly on information that spans more than one cell (superposition does not hold: adding contributions from separate cells does not lead to the right result).\n\n### Stable boundary conditions and conservation properties.\n\nIn the example considered in this tutorial step we use three different types of boundary conditions: essential-like boundary conditions (we prescribe a state at the left boundary of our domain), outflow boundary conditions (also called \"do-nothing\" boundary conditions) at the right boundary of the domain, and \"reflecting\" boundary conditions \\(\\mathbf{m} \\cdot\n\\boldsymbol{\\nu} = 0\\) (also called \"slip\" boundary conditions) at the top, bottom, and surface of the obstacle. We will not discuss much about essential and \"do-nothing\" boundary conditions since their implementation is relatively easy and the reader will be able to pick-up the implementation directly from the (documented) source code. In this portion of the introduction we will focus only on the \"reflecting\" boundary conditions which are somewhat more tricky.\n\nNote\n:   At the time of this writing (early 2020) it is not unreasonable to say that both analysis and implementation of stable boundary conditions for hyperbolic systems of conservation laws is an open issue. For the case of variational formulations, stable boundary conditions are those leading to a well-posed (coercive) bilinear form. But for general hyperbolic systems of conservation laws (and for the algebraic formulation used in this tutorial) coercivity has no applicability and/or meaning as a notion of stability. In this tutorial step we will use preservation of the invariant set as our main notion of stability which (at the very least) guarantees well-posedness of the discrete problem.\n\nFor the case of the reflecting boundary conditions we will proceed as follows:\n\n* For every time step advance in time satisfying no boundary condition at all.\n* Let \\(\\partial\\Omega^r\\) be the portion of the boundary where we want to enforce reflecting boundary conditions. At the end of the time step we enforce reflecting boundary conditions strongly in a post-processing step where we execute the projection\n\n  \\begin{align\\*}\n  \\mathbf{m}\\_i \\dealcoloneq \\mathbf{m}\\_i - (\\widehat{\\boldsymbol{\\nu}}\\_i\n  \\cdot \\mathbf{m}\\_i) \\widehat{\\boldsymbol{\\nu}}\\_i \\ \\\n  \\text{where} \\ \\\n  \\widehat{\\boldsymbol{\\nu}}\\_i \\dealcoloneq\n  \\frac{\\int\\_{\\partial\\Omega} \\phi\\_i \\widehat{\\boldsymbol{\\nu}} \\,\n  \\, \\mathrm{d}\\mathbf{s}}{\\big|\\int\\_{\\partial\\Omega} \\phi\\_i\n  \\widehat{\\boldsymbol{\\nu}} \\, \\mathrm{d}\\mathbf{s}\\big|}\n  \\ \\ \\text{for all }\\mathbf{x}\\_i \\in \\partial\\Omega^r\n  \\ \\ \\ \\ \\boldsymbol{(1)}\n  \\end{align\\*}\n\n  that removes the normal component of \\(\\mathbf{m}\\). This is a somewhat naive idea that preserves a few fundamental properties of the PDE as we explain below.\n\nThis is approach is usually called \"explicit treatment of boundary conditions\". The well seasoned finite element person might find this approach questionable. No doubt, when solving parabolic, or elliptic equations, we typically enforce essential (Dirichlet-like) boundary conditions by making them part of the approximation space \\(\\mathbb{V}\\), and treat natural (e.g. Neumann) boundary conditions as part of the variational formulation. We also know that explicit treatment of boundary conditions (in the context of parabolic PDEs) almost surely leads to catastrophic consequences. However, in the context of nonlinear hyperbolic equations we have that:\n\n* It is relatively easy to prove that (for the case of reflecting boundary conditions) explicit treatment of boundary conditions is not only conservative but also guarantees preservation of the property \\(\\mathbf{U}\\_i \\in \\mathcal{B}\\) for all \\(i \\in \\mathcal{V}\\) (well-posedness). This is perhaps the most important reason to use explicit enforcement of boundary conditions.\n* To the best of our knowledge: we are not aware of any mathematical result proving that it is possible to guarantee the property \\(\\mathbf{U}\\_i \\in\n  \\mathcal{B}\\) for all \\(i \\in \\mathcal{V}\\) when using either direct enforcement of boundary conditions into the approximation space, or weak enforcement using the Nitsche penalty method (which is for example widely used in discontinuous Galerkin schemes). In addition, some of these traditional ideas lead to quite restrictive time step constraints.\n* There is enough numerical evidence suggesting that explicit treatment of Dirichlet-like boundary conditions is stable under CFL conditions and does not introduce any loss in accuracy.\n\nIf \\(\\mathbf{u}\\_t + \\text{div} \\, \\mathbb{f}(\\mathbf{u}) = \\boldsymbol{0}\\) represents Euler's equation with reflecting boundary conditions on the entirety of the boundary (i.e. \\(\\partial\\Omega^r \\equiv \\partial\\Omega\\)) and we integrate in space and time \\(\\int\\_{\\Omega}\\int\\_{t\\_1}^{t\\_2}\\) we would obtain\n\n\\begin{align\\*}\n\\int\\_{\\Omega} \\rho(\\mathbf{x},t\\_2) \\, \\mathrm{d}\\mathbf{x} =\n\\int\\_{\\Omega} \\rho(\\mathbf{x},t\\_1) \\, \\mathrm{d}\\mathbf{x} \\ , \\ \\\n\\int\\_{\\Omega} \\mathbf{m}(\\mathbf{x},t\\_2) \\, \\mathrm{d}\\mathbf{x}\n+ \\int\\_{t\\_1}^{t\\_2} \\! \\int\\_{\\partial\\Omega} p \\boldsymbol{\\nu} \\,\n\\mathrm{d}\\mathbf{s} \\mathrm{d}t =\n\\int\\_{\\Omega} \\mathbf{m}(\\mathbf{x},t\\_1) \\,\n\\mathrm{d}\\mathbf{x} \\ , \\ \\\n\\int\\_{\\Omega} E(\\mathbf{x},t\\_2) \\, \\mathrm{d}\\mathbf{x} =\n\\int\\_{\\Omega} E(\\mathbf{x},t\\_1) \\, \\mathrm{d}\\mathbf{x} \\ \\ \\ \\\n\\boldsymbol{(2)}\n\\end{align\\*}\n\nNote that momentum is NOT a conserved quantity (interaction with walls leads to momentum gain/loss): however \\(\\mathbf{m}\\) has to satisfy a momentum balance. Even though we will not use reflecting boundary conditions in the entirety of the domain, we would like to know that our implementation of reflecting boundary conditions is consistent with the conservation properties mentioned above. In particular, if we use the projection \\(\\boldsymbol{(1)}\\) in the entirety of the domain the following discrete mass-balance can be guaranteed:\n\n\\begin{align\\*}\n\\sum\\_{i \\in \\mathcal{V}} m\\_i \\rho\\_i^{n+1} =\n\\sum\\_{i \\in \\mathcal{V}} m\\_i \\rho\\_i^{n} \\ , \\ \\\n\\sum\\_{i \\in \\mathcal{V}} m\\_i \\mathbf{m}\\_i^{n+1}\n+ \\tau\\_n \\int\\_{\\partial\\Omega} \\Big(\\sum\\_{i \\in \\mathcal{V}} p\\_i^{n} \\phi\\_i\\Big)\n\\widehat{\\boldsymbol{\\nu}} \\mathrm{d}\\mathbf{s} =\n\\sum\\_{i \\in \\mathcal{V}} m\\_i \\mathbf{m}\\_i^{n} \\ , \\ \\\n\\sum\\_{i \\in \\mathcal{V}} m\\_i E\\_i^{n+1} = \\sum\\_{i \\in \\mathcal{V}} m\\_i\nE\\_i^{n} \\ \\ \\ \\\n\\boldsymbol{(3)}\n\\end{align\\*}\n\nwhere \\(p\\_i\\) is the pressure at the nodes that lie at the boundary. Clearly \\(\\boldsymbol{(3)}\\) is the discrete counterpart of \\(\\boldsymbol{(2)}\\). The proof of identity \\(\\boldsymbol{(3)}\\) is omitted, but we briefly mention that it hinges on the definition of the *nodal normal* \\(\\widehat{\\boldsymbol{\\nu}}\\_i\\) provided in \\(\\boldsymbol{(1)}\\). We also note that this enforcement of reflecting boundary conditions is different from the one originally advanced in [[107]](citelist.html#CITEREF_GuermondEtAl2018).\n\nThe commented program\n=====================\n\n### Include files\n\nThe set of include files is quite standard. The most intriguing part is the fact that we will rely solely on deal.II data structures for MPI parallelization, in particular [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) and [LinearAlgebra::distributed::Vector](classLinearAlgebra_1_1distributed_1_1Vector.html) included through `distributed/tria.h` and `lac/la_parallel_vector.h`. Instead of a Trilinos, or PETSc specific matrix class, we will use a non-distributed [SparseMatrix](classSparseMatrix.html) (`lac/sparse_matrix.h`) to store the local part of the \\(\\mathbf{c}\\_{ij}\\), \\(\\mathbf{n}\\_{ij}\\) and \\(d\\_{ij}\\) matrices.\n\n```\n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/parallel.h>\n   #include <deal.II/base/parameter_acceptor.h>\n   #include <deal.II/base/partitioner.h>\n   #include <deal.II/base/quadrature.h>\n   #include <deal.II/base/timer.h>\n   #include <deal.II/base/work_stream.h>\n   \n   #include <deal.II/distributed/solution_transfer.h>\n   #include <deal.II/distributed/tria.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe.h>\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/fe/mapping.h>\n   #include <deal.II/fe/mapping_q.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/manifold_lib.h>\n   \n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/la_parallel_vector.h>\n   #include <deal.II/lac/sparse_matrix.h>\n   #include <deal.II/lac/sparse_matrix.templates.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/meshworker/scratch_data.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nIn addition to above deal.II specific includes, we also include four boost headers. The first two are for binary archives that we will use for implementing a check-pointing and restart mechanism.\n\n```\n   #include <boost/archive/binary_iarchive.hpp>\n   #include <boost/archive/binary_oarchive.hpp>\n```\n\nThe last two header files are for creating custom iterator ranges over integer intervals.\n\n```\n   #include <deal.II/base/std_cxx20/iota_view.h>\n   #include <boost/range/iterator_range.hpp>\n```\n\nFor std::isnan, std::isinf, std::ifstream, std::async, and std::future\n\n```\n   #include <cmath>\n   #include <fstream>\n   #include <future>\n```\n\n### Class template declarations\n\nWe begin our actual implementation by declaring all classes with their data structures and methods upfront. In contrast to previous example steps we use a more fine-grained encapsulation of concepts, data structures, and parameters into individual classes. A single class thus usually centers around either a single data structure (such as the [Triangulation](classTriangulation.html)) in the `Discretization` class, or a single method (such as the `make_one_step()` function of the `TimeStepping` class). We typically declare parameter variables and scratch data object `private` and make methods and data structures used by other classes `public`.\n\nNote\n:   A cleaner approach would be to guard access to all data structures by [getter/setter functions](https://en.wikipedia.org/wiki/Mutator_method). For the sake of brevity, we refrain from that approach, though.\n\nWe also note that the vast majority of classes is derived from [ParameterAcceptor](classParameterAcceptor.html). This facilitates the population of all the global parameters into a single (global) [ParameterHandler](classParameterHandler.html). More explanations about the use of inheritance from [ParameterAcceptor](classParameterAcceptor.html) as a global subscription mechanism can be found in [step-60](step_60.html).\n\n```\n   namespace Step69\n   {\n     using namespace dealii;\n```\n\nWe start with defining a number of [types::boundary\\_id](namespacetypes.html#a10c23e1699231bd1fac0ebdd1890095d) constants used throughout the tutorial step. This allows us to refer to boundary types by a mnemonic (such as `do_nothing`) rather than a numerical value.\n\n```\n     namespace Boundaries\n     {\n       constexpr types::boundary_id do_nothing = 0;\n       constexpr types::boundary_id free_slip  = 1;\n       constexpr types::boundary_id dirichlet  = 2;\n     } // namespace Boundaries\n```\n\n#### The `Discretization` class\n\nThe class `Discretization` contains all data structures concerning the mesh (triangulation) and discretization (mapping, finite element, quadrature) of the problem. As mentioned, we use the [ParameterAcceptor](classParameterAcceptor.html) class to automatically populate problem-specific parameters, such as the geometry information (`length`, etc.) or the refinement level (`refinement`) from a parameter file. This requires us to split the initialization of data structures into two functions: We initialize everything that does not depend on parameters in the constructor, and defer the creation of the mesh to the `setup()` method that can be called once all parameters are read in via [ParameterAcceptor::initialize()](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e).\n\n```\n     template <int dim>\n     class Discretization : public ParameterAcceptor\n     {\n     public:\n       Discretization(const MPI_Comm     mpi_communicator,\n                      TimerOutput       &computing_timer,\n                      const std::string &subsection = \"Discretization\");\n   \n       void setup();\n   \n       const MPI_Comm mpi_communicator;\n   \n       parallel::distributed::Triangulation<dim> triangulation;\n   \n       const MappingQ<dim>   mapping;\n       const FE_Q<dim>       finite_element;\n       const QGauss<dim>     quadrature;\n       const QGauss<dim - 1> face_quadrature;\n   \n       unsigned int refinement;\n   \n     private:\n       TimerOutput &computing_timer;\n   \n       double length;\n       double height;\n       double disk_position;\n       double disk_diameter;\n     };\n```\n\n#### The `OfflineData` class\n\nThe class `OfflineData` contains pretty much all components of the discretization that do not evolve in time, in particular, the [DoFHandler](classDoFHandler.html), [SparsityPattern](classSparsityPattern.html), boundary maps, the [lumped mass matrix](DEALGlossary.html#GlossLumpedMassMatrix), \\(\\mathbf{c}\\_{ij}\\) and \\(\\mathbf{n}\\_{ij}\\) matrices. Here, the term *offline* refers to the fact that all the class members of `OfflineData` have well-defined values independent of the current time step. This means that they can be initialized ahead of time (at *time step zero*) and are not meant to be modified at any later time step. For instance, the sparsity pattern should not change as we advance in time (we are not doing any form of adaptivity in space). Similarly, the entries of the lumped mass matrix should not be modified as we advance in time either.\n\nWe also compute and store a `boundary_normal_map` that contains a map from a global index of type [types::global\\_dof\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) of a boundary degree of freedom to a tuple consisting of a normal vector, the boundary id, and the position associated with the degree of freedom. We have to compute and store this geometric information in this class because we won't have access to geometric (or cell-based) information later on in the algebraic loops over the sparsity pattern.\n\nNote\n:   Even though this class currently does not have any parameters that could be read in from a parameter file we nevertheless derive from [ParameterAcceptor](classParameterAcceptor.html) and follow the same idiom of providing a `setup()` (and `assemble()`) method as for the class Discretization.\n\n```\n     template <int dim>\n     class OfflineData : public ParameterAcceptor\n     {\n     public:\n       using BoundaryNormalMap =\n         std::map<types::global_dof_index,\n                  std::tuple<Tensor<1, dim>, types::boundary_id, Point<dim>>>;\n   \n       OfflineData(const MPI_Comm             mpi_communicator,\n                   TimerOutput               &computing_timer,\n                   const Discretization<dim> &discretization,\n                   const std::string         &subsection = \"OfflineData\");\n   \n       void setup();\n       void assemble();\n   \n       DoFHandler<dim> dof_handler;\n   \n       std::shared_ptr<const Utilities::MPI::Partitioner> partitioner;\n   \n       unsigned int n_locally_owned;\n       unsigned int n_locally_relevant;\n   \n       SparsityPattern sparsity_pattern;\n   \n       BoundaryNormalMap boundary_normal_map;\n   \n       SparseMatrix<double>                  lumped_mass_matrix;\n       std::array<SparseMatrix<double>, dim> cij_matrix;\n       std::array<SparseMatrix<double>, dim> nij_matrix;\n       SparseMatrix<double>                  norm_matrix;\n   \n     private:\n       const MPI_Comm mpi_communicator;\n       TimerOutput   &computing_timer;\n   \n       SmartPointer<const Discretization<dim>> discretization;\n     };\n```\n\n#### The `ProblemDescription` class\n\nThe member functions of this class are utility functions and data structures specific to Euler's equations:\n\n* The type alias `state_type` is used for the states \\(\\mathbf{U}\\_i^n\\)\n* The type alias `flux_type` is used for the fluxes \\(\\mathbb{f}(\\mathbf{U}\\_j^n)\\).\n* The `momentum` function extracts \\(\\textbf{m}\\) out of the state vector \\([\\rho,\\textbf{m},E]\\) and stores it in a `Tensor<1, dim>`.\n* The `internal_energy` function computes \\(E -\n  \\frac{|\\textbf{m}|^2}{2\\rho}\\) from a given state vector \\([\\rho,\\textbf{m},E]\\).\n\nThe purpose of the class members `component_names`, `pressure`, and `speed_of_sound` is evident from their names. We also provide a function `compute_lambda_max()`, that computes the wave speed estimate mentioned above, \\(\\lambda\\_{max}(\\mathbf{U},\\mathbf{V},\\mathbf{n})\\), which is used in the computation of the \\(d\\_{ij}\\) matrix.\n\nNote\n:   The `DEAL_II_ALWAYS_INLINE` macro expands to a (compiler specific) pragma that ensures that the corresponding function defined in this class is always inlined, i.e., the function body is put in place for every invocation of the function, and no call (and code indirection) is generated. This is stronger than the `inline` keyword, which is more or less a (mild) suggestion to the compiler that the programmer thinks it would be beneficial to inline the function. `DEAL_II_ALWAYS_INLINE` should only be used rarely and with caution in situations such as this one, where we actually know (due to benchmarking) that inlining the function in question improves performance.\n\nFinally, we observe that this is the only class in this tutorial step that is tied to a particular \"physics\" or \"hyperbolic conservation\nlaw\" (in this case Euler's equations). All the other classes are primarily \"discretization\" classes, very much agnostic of the particular physics being solved.\n\n```\n     template <int dim>\n     class ProblemDescription\n     {\n     public:\n       static constexpr unsigned int n_solution_variables = 2 + dim;\n   \n       using state_type = Tensor<1, n_solution_variables>;\n       using flux_type  = Tensor<1, n_solution_variables, Tensor<1, dim>>;\n   \n       const static std::array<std::string, n_solution_variables> component_names;\n   \n       static constexpr double gamma = 7. / 5.;\n   \n       static DEAL_II_ALWAYS_INLINE inline Tensor<1, dim>\n       momentum(const state_type &U);\n   \n       static DEAL_II_ALWAYS_INLINE inline double\n       internal_energy(const state_type &U);\n   \n       static DEAL_II_ALWAYS_INLINE inline double pressure(const state_type &U);\n   \n       static DEAL_II_ALWAYS_INLINE inline double\n       speed_of_sound(const state_type &U);\n   \n       static DEAL_II_ALWAYS_INLINE inline flux_type flux(const state_type &U);\n   \n       static DEAL_II_ALWAYS_INLINE inline double\n       compute_lambda_max(const state_type     &U_i,\n                          const state_type     &U_j,\n                          const Tensor<1, dim> &n_ij);\n     };\n```\n\n#### The `InitialValues` class\n\nThe class `InitialValues`'s only public data attribute is a std::function `initial_state` that computes the initial state of a given point and time. This function is used for populating the initial flow field as well as setting Dirichlet boundary conditions (at inflow boundaries) explicitly in every time step.\n\nFor the purpose of this example step we simply implement a homogeneous uniform flow field for which the direction and a 1d primitive state (density, velocity, pressure) are read from the parameter file.\n\nIt would be desirable to initialize the class in a single shot: initialize/set the parameters and define the class members that depend on these default parameters. However, since we do not know the actual values for the parameters, this would be sort of meaningless and unsafe in general (we would like to have mechanisms to check the consistency of the input parameters). Instead of defining another `setup()` method to be called (by-hand) after the call to [ParameterAcceptor::initialize()](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) we provide an \"implementation\" for the class member `parse_parameters_call_back()` which is automatically called when invoking [ParameterAcceptor::initialize()](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) for every class that inherits from ParameterAceptor.\n\n```\n     template <int dim>\n     class InitialValues : public ParameterAcceptor\n     {\n     public:\n       using state_type = typename ProblemDescription<dim>::state_type;\n   \n       InitialValues(const std::string &subsection = \"InitialValues\");\n   \n       std::function<state_type(const Point<dim> &point, double t)> initial_state;\n   \n     private:\n```\n\nWe declare a private callback function that will be wired up to the [ParameterAcceptor::parse\\_parameters\\_call\\_back](classParameterAcceptor.html#ac7ab79c5ce7c43ddcd9277ed2c19f7fe) signal.\n\n```\n       void parse_parameters_callback();\n   \n       Tensor<1, dim> initial_direction;\n       Tensor<1, 3>   initial_1d_state;\n     };\n```\n\n#### The `TimeStepping` class\n\nWith the `OfflineData` and `ProblemDescription` classes at hand we can now implement the explicit time-stepping scheme that was introduced in the discussion above. The main method of the `TimeStepping` class is `make_one_step(vector_type &U,\nconst double t)` that takes a reference to a state vector `U` and a time point `t` (as input arguments) computes the updated solution, stores it in the vector `temp`, swaps its contents with the vector `U`, and finally returns the chosen step-size \\(\\tau\\).\n\nThe other important method is `prepare()` which primarily sets the proper partition and sparsity pattern for the temporary vector `temp` and the matrix `dij_matrix` respectively.\n\n```\n     template <int dim>\n     class TimeStepping : public ParameterAcceptor\n     {\n     public:\n       static constexpr unsigned int n_solution_variables =\n         ProblemDescription<dim>::n_solution_variables;\n   \n       using state_type = typename ProblemDescription<dim>::state_type;\n       using flux_type  = typename ProblemDescription<dim>::flux_type;\n   \n       using vector_type = std::array<LinearAlgebra::distributed::Vector<double>,\n                                      n_solution_variables>;\n   \n       TimeStepping(const MPI_Comm            mpi_communicator,\n                    TimerOutput              &computing_timer,\n                    const OfflineData<dim>   &offline_data,\n                    const InitialValues<dim> &initial_values,\n                    const std::string        &subsection = \"TimeStepping\");\n   \n       void prepare();\n   \n       double make_one_step(vector_type &U, const double t);\n   \n     private:\n       const MPI_Comm mpi_communicator;\n       TimerOutput   &computing_timer;\n   \n       SmartPointer<const OfflineData<dim>>   offline_data;\n       SmartPointer<const InitialValues<dim>> initial_values;\n   \n       SparseMatrix<double> dij_matrix;\n   \n       vector_type temporary_vector;\n   \n       double cfl_update;\n     };\n```\n\n#### The `SchlierenPostprocessor` class\n\nAt its core, the SchlierenPostprocessor class implements the class member `compute_schlieren()`. The main purpose of this class member is to compute an auxiliary finite element field `schlieren`, that is defined at each node by\n\n\\[ \\text{schlieren}[i] = e^{\\beta \\frac{ |\\nabla r\\_i|\n- \\min\\_j |\\nabla r\\_j| }{\\max\\_j |\\nabla r\\_j| - \\min\\_j |\\nabla r\\_j| } }, \\]\n\nwhere \\(r\\) can in principle be any scalar quantity. In practice though, the density is a natural candidate, viz. \\(r \\dealcoloneq \\rho\\). [Schlieren](https://en.wikipedia.org/wiki/Schlieren) postprocessing is a standard method for enhancing the contrast of a visualization inspired by actual experimental X-ray and shadowgraphy techniques of visualization. (See [step-67](step_67.html) for another example where we create a Schlieren plot.)\n\n```\n     template <int dim>\n     class SchlierenPostprocessor : public ParameterAcceptor\n     {\n     public:\n       static constexpr unsigned int n_solution_variables =\n         ProblemDescription<dim>::n_solution_variables;\n   \n       using state_type = typename ProblemDescription<dim>::state_type;\n   \n       using vector_type = std::array<LinearAlgebra::distributed::Vector<double>,\n                                      n_solution_variables>;\n   \n       SchlierenPostprocessor(\n         const MPI_Comm          mpi_communicator,\n         TimerOutput            &computing_timer,\n         const OfflineData<dim> &offline_data,\n         const std::string      &subsection = \"SchlierenPostprocessor\");\n   \n       void prepare();\n   \n       void compute_schlieren(const vector_type &U);\n   \n       LinearAlgebra::distributed::Vector<double> schlieren;\n   \n     private:\n       const MPI_Comm mpi_communicator;\n       TimerOutput   &computing_timer;\n   \n       SmartPointer<const OfflineData<dim>> offline_data;\n   \n       Vector<double> r;\n   \n       unsigned int schlieren_index;\n       double       schlieren_beta;\n     };\n```\n\n#### The `MainLoop` class\n\nNow, all that is left to do is to chain the methods implemented in the `TimeStepping`, `InitialValues`, and `SchlierenPostprocessor` classes together. We do this in a separate class `MainLoop` that contains an object of every class and again reads in a number of parameters with the help of the [ParameterAcceptor](classParameterAcceptor.html) class.\n\n```\n     template <int dim>\n     class MainLoop : public ParameterAcceptor\n     {\n     public:\n       using vector_type = typename TimeStepping<dim>::vector_type;\n   \n       MainLoop(const MPI_Comm mpi_communnicator);\n   \n       void run();\n   \n     private:\n       vector_type interpolate_initial_values(const double t = 0);\n   \n       void checkpoint(const vector_type &U,\n                       const std::string &name,\n                       double             t,\n                       unsigned int       cycle);\n   \n       void output(const vector_type &U,\n                   const std::string &name,\n                   double             t,\n                   unsigned int       cycle);\n   \n       const MPI_Comm     mpi_communicator;\n       std::ostringstream timer_output;\n       TimerOutput        computing_timer;\n   \n       ConditionalOStream pcout;\n   \n       std::string base_name;\n       double      t_final;\n       double      output_granularity;\n   \n       bool asynchronous_writeback;\n   \n       bool resume;\n   \n       Discretization<dim>         discretization;\n       OfflineData<dim>            offline_data;\n       InitialValues<dim>          initial_values;\n       TimeStepping<dim>           time_stepping;\n       SchlierenPostprocessor<dim> schlieren_postprocessor;\n   \n       vector_type output_vector;\n   \n       std::future<void> background_thread_state;\n     };\n```\n\n### Implementation\n\n#### Grid generation, setup of data structures\n\nThe first major task at hand is the typical triplet of grid generation, setup of data structures, and assembly. A notable novelty in this example step is the use of the [ParameterAcceptor](classParameterAcceptor.html) class that we use to populate parameter values: we first initialize the [ParameterAcceptor](classParameterAcceptor.html) class by calling its constructor with a string `subsection` denoting the correct subsection in the parameter file. Then, in the constructor body every parameter value is initialized to a sensible default value and registered with the [ParameterAcceptor](classParameterAcceptor.html) class with a call to [ParameterAcceptor::add\\_parameter()](classParameterAcceptor.html#af2a534c7f1ea5bfa165fa8a469744a5d).\n\n```\n     template <int dim>\n     Discretization<dim>::Discretization(const MPI_Comm     mpi_communicator,\n                                         TimerOutput       &computing_timer,\n                                         const std::string &subsection)\n       : ParameterAcceptor(subsection)\n       , mpi_communicator(mpi_communicator)\n       , triangulation(mpi_communicator)\n       , mapping(1)\n       , finite_element(1)\n       , quadrature(3)\n       , face_quadrature(3)\n       , computing_timer(computing_timer)\n     {\n       length = 4.;\n       add_parameter(\"length\", length, \"Length of computational domain\");\n   \n       height = 2.;\n       add_parameter(\"height\", height, \"Height of computational domain\");\n   \n       disk_position = 0.6;\n       add_parameter(\"object position\",\n                     disk_position,\n                     \"x position of immersed disk center point\");\n   \n       disk_diameter = 0.5;\n       add_parameter(\"object diameter\",\n                     disk_diameter,\n                     \"Diameter of immersed disk\");\n   \n       refinement = 5;\n       add_parameter(\"refinement\",\n                     refinement,\n                     \"Number of refinement steps of the geometry\");\n     }\n```\n\nNote that in the previous constructor we only passed the MPI communicator to the `triangulation` but we still have not initialized the underlying geometry/mesh. As mentioned earlier, we have to postpone this task to the `setup()` function that gets called after the [ParameterAcceptor::initialize()](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) function has populated all parameter variables with the final values read from the parameter file.\n\nThe `setup()` function is the last class member that has to be implemented. It creates the actual triangulation that is a benchmark configuration consisting of a channel with a disk obstacle, see [[107]](citelist.html#CITEREF_GuermondEtAl2018). We construct the geometry by modifying the mesh generated by [GridGenerator::hyper\\_cube\\_with\\_cylindrical\\_hole()](namespaceGridGenerator.html#a17568b9552c9b4f28c7345ad5431fece). We refer to [step-49](step_49.html), [step-53](step_53.html), and [step-54](step_54.html) for an overview how to create advanced meshes. We first create 4 temporary (non distributed) coarse triangulations that we stitch together with the GridGenerator::merge\\_triangulation() function. We center the disk at \\((0,0)\\) with a diameter of `disk_diameter`. The lower left corner of the channel has coordinates (`-disk_position`, `-height/2`) and the upper right corner has (`length-disk_position`, `height/2`).\n\n```\n     template <int dim>\n     void Discretization<dim>::setup()\n     {\n       TimerOutput::Scope scope(computing_timer, \"discretization - setup\");\n   \n       triangulation.clear();\n   \n       Triangulation<dim> tria1, tria2, tria3, tria4, tria5, tria6;\n   \n       GridGenerator::hyper_cube_with_cylindrical_hole(\n         tria1, disk_diameter / 2., disk_diameter, 0.5, 1, false);\n   \n       GridGenerator::subdivided_hyper_rectangle(\n         tria2,\n         {2, 1},\n         Point<2>(-disk_diameter, disk_diameter),\n         Point<2>(disk_diameter, height / 2.));\n   \n       GridGenerator::subdivided_hyper_rectangle(\n         tria3,\n         {2, 1},\n         Point<2>(-disk_diameter, -disk_diameter),\n         Point<2>(disk_diameter, -height / 2.));\n   \n       GridGenerator::subdivided_hyper_rectangle(\n         tria4,\n         {6, 2},\n         Point<2>(disk_diameter, -disk_diameter),\n         Point<2>(length - disk_position, disk_diameter));\n   \n       GridGenerator::subdivided_hyper_rectangle(\n         tria5,\n         {6, 1},\n         Point<2>(disk_diameter, disk_diameter),\n         Point<2>(length - disk_position, height / 2.));\n   \n       GridGenerator::subdivided_hyper_rectangle(\n         tria6,\n         {6, 1},\n         Point<2>(disk_diameter, -height / 2.),\n         Point<2>(length - disk_position, -disk_diameter));\n   \n       GridGenerator::merge_triangulations(\n         {&tria1, &tria2, &tria3, &tria4, &tria5, &tria6},\n         triangulation,\n         1.e-12,\n         true);\n   \n       triangulation.set_manifold(0, PolarManifold<2>(Point<2>()));\n```\n\nWe have to fix up the left edge that is currently located at \\(x=-\\)`disk_diameter` and has to be shifted to \\(x=-\\)`disk_position`. As a last step the boundary has to be colorized with `Boundaries::do_nothing` on the right, `dirichlet` on the left and `free_slip` on the upper and lower outer boundaries and the obstacle.\n\n```\n       for (const auto &cell : triangulation.active_cell_iterators())\n         {\n           for (const auto v : cell->vertex_indices())\n             {\n               if (cell->vertex(v)[0] <= -disk_diameter + 1.e-6)\n                 cell->vertex(v)[0] = -disk_position;\n             }\n         }\n   \n       for (const auto &cell : triangulation.active_cell_iterators())\n         {\n           for (const auto f : cell->face_indices())\n             {\n               const auto face = cell->face(f);\n   \n               if (face->at_boundary())\n                 {\n                   const auto center = face->center();\n   \n                   if (center[0] > length - disk_position - 1.e-6)\n                     face->set_boundary_id(Boundaries::do_nothing);\n                   else if (center[0] < -disk_position + 1.e-6)\n                     face->set_boundary_id(Boundaries::dirichlet);\n                   else\n                     face->set_boundary_id(Boundaries::free_slip);\n                 }\n             }\n         }\n     }\n```\n\n#### Assembly of offline matrices\n\nNot much is done in the constructor of `OfflineData` other than initializing the corresponding class members in the initialization list.\n\n```\n     template <int dim>\n     OfflineData<dim>::OfflineData(const MPI_Comm             mpi_communicator,\n                                   TimerOutput               &computing_timer,\n                                   const Discretization<dim> &discretization,\n                                   const std::string         &subsection)\n       : ParameterAcceptor(subsection)\n       , dof_handler(discretization.triangulation)\n       , mpi_communicator(mpi_communicator)\n       , computing_timer(computing_timer)\n       , discretization(&discretization)\n     {}\n```\n\nNow we can initialize the [DoFHandler](classDoFHandler.html), extract the [IndexSet](classIndexSet.html) objects for locally owned and locally relevant DOFs, and initialize a [Utilities::MPI::Partitioner](classUtilities_1_1MPI_1_1Partitioner.html) object that is needed for distributed vectors.\n\n```\n     template <int dim>\n     void OfflineData<dim>::setup()\n     {\n       IndexSet locally_owned;\n       IndexSet locally_relevant;\n   \n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"offline_data - distribute dofs\");\n   \n         dof_handler.distribute_dofs(discretization->finite_element);\n   \n         locally_owned   = dof_handler.locally_owned_dofs();\n         n_locally_owned = locally_owned.n_elements();\n   \n         locally_relevant   = DoFTools::extract_locally_relevant_dofs(dof_handler);\n         n_locally_relevant = locally_relevant.n_elements();\n   \n         partitioner =\n           std::make_shared<Utilities::MPI::Partitioner>(locally_owned,\n                                                         locally_relevant,\n                                                         mpi_communicator);\n       }\n```\n\n#### Translation to local index ranges\n\nWe are now in a position to create the sparsity pattern for our matrices. There are quite a few peculiarities that need a detailed explanation. We avoid using a distributed matrix class (as for example provided by Trilinos or PETSc) and instead rely on deal.II's own [SparseMatrix](classSparseMatrix.html) object to store the local part of all matrices. This design decision is motivated by the fact that (a) we actually never perform a matrix-vector multiplication, and (b) we can always assemble the local part of a matrix exclusively on a given MPI rank. Instead, we will compute nonlinear updates while iterating over (the local part) of a connectivity stencil; a task for which deal.II's own [SparsityPattern](classSparsityPattern.html) is specifically optimized for.\n\nThis design consideration has a caveat, though. What makes the deal.II [SparseMatrix](classSparseMatrix.html) class fast is the [compressed row storage (CSR)](https://en.wikipedia.org/wiki/Sparse_matrix) used in the [SparsityPattern](classSparsityPattern.html) (see [Sparsity patterns](group__Sparsity.html)). This, unfortunately, does not play nicely with a global distributed index range because a sparsity pattern with CSR cannot contain \"holes\" in the index range. The distributed matrices offered by deal.II avoid this by translating from a global index range into a contiguous local index range. But this is precisely the type of index manipulation we want to avoid in our iteration over the stencil because it creates a measurable overhead.\n\nThe [Utilities::MPI::Partitioner](classUtilities_1_1MPI_1_1Partitioner.html) class already implements the translation from a global index range to a contiguous local (per MPI rank) index range: we don't have to reinvent the wheel. We just need to use that translation capability (once and only once) in order to create a \"local\" sparsity pattern for the contiguous index range \\([0,\\)`n_locally_relevant` \\()\\). That capability can be invoked by the [Utilities::MPI::Partitioner::global\\_to\\_local()](classUtilities_1_1MPI_1_1Partitioner.html#a11316c010d3d51912cdfe1939651ad72) function. Once the sparsity pattern is created using local indices, all that is left to do is to ensure that (when implementing our scatter and gather auxiliary functions) we always access elements of a distributed vector by a call to [LinearAlgebra::distributed::Vector::local\\_element()](classLinearAlgebra_1_1distributed_1_1Vector.html#a1c4bc946b94f19d7e11c00f41a39db02). This way we avoid index translations altogether and operate exclusively with local indices.\n\n```\n       {\n         TimerOutput::Scope scope(\n           computing_timer,\n           \"offline_data - create sparsity pattern and set up matrices\");\n```\n\nWe have to create the \"local\" sparsity pattern by hand. We therefore loop over all locally owned and ghosted cells (see [GlossArtificialCell](DEALGlossary.html#GlossArtificialCell)) and extract the (global) `dof_indices` associated with the cell DOFs and renumber them using `partitioner->global_to_local(index)`.\n\nNote\n:   In the case of a locally owned dof, such renumbering consist of applying a shift (i.e. we subtract an offset) such that now they will become a number in the integer interval \\([0,\\)`n_locally_owned` \\()\\). However, in the case of a ghosted dof (i.e. not locally owned) the situation is quite different, since the global indices associated with ghosted DOFs will not be (in general) a contiguous set of integers.\n\n```\n           DynamicSparsityPattern dsp(n_locally_relevant, n_locally_relevant);\n     \n           const auto dofs_per_cell =\n             discretization->finite_element.n_dofs_per_cell();\n           std::vector<types::global_dof_index> dof_indices(dofs_per_cell);\n     \n           for (const auto &cell : dof_handler.active_cell_iterators())\n             {\n               if (cell->is_artificial())\n                 continue;\n     \n               /* We transform the set of global dof indices on the cell to the\n*               * corresponding \"local\" index range on the MPI process: */\n               cell->get_dof_indices(dof_indices);\n               std::transform(dof_indices.begin(),\n                              dof_indices.end(),\n                              dof_indices.begin(),\n                              [&](types::global_dof_index index) {\n                                return partitioner->global_to_local(index);\n                              });\n     \n               /* And simply add, for each dof, a coupling to all other \"local\"\n*               * dofs on the cell: */\n               for (const auto dof : dof_indices)\n                 dsp.add_entries(dof, dof_indices.begin(), dof_indices.end());\n             }\n     \n           sparsity_pattern.copy_from(dsp);\n     \n           lumped_mass_matrix.reinit(sparsity_pattern);\n           norm_matrix.reinit(sparsity_pattern);\n           for (auto &matrix : cij_matrix)\n             matrix.reinit(sparsity_pattern);\n           for (auto &matrix : nij_matrix)\n             matrix.reinit(sparsity_pattern);\n         }\n       }\n```\n\nThis concludes the setup of the [DoFHandler](classDoFHandler.html) and [SparseMatrix](classSparseMatrix.html) objects. Next, we have to assemble various matrices. We define a number of helper functions and data structures in an anonymous namespace.\n\n```\n     namespace\n     {\n```\n\n`CopyData` class that will be used to assemble the offline data matrices using [WorkStream](namespaceWorkStream.html). It acts as a container: it is just a struct where [WorkStream](namespaceWorkStream.html) stores the local cell contributions. Note that it also contains a class member `local_boundary_normal_map` used to store the local contributions required to compute the normals at the boundary.\n\n```\n       template <int dim>\n       struct CopyData\n       {\n         bool                                         is_artificial;\n         std::vector<types::global_dof_index>         local_dof_indices;\n         typename OfflineData<dim>::BoundaryNormalMap local_boundary_normal_map;\n         FullMatrix<double>                           cell_lumped_mass_matrix;\n         std::array<FullMatrix<double>, dim>          cell_cij_matrix;\n       };\n```\n\nNext we introduce a number of helper functions that are all concerned about reading and writing matrix and vector entries. They are mainly motivated by providing slightly more efficient code and [syntactic sugar](https://en.wikipedia.org/wiki/Syntactic_sugar) for otherwise somewhat tedious code.\n\nThe first function we introduce, `get_entry()`, will be used to read the value stored at the entry pointed by a [SparsityPattern](classSparsityPattern.html) iterator `it` of `matrix`. The function works around a small deficiency in the [SparseMatrix](classSparseMatrix.html) interface: The [SparsityPattern](classSparsityPattern.html) is concerned with all index operations of the sparse matrix stored in CRS format. As such the iterator already knows the global index of the corresponding matrix entry in the low-level vector stored in the [SparseMatrix](classSparseMatrix.html) object. Due to the lack of an interface in the [SparseMatrix](classSparseMatrix.html) for accessing the element directly with a [SparsityPattern](classSparsityPattern.html) iterator, we unfortunately have to create a temporary [SparseMatrix](classSparseMatrix.html) iterator. We simply hide this in the `get_entry()` function.\n\n```\n       template <typename IteratorType>\n       DEAL_II_ALWAYS_INLINE inline SparseMatrix<double>::value_type\n       get_entry(const SparseMatrix<double> &matrix, const IteratorType &it)\n       {\n         const SparseMatrix<double>::const_iterator matrix_iterator(\n           &matrix, it->global_index());\n         return matrix_iterator->value();\n       }\n```\n\nThe `set_entry()` helper is the inverse operation of `get_value()`: Given an iterator and a value, it sets the entry pointed to by the iterator in the matrix.\n\n```\n       template <typename IteratorType>\n       DEAL_II_ALWAYS_INLINE inline void\n       set_entry(SparseMatrix<double>            &matrix,\n                 const IteratorType              &it,\n                 SparseMatrix<double>::value_type value)\n       {\n         SparseMatrix<double>::iterator matrix_iterator(&matrix,\n                                                        it->global_index());\n         matrix_iterator->value() = value;\n       }\n```\n\n`gather_get_entry()`: we note that \\(\\mathbf{c}\\_{ij} \\in\n\\mathbb{R}^d\\). If \\(d=2\\) then \\(\\mathbf{c}\\_{ij} =\n[\\mathbf{c}\\_{ij}^1,\\mathbf{c}\\_{ij}^2]^\\top\\). Which basically implies that we need one matrix per space dimension to store the \\(\\mathbf{c}\\_{ij}\\) vectors. Similar observation follows for the matrix \\(\\mathbf{n}\\_{ij}\\). The purpose of `gather_get_entry()` is to retrieve those entries and store them into a `Tensor<1, dim>` for our convenience.\n\n```\n       template <std::size_t k, typename IteratorType>\n       DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n       gather_get_entry(const std::array<SparseMatrix<double>, k> &c_ij,\n                        const IteratorType                         it)\n       {\n         Tensor<1, k> result;\n         for (unsigned int j = 0; j < k; ++j)\n           result[j] = get_entry(c_ij[j], it);\n         return result;\n       }\n```\n\n`gather()` (first interface): this first function signature, having three input arguments, will be used to retrieve the individual components `(i,l)` of a matrix. The functionality of `gather_get_entry()` and `gather()` is very much the same, but their context is different: the function `gather()` does not rely on an iterator (that actually knows the value pointed to) but rather on the indices `(i,l)` of the entry in order to retrieve its actual value. We should expect `gather()` to be slightly more expensive than `gather_get_entry()`. The use of `gather()` will be limited to the task of computing the algebraic viscosity \\(d\\_{ij}\\) in the particular case that when both \\(i\\) and \\(j\\) lie at the boundary.\n\nNote\n:   The reader should be aware that accessing an arbitrary `(i,l)` entry of a matrix (say for instance Trilinos or PETSc matrices) is in general unacceptably expensive. Here is where we might want to keep an eye on complexity: we want this operation to have constant complexity, which is the case of the current implementation using deal.II matrices.\n\n```\n       template <std::size_t k>\n       DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n       gather(const std::array<SparseMatrix<double>, k> &n_ij,\n              const unsigned int                         i,\n              const unsigned int                         j)\n       {\n         Tensor<1, k> result;\n         for (unsigned int l = 0; l < k; ++l)\n           result[l] = n_ij[l](i, j);\n         return result;\n       }\n```\n\n`gather()` (second interface): this second function signature having two input arguments will be used to gather the state at a node `i` and return it as a `Tensor<1,n_solution_variables>` for our convenience.\n\n```\n       template <std::size_t k>\n       DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n       gather(const std::array<LinearAlgebra::distributed::Vector<double>, k> &U,\n              const unsigned int                                               i)\n       {\n         Tensor<1, k> result;\n         for (unsigned int j = 0; j < k; ++j)\n           result[j] = U[j].local_element(i);\n         return result;\n       }\n```\n\n`scatter()`: this function has three input arguments, the first one is meant to be a \"global object\" (say a locally owned or locally relevant vector), the second argument which could be a `Tensor<1,n_solution_variables>`, and the last argument which represents a index of the global object. This function will be primarily used to write the updated nodal values, stored as `Tensor<1,n_solution_variables>`, into the global objects.\n\n```\n       template <std::size_t k, int k2>\n       DEAL_II_ALWAYS_INLINE inline void\n       scatter(std::array<LinearAlgebra::distributed::Vector<double>, k> &U,\n               const Tensor<1, k2>                                       &tensor,\n               const unsigned int                                         i)\n       {\n         static_assert(k == k2,\n                       \"The dimensions of the input arguments must agree\");\n         for (unsigned int j = 0; j < k; ++j)\n           U[j].local_element(i) = tensor[j];\n       }\n     } // namespace\n```\n\nWe are now in a position to assemble all matrices stored in `OfflineData`: the lumped mass entries \\(m\\_i\\), the vector-valued matrices \\(\\mathbf{c}\\_{ij}\\) and \\(\\mathbf{n}\\_{ij} =\n\\frac{\\mathbf{c}\\_{ij}}{|\\mathbf{c}\\_{ij}|}\\), and the boundary normals \\(\\boldsymbol{\\nu}\\_i\\).\n\nIn order to exploit thread parallelization we use the [WorkStream](namespaceWorkStream.html) approach detailed in the [Parallel computing with multiple processors](group__threads.html) accessing shared memory. As customary this requires definition of\n\n* Scratch data (i.e. input info required to carry out computations): in this case it is `scratch_data`.\n* The worker: in our case this is the `local_assemble_system()` function that actually computes the local (i.e. current cell) contributions from the scratch data.\n* A copy data: a struct that contains all the local assembly contributions, in this case `CopyData<dim>()`.\n* A copy data routine: in this case it is `copy_local_to_global()` in charge of actually copying these local contributions into the global objects (matrices and/or vectors)\n\nMost of the following lines are spent in the definition of the worker `local_assemble_system()` and the copy data routine `copy_local_to_global()`. There is not much to say about the [WorkStream](namespaceWorkStream.html) framework since the vast majority of ideas are reasonably well-documented in [step-9](step_9.html), [step-13](step_13.html) and [step-32](step_32.html) among others.\n\nFinally, assuming that \\(\\mathbf{x}\\_i\\) is a support point at the boundary, the (nodal) normals are defined as:\n\n\\begin{align\\*}\n\\widehat{\\boldsymbol{\\nu}}\\_i \\dealcoloneq\n\\frac{\\int\\_{\\partial\\Omega} \\phi\\_i \\widehat{\\boldsymbol{\\nu}} \\,\n\\, \\mathrm{d}\\mathbf{s}}{\\big|\\int\\_{\\partial\\Omega} \\phi\\_i\n\\widehat{\\boldsymbol{\\nu}} \\, \\mathrm{d}\\mathbf{s}\\big|}\n\\end{align\\*}\n\nWe will compute the numerator of this expression first and store it in `OfflineData<dim>::BoundaryNormalMap`. We will normalize these vectors in a posterior loop.\n\n```\n     template <int dim>\n     void OfflineData<dim>::assemble()\n     {\n       lumped_mass_matrix = 0.;\n       norm_matrix        = 0.;\n       for (auto &matrix : cij_matrix)\n         matrix = 0.;\n       for (auto &matrix : nij_matrix)\n         matrix = 0.;\n   \n       unsigned int dofs_per_cell =\n         discretization->finite_element.n_dofs_per_cell();\n       unsigned int n_q_points = discretization->quadrature.size();\n```\n\nWhat follows is the initialization of the scratch data required by [WorkStream](namespaceWorkStream.html)\n\n```\n       MeshWorker::ScratchData<dim> scratch_data(\n         discretization->mapping,\n         discretization->finite_element,\n         discretization->quadrature,\n         update_values | update_gradients | update_quadrature_points |\n           update_JxW_values,\n         discretization->face_quadrature,\n         update_normal_vectors | update_values | update_JxW_values);\n   \n       {\n         TimerOutput::Scope scope(\n           computing_timer,\n           \"offline_data - assemble lumped mass matrix, and c_ij\");\n   \n         const auto local_assemble_system = \n           [&](const typename DoFHandler<dim>::cell_iterator &cell,\n               MeshWorker::ScratchData<dim>                  &scratch,\n               CopyData<dim>                                 &copy) {\n             copy.is_artificial = cell->is_artificial();\n             if (copy.is_artificial)\n               return;\n   \n             copy.local_boundary_normal_map.clear();\n             copy.cell_lumped_mass_matrix.reinit(dofs_per_cell, dofs_per_cell);\n             for (auto &matrix : copy.cell_cij_matrix)\n               matrix.reinit(dofs_per_cell, dofs_per_cell);\n   \n             const auto &fe_values = scratch.reinit(cell);\n   \n             copy.local_dof_indices.resize(dofs_per_cell);\n             cell->get_dof_indices(copy.local_dof_indices);\n   \n             std::transform(copy.local_dof_indices.begin(),\n                            copy.local_dof_indices.end(),\n                            copy.local_dof_indices.begin(),\n                            [&](types::global_dof_index index) {\n                              return partitioner->global_to_local(index);\n                            });\n```\n\nWe compute the local contributions for the lumped mass matrix entries \\(m\\_i\\) and and vectors \\(c\\_{ij}\\) in the usual fashion:\n\n```\n             for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n               {\n                 const auto JxW = fe_values.JxW(q_point);\n   \n                 for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                   {\n                     const auto value_JxW =\n                       fe_values.shape_value(j, q_point) * JxW;\n                     const auto grad_JxW = fe_values.shape_grad(j, q_point) * JxW;\n   \n                     copy.cell_lumped_mass_matrix(j, j) += value_JxW;\n   \n                     for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                       {\n                         const auto value = fe_values.shape_value(i, q_point);\n                         for (unsigned int d = 0; d < dim; ++d)\n                           copy.cell_cij_matrix[d](i, j) += value * grad_JxW[d];\n   \n                       } /* i */\n                   }     /* j */\n               }         /* q */\n```\n\nNow we have to compute the boundary normals. Note that the following loop does not do much unless the element has faces on the boundary of the domain.\n\n```\n             for (const auto f : cell->face_indices())\n               {\n                 const auto face = cell->face(f);\n                 const auto id   = face->boundary_id();\n   \n                 if (!face->at_boundary())\n                   continue;\n   \n                 const auto &fe_face_values = scratch.reinit(cell, f);\n   \n                 const unsigned int n_face_q_points =\n                   fe_face_values.get_quadrature().size();\n   \n                 for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                   {\n                     if (!discretization->finite_element.has_support_on_face(j, f))\n                       continue;\n```\n\nNote that \"normal\" will only represent the contributions from one of the faces in the support of the shape function phi\\_j. So we cannot normalize this local contribution right here, we have to take it \"as is\", store it and pass it to the copy data routine. The proper normalization requires an additional loop on nodes. This is done in the copy function below.\n\n```\n                     Tensor<1, dim> normal;\n                     if (id == Boundaries::free_slip)\n                       {\n                         for (unsigned int q = 0; q < n_face_q_points; ++q)\n                           normal += fe_face_values.normal_vector(q) *\n                                     fe_face_values.shape_value(j, q);\n                       }\n   \n                     const auto index = copy.local_dof_indices[j];\n   \n                     Point<dim> position;\n                     for (const auto v : cell->vertex_indices())\n                       if (cell->vertex_dof_index(v, 0) ==\n                           partitioner->local_to_global(index))\n                         {\n                           position = cell->vertex(v);\n                           break;\n                         }\n   \n                     const auto old_id =\n                       std::get<1>(copy.local_boundary_normal_map[index]);\n                     copy.local_boundary_normal_map[index] =\n                       std::make_tuple(normal, std::max(old_id, id), position);\n                   }\n               }\n           };\n```\n\nLast, we provide a copy\\_local\\_to\\_global function as required for the [WorkStream](namespaceWorkStream.html)\n\n```\n         const auto copy_local_to_global = [&](const CopyData<dim> &copy) {\n           if (copy.is_artificial)\n             return;\n   \n           for (const auto &it : copy.local_boundary_normal_map)\n             {\n               std::get<0>(boundary_normal_map[it.first]) +=\n                 std::get<0>(it.second);\n               std::get<1>(boundary_normal_map[it.first]) =\n                 std::max(std::get<1>(boundary_normal_map[it.first]),\n                          std::get<1>(it.second));\n               std::get<2>(boundary_normal_map[it.first]) = std::get<2>(it.second);\n             }\n   \n           lumped_mass_matrix.add(copy.local_dof_indices,\n                                  copy.cell_lumped_mass_matrix);\n   \n           for (int k = 0; k < dim; ++k)\n             {\n               cij_matrix[k].add(copy.local_dof_indices, copy.cell_cij_matrix[k]);\n               nij_matrix[k].add(copy.local_dof_indices, copy.cell_cij_matrix[k]);\n             }\n         };\n   \n         WorkStream::run(dof_handler.begin_active(),\n                         dof_handler.end(),\n                         local_assemble_system,\n                         copy_local_to_global,\n                         scratch_data,\n                         CopyData<dim>());\n       }\n```\n\nAt this point in time we are done with the computation of \\(m\\_i\\) and \\(\\mathbf{c}\\_{ij}\\), but so far the matrix `nij_matrix` contains just a copy of the matrix `cij_matrix`. That's not what we really want: we have to normalize its entries. In addition, we have not filled the entries of the matrix `norm_matrix` and the vectors stored in the map `OfflineData<dim>::BoundaryNormalMap` are not normalized.\n\nIn principle, this is just offline data, it doesn't make much sense to over-optimize their computation, since their cost will get amortized over the many time steps that we are going to use. However, computing/storing the entries of the matrix `norm_matrix` and the normalization of `nij_matrix` are perfect to illustrate thread-parallel node-loops:\n\n* we want to visit every node \\(i\\) in the mesh/sparsity graph,\n* and for every such node we want to visit to every \\(j\\) such that \\(\\mathbf{c}\\_{ij} \\not \\equiv 0\\).\n\nFrom an algebraic point of view, this is equivalent to: visiting every row in the matrix and for each one of these rows execute a loop on the columns. Node-loops is a core theme of this tutorial step (see the pseudo-code in the introduction) that will repeat over and over again. That's why this is the right time to introduce them.\n\nWe have the thread parallelization capability [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) that is somehow more general than the [WorkStream](namespaceWorkStream.html) framework. In particular, [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) can be used for our node-loops. This functionality requires four input arguments which we explain in detail (for the specific case of our thread-parallel node loops):\n\n* The iterator `indices.begin()` points to a row index.\n* The iterator `indices.end()` points to a numerically higher row index.\n* The function `on_subranges(index_begin, index_end)` (where `index_begin` and `index_end` define a sub-range within the range spanned by the begin and end iterators defined in the two previous bullets) applies an operation to every iterator in such subrange. We may as well call `on_subranges` the \"worker\".\n* Grainsize: minimum number of iterators (in this case representing rows) processed by each thread. We decided for a minimum of 4096 rows.\n\nA minor caveat here is that the iterators `indices.begin()` and `indices.end()` supplied to [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) have to be random access iterators: internally, [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) will break the range defined by the `indices.begin()` and `indices.end()` iterators into subranges (we want to be able to read any entry in those subranges with constant complexity). In order to provide such iterators we resort to [std\\_cxx20::ranges::iota\\_view](namespacestd__cxx20_1_1ranges.html#a9dff050b99f7261ebe5f1e9488dab987).\n\nThe bulk of the following piece of code is spent defining the \"worker\" `on_subranges`: i.e. the operation applied at each row of the sub-range. Given a fixed `row_index` we want to visit every column/entry in such row. In order to execute such columns-loops we use [std::for\\_each](http://www.cplusplus.com/reference/algorithm/for_each/) from the standard library, where:\n\n* `sparsity_pattern.begin(row_index)` gives us an iterator starting at the first column of the row,\n* `sparsity_pattern.end(row_index)` is an iterator pointing at the last column of the row,\n* the last argument required by `std::for_each` is the operation applied at each nonzero entry (a lambda expression in this case) of such row.\n\nWe note that, [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) will operate on disjoint sets of rows (the subranges) and our goal is to write into these rows. Because of the simple nature of the operations we want to carry out (computation and storage of normals, and normalization of the \\(\\mathbf{c}\\_{ij}\\) of entries) threads cannot conflict attempting to write the same entry (we do not need a scheduler).\n\n```\n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"offline_data - compute |c_ij|, and n_ij\");\n   \n         const std_cxx20::ranges::iota_view<unsigned int, unsigned int> indices(\n           0, n_locally_relevant);\n   \n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             for (const auto row_index :\n                  std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                    *index_begin, *index_end))\n               {\n```\n\nFirst column-loop: we compute and store the entries of the matrix norm\\_matrix and write normalized entries into the matrix nij\\_matrix:\n\n```\n                 std::for_each(sparsity_pattern.begin(row_index),\n                               sparsity_pattern.end(row_index),\n                               [&](const SparsityPatternIterators::Accessor &jt) {\n                                 const auto c_ij =\n                                   gather_get_entry(cij_matrix, &jt);\n                                 const double norm = c_ij.norm();\n   \n                                 set_entry(norm_matrix, &jt, norm);\n                                 for (unsigned int j = 0; j < dim; ++j)\n                                   set_entry(nij_matrix[j], &jt, c_ij[j] / norm);\n                               });\n               }\n           };\n   \n         parallel::apply_to_subranges(indices.begin(),\n                                      indices.end(),\n                                      on_subranges,\n                                      4096);\n```\n\nFinally, we normalize the vectors stored in `OfflineData<dim>::BoundaryNormalMap`. This operation has not been thread parallelized as it would neither illustrate any important concept nor lead to any noticeable speed gain.\n\n```\n         for (auto &it : boundary_normal_map)\n           {\n             auto &normal = std::get<0>(it.second);\n             normal /= (normal.norm() + std::numeric_limits<double>::epsilon());\n           }\n       }\n     }\n```\n\nAt this point we are very much done with anything related to offline data.\n\n#### Equation of state and approximate Riemann solver\n\nIn this section we describe the implementation of the class members of the `ProblemDescription` class. Most of the code here is specific to the compressible Euler's equations with an ideal gas law. If we wanted to re-purpose [step-69](step_69.html) for a different conservation law (say for: instance the shallow water equation) most of the implementation of this class would have to change. But most of the other classes (in particular those defining loop structures) would remain unchanged.\n\nWe start by implementing a number of small member functions for computing `momentum`, `internal_energy`, `pressure`, `speed_of_sound`, and the flux `f` of the system. The functionality of each one of these functions is self-explanatory from their names.\n\n```\n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline Tensor<1, dim>\n     ProblemDescription<dim>::momentum(const state_type &U)\n     {\n       Tensor<1, dim> result;\n       std::copy_n(&U[1], dim, &result[0]);\n       return result;\n     }\n   \n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline double\n     ProblemDescription<dim>::internal_energy(const state_type &U)\n     {\n       const double &rho = U[0];\n       const auto    m   = momentum(U);\n       const double &E   = U[dim + 1];\n       return E - 0.5 * m.norm_square() / rho;\n     }\n   \n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline double\n     ProblemDescription<dim>::pressure(const state_type &U)\n     {\n       return (gamma - 1.) * internal_energy(U);\n     }\n   \n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline double\n     ProblemDescription<dim>::speed_of_sound(const state_type &U)\n     {\n       const double &rho = U[0];\n       const double  p   = pressure(U);\n   \n       return std::sqrt(gamma * p / rho);\n     }\n   \n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline typename ProblemDescription<dim>::flux_type\n     ProblemDescription<dim>::flux(const state_type &U)\n     {\n       const double &rho = U[0];\n       const auto    m   = momentum(U);\n       const auto    p   = pressure(U);\n       const double &E   = U[dim + 1];\n   \n       flux_type result;\n   \n       result[0] = m;\n       for (unsigned int i = 0; i < dim; ++i)\n         {\n           result[1 + i] = m * m[i] / rho;\n           result[1 + i][i] += p;\n         }\n       result[dim + 1] = m / rho * (E + p);\n   \n       return result;\n     }\n```\n\nNow we discuss the computation of \\(\\lambda\\_{\\text{max}}\n(\\mathbf{U}\\_i^{n},\\mathbf{U}\\_j^{n}, \\textbf{n}\\_{ij})\\). The analysis and derivation of sharp upper-bounds of maximum wavespeeds of Riemann problems is a very technical endeavor and we cannot include an advanced discussion about it in this tutorial. In this portion of the documentation we will limit ourselves to sketch the main functionality of our implementation functions and point to specific academic references in order to help the (interested) reader trace the source (and proper mathematical justification) of these ideas.\n\nIn general, obtaining a sharp guaranteed upper-bound on the maximum wavespeed requires solving a quite expensive scalar nonlinear problem. This is typically done with an iterative solver. In order to simplify the presentation in this example step we decided not to include such an iterative scheme. Instead, we will just use an initial guess as a guess for an upper bound on the maximum wavespeed. More precisely, equations (2.11) (3.7), (3.8) and (4.3) of [[105]](citelist.html#CITEREF_GuermondPopov2016b) are enough to define a guaranteed upper bound on the maximum wavespeed. This estimate is returned by a call to the function `lambda_max_two_rarefaction()`. At its core the construction of such an upper bound uses the so-called two-rarefaction approximation for the intermediate pressure \\(p^\\*\\), see for instance Equation (4.46), page 128 in [[78]](citelist.html#CITEREF_Toro2009).\n\nThe estimate returned by `lambda_max_two_rarefaction()` is guaranteed to be an upper bound, it is in general quite sharp, and overall sufficient for our purposes. However, for some specific situations (in particular when one of states is close to vacuum conditions) such an estimate will be overly pessimistic. That's why we used a second estimate to avoid this degeneracy that will be invoked by a call to the function `lambda_max_expansion()`. The most important function here is `compute_lambda_max()` which takes the minimum between the estimates returned by `lambda_max_two_rarefaction()` and `lambda_max_expansion()`.\n\nWe start again by defining a couple of helper functions:\n\nThe first function takes a state `U` and a unit vector `n_ij` and computes the *projected* 1d state in direction of the unit vector.\n\n```\n     namespace\n     {\n       template <int dim>\n       DEAL_II_ALWAYS_INLINE inline std::array<double, 4> riemann_data_from_state(\n         const typename ProblemDescription<dim>::state_type U,\n         const Tensor<1, dim>                              &n_ij)\n       {\n         Tensor<1, 3> projected_U;\n         projected_U[0] = U[0];\n```\n\nFor this, we have to change the momentum to \\(\\textbf{m}\\cdot\nn\\_{ij}\\) and have to subtract the kinetic energy of the perpendicular part from the total energy:\n\n```\n         const auto m   = ProblemDescription<dim>::momentum(U);\n         projected_U[1] = n_ij * m;\n   \n         const auto perpendicular_m = m - projected_U[1] * n_ij;\n         projected_U[2] = U[1 + dim] - 0.5 * perpendicular_m.norm_square() / U[0];\n```\n\nWe return the 1d state in *primitive* variables instead of conserved quantities. The return array consists of density \\(\\rho\\), velocity \\(u\\), pressure \\(p\\) and local speed of sound \\(a\\):\n\n```\n         return {{projected_U[0],\n                  projected_U[1] / projected_U[0],\n                  ProblemDescription<1>::pressure(projected_U),\n                  ProblemDescription<1>::speed_of_sound(projected_U)}};\n       }\n```\n\nAt this point we also define two small functions that return the positive and negative part of a double.\n\n```\n       DEAL_II_ALWAYS_INLINE inline double positive_part(const double number)\n       {\n         return std::max(number, 0.);\n       }\n   \n   \n       DEAL_II_ALWAYS_INLINE inline double negative_part(const double number)\n       {\n         return -std::min(number, 0.);\n       }\n```\n\nNext, we need two local wavenumbers that are defined in terms of a primitive state \\([\\rho, u, p, a]\\) and a given pressure \\(p^\\ast\\) [[106]](citelist.html#CITEREF_GuermondPopov2016) Eqn. (3.7):\n\n\\begin{align\\*}\n\\lambda^- = u - a\\,\\sqrt{1 + \\frac{\\gamma+1}{2\\gamma}\n\\left(\\frac{p^\\ast-p}{p}\\right)\\_+}\n\\end{align\\*}\n\nHere, the \\((\\cdot)\\_{+}\\) denotes the positive part of the given argument.\n\n```\n       DEAL_II_ALWAYS_INLINE inline double\n       lambda1_minus(const std::array<double, 4> &riemann_data,\n                     const double                 p_star)\n       {\n         /* Implements formula (3.7) in Guermond-Popov-2016 */\n   \n         constexpr double gamma = ProblemDescription<1>::gamma;\n         const auto       u     = riemann_data[1];\n         const auto       p     = riemann_data[2];\n         const auto       a     = riemann_data[3];\n   \n         const double factor = (gamma + 1.0) / 2.0 / gamma;\n         const double tmp    = positive_part((p_star - p) / p);\n         return u - a * std::sqrt(1.0 + factor * tmp);\n       }\n```\n\nAnalougously [[106]](citelist.html#CITEREF_GuermondPopov2016) Eqn. (3.8):\n\n\\begin{align\\*}\n\\lambda^+ = u + a\\,\\sqrt{1 + \\frac{\\gamma+1}{2\\gamma}\n\\left(\\frac{p^\\ast-p}{p}\\right)\\_+}\n\\end{align\\*}\n\n```\n       DEAL_II_ALWAYS_INLINE inline double\n       lambda3_plus(const std::array<double, 4> &riemann_data, const double p_star)\n       {\n         /* Implements formula (3.8) in Guermond-Popov-2016 */\n   \n         constexpr double gamma = ProblemDescription<1>::gamma;\n         const auto       u     = riemann_data[1];\n         const auto       p     = riemann_data[2];\n         const auto       a     = riemann_data[3];\n   \n         const double factor = (gamma + 1.0) / 2.0 / gamma;\n         const double tmp    = positive_part((p_star - p) / p);\n         return u + a * std::sqrt(1.0 + factor * tmp);\n       }\n```\n\nAll that is left to do is to compute the maximum of \\(\\lambda^-\\) and \\(\\lambda^+\\) computed from the left and right primitive state ([[106]](citelist.html#CITEREF_GuermondPopov2016) Eqn. (2.11)), where \\(p^\\ast\\) is given by [[106]](citelist.html#CITEREF_GuermondPopov2016) Eqn (4.3):\n\n```\n       DEAL_II_ALWAYS_INLINE inline double\n       lambda_max_two_rarefaction(const std::array<double, 4> &riemann_data_i,\n                                  const std::array<double, 4> &riemann_data_j)\n       {\n         constexpr double gamma = ProblemDescription<1>::gamma;\n         const auto       u_i   = riemann_data_i[1];\n         const auto       p_i   = riemann_data_i[2];\n         const auto       a_i   = riemann_data_i[3];\n         const auto       u_j   = riemann_data_j[1];\n         const auto       p_j   = riemann_data_j[2];\n         const auto       a_j   = riemann_data_j[3];\n   \n         const double numerator = a_i + a_j - (gamma - 1.) / 2. * (u_j - u_i);\n   \n         const double denominator =\n           a_i * std::pow(p_i / p_j, -1. * (gamma - 1.) / 2. / gamma) + a_j * 1.;\n   \n         /* Formula (4.3) in Guermond-Popov-2016 */\n   \n         const double p_star =\n           p_j * std::pow(numerator / denominator, 2. * gamma / (gamma - 1));\n   \n         const double lambda1 = lambda1_minus(riemann_data_i, p_star);\n         const double lambda3 = lambda3_plus(riemann_data_j, p_star);\n   \n         /* Formula (2.11) in Guermond-Popov-2016 */\n   \n         return std::max(positive_part(lambda3), negative_part(lambda1));\n       }\n```\n\nWe compute the second upper bound of the maximal wavespeed that is, in general, not as sharp as the two-rarefaction estimate. But it will save the day in the context of near vacuum conditions when the two-rarefaction approximation might attain extreme values:\n\n\\begin{align\\*}\n\\lambda\\_{\\text{exp}} = \\max(u\\_i,u\\_j) + 5. \\max(a\\_i, a\\_j).\n\\end{align\\*}\n\nNote\n:   The constant 5.0 multiplying the maximum of the sound speeds is *neither* an ad-hoc constant, *nor* a tuning parameter. It defines an upper bound for any \\(\\gamma \\in [0,5/3]\\). Do not play with it!\n\n```\n       DEAL_II_ALWAYS_INLINE inline double\n       lambda_max_expansion(const std::array<double, 4> &riemann_data_i,\n                            const std::array<double, 4> &riemann_data_j)\n       {\n         const auto u_i = riemann_data_i[1];\n         const auto a_i = riemann_data_i[3];\n         const auto u_j = riemann_data_j[1];\n         const auto a_j = riemann_data_j[3];\n   \n         return std::max(std::abs(u_i), std::abs(u_j)) + 5. * std::max(a_i, a_j);\n       }\n     } // namespace\n```\n\nThe following is the main function that we are going to call in order to compute \\(\\lambda\\_{\\text{max}} (\\mathbf{U}\\_i^{n},\\mathbf{U}\\_j^{n},\n\\textbf{n}\\_{ij})\\). We simply compute both maximal wavespeed estimates and return the minimum.\n\n```\n     template <int dim>\n     DEAL_II_ALWAYS_INLINE inline double\n     ProblemDescription<dim>::compute_lambda_max(const state_type     &U_i,\n                                                 const state_type     &U_j,\n                                                 const Tensor<1, dim> &n_ij)\n     {\n       const auto riemann_data_i = riemann_data_from_state(U_i, n_ij);\n       const auto riemann_data_j = riemann_data_from_state(U_j, n_ij);\n   \n       const double lambda_1 =\n         lambda_max_two_rarefaction(riemann_data_i, riemann_data_j);\n   \n       const double lambda_2 =\n         lambda_max_expansion(riemann_data_i, riemann_data_j);\n   \n       return std::min(lambda_1, lambda_2);\n     }\n```\n\nWe conclude this section by defining static arrays `component_names` that contain strings describing the component names of our state vector. We have template specializations for dimensions one, two and three, that are used later in [DataOut](classDataOut.html) for naming the corresponding components:\n\n```\n     template <>\n     const std::array<std::string, 3> ProblemDescription<1>::component_names{\n       {\"rho\", \"m\", \"E\"}};\n   \n     template <>\n     const std::array<std::string, 4> ProblemDescription<2>::component_names{\n       {\"rho\", \"m_1\", \"m_2\", \"E\"}};\n   \n     template <>\n     const std::array<std::string, 5> ProblemDescription<3>::component_names{\n       {\"rho\", \"m_1\", \"m_2\", \"m_3\", \"E\"}};\n```\n\n#### Initial values\n\nThe last preparatory step, before we discuss the implementation of the forward Euler scheme, is to briefly implement the `InitialValues` class.\n\nIn the constructor we initialize all parameters with default values, declare all parameters for the `ParameterAcceptor` class and connect the `parse_parameters_call_back` slot to the respective signal.\n\nThe `parse_parameters_call_back` slot will be invoked from ParameterAceptor after the call to [ParameterAcceptor::initialize()](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e). In that regard, its use is appropriate for situations where the parameters have to be postprocessed (in some sense) or some consistency condition between the parameters has to be checked.\n\n```\n       template <int dim>\n       InitialValues<dim>::InitialValues(const std::string &subsection)\n         : ParameterAcceptor(subsection)\n       {\n         /* We wire up the slot InitialValues<dim>::parse_parameters_callback to\n*           the ParameterAcceptor::parse_parameters_call_back signal: */\n         ParameterAcceptor::parse_parameters_call_back.connect(\n           [&]() { this->parse_parameters_callback(); });\n     \n         initial_direction[0] = 1.;\n         add_parameter(\"initial direction\",\n                       initial_direction,\n                       \"Initial direction of the uniform flow field\");\n     \n         initial_1d_state[0] = ProblemDescription<dim>::gamma;\n         initial_1d_state[1] = 3.;\n         initial_1d_state[2] = 1.;\n         add_parameter(\"initial 1d state\",\n                       initial_1d_state,\n                       \"Initial 1d state (rho, u, p) of the uniform flow field\");\n       }\n```\n\nSo far the constructor of `InitialValues` has defined default values for the two private members `initial_direction` and `initial_1d_state` and added them to the parameter list. But we have not defined an implementation of the only public member that we really care about, which is `initial_state()` (the function that we are going to call to actually evaluate the initial solution at the mesh nodes). At the top of the function, we have to ensure that the provided initial direction is not the zero vector.\n\nNote\n:   As commented, we could have avoided using the method `parse_parameters_call_back`  and defined a class member `setup()` in order to define the implementation of `initial_state()`. But for illustrative purposes we want to document a different way here and use the call back signal from [ParameterAcceptor](classParameterAcceptor.html).\n\n```\n     template <int dim>\n     void InitialValues<dim>::parse_parameters_callback()\n     {\n       AssertThrow(initial_direction.norm() != 0.,\n                   ExcMessage(\n                     \"Initial shock front direction is set to the zero vector.\"));\n       initial_direction /= initial_direction.norm();\n```\n\nNext, we implement the `initial_state` function object with a lambda function computing a uniform flow field. For this we have to translate a given primitive 1d state (density \\(\\rho\\), velocity \\(u\\), and pressure \\(p\\)) into a conserved n-dimensional state (density \\(\\rho\\), momentum \\(\\mathbf{m}\\), and total energy \\(E\\)).\n\n```\n       initial_state = [this](const Point<dim> & /*point*/, double /*t*/) {\n         const double            rho   = initial_1d_state[0];\n         const double            u     = initial_1d_state[1];\n         const double            p     = initial_1d_state[2];\n         static constexpr double gamma = ProblemDescription<dim>::gamma;\n   \n         state_type state;\n   \n         state[0] = rho;\n         for (unsigned int i = 0; i < dim; ++i)\n           state[1 + i] = rho * u * initial_direction[i];\n   \n         state[dim + 1] = p / (gamma - 1.) + 0.5 * rho * u * u;\n   \n         return state;\n       };\n     }\n```\n\n#### The Forward Euler step\n\nThe constructor of the `TimeStepping` class does not contain any surprising code:\n\n```\n     template <int dim>\n     TimeStepping<dim>::TimeStepping(\n       const MPI_Comm            mpi_communicator,\n       TimerOutput              &computing_timer,\n       const OfflineData<dim>   &offline_data,\n       const InitialValues<dim> &initial_values,\n       const std::string        &subsection /*= \"TimeStepping\"*/)\n       : ParameterAcceptor(subsection)\n       , mpi_communicator(mpi_communicator)\n       , computing_timer(computing_timer)\n       , offline_data(&offline_data)\n       , initial_values(&initial_values)\n     {\n       cfl_update = 0.80;\n       add_parameter(\"cfl update\",\n                     cfl_update,\n                     \"Relative CFL constant used for update\");\n     }\n```\n\nIn the class member `prepare()` we initialize the temporary vector `temp` and the matrix `dij_matrix`. The vector `temp` will be used to store the solution update temporarily before its contents is swapped with the old vector.\n\n```\n     template <int dim>\n     void TimeStepping<dim>::prepare()\n     {\n       TimerOutput::Scope scope(computing_timer,\n                                \"time_stepping - prepare scratch space\");\n   \n       for (auto &it : temporary_vector)\n         it.reinit(offline_data->partitioner);\n   \n       dij_matrix.reinit(offline_data->sparsity_pattern);\n     }\n```\n\nIt is now time to implement the forward Euler step. Given a (writable reference) to the old state `U` at time \\(t\\) we update the state `U` in place and return the chosen time-step size. We first declare a number of read-only references to various different variables and data structures. We do this is mainly to have shorter variable names (e.g., `sparsity` instead of `offline_data->sparsity_pattern`).\n\n```\n     template <int dim>\n     double TimeStepping<dim>::make_one_step(vector_type &U, const double t)\n     {\n       const auto &n_locally_owned    = offline_data->n_locally_owned;\n       const auto &n_locally_relevant = offline_data->n_locally_relevant;\n   \n       const std_cxx20::ranges::iota_view<unsigned int, unsigned int>\n         indices_owned(0, n_locally_owned);\n       const std_cxx20::ranges::iota_view<unsigned int, unsigned int>\n         indices_relevant(0, n_locally_relevant);\n   \n       const auto &sparsity = offline_data->sparsity_pattern;\n   \n       const auto &lumped_mass_matrix = offline_data->lumped_mass_matrix;\n       const auto &norm_matrix        = offline_data->norm_matrix;\n       const auto &nij_matrix         = offline_data->nij_matrix;\n       const auto &cij_matrix         = offline_data->cij_matrix;\n   \n       const auto &boundary_normal_map = offline_data->boundary_normal_map;\n```\n\n**Step 1**: Computing the \\(d\\_{ij}\\) graph viscosity matrix.\n\nIt is important to highlight that the viscosity matrix has to be symmetric, i.e., \\(d\\_{ij} = d\\_{ji}\\). In this regard we note here that \\(\\int\\_{\\Omega} \\nabla \\phi\\_j \\phi\\_i \\, \\mathrm{d}\\mathbf{x}= -\n\\int\\_{\\Omega} \\nabla \\phi\\_i \\phi\\_j \\, \\mathrm{d}\\mathbf{x}\\) (or equivalently \\(\\mathbf{c}\\_{ij} = - \\mathbf{c}\\_{ji}\\)) provided either \\(\\mathbf{x}\\_i\\) or \\(\\mathbf{x}\\_j\\) is a support point located away from the boundary. In this case we can check that \\(\\lambda\\_{\\text{max}} (\\mathbf{U}\\_i^{n}, \\mathbf{U}\\_j^{n},\n\\textbf{n}\\_{ij}) = \\lambda\\_{\\text{max}} (\\mathbf{U}\\_j^{n},\n\\mathbf{U}\\_i^{n},\\textbf{n}\\_{ji})\\) by construction, which guarantees the property \\(d\\_{ij} = d\\_{ji}\\).\n\nHowever, if both support points \\(\\mathbf{x}\\_i\\) or \\(\\mathbf{x}\\_j\\) happen to lie on the boundary, then, the equalities \\(\\mathbf{c}\\_{ij} =\n- \\mathbf{c}\\_{ji}\\) and \\(\\lambda\\_{\\text{max}} (\\mathbf{U}\\_i^{n},\n\\mathbf{U}\\_j^{n}, \\textbf{n}\\_{ij}) = \\lambda\\_{\\text{max}}\n(\\mathbf{U}\\_j^{n}, \\mathbf{U}\\_i^{n}, \\textbf{n}\\_{ji})\\) do not necessarily hold true. The only mathematically safe solution for this dilemma is to compute both of them \\(d\\_{ij}\\) and \\(d\\_{ji}\\) and take the maximum.\n\nOverall, the computation of \\(d\\_{ij}\\) is quite expensive. In order to save some computing time we exploit the fact that the viscosity matrix has to be symmetric (as mentioned above): we only compute the upper-triangular entries of \\(d\\_{ij}\\) and copy the corresponding entries to the lower-triangular counterpart.\n\nWe use again [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) for thread-parallel for loops. Pretty much all the ideas for parallel traversal that we introduced when discussing the assembly of the matrix `norm_matrix` and the normalization of `nij_matrix` above are used here again.\n\nWe define again a \"worker\" function `on_subranges` that computes the viscosity \\(d\\_{ij}\\) for a subrange `[*index_begin, *index_end)` of column indices:\n\n```\n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"time_stepping - 1 compute d_ij\");\n   \n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             for (const auto i :\n                  std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                    *index_begin, *index_end))\n               {\n                 const auto U_i = gather(U, i);\n```\n\nFor a given column index i we iterate over the columns of the sparsity pattern from `sparsity.begin(i)` to `sparsity.end(i)`:\n\n```\n                 for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                   {\n                     const auto j = jt->column();\n```\n\nWe only compute \\(d\\_{ij}\\) if \\(j < i\\) (upper triangular entries) and later copy the values over to \\(d\\_{ji}\\).\n\n```\n                     if (j >= i)\n                       continue;\n   \n                     const auto U_j = gather(U, j);\n   \n                     const auto   n_ij = gather_get_entry(nij_matrix, jt);\n                     const double norm = get_entry(norm_matrix, jt);\n   \n                     const auto lambda_max =\n                       ProblemDescription<dim>::compute_lambda_max(U_i, U_j, n_ij);\n   \n                     double d = norm * lambda_max;\n```\n\nIf both support points happen to be at the boundary we have to compute \\(d\\_{ji}\\) as well and then take \\(\\max(d\\_{ij},d\\_{ji})\\). After this we can finally set the upper triangular and lower triangular entries.\n\n```\n                     if (boundary_normal_map.count(i) != 0 &&\n                         boundary_normal_map.count(j) != 0)\n                       {\n                         const auto n_ji = gather(nij_matrix, j, i);\n                         const auto lambda_max_2 =\n                           ProblemDescription<dim>::compute_lambda_max(U_j,\n                                                                       U_i,\n                                                                       n_ji);\n                         const double norm_2 = norm_matrix(j, i);\n   \n                         d = std::max(d, norm_2 * lambda_max_2);\n                       }\n   \n                     set_entry(dij_matrix, jt, d);\n                     dij_matrix(j, i) = d;\n                   }\n               }\n           };\n   \n         parallel::apply_to_subranges(indices_relevant.begin(),\n                                      indices_relevant.end(),\n                                      on_subranges,\n                                      4096);\n       }\n```\n\n**Step 2**: Compute diagonal entries \\(d\\_{ii}\\) and \\(\\tau\\_{\\text{max}}\\).\n\nSo far we have computed all off-diagonal entries of the matrix `dij_matrix`. We still have to fill its diagonal entries defined as \\(d\\_{ii}^n = - \\sum\\_{j \\in \\mathcal{I}(i)\\backslash \\{i\\}}\nd\\_{ij}^n\\). We use again [parallel::apply\\_to\\_subranges()](namespaceparallel.html#a73a5366855f164ba6dcde9fbe0c689b8) for this purpose. While computing the \\(d\\_{ii}\\)s we also determine the largest admissible time-step, which is defined as\n\n\\[\n\\tau\\_n \\dealcoloneq c\\_{\\text{cfl}}\\,\\min\\_{i\\in\\mathcal{V}}\n\\left(\\frac{m\\_i}{-2\\,d\\_{ii}^{n}}\\right) \\, .\n\\]\n\nNote that the operation \\(\\min\\_{i \\in \\mathcal{V}}\\) is intrinsically global, it operates on all nodes: first we have to take the minimum over all threads (of a given node) and then we have to take the minimum over all MPI processes. In the current implementation:\n\n* We store `tau_max` (per node) as [`std::atomic<double>`](http://www.cplusplus.com/reference/atomic/atomic/). The internal implementation of `std::atomic` will take care of guarding any possible race condition when more than one thread attempts to read and/or write `tau_max` at the same time.\n* In order to take the minimum over all MPI process we use the utility function `Utilities::MPI::min`.\n\n```\n       std::atomic<double> tau_max{std::numeric_limits<double>::infinity()};\n   \n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"time_stepping - 2 compute d_ii, and tau_max\");\n```\n\non\\_subranges() will be executed on every thread individually. The variable `tau_max_on_subrange` is thus stored thread locally.\n\n```\n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             double tau_max_on_subrange = std::numeric_limits<double>::infinity();\n   \n             for (const auto i :\n                  std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                    *index_begin, *index_end))\n               {\n                 double d_sum = 0.;\n   \n                 for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                   {\n                     const auto j = jt->column();\n   \n                     if (j == i)\n                       continue;\n   \n                     d_sum -= get_entry(dij_matrix, jt);\n                   }\n```\n\nWe store the negative sum of the d\\_ij entries at the diagonal position\n\n```\n                 dij_matrix.diag_element(i) = d_sum;\n```\n\nand compute the maximal local time-step size `tau`:\n\n```\n                 const double mass   = lumped_mass_matrix.diag_element(i);\n                 const double tau    = cfl_update * mass / (-2. * d_sum);\n                 tau_max_on_subrange = std::min(tau_max_on_subrange, tau);\n               }\n```\n\n`tau_max_on_subrange` contains the largest possible time-step size computed for the (thread local) subrange. At this point we have to synchronize the value over all threads. This is were we use the [`std::atomic<double>`](http://www.cplusplus.com/reference/atomic/atomic/) *compare exchange* update mechanism:\n\n```\n             double current_tau_max = tau_max.load();\n             while (current_tau_max > tau_max_on_subrange &&\n                    !tau_max.compare_exchange_weak(current_tau_max,\n                                                   tau_max_on_subrange))\n               ;\n           };\n   \n         parallel::apply_to_subranges(indices_relevant.begin(),\n                                      indices_relevant.end(),\n                                      on_subranges,\n                                      4096);\n```\n\nAfter all threads have finished we can simply synchronize the value over all MPI processes:\n\n```\n         tau_max.store(Utilities::MPI::min(tau_max.load(), mpi_communicator));\n```\n\nThis is a good point to verify that the computed `tau_max` is indeed a valid floating point number.\n\n```\n         AssertThrow(\n           !std::isnan(tau_max.load()) && !std::isinf(tau_max.load()) &&\n             tau_max.load() > 0.,\n           ExcMessage(\n             \"I'm sorry, Dave. I'm afraid I can't do that. - We crashed.\"));\n       }\n```\n\n**Step 3**: Perform update.\n\nAt this point, we have computed all viscosity coefficients \\(d\\_{ij}\\) and we know the maximal admissible time-step size \\(\\tau\\_{\\text{max}}\\). This means we can now compute the update:\n\n\\[\n\\mathbf{U}\\_i^{n+1} = \\mathbf{U}\\_i^{n} - \\frac{\\tau\\_{\\text{max}} }{m\\_i}\n\\sum\\_{j \\in \\mathcal{I}(i)} (\\mathbb{f}(\\mathbf{U}\\_j^{n}) -\n\\mathbb{f}(\\mathbf{U}\\_i^{n})) \\cdot \\mathbf{c}\\_{ij} - d\\_{ij}\n(\\mathbf{U}\\_j^{n} - \\mathbf{U}\\_i^{n})\n\\]\n\nThis update formula is slightly different from what was discussed in the introduction (in the pseudo-code). However, it can be shown that both equations are algebraically equivalent (they will produce the same numerical values). We favor this second formula since it has natural cancellation properties that might help avoid numerical artifacts.\n\n```\n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"time_stepping - 3 perform update\");\n   \n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             for (const auto i :\n                  boost::make_iterator_range(index_begin, index_end))\n               {\n                 Assert(i < n_locally_owned, ExcInternalError());\n   \n                 const auto U_i = gather(U, i);\n   \n                 const auto   f_i = ProblemDescription<dim>::flux(U_i);\n                 const double m_i = lumped_mass_matrix.diag_element(i);\n   \n                 auto U_i_new = U_i;\n   \n                 for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                   {\n                     const auto j = jt->column();\n   \n                     const auto U_j = gather(U, j);\n                     const auto f_j = ProblemDescription<dim>::flux(U_j);\n   \n                     const auto c_ij = gather_get_entry(cij_matrix, jt);\n                     const auto d_ij = get_entry(dij_matrix, jt);\n   \n                     for (unsigned int k = 0; k < n_solution_variables; ++k)\n                       {\n                         U_i_new[k] +=\n                           tau_max / m_i *\n                           (-(f_j[k] - f_i[k]) * c_ij + d_ij * (U_j[k] - U_i[k]));\n                       }\n                   }\n   \n                 scatter(temporary_vector, U_i_new, i);\n               }\n           };\n   \n         parallel::apply_to_subranges(indices_owned.begin(),\n                                      indices_owned.end(),\n                                      on_subranges,\n                                      4096);\n       }\n```\n\n**Step 4**: Fix up boundary states.\n\nAs a last step in the Forward Euler method, we have to fix up all boundary states. As discussed in the intro we\n\n* advance in time satisfying no boundary condition at all,\n* at the end of the time step enforce boundary conditions strongly in a post-processing step.\n\nHere, we compute the correction\n\n\\[\n\\mathbf{m}\\_i \\dealcoloneq \\mathbf{m}\\_i - (\\boldsymbol{\\nu}\\_i \\cdot\n\\mathbf{m}\\_i) \\boldsymbol{\\nu}\\_i,\n\\]\n\nwhich removes the normal component of \\(\\mathbf{m}\\).\n\n```\n       {\n         TimerOutput::Scope scope(computing_timer,\n                                  \"time_stepping - 4 fix boundary states\");\n   \n         for (const auto &it : boundary_normal_map)\n           {\n             const auto i = it.first;\n```\n\nWe only iterate over the locally owned subset:\n\n```\n             if (i >= n_locally_owned)\n               continue;\n   \n             const auto &normal   = std::get<0>(it.second);\n             const auto &id       = std::get<1>(it.second);\n             const auto &position = std::get<2>(it.second);\n   \n             auto U_i = gather(temporary_vector, i);\n```\n\nOn free slip boundaries we remove the normal component of the momentum:\n\n```\n             if (id == Boundaries::free_slip)\n               {\n                 auto m = ProblemDescription<dim>::momentum(U_i);\n                 m -= (m * normal) * normal;\n                 for (unsigned int k = 0; k < dim; ++k)\n                   U_i[k + 1] = m[k];\n               }\n```\n\nOn Dirichlet boundaries we enforce initial conditions strongly:\n\n```\n             else if (id == Boundaries::dirichlet)\n               {\n                 U_i = initial_values->initial_state(position, t + tau_max);\n               }\n   \n             scatter(temporary_vector, U_i, i);\n           }\n       }\n```\n\n**Step 5**: We now update the ghost layer over all MPI ranks, swap the temporary vector with the solution vector `U` (that will get returned by reference) and return the chosen time-step size \\(\\tau\\_{\\text{max}}\\):\n\n```\n       for (auto &it : temporary_vector)\n         it.update_ghost_values();\n   \n       U.swap(temporary_vector);\n   \n       return tau_max;\n     }\n```\n\n#### Schlieren postprocessing\n\nAt various intervals we will output the current state `U` of the solution together with a so-called Schlieren plot. The constructor of the `SchlierenPostprocessor` class again contains no surprises. We simply supply default values to and register two parameters:\n\n* schlieren\\_beta: is an ad-hoc positive amplification factor in order to enhance the contrast in the visualization. Its actual value is a matter of taste.\n* schlieren\\_index: is an integer indicating which component of the state \\([\\rho, \\mathbf{m},E]\\) are we going to use in order to generate the visualization.\n\n```\n     template <int dim>\n     SchlierenPostprocessor<dim>::SchlierenPostprocessor(\n       const MPI_Comm          mpi_communicator,\n       TimerOutput            &computing_timer,\n       const OfflineData<dim> &offline_data,\n       const std::string      &subsection /*= \"SchlierenPostprocessor\"*/)\n       : ParameterAcceptor(subsection)\n       , mpi_communicator(mpi_communicator)\n       , computing_timer(computing_timer)\n       , offline_data(&offline_data)\n     {\n       schlieren_beta = 10.;\n       add_parameter(\"schlieren beta\",\n                     schlieren_beta,\n                     \"Beta factor used in Schlieren-type postprocessor\");\n   \n       schlieren_index = 0;\n       add_parameter(\"schlieren index\",\n                     schlieren_index,\n                     \"Use the corresponding component of the state vector for the \"\n                     \"schlieren plot\");\n     }\n```\n\nAgain, the `prepare()` function initializes two temporary the vectors (`r` and `schlieren`).\n\n```\n     template <int dim>\n     void SchlierenPostprocessor<dim>::prepare()\n     {\n       TimerOutput::Scope scope(computing_timer,\n                                \"schlieren_postprocessor - prepare scratch space\");\n   \n       r.reinit(offline_data->n_locally_relevant);\n       schlieren.reinit(offline_data->partitioner);\n     }\n```\n\nWe now discuss the implementation of the class member `SchlierenPostprocessor<dim>::compute_schlieren()`, which basically takes a component of the state vector `U` and computes the Schlieren indicator for such component (the formula of the Schlieren indicator can be found just before the declaration of the class `SchlierenPostprocessor`). We start by noting that this formula requires the \"nodal gradients\" \\(\\nabla r\\_j\\). However, nodal values of gradients are not defined for \\(\\mathcal{C}^0\\) finite element functions. More generally, pointwise values of gradients are not defined for \\(W^{1,p}(\\Omega)\\) functions. The simplest technique we can use to recover gradients at nodes is weighted-averaging i.e.\n\n\\[ \\nabla r\\_j \\dealcoloneq \\frac{1}{\\int\\_{S\\_i} \\omega\\_i(\\mathbf{x}) \\,\n\\mathrm{d}\\mathbf{x}}\n\\int\\_{S\\_i} r\\_h(\\mathbf{x}) \\omega\\_i(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x}\n\\ \\ \\ \\ \\ \\mathbf{(\\*)} \\]\n\nwhere \\(S\\_i\\) is the support of the shape function \\(\\phi\\_i\\), and \\(\\omega\\_i(\\mathbf{x})\\) is the weight. The weight could be any positive function such as \\(\\omega\\_i(\\mathbf{x}) \\equiv 1\\) (that would allow us to recover the usual notion of mean value). But as usual, the goal is to reuse the off-line data as much as possible. In this sense, the most natural choice of weight is \\(\\omega\\_i = \\phi\\_i\\). Inserting this choice of weight and the expansion \\(r\\_h(\\mathbf{x}) = \\sum\\_{j \\in \\mathcal{V}}\nr\\_j \\phi\\_j(\\mathbf{x})\\) into \\(\\mathbf{(\\*)}\\) we get :\n\n\\[ \\nabla r\\_j \\dealcoloneq \\frac{1}{m\\_i} \\sum\\_{j \\in \\mathcal{I}(i)} r\\_j\n\\mathbf{c}\\_{ij} \\ \\ \\ \\ \\ \\mathbf{(\\*\\*)} \\, . \\]\n\nUsing this last formula we can recover averaged nodal gradients without resorting to any form of quadrature. This idea aligns quite well with the whole spirit of edge-based schemes (or algebraic schemes) where we want to operate on matrices and vectors as directly as it could be possible avoiding by all means assembly of bilinear forms, cell-loops, quadrature, or any other intermediate construct/operation between the input arguments (the state from the previous time-step) and the actual matrices and vectors required to compute the update.\n\nThe second thing to note is that we have to compute global minimum and maximum \\(\\max\\_j |\\nabla r\\_j|\\) and \\(\\min\\_j |\\nabla r\\_j|\\). Following the same ideas used to compute the time step size in the class member `TimeStepping<dim>::step()` we define \\(\\max\\_j |\\nabla r\\_j|\\) and \\(\\min\\_j |\\nabla r\\_j|\\) as atomic doubles in order to resolve any conflicts between threads. As usual, we use `Utilities::MPI::max()` and `Utilities::MPI::min()` to find the global maximum/minimum among all MPI processes.\n\nFinally, it is not possible to compute the Schlieren indicator in a single loop over all nodes. The entire operation requires two loops over nodes:\n\n* The first loop computes \\(|\\nabla r\\_i|\\) for all \\(i \\in \\mathcal{V}\\) in the mesh, and the bounds \\(\\max\\_j |\\nabla r\\_j|\\) and \\(\\min\\_j |\\nabla r\\_j|\\).\n* The second loop finally computes the Schlieren indicator using the formula\n\n\\[ \\text{schlieren}[i] = e^{\\beta \\frac{ |\\nabla r\\_i|\n- \\min\\_j |\\nabla r\\_j| }{\\max\\_j |\\nabla r\\_j| - \\min\\_j |\\nabla r\\_j| } }\n\\, . \\]\n\nThis means that we will have to define two workers `on_subranges` for each one of these stages.\n\n```\n     template <int dim>\n     void SchlierenPostprocessor<dim>::compute_schlieren(const vector_type &U)\n     {\n       TimerOutput::Scope scope(\n         computing_timer, \"schlieren_postprocessor - compute schlieren plot\");\n   \n       const auto &sparsity            = offline_data->sparsity_pattern;\n       const auto &lumped_mass_matrix  = offline_data->lumped_mass_matrix;\n       const auto &cij_matrix          = offline_data->cij_matrix;\n       const auto &boundary_normal_map = offline_data->boundary_normal_map;\n       const auto &n_locally_owned     = offline_data->n_locally_owned;\n   \n       const auto indices =\n         std_cxx20::ranges::iota_view<unsigned int, unsigned int>(0,\n                                                                  n_locally_owned);\n```\n\nWe define the r\\_i\\_max and r\\_i\\_min in the current MPI process as atomic doubles in order to avoid race conditions between threads:\n\n```\n       std::atomic<double> r_i_max{0.};\n       std::atomic<double> r_i_min{std::numeric_limits<double>::infinity()};\n```\n\nFirst loop: compute the averaged gradient at each node and the global maxima and minima of the gradients.\n\n```\n       {\n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             double r_i_max_on_subrange = 0.;\n             double r_i_min_on_subrange = std::numeric_limits<double>::infinity();\n   \n             for (const auto i :\n                  boost::make_iterator_range(index_begin, index_end))\n               {\n                 Assert(i < n_locally_owned, ExcInternalError());\n   \n                 Tensor<1, dim> r_i;\n   \n                 for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                   {\n                     const auto j = jt->column();\n   \n                     if (i == j)\n                       continue;\n   \n                     const auto U_js = U[schlieren_index].local_element(j);\n                     const auto c_ij = gather_get_entry(cij_matrix, jt);\n                     r_i += c_ij * U_js;\n                   }\n```\n\nWe fix up the gradient r\\_i at free slip boundaries similarly to how we fixed up boundary states in the forward Euler step. This avoids sharp, artificial gradients in the Schlieren plot at free slip boundaries and is a purely cosmetic choice.\n\n```\n                 const auto bnm_it = boundary_normal_map.find(i);\n                 if (bnm_it != boundary_normal_map.end())\n                   {\n                     const auto &normal = std::get<0>(bnm_it->second);\n                     const auto &id     = std::get<1>(bnm_it->second);\n   \n                     if (id == Boundaries::free_slip)\n                       r_i -= 1. * (r_i * normal) * normal;\n                     else\n                       r_i = 0.;\n                   }\n```\n\nWe remind the reader that we are not interested in the nodal gradients per se. We only want their norms in order to compute the Schlieren indicator (weighted with the lumped mass matrix \\(m\\_i\\)):\n\n```\n                 const double m_i    = lumped_mass_matrix.diag_element(i);\n                 r[i]                = r_i.norm() / m_i;\n                 r_i_max_on_subrange = std::max(r_i_max_on_subrange, r[i]);\n                 r_i_min_on_subrange = std::min(r_i_min_on_subrange, r[i]);\n               }\n```\n\nWe compare the current\\_r\\_i\\_max and current\\_r\\_i\\_min (in the current subrange) with r\\_i\\_max and r\\_i\\_min (for the current MPI process) and update them if necessary:\n\n```\n             double current_r_i_max = r_i_max.load();\n             while (current_r_i_max < r_i_max_on_subrange &&\n                    !r_i_max.compare_exchange_weak(current_r_i_max,\n                                                   r_i_max_on_subrange))\n               ;\n   \n             double current_r_i_min = r_i_min.load();\n             while (current_r_i_min > r_i_min_on_subrange &&\n                    !r_i_min.compare_exchange_weak(current_r_i_min,\n                                                   r_i_min_on_subrange))\n               ;\n           };\n   \n         parallel::apply_to_subranges(indices.begin(),\n                                      indices.end(),\n                                      on_subranges,\n                                      4096);\n       }\n```\n\nAnd synchronize `r_i_max` and `r_i_min` over all MPI processes.\n\n```\n       r_i_max.store(Utilities::MPI::max(r_i_max.load(), mpi_communicator));\n       r_i_min.store(Utilities::MPI::min(r_i_min.load(), mpi_communicator));\n```\n\nSecond loop: we now have the vector `r` and the scalars `r_i_max` and `r_i_min` at our disposal. We are thus in a position to actually compute the Schlieren indicator.\n\n```\n       {\n         const auto on_subranges = \n           [&](const auto index_begin, const auto index_end) {\n             for (const auto i :\n                  boost::make_iterator_range(index_begin, index_end))\n               {\n                 Assert(i < n_locally_owned, ExcInternalError());\n   \n                 schlieren.local_element(i) =\n                   1. - std::exp(-schlieren_beta * (r[i] - r_i_min) /\n                                 (r_i_max - r_i_min));\n               }\n           };\n   \n         parallel::apply_to_subranges(indices.begin(),\n                                      indices.end(),\n                                      on_subranges,\n                                      4096);\n       }\n```\n\nAnd finally, exchange ghost elements.\n\n```\n       schlieren.update_ghost_values();\n     }\n```\n\n#### The main loop\n\nWith all classes implemented it is time to create an instance of `Discretization<dim>`, `OfflineData<dim>`, `InitialValues<dim>`, `TimeStepping<dim>`, and `SchlierenPostprocessor<dim>`, and run the forward Euler step in a loop.\n\nIn the constructor of `MainLoop<dim>` we now initialize an instance of all classes, and declare a number of parameters controlling output. Most notable, we declare a boolean parameter `resume` that will control whether the program attempts to restart from an interrupted computation, or not.\n\n```\n     template <int dim>\n     MainLoop<dim>::MainLoop(const MPI_Comm mpi_communicator)\n       : ParameterAcceptor(\"A - MainLoop\")\n       , mpi_communicator(mpi_communicator)\n       , computing_timer(mpi_communicator,\n                         timer_output,\n                         TimerOutput::never,\n                         TimerOutput::cpu_and_wall_times)\n       , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n       , discretization(mpi_communicator, computing_timer, \"B - Discretization\")\n       , offline_data(mpi_communicator,\n                      computing_timer,\n                      discretization,\n                      \"C - OfflineData\")\n       , initial_values(\"D - InitialValues\")\n       , time_stepping(mpi_communicator,\n                       computing_timer,\n                       offline_data,\n                       initial_values,\n                       \"E - TimeStepping\")\n       , schlieren_postprocessor(mpi_communicator,\n                                 computing_timer,\n                                 offline_data,\n                                 \"F - SchlierenPostprocessor\")\n     {\n       base_name = \"test\";\n       add_parameter(\"basename\", base_name, \"Base name for all output files\");\n   \n       t_final = 4.;\n       add_parameter(\"final time\", t_final, \"Final time\");\n   \n       output_granularity = 0.02;\n       add_parameter(\"output granularity\",\n                     output_granularity,\n                     \"time interval for output\");\n   \n       asynchronous_writeback = true;\n       add_parameter(\"asynchronous writeback\",\n                     asynchronous_writeback,\n                     \"Write out solution in a background thread performing IO\");\n   \n       resume = false;\n       add_parameter(\"resume\", resume, \"Resume an interrupted computation.\");\n     }\n```\n\nWe start by implementing a helper function `print_head()` in an anonymous namespace that is used to output messages in the terminal with some nice formatting.\n\n```\n     namespace\n     {\n       void print_head(ConditionalOStream &pcout,\n                       const std::string  &header,\n                       const std::string  &secondary = \"\")\n       {\n         const auto header_size   = header.size();\n         const auto padded_header = std::string((34 - header_size) / 2, ' ') +\n                                    header +\n                                    std::string((35 - header_size) / 2, ' ');\n   \n         const auto secondary_size = secondary.size();\n         const auto padded_secondary =\n           std::string((34 - secondary_size) / 2, ' ') + secondary +\n           std::string((35 - secondary_size) / 2, ' ');\n   \n         /* clang-format off */\n         pcout << std::endl;\n         pcout << \"    ####################################################\" << std::endl;\n         pcout << \"    #########                                  #########\" << std::endl;\n         pcout << \"    #########\"     <<  padded_header   <<     \"#########\" << std::endl;\n         pcout << \"    #########\"     << padded_secondary <<     \"#########\" << std::endl;\n         pcout << \"    #########                                  #########\" << std::endl;\n         pcout << \"    ####################################################\" << std::endl;\n         pcout << std::endl;\n         /* clang-format on */\n       }\n     } // namespace\n```\n\nWith `print_head` in place it is now time to implement the `MainLoop<dim>::run()` that contains the main loop of our program.\n\n```\n     template <int dim>\n     void MainLoop<dim>::run()\n     {\n```\n\nWe start by reading in parameters and initializing all objects. We note here that the call to [ParameterAcceptor::initialize](classParameterAcceptor.html#a8c735525d2865112e5d67f9ba697224e) reads in all parameters from the parameter file (whose name is given as a string argument). [ParameterAcceptor](classParameterAcceptor.html) handles a global [ParameterHandler](classParameterHandler.html) that is initialized with subsections and parameter declarations for all class instances that are derived from ParameterAceptor. The call to initialize enters the subsection for each each derived class, and sets all variables that were added using [ParameterAcceptor::add\\_parameter()](classParameterAcceptor.html#af2a534c7f1ea5bfa165fa8a469744a5d)\n\n```\n       pcout << \"Reading parameters and allocating objects... \" << std::flush;\n   \n       ParameterAcceptor::initialize(\"step-69.prm\");\n       pcout << \"done\" << std::endl;\n```\n\nNext we create the triangulation, assemble all matrices, set up scratch space, and initialize the DataOut<dim> object. All of these operations are pretty standard and discussed in detail in the Discretization and OfflineData classes.\n\n```\n       {\n         print_head(pcout, \"create triangulation\");\n   \n         discretization.setup();\n   \n         if (resume)\n           discretization.triangulation.load(base_name + \"-checkpoint.mesh\");\n         else\n           discretization.triangulation.refine_global(discretization.refinement);\n   \n         pcout << \"Number of active cells:       \"\n               << discretization.triangulation.n_global_active_cells()\n               << std::endl;\n   \n         print_head(pcout, \"compute offline data\");\n         offline_data.setup();\n         offline_data.assemble();\n   \n         pcout << \"Number of degrees of freedom: \"\n               << offline_data.dof_handler.n_dofs() << std::endl;\n   \n         print_head(pcout, \"set up time step\");\n         time_stepping.prepare();\n         schlieren_postprocessor.prepare();\n       }\n```\n\nWe will store the current time and state in the variable `t` and vector `U`:\n\n```\n       double       t            = 0.;\n       unsigned int output_cycle = 0;\n   \n       vector_type U;\n       for (auto &it : U)\n         it.reinit(offline_data.partitioner);\n```\n\n##### Resume\n\nBy default the boolean `resume` is set to false, i.e. the following code snippet is not run. However, if `resume==true` we indicate that we have indeed an interrupted computation and the program shall restart by reading in an old state consisting of `t`, `output_cycle`, and the state vector `U` from checkpoint files.\n\nA this point we have already read in the stored refinement history of our parallel distributed mesh. What is missing are the actual state vector `U`, the time and output cycle. We use the [SolutionTransfer](classSolutionTransfer.html) class in combination with the distributed::Triangulation::load() / distributed::Triangulation::save() mechanism to read in the state vector. A separate `boost::archive` is used to retrieve `t` and `output_cycle`. The checkpoint files will be created in the `output()` routine discussed below.\n\n```\n       if (resume)\n         {\n           print_head(pcout, \"resume interrupted computation\");\n   \n           parallel::distributed::\n             SolutionTransfer<dim, LinearAlgebra::distributed::Vector<double>>\n               solution_transfer(offline_data.dof_handler);\n   \n           std::vector<LinearAlgebra::distributed::Vector<double> *> vectors;\n           std::transform(U.begin(),\n                          U.end(),\n                          std::back_inserter(vectors),\n                          [](auto &it) { return &it; });\n           solution_transfer.deserialize(vectors);\n   \n           for (auto &it : U)\n             it.update_ghost_values();\n   \n           std::ifstream file(base_name + \"-checkpoint.metadata\",\n                              std::ios::binary);\n   \n           boost::archive::binary_iarchive ia(file);\n           ia >> t >> output_cycle;\n         }\n       else\n         {\n           print_head(pcout, \"interpolate initial values\");\n           U = interpolate_initial_values();\n         }\n```\n\nWith either the initial state set up, or an interrupted state restored it is time to enter the main loop:\n\n```\n       output(U, base_name, t, output_cycle++);\n   \n       print_head(pcout, \"enter main loop\");\n   \n       unsigned int timestep_number = 1;\n       while (t < t_final)\n         {\n```\n\nWe first print an informative status message\n\n```\n           std::ostringstream head;\n           std::ostringstream secondary;\n   \n           head << \"Cycle  \" << Utilities::int_to_string(timestep_number, 6)\n                << \"  (\"                                                   \n                << std::fixed << std::setprecision(1) << t / t_final * 100 \n                << \"%)\";\n           secondary << \"at time t = \" << std::setprecision(8) << std::fixed << t;\n   \n           print_head(pcout, head.str(), secondary.str());\n```\n\nand then perform a single forward Euler step. Note that the state vector `U` is updated in place and that `time_stepping.make_one_step()` returns the chosen step size.\n\n```\n           t += time_stepping.make_one_step(U, t);\n```\n\nPost processing, generating output and writing out the current state is a CPU and IO intensive task that we cannot afford to do every time step - in particular with explicit time stepping. We thus only schedule output by calling the `output()` function if we are past a threshold set by `output_granularity`.\n\n```\n           if (t > output_cycle * output_granularity)\n             {\n               checkpoint(U, base_name, t, output_cycle);\n               output(U, base_name, t, output_cycle);\n               ++output_cycle;\n             }\n   \n           ++timestep_number;\n         }\n```\n\nWe wait for any remaining background output thread to finish before printing a summary and exiting.\n\n```\n       if (background_thread_state.valid())\n         background_thread_state.wait();\n   \n       computing_timer.print_summary();\n       pcout << timer_output.str() << std::endl;\n     }\n```\n\nThe `interpolate_initial_values` takes an initial time \"t\" as input argument and populates a state vector `U` with the help of the `InitialValues<dim>::initial_state` object.\n\n```\n     template <int dim>\n     typename MainLoop<dim>::vector_type\n     MainLoop<dim>::interpolate_initial_values(const double t)\n     {\n       pcout << \"MainLoop<dim>::interpolate_initial_values(t = \" << t << ')'\n             << std::endl;\n       TimerOutput::Scope scope(computing_timer,\n                                \"main_loop - setup scratch space\");\n   \n       vector_type U;\n   \n       for (auto &it : U)\n         it.reinit(offline_data.partitioner);\n   \n       constexpr auto n_solution_variables =\n         ProblemDescription<dim>::n_solution_variables;\n```\n\nThe function signature of `InitialValues<dim>::initial_state` is not quite right for [VectorTools::interpolate()](namespaceVectorTools.html#a35950c839da51812962d41ee4075b3b8). We work around this issue by, first, creating a lambda function that for a given position `x` returns just the value of the `i`th component. This lambda in turn is converted to a Function<dim> object with the help of the [ScalarFunctionFromFunctionObject](classScalarFunctionFromFunctionObject.html) wrapper.\n\n```\n       for (unsigned int i = 0; i < n_solution_variables; ++i)\n         VectorTools::interpolate(offline_data.dof_handler,\n                                  ScalarFunctionFromFunctionObject<dim, double>(\n                                    [&](const Point<dim> &x) {\n                                      return initial_values.initial_state(x, t)[i];\n                                    }),\n                                  U[i]);\n   \n       for (auto &it : U)\n         it.update_ghost_values();\n   \n       return U;\n     }\n```\n\n##### Output and checkpointing\n\nWe checkpoint the current state by doing the precise inverse operation to what we discussed for the [resume logic](Resume):\n\n```\n     template <int dim>\n     void MainLoop<dim>::checkpoint(const typename MainLoop<dim>::vector_type &U,\n                                    const std::string &name,\n                                    const double       t,\n                                    const unsigned int cycle)\n     {\n       print_head(pcout, \"checkpoint computation\");\n   \n       parallel::distributed::\n         SolutionTransfer<dim, LinearAlgebra::distributed::Vector<double>>\n           solution_transfer(offline_data.dof_handler);\n   \n       std::vector<const LinearAlgebra::distributed::Vector<double> *> vectors;\n       std::transform(U.begin(),\n                      U.end(),\n                      std::back_inserter(vectors),\n                      [](auto &it) { return &it; });\n   \n       solution_transfer.prepare_for_serialization(vectors);\n   \n       discretization.triangulation.save(name + \"-checkpoint.mesh\");\n   \n       if (Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n         {\n           std::ofstream file(name + \"-checkpoint.metadata\", std::ios::binary);\n           boost::archive::binary_oarchive oa(file);\n           oa << t << cycle;\n         }\n     }\n```\n\nWriting out the final vtk files is quite an IO intensive task that can stall the main loop for a while. In order to avoid this we use an [asynchronous IO](https://en.wikipedia.org/wiki/Asynchronous_I/O) strategy by creating a background thread that will perform IO while the main loop is allowed to continue. In order for this to work we have to be mindful of two things:\n\n* Before running the `output_worker` thread, we have to create a copy of the state vector `U`. We store it in the vector `output_vector`.\n* We have to avoid any MPI communication in the background thread, otherwise the program might deadlock. This implies that we have to run the postprocessing outside of the worker thread.\n\n```\n     template <int dim>\n     void MainLoop<dim>::output(const typename MainLoop<dim>::vector_type &U,\n                                const std::string                         &name,\n                                const double                               t,\n                                const unsigned int                         cycle)\n     {\n       pcout << \"MainLoop<dim>::output(t = \" << t << ')' << std::endl;\n```\n\nIf the asynchronous writeback option is set we launch a background thread performing all the slow IO to disc. In that case we have to make sure that the background thread actually finished running. If not, we have to wait to for it to finish. We launch said background thread with [`std::async()`](https://en.cppreference.com/w/cpp/thread/async) that returns a [`std::future`](https://en.cppreference.com/w/cpp/thread/future) object. This `std::future` object contains the return value of the function, which is in our case simply `void`.\n\n```\n       if (background_thread_state.valid())\n         {\n           TimerOutput::Scope timer(computing_timer, \"main_loop - stalled output\");\n           background_thread_state.wait();\n         }\n   \n       constexpr auto n_solution_variables =\n         ProblemDescription<dim>::n_solution_variables;\n```\n\nAt this point we make a copy of the state vector, run the schlieren postprocessor, and run [DataOut<dim>::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646) The actual output code is standard: We create a [DataOut](classDataOut.html) instance, attach all data vectors we want to output and call [DataOut<dim>::build\\_patches()](classDataOut.html#a087f63e22f0614bca326dbdca288c646). There is one twist, however. In order to perform asynchronous IO on a background thread we create the DataOut<dim> object as a shared pointer that we pass on to the worker thread to ensure that once we exit this function and the worker thread finishes the DataOut<dim> object gets destroyed again.\n\n```\n       for (unsigned int i = 0; i < n_solution_variables; ++i)\n         {\n           output_vector[i] = U[i];\n           output_vector[i].update_ghost_values();\n         }\n   \n       schlieren_postprocessor.compute_schlieren(output_vector);\n   \n       std::unique_ptr<DataOut<dim>> data_out = std::make_unique<DataOut<dim>>();\n       data_out->attach_dof_handler(offline_data.dof_handler);\n   \n       for (unsigned int i = 0; i < n_solution_variables; ++i)\n         data_out->add_data_vector(output_vector[i],\n                                   ProblemDescription<dim>::component_names[i]);\n   \n       data_out->add_data_vector(schlieren_postprocessor.schlieren,\n                                 \"schlieren_plot\");\n   \n       data_out->build_patches(discretization.mapping,\n                               discretization.finite_element.degree - 1);\n```\n\nNext we create a lambda function for the background thread. We [capture](https://en.cppreference.com/w/cpp/language/lambda) the `this` pointer as well as most of the arguments of the output function by value so that we have access to them inside the lambda function.\n\nThe first capture argument of the lambda function, `data_out_copy` in essence creates a local variable inside the lambda function into which we \"move\" the `data_out` variable from above. The way this works is that we create a `std::unique_ptr` above that points to the [DataOut](classDataOut.html) object. But we have no use for it any more after this point: We really just want to move ownership from the current function to the lambda function implemented in the following few lines. We could have done this by using a `std::shared_ptr` above and giving the lambda function a copy of that shared pointer; once the current function returns (but maybe while the lambda function is still running), our local shared pointer would go out of scope and stop pointing at the actual object, at which point the lambda function simply becomes the sole owner. But using the `std::unique_ptr` is conceptually cleaner as it makes it clear that the current function's `data_out` variable isn't even pointing to the object any more.\n\n```\n       auto output_worker =\n         [data_out_copy = std::move(data_out), this, name, t, cycle]() {\n           const DataOutBase::VtkFlags flags(\n             t, cycle, true, DataOutBase::CompressionLevel::best_speed);\n           data_out_copy->set_flags(flags);\n   \n           data_out_copy->write_vtu_with_pvtu_record(\n             \"\", name + \"-solution\", cycle, mpi_communicator, 6);\n         };\n```\n\nIf the asynchronous writeback option is set we launch a new background thread with the help of [`std::async`](https://en.cppreference.com/w/cpp/thread/async) function. The function returns a [`std::future`](https://en.cppreference.com/w/cpp/thread/future) object that we can use to query the status of the background thread. At this point we can return from the `output()` function and resume with the time stepping in the main loop - the thread will run in the background.\n\n```\n       if (asynchronous_writeback)\n         {\n           background_thread_state =\n             std::async(std::launch::async, std::move(output_worker));\n         }\n       else\n         {\n           output_worker();\n         }\n     }\n   \n   } // namespace Step69\n```\n\nAnd finally, the main function.\n\n```\n   int main(int argc, char *argv[])\n   {\n     try\n       {\n         constexpr int dim = 2;\n   \n         using namespace dealii;\n         using namespace Step69;\n   \n         Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv);\n   \n         MPI_Comm      mpi_communicator(MPI_COMM_WORLD);\n         MainLoop<dim> main_loop(mpi_communicator);\n   \n         main_loop.run();\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       };\n   }\n```\n\nResults\n=======\n\nRunning the program with default parameters in release mode takes about 1 minute on a 4 core machine (with hyperthreading):\n\n```\n# mpirun -np 4 ./step-69 | tee output\nReading parameters and allocating objects... done\n\n    ####################################################\n    #########                                  #########\n    #########       create triangulation       #########\n    #########                                  #########\n    ####################################################\n\nNumber of active cells:       36864\n\n    ####################################################\n    #########                                  #########\n    #########       compute offline data       #########\n    #########                                  #########\n    ####################################################\n\nNumber of degrees of freedom: 37376\n\n    ####################################################\n    #########                                  #########\n    #########         set up time step         #########\n    #########                                  #########\n    ####################################################\n\n    ####################################################\n    #########                                  #########\n    #########    interpolate initial values    #########\n    #########                                  #########\n    #########                                  #########\n    ####################################################\n\nTimeLoop<dim>::interpolate_initial_values(t = 0)\nTimeLoop<dim>::output(t = 0, checkpoint = 0)\n\n    ####################################################\n    #########                                  #########\n    #########         enter main loop          #########\n    #########                                  #########\n    #########                                  #########\n    ####################################################\n\n    ####################################################\n    #########                                  #########\n    #########      Cycle  000001  (0.0%)       #########\n    #########      at time t = 0.00000000      #########\n    #########                                  #########\n    ####################################################\n\n[...]\n\n    ####################################################\n    #########                                  #########\n    #########     Cycle  007553  (100.0%)      #########\n    #########      at time t = 3.99984036      #########\n    #########                                  #########\n    ####################################################\n\nTimeLoop<dim>::output(t = 4.00038, checkpoint = 1)\n\n+------------------------------------------------------------------------+------------+------------+\n| Total CPU time elapsed since start                                     |       357s |            |\n|                                                                        |            |            |\n| Section                                                    | no. calls |  CPU time  | % of total |\n+------------------------------------------------------------+-----------+------------+------------+\n| discretization - setup                                     |         1 |     0.113s |         0% |\n| offline_data - assemble lumped mass matrix, and c_ij       |         1 |     0.167s |         0% |\n| offline_data - compute |c_ij|, and n_ij                    |         1 |   0.00255s |         0% |\n| offline_data - create sparsity pattern and set up matrices |         1 |    0.0224s |         0% |\n| offline_data - distribute dofs                             |         1 |    0.0617s |         0% |\n| offline_data - fix slip boundary c_ij                      |         1 |    0.0329s |         0% |\n| schlieren_postprocessor - compute schlieren plot           |       201 |     0.811s |      0.23% |\n| schlieren_postprocessor - prepare scratch space            |         1 |   7.6e-05s |         0% |\n| time_loop - setup scratch space                            |         1 |     0.127s |         0% |\n| time_loop - stalled output                                 |       200 |  0.000685s |         0% |\n| time_step - 1 compute d_ij                                 |      7553 |       240s |        67% |\n| time_step - 2 compute d_ii, and tau_max                    |      7553 |      11.5s |       3.2% |\n| time_step - 3 perform update                               |      7553 |       101s |        28% |\n| time_step - 4 fix boundary states                          |      7553 |     0.724s |       0.2% |\n| time_step - prepare scratch space                          |         1 |   0.00245s |         0% |\n+------------------------------------------------------------+-----------+------------+------------+\n\n```\n\nOne thing that becomes evident is the fact that the program spends two thirds of the execution time computing the graph viscosity d\\_ij and about a third of the execution time in performing the update, where computing the flux \\(f(U)\\) is the expensive operation. The preset default resolution is about 37k gridpoints, which amounts to about 148k spatial degrees of freedom in 2D. An animated schlieren plot of the solution looks as follows:\n\n![](images/steps/developer/step-69.coarse.gif)\n\nIt is evident that 37k gridpoints for the first-order method is nowhere near the resolution needed to resolve any flow features. For comparison, here is a \"reference\" computation with a second-order method and about 9.5M gridpoints ([github project page](https://github.com/conservation-laws/ryujin)):\n\n![](images/steps/developer/step-69.2nd-order.t400.jpg)\n\nSo, we give the first-order method a second chance and run it with about 2.4M gridpoints on a small compute server:\n\n```\n# mpirun -np 16 ./step-69 | tee output\n\n[...]\n\n    ####################################################\n    #########                                  #########\n    #########     Cycle  070216  (100.0%)      #########\n    #########      at time t = 3.99999231      #########\n    #########                                  #########\n    ####################################################\n\nTimeLoop<dim>::output(t = 4.00006, checkpoint = 1)\n\n[...]\n\n+------------------------------------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start                               |  6.75e+03s |            |\n|                                                                        |            |            |\n| Section                                                    | no. calls |  wall time | % of total |\n+------------------------------------------------------------+-----------+------------+------------+\n| discretization - setup                                     |         1 |      1.97s |         0% |\n| offline_data - assemble lumped mass matrix, and c_ij       |         1 |      1.19s |         0% |\n| offline_data - compute |c_ij|, and n_ij                    |         1 |    0.0172s |         0% |\n| offline_data - create sparsity pattern and set up matrices |         1 |     0.413s |         0% |\n| offline_data - distribute dofs                             |         1 |      1.05s |         0% |\n| offline_data - fix slip boundary c_ij                      |         1 |     0.252s |         0% |\n| schlieren_postprocessor - compute schlieren plot           |       201 |      1.82s |         0% |\n| schlieren_postprocessor - prepare scratch space            |         1 |  0.000497s |         0% |\n| time_loop - setup scratch space                            |         1 |      1.45s |         0% |\n| time_loop - stalled output                                 |       200 |   0.00342s |         0% |\n| time_step - 1 compute d_ij                                 |     70216 |  4.38e+03s |        65% |\n| time_step - 2 compute d_ii, and tau_max                    |     70216 |       419s |       6.2% |\n| time_step - 3 perform update                               |     70216 |  1.87e+03s |        28% |\n| time_step - 4 fix boundary states                          |     70216 |        24s |      0.36% |\n| time_step - prepare scratch space                          |         1 |    0.0227s |         0% |\n+------------------------------------------------------------+-----------+------------+------------+\n\n```\n\nAnd with the following result:\n\n![](images/steps/developer/step-69.fine.gif)\n\nThat's substantially better, although of course at the price of having run the code for roughly 2 hours on 16 cores.\n\n### Possibilities for extensions\n\nThe program showcased here is really only first-order accurate, as discussed above. The pictures above illustrate how much diffusion that introduces and how far the solution is from one that actually resolves the features we care about.\n\nThis can be fixed, but it would exceed what a *tutorial* is about. Nevertheless, it is worth showing what one can achieve by adding a second-order scheme. For example, here is a video computed with [the following research code](https://conservation-laws.org/) that shows (with a different color scheme) a 2d simulation that corresponds to the cases shown above:\n\nThis simulation was done with 38 million degrees of freedom (continuous \\(Q\\_1\\) finite elements) per component of the solution vector. The exquisite detail of the solution is remarkable for these kinds of simulations, including in the sub-sonic region behind the obstacle.\n\nOne can also with relative ease further extend this to the 3d case:\n\nSolving this becomes expensive, however: The simulation was done with 1,817 million degrees of freedom (continuous \\(Q\\_1\\) finite elements) per component (for a total of 9.09 billion spatial degrees of freedom) and ran on 30,720 MPI ranks. The code achieved an average throughput of 969M grid points per second (0.04M gridpoints per second per CPU). The front and back wall show a \"Schlieren plot\": the magnitude of the gradient of the density on an exponential scale from white (low) to black (high). All other cutplanes and the surface of the obstacle show the magnitude of the vorticity on a white (low) - yellow (medium) - red (high) scale. (The scales of the individual cutplanes have been adjusted for a nicer visualization.)\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2020 - 2023 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Matthias Maier, Texas A&M University;\n *          Ignacio Tomas, Texas A&M University, Sandia National Laboratories\n *\n * Sandia National Laboratories is a multimission laboratory managed and\n * operated by National Technology & Engineering Solutions of Sandia, LLC, a\n * wholly owned subsidiary of Honeywell International Inc., for the U.S.\n * Department of Energy's National Nuclear Security Administration under\n * contract DE-NA0003525. This document describes objective technical results\n * and analysis. Any subjective views or opinions that might be expressed in\n * the paper do not necessarily represent the views of the U.S. Department of\n * Energy or the United States Government.\n */\n \n \n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/parallel.h>\n#include <deal.II/base/parameter_acceptor.h>\n#include <deal.II/base/partitioner.h>\n#include <deal.II/base/quadrature.h>\n#include <deal.II/base/timer.h>\n#include <deal.II/base/work_stream.h>\n \n#include <deal.II/distributed/solution_transfer.h>\n#include <deal.II/distributed/tria.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe.h>\n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/fe/mapping.h>\n#include <deal.II/fe/mapping_q.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/manifold_lib.h>\n \n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/la_parallel_vector.h>\n#include <deal.II/lac/sparse_matrix.h>\n#include <deal.II/lac/sparse_matrix.templates.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/meshworker/scratch_data.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <boost/archive/binary_iarchive.hpp>\n#include <boost/archive/binary_oarchive.hpp>\n \n#include <deal.II/base/std_cxx20/iota_view.h>\n#include <boost/range/iterator_range.hpp>\n \n#include <cmath>\n#include <fstream>\n#include <future>\n \n \nnamespace Step69\n{\n using namespace dealii;\n \n \n namespace Boundaries\n  {\n constexpr types::boundary_id do_nothing = 0;\n constexpr types::boundary_id free_slip  = 1;\n constexpr types::boundary_id dirichlet  = 2;\n  } // namespace Boundaries\n \n template <int dim>\n class Discretization : public ParameterAcceptor\n  {\n public:\n    Discretization(const MPI_Comm     mpi_communicator,\n TimerOutput       &computing_timer,\n const std::string &subsection = \"Discretization\");\n \n void setup();\n \n const MPI_Comm mpi_communicator;\n \n parallel::distributed::Triangulation<dim> triangulation;\n \n const MappingQ<dim>   mapping;\n const FE_Q<dim>       finite_element;\n const QGauss<dim>     quadrature;\n const QGauss<dim - 1> face_quadrature;\n \n unsigned int refinement;\n \n private:\n TimerOutput &computing_timer;\n \n double length;\n double height;\n double disk_position;\n double disk_diameter;\n  };\n \n template <int dim>\n class OfflineData : public ParameterAcceptor\n  {\n public:\n using BoundaryNormalMap =\n      std::map<types::global_dof_index,\n               std::tuple<Tensor<1, dim>, types::boundary_id, Point<dim>>>;\n \n    OfflineData(const MPI_Comm             mpi_communicator,\n TimerOutput               &computing_timer,\n const Discretization<dim> &discretization,\n const std::string         &subsection = \"OfflineData\");\n \n void setup();\n void assemble();\n \n DoFHandler<dim> dof_handler;\n \n    std::shared_ptr<const Utilities::MPI::Partitioner> partitioner;\n \n unsigned int n_locally_owned;\n unsigned int n_locally_relevant;\n \n SparsityPattern sparsity_pattern;\n \n    BoundaryNormalMap boundary_normal_map;\n \n SparseMatrix<double>                  lumped_mass_matrix;\n    std::array<SparseMatrix<double>, dim> cij_matrix;\n    std::array<SparseMatrix<double>, dim> nij_matrix;\n SparseMatrix<double>                  norm_matrix;\n \n private:\n const MPI_Comm mpi_communicator;\n TimerOutput   &computing_timer;\n \n SmartPointer<const Discretization<dim>> discretization;\n  };\n \n template <int dim>\n class ProblemDescription\n  {\n public:\n static constexpr unsigned int n_solution_variables = 2 + dim;\n \n using state_type = Tensor<1, n_solution_variables>;\n using flux_type  = Tensor<1, n_solution_variables, Tensor<1, dim>>;\n \n const static std::array<std::string, n_solution_variables> component_names;\n \n static constexpr double gamma = 7. / 5.;\n \n static DEAL_II_ALWAYS_INLINE inline Tensor<1, dim>\n    momentum(const state_type &U);\n \n static DEAL_II_ALWAYS_INLINE inline double\n    internal_energy(const state_type &U);\n \n static DEAL_II_ALWAYS_INLINE inline double pressure(const state_type &U);\n \n static DEAL_II_ALWAYS_INLINE inline double\n    speed_of_sound(const state_type &U);\n \n static DEAL_II_ALWAYS_INLINE inline flux_type flux(const state_type &U);\n \n static DEAL_II_ALWAYS_INLINE inline double\n    compute_lambda_max(const state_type     &U_i,\n const state_type     &U_j,\n const Tensor<1, dim> &n_ij);\n  };\n \n template <int dim>\n class InitialValues : public ParameterAcceptor\n  {\n public:\n using state_type = typename ProblemDescription<dim>::state_type;\n \n    InitialValues(const std::string &subsection = \"InitialValues\");\n \n    std::function<state_type(const Point<dim> &point, double t)> initial_state;\n \n private:\n void parse_parameters_callback();\n \n Tensor<1, dim> initial_direction;\n Tensor<1, 3>   initial_1d_state;\n  };\n \n template <int dim>\n class TimeStepping : public ParameterAcceptor\n  {\n public:\n static constexpr unsigned int n_solution_variables =\n      ProblemDescription<dim>::n_solution_variables;\n \n using state_type = typename ProblemDescription<dim>::state_type;\n using flux_type  = typename ProblemDescription<dim>::flux_type;\n \n using vector_type = std::array<LinearAlgebra::distributed::Vector<double>,\n                                   n_solution_variables>;\n \n TimeStepping(const MPI_Comm            mpi_communicator,\n TimerOutput              &computing_timer,\n const OfflineData<dim>   &offline_data,\n const InitialValues<dim> &initial_values,\n const std::string        &subsection = \"TimeStepping\");\n \n void prepare();\n \n double make_one_step(vector_type &U, const double t);\n \n private:\n const MPI_Comm mpi_communicator;\n TimerOutput   &computing_timer;\n \n SmartPointer<const OfflineData<dim>>   offline_data;\n SmartPointer<const InitialValues<dim>> initial_values;\n \n SparseMatrix<double> dij_matrix;\n \n    vector_type temporary_vector;\n \n double cfl_update;\n  };\n \n template <int dim>\n class SchlierenPostprocessor : public ParameterAcceptor\n  {\n public:\n static constexpr unsigned int n_solution_variables =\n      ProblemDescription<dim>::n_solution_variables;\n \n using state_type = typename ProblemDescription<dim>::state_type;\n \n using vector_type = std::array<LinearAlgebra::distributed::Vector<double>,\n                                   n_solution_variables>;\n \n    SchlierenPostprocessor(\n const MPI_Comm          mpi_communicator,\n TimerOutput            &computing_timer,\n const OfflineData<dim> &offline_data,\n const std::string      &subsection = \"SchlierenPostprocessor\");\n \n void prepare();\n \n void compute_schlieren(const vector_type &U);\n \n LinearAlgebra::distributed::Vector<double> schlieren;\n \n private:\n const MPI_Comm mpi_communicator;\n TimerOutput   &computing_timer;\n \n SmartPointer<const OfflineData<dim>> offline_data;\n \n Vector<double> r;\n \n unsigned int schlieren_index;\n double       schlieren_beta;\n  };\n \n template <int dim>\n class MainLoop : public ParameterAcceptor\n  {\n public:\n using vector_type = typename TimeStepping<dim>::vector_type;\n \n    MainLoop(const MPI_Comm mpi_communnicator);\n \n void run();\n \n private:\n    vector_type interpolate_initial_values(const double t = 0);\n \n void checkpoint(const vector_type &U,\n const std::string &name,\n double             t,\n unsigned int       cycle);\n \n void output(const vector_type &U,\n const std::string &name,\n double             t,\n unsigned int       cycle);\n \n const MPI_Comm     mpi_communicator;\n    std::ostringstream timer_output;\n TimerOutput        computing_timer;\n \n ConditionalOStream pcout;\n \n    std::string base_name;\n double      t_final;\n double      output_granularity;\n \n bool asynchronous_writeback;\n \n bool resume;\n \n    Discretization<dim>         discretization;\n    OfflineData<dim>            offline_data;\n    InitialValues<dim>          initial_values;\n    TimeStepping<dim>           time_stepping;\n    SchlierenPostprocessor<dim> schlieren_postprocessor;\n \n    vector_type output_vector;\n \n    std::future<void> background_thread_state;\n  };\n \n \n \n template <int dim>\n  Discretization<dim>::Discretization(const MPI_Comm     mpi_communicator,\n TimerOutput       &computing_timer,\n const std::string &subsection)\n    : ParameterAcceptor(subsection)\n    , mpi_communicator(mpi_communicator)\n    , triangulation(mpi_communicator)\n    , mapping(1)\n    , finite_element(1)\n    , quadrature(3)\n    , face_quadrature(3)\n    , computing_timer(computing_timer)\n  {\n    length = 4.;\n    add_parameter(\"length\", length, \"Length of computational domain\");\n \n    height = 2.;\n    add_parameter(\"height\", height, \"Height of computational domain\");\n \n    disk_position = 0.6;\n    add_parameter(\"object position\",\n                  disk_position,\n \"x position of immersed disk center point\");\n \n    disk_diameter = 0.5;\n    add_parameter(\"object diameter\",\n                  disk_diameter,\n \"Diameter of immersed disk\");\n \n    refinement = 5;\n    add_parameter(\"refinement\",\n                  refinement,\n \"Number of refinement steps of the geometry\");\n  }\n \n template <int dim>\n void Discretization<dim>::setup()\n  {\n TimerOutput::Scope scope(computing_timer, \"discretization - setup\");\n \n triangulation.clear();\n \n Triangulation<dim> tria1, tria2, tria3, tria4, tria5, tria6;\n \n GridGenerator::hyper_cube_with_cylindrical_hole(\n      tria1, disk_diameter / 2., disk_diameter, 0.5, 1, false);\n \n GridGenerator::subdivided_hyper_rectangle(\n      tria2,\n      {2, 1},\n Point<2>(-disk_diameter, disk_diameter),\n Point<2>(disk_diameter, height / 2.));\n \n GridGenerator::subdivided_hyper_rectangle(\n      tria3,\n      {2, 1},\n Point<2>(-disk_diameter, -disk_diameter),\n Point<2>(disk_diameter, -height / 2.));\n \n GridGenerator::subdivided_hyper_rectangle(\n      tria4,\n      {6, 2},\n Point<2>(disk_diameter, -disk_diameter),\n Point<2>(length - disk_position, disk_diameter));\n \n GridGenerator::subdivided_hyper_rectangle(\n      tria5,\n      {6, 1},\n Point<2>(disk_diameter, disk_diameter),\n Point<2>(length - disk_position, height / 2.));\n \n GridGenerator::subdivided_hyper_rectangle(\n      tria6,\n      {6, 1},\n Point<2>(disk_diameter, -height / 2.),\n Point<2>(length - disk_position, -disk_diameter));\n \n GridGenerator::merge_triangulations(\n      {&tria1, &tria2, &tria3, &tria4, &tria5, &tria6},\n triangulation,\n      1.e-12,\n true);\n \n triangulation.set_manifold(0, PolarManifold<2>(Point<2>()));\n \n \n for (const auto &cell : triangulation.active_cell_iterators())\n      {\n for (const auto v : cell->vertex_indices())\n          {\n if (cell->vertex(v)[0] <= -disk_diameter + 1.e-6)\n              cell->vertex(v)[0] = -disk_position;\n          }\n      }\n \n for (const auto &cell : triangulation.active_cell_iterators())\n      {\n for (const auto f : cell->face_indices())\n          {\n const auto face = cell->face(f);\n \n if (face->at_boundary())\n              {\n const auto center = face->center();\n \n if (center[0] > length - disk_position - 1.e-6)\n                  face->set_boundary_id(Boundaries::do_nothing);\n else if (center[0] < -disk_position + 1.e-6)\n                  face->set_boundary_id(Boundaries::dirichlet);\n else\n                  face->set_boundary_id(Boundaries::free_slip);\n              }\n          }\n      }\n  }\n \n \n template <int dim>\n  OfflineData<dim>::OfflineData(const MPI_Comm             mpi_communicator,\n TimerOutput               &computing_timer,\n const Discretization<dim> &discretization,\n const std::string         &subsection)\n    : ParameterAcceptor(subsection)\n    , dof_handler(discretization.triangulation)\n    , mpi_communicator(mpi_communicator)\n    , computing_timer(computing_timer)\n    , discretization(&discretization)\n  {}\n \n template <int dim>\n void OfflineData<dim>::setup()\n  {\n IndexSet locally_owned;\n IndexSet locally_relevant;\n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"offline_data - distribute dofs\");\n \n      dof_handler.distribute_dofs(discretization->finite_element);\n \n      locally_owned   = dof_handler.locally_owned_dofs();\n      n_locally_owned = locally_owned.n_elements();\n \n      locally_relevant   = DoFTools::extract_locally_relevant_dofs(dof_handler);\n      n_locally_relevant = locally_relevant.n_elements();\n \n      partitioner =\n        std::make_shared<Utilities::MPI::Partitioner>(locally_owned,\n                                                      locally_relevant,\n                                                      mpi_communicator);\n    }\n \n \n \n    {\n TimerOutput::Scope scope(\n        computing_timer,\n \"offline_data - create sparsity pattern and set up matrices\");\n \n \n DynamicSparsityPattern dsp(n_locally_relevant, n_locally_relevant);\n \n const auto dofs_per_cell =\n        discretization->finite_element.n_dofs_per_cell();\n      std::vector<types::global_dof_index> dof_indices(dofs_per_cell);\n \n for (const auto &cell : dof_handler.active_cell_iterators())\n        {\n if (cell->is_artificial())\n continue;\n \n /* We transform the set of global dof indices on the cell to the\n           * corresponding \"local\" index range on the MPI process: */\n          cell->get_dof_indices(dof_indices);\n          std::transform(dof_indices.begin(),\n                         dof_indices.end(),\n                         dof_indices.begin(),\n                         [&](types::global_dof_index index) {\n                           return partitioner->global_to_local(index);\n                         });\n \n /* And simply add, for each dof, a coupling to all other \"local\"\n           * dofs on the cell: */\n for (const auto dof : dof_indices)\n            dsp.add_entries(dof, dof_indices.begin(), dof_indices.end());\n        }\n \n      sparsity_pattern.copy_from(dsp);\n \n      lumped_mass_matrix.reinit(sparsity_pattern);\n      norm_matrix.reinit(sparsity_pattern);\n for (auto &matrix : cij_matrix)\n matrix.reinit(sparsity_pattern);\n for (auto &matrix : nij_matrix)\n matrix.reinit(sparsity_pattern);\n    }\n  }\n \n \n namespace\n  {\n \n template <int dim>\n struct CopyData\n    {\n bool                                         is_artificial;\n      std::vector<types::global_dof_index>         local_dof_indices;\n typename OfflineData<dim>::BoundaryNormalMap local_boundary_normal_map;\n FullMatrix<double>                           cell_lumped_mass_matrix;\n      std::array<FullMatrix<double>, dim>          cell_cij_matrix;\n    };\n \n \n \n template <typename IteratorType>\n DEAL_II_ALWAYS_INLINE inline SparseMatrix<double>::value_type\n    get_entry(const SparseMatrix<double> &matrix, const IteratorType &it)\n    {\n const SparseMatrix<double>::const_iterator matrix_iterator(\n        &matrix, it->global_index());\n return matrix_iterator->value();\n    }\n \n \n template <typename IteratorType>\n DEAL_II_ALWAYS_INLINE inline void\n    set_entry(SparseMatrix<double>            &matrix,\n const IteratorType              &it,\n SparseMatrix<double>::value_type value)\n    {\n SparseMatrix<double>::iterator matrix_iterator(&matrix,\n                                                     it->global_index());\n      matrix_iterator->value() = value;\n    }\n \n \n template <std::size_t k, typename IteratorType>\n DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n    gather_get_entry(const std::array<SparseMatrix<double>, k> &c_ij,\n const IteratorType                         it)\n    {\n Tensor<1, k> result;\n for (unsigned int j = 0; j < k; ++j)\n        result[j] = get_entry(c_ij[j], it);\n return result;\n    }\n \n \n template <std::size_t k>\n DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n gather(const std::array<SparseMatrix<double>, k> &n_ij,\n const unsigned int                         i,\n const unsigned int                         j)\n    {\n Tensor<1, k> result;\n for (unsigned int l = 0; l < k; ++l)\n        result[l] = n_ij[l](i, j);\n return result;\n    }\n \n \n template <std::size_t k>\n DEAL_II_ALWAYS_INLINE inline Tensor<1, k>\n gather(const std::array<LinearAlgebra::distributed::Vector<double>, k> &U,\n const unsigned int                                               i)\n    {\n Tensor<1, k> result;\n for (unsigned int j = 0; j < k; ++j)\n        result[j] = U[j].local_element(i);\n return result;\n    }\n \n \n template <std::size_t k, int k2>\n DEAL_II_ALWAYS_INLINE inline void\n scatter(std::array<LinearAlgebra::distributed::Vector<double>, k> &U,\n const Tensor<1, k2>                                       &tensor,\n const unsigned int                                         i)\n    {\n static_assert(k == k2,\n \"The dimensions of the input arguments must agree\");\n for (unsigned int j = 0; j < k; ++j)\n        U[j].local_element(i) = tensor[j];\n    }\n  } // namespace\n \n \n template <int dim>\n void OfflineData<dim>::assemble()\n  {\n    lumped_mass_matrix = 0.;\n    norm_matrix        = 0.;\n for (auto &matrix : cij_matrix)\n matrix = 0.;\n for (auto &matrix : nij_matrix)\n matrix = 0.;\n \n unsigned int dofs_per_cell =\n      discretization->finite_element.n_dofs_per_cell();\n unsigned int n_q_points = discretization->quadrature.size();\n \n \n MeshWorker::ScratchData<dim> scratch_data(\n      discretization->mapping,\n      discretization->finite_element,\n      discretization->quadrature,\n update_values | update_gradients | update_quadrature_points |\n update_JxW_values,\n      discretization->face_quadrature,\n update_normal_vectors | update_values | update_JxW_values);\n \n    {\n TimerOutput::Scope scope(\n        computing_timer,\n \"offline_data - assemble lumped mass matrix, and c_ij\");\n \n const auto local_assemble_system = \n        [&](const typename DoFHandler<dim>::cell_iterator &cell,\n MeshWorker::ScratchData<dim>                  &scratch,\n            CopyData<dim>                                 &copy) {\n copy.is_artificial = cell->is_artificial();\n if (copy.is_artificial)\n return;\n \n copy.local_boundary_normal_map.clear();\n copy.cell_lumped_mass_matrix.reinit(dofs_per_cell, dofs_per_cell);\n for (auto &matrix : copy.cell_cij_matrix)\n matrix.reinit(dofs_per_cell, dofs_per_cell);\n \n const auto &fe_values = scratch.reinit(cell);\n \n copy.local_dof_indices.resize(dofs_per_cell);\n          cell->get_dof_indices(copy.local_dof_indices);\n \n          std::transform(copy.local_dof_indices.begin(),\n copy.local_dof_indices.end(),\n copy.local_dof_indices.begin(),\n                         [&](types::global_dof_index index) {\n                           return partitioner->global_to_local(index);\n                         });\n \n for (unsigned int q_point = 0; q_point < n_q_points; ++q_point)\n            {\n const auto JxW = fe_values.JxW(q_point);\n \n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                {\n const auto value_JxW =\n                    fe_values.shape_value(j, q_point) * JxW;\n const auto grad_JxW = fe_values.shape_grad(j, q_point) * JxW;\n \n copy.cell_lumped_mass_matrix(j, j) += value_JxW;\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                    {\n const auto value = fe_values.shape_value(i, q_point);\n for (unsigned int d = 0; d < dim; ++d)\n copy.cell_cij_matrix[d](i, j) += value * grad_JxW[d];\n \n                    } /* i */\n                }     /* j */\n            }         /* q */\n \n for (const auto f : cell->face_indices())\n            {\n const auto face = cell->face(f);\n const auto id   = face->boundary_id();\n \n if (!face->at_boundary())\n continue;\n \n const auto &fe_face_values = scratch.reinit(cell, f);\n \n const unsigned int n_face_q_points =\n                fe_face_values.get_quadrature().size();\n \n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                {\n if (!discretization->finite_element.has_support_on_face(j, f))\n continue;\n \n Tensor<1, dim> normal;\n if (id == Boundaries::free_slip)\n                    {\n for (unsigned int q = 0; q < n_face_q_points; ++q)\n                        normal += fe_face_values.normal_vector(q) *\n                                  fe_face_values.shape_value(j, q);\n                    }\n \n const auto index = copy.local_dof_indices[j];\n \n Point<dim> position;\n for (const auto v : cell->vertex_indices())\n                    if (cell->vertex_dof_index(v, 0) ==\n                        partitioner->local_to_global(index))\n                      {\n                        position = cell->vertex(v);\n break;\n                      }\n \n const auto old_id =\n                    std::get<1>(copy.local_boundary_normal_map[index]);\n copy.local_boundary_normal_map[index] =\n                    std::make_tuple(normal, std::max(old_id, id), position);\n                }\n            }\n        };\n \n const auto copy_local_to_global = [&](const CopyData<dim> &copy) {\n if (copy.is_artificial)\n return;\n \n for (const auto &it : copy.local_boundary_normal_map)\n          {\n            std::get<0>(boundary_normal_map[it.first]) +=\n              std::get<0>(it.second);\n            std::get<1>(boundary_normal_map[it.first]) =\n std::max(std::get<1>(boundary_normal_map[it.first]),\n                       std::get<1>(it.second));\n            std::get<2>(boundary_normal_map[it.first]) = std::get<2>(it.second);\n          }\n \n        lumped_mass_matrix.add(copy.local_dof_indices,\n copy.cell_lumped_mass_matrix);\n \n for (int k = 0; k < dim; ++k)\n          {\n            cij_matrix[k].add(copy.local_dof_indices, copy.cell_cij_matrix[k]);\n            nij_matrix[k].add(copy.local_dof_indices, copy.cell_cij_matrix[k]);\n          }\n      };\n \n WorkStream::run(dof_handler.begin_active(),\n                      dof_handler.end(),\n                      local_assemble_system,\n                      copy_local_to_global,\n                      scratch_data,\n                      CopyData<dim>());\n    }\n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"offline_data - compute |c_ij|, and n_ij\");\n \n const std_cxx20::ranges::iota_view<unsigned int, unsigned int> indices(\n        0, n_locally_relevant);\n \n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n for (const auto row_index :\n std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                 *index_begin, *index_end))\n            {\n              std::for_each(sparsity_pattern.begin(row_index),\n                            sparsity_pattern.end(row_index),\n                            [&](const SparsityPatternIterators::Accessor &jt) {\n                              const auto c_ij =\n                                gather_get_entry(cij_matrix, &jt);\n                              const double norm = c_ij.norm();\n \n                              set_entry(norm_matrix, &jt, norm);\n                              for (unsigned int j = 0; j < dim; ++j)\n                                set_entry(nij_matrix[j], &jt, c_ij[j] / norm);\n                            });\n            }\n        };\n \n parallel::apply_to_subranges(indices.begin(),\n                                   indices.end(),\n                                   on_subranges,\n                                   4096);\n \n for (auto &it : boundary_normal_map)\n        {\n auto &normal = std::get<0>(it.second);\n          normal /= (normal.norm() + std::numeric_limits<double>::epsilon());\n        }\n    }\n  }\n \n \n \n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline Tensor<1, dim>\n  ProblemDescription<dim>::momentum(const state_type &U)\n  {\n Tensor<1, dim> result;\n    std::copy_n(&U[1], dim, &result[0]);\n return result;\n  }\n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline double\n  ProblemDescription<dim>::internal_energy(const state_type &U)\n  {\n const double &rho = U[0];\n const auto    m   = momentum(U);\n const double &E   = U[dim + 1];\n return E - 0.5 * m.norm_square() / rho;\n  }\n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline double\n  ProblemDescription<dim>::pressure(const state_type &U)\n  {\n return (gamma - 1.) * internal_energy(U);\n  }\n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline double\n  ProblemDescription<dim>::speed_of_sound(const state_type &U)\n  {\n const double &rho = U[0];\n const double  p   = pressure(U);\n \n return std::sqrt(gamma * p / rho);\n  }\n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline typename ProblemDescription<dim>::flux_type\n  ProblemDescription<dim>::flux(const state_type &U)\n  {\n const double &rho = U[0];\n const auto    m   = momentum(U);\n const auto    p   = pressure(U);\n const double &E   = U[dim + 1];\n \n    flux_type result;\n \n    result[0] = m;\n for (unsigned int i = 0; i < dim; ++i)\n      {\n        result[1 + i] = m * m[i] / rho;\n        result[1 + i][i] += p;\n      }\n    result[dim + 1] = m / rho * (E + p);\n \n return result;\n  }\n \n namespace\n  {\n template <int dim>\n DEAL_II_ALWAYS_INLINE inline std::array<double, 4> riemann_data_from_state(\n const typename ProblemDescription<dim>::state_type U,\n const Tensor<1, dim>                              &n_ij)\n    {\n Tensor<1, 3> projected_U;\n      projected_U[0] = U[0];\n \n const auto m   = ProblemDescription<dim>::momentum(U);\n      projected_U[1] = n_ij * m;\n \n const auto perpendicular_m = m - projected_U[1] * n_ij;\n      projected_U[2] = U[1 + dim] - 0.5 * perpendicular_m.norm_square() / U[0];\n \n \n return {{projected_U[0],\n               projected_U[1] / projected_U[0],\n               ProblemDescription<1>::pressure(projected_U),\n               ProblemDescription<1>::speed_of_sound(projected_U)}};\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double positive_part(const double number)\n    {\n return std::max(number, 0.);\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double negative_part(const double number)\n    {\n return -std::min(number, 0.);\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double\n    lambda1_minus(const std::array<double, 4> &riemann_data,\n const double                 p_star)\n    {\n /* Implements formula (3.7) in Guermond-Popov-2016 */\n \n constexpr double gamma = ProblemDescription<1>::gamma;\n const auto       u     = riemann_data[1];\n const auto       p     = riemann_data[2];\n const auto       a     = riemann_data[3];\n \n const double factor = (gamma + 1.0) / 2.0 / gamma;\n const double tmp    = positive_part((p_star - p) / p);\n return u - a * std::sqrt(1.0 + factor * tmp);\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double\n    lambda3_plus(const std::array<double, 4> &riemann_data, const double p_star)\n    {\n /* Implements formula (3.8) in Guermond-Popov-2016 */\n \n constexpr double gamma = ProblemDescription<1>::gamma;\n const auto       u     = riemann_data[1];\n const auto       p     = riemann_data[2];\n const auto       a     = riemann_data[3];\n \n const double factor = (gamma + 1.0) / 2.0 / gamma;\n const double tmp    = positive_part((p_star - p) / p);\n return u + a * std::sqrt(1.0 + factor * tmp);\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double\n    lambda_max_two_rarefaction(const std::array<double, 4> &riemann_data_i,\n const std::array<double, 4> &riemann_data_j)\n    {\n constexpr double gamma = ProblemDescription<1>::gamma;\n const auto       u_i   = riemann_data_i[1];\n const auto       p_i   = riemann_data_i[2];\n const auto       a_i   = riemann_data_i[3];\n const auto       u_j   = riemann_data_j[1];\n const auto       p_j   = riemann_data_j[2];\n const auto       a_j   = riemann_data_j[3];\n \n const double numerator = a_i + a_j - (gamma - 1.) / 2. * (u_j - u_i);\n \n const double denominator =\n        a_i * std::pow(p_i / p_j, -1. * (gamma - 1.) / 2. / gamma) + a_j * 1.;\n \n /* Formula (4.3) in Guermond-Popov-2016 */\n \n const double p_star =\n        p_j * std::pow(numerator / denominator, 2. * gamma / (gamma - 1));\n \n const double lambda1 = lambda1_minus(riemann_data_i, p_star);\n const double lambda3 = lambda3_plus(riemann_data_j, p_star);\n \n /* Formula (2.11) in Guermond-Popov-2016 */\n \n return std::max(positive_part(lambda3), negative_part(lambda1));\n    }\n \n \n DEAL_II_ALWAYS_INLINE inline double\n    lambda_max_expansion(const std::array<double, 4> &riemann_data_i,\n const std::array<double, 4> &riemann_data_j)\n    {\n const auto u_i = riemann_data_i[1];\n const auto a_i = riemann_data_i[3];\n const auto u_j = riemann_data_j[1];\n const auto a_j = riemann_data_j[3];\n \n return std::max(std::abs(u_i), std::abs(u_j)) + 5. * std::max(a_i, a_j);\n    }\n  } // namespace\n \n \n template <int dim>\n DEAL_II_ALWAYS_INLINE inline double\n  ProblemDescription<dim>::compute_lambda_max(const state_type     &U_i,\n const state_type     &U_j,\n const Tensor<1, dim> &n_ij)\n  {\n const auto riemann_data_i = riemann_data_from_state(U_i, n_ij);\n const auto riemann_data_j = riemann_data_from_state(U_j, n_ij);\n \n const double lambda_1 =\n      lambda_max_two_rarefaction(riemann_data_i, riemann_data_j);\n \n const double lambda_2 =\n      lambda_max_expansion(riemann_data_i, riemann_data_j);\n \n return std::min(lambda_1, lambda_2);\n  }\n \n \n template <>\n const std::array<std::string, 3> ProblemDescription<1>::component_names{\n    {\"rho\", \"m\", \"E\"}};\n \n template <>\n const std::array<std::string, 4> ProblemDescription<2>::component_names{\n    {\"rho\", \"m_1\", \"m_2\", \"E\"}};\n \n template <>\n const std::array<std::string, 5> ProblemDescription<3>::component_names{\n    {\"rho\", \"m_1\", \"m_2\", \"m_3\", \"E\"}};\n \n \n \n template <int dim>\n  InitialValues<dim>::InitialValues(const std::string &subsection)\n    : ParameterAcceptor(subsection)\n  {\n /* We wire up the slot InitialValues<dim>::parse_parameters_callback to\n       the ParameterAcceptor::parse_parameters_call_back signal: */\n ParameterAcceptor::parse_parameters_call_back.connect(\n      [&]() { this->parse_parameters_callback(); });\n \n    initial_direction[0] = 1.;\n    add_parameter(\"initial direction\",\n                  initial_direction,\n \"Initial direction of the uniform flow field\");\n \n    initial_1d_state[0] = ProblemDescription<dim>::gamma;\n    initial_1d_state[1] = 3.;\n    initial_1d_state[2] = 1.;\n    add_parameter(\"initial 1d state\",\n                  initial_1d_state,\n \"Initial 1d state (rho, u, p) of the uniform flow field\");\n  }\n \n \n template <int dim>\n void InitialValues<dim>::parse_parameters_callback()\n  {\n AssertThrow(initial_direction.norm() != 0.,\n                ExcMessage(\n \"Initial shock front direction is set to the zero vector.\"));\n    initial_direction /= initial_direction.norm();\n \n \n    initial_state = [this](const Point<dim> & /*point*/, double /*t*/) {\n const double            rho   = initial_1d_state[0];\n const double            u     = initial_1d_state[1];\n const double            p     = initial_1d_state[2];\n static constexpr double gamma = ProblemDescription<dim>::gamma;\n \n      state_type state;\n \n      state[0] = rho;\n for (unsigned int i = 0; i < dim; ++i)\n        state[1 + i] = rho * u * initial_direction[i];\n \n      state[dim + 1] = p / (gamma - 1.) + 0.5 * rho * u * u;\n \n return state;\n    };\n  }\n \n \n \n template <int dim>\n TimeStepping<dim>::TimeStepping(\n const MPI_Comm            mpi_communicator,\n TimerOutput              &computing_timer,\n const OfflineData<dim>   &offline_data,\n const InitialValues<dim> &initial_values,\n const std::string        &subsection /*= \"TimeStepping\"*/)\n    : ParameterAcceptor(subsection)\n    , mpi_communicator(mpi_communicator)\n    , computing_timer(computing_timer)\n    , offline_data(&offline_data)\n    , initial_values(&initial_values)\n  {\n    cfl_update = 0.80;\n    add_parameter(\"cfl update\",\n                  cfl_update,\n \"Relative CFL constant used for update\");\n  }\n \n \n template <int dim>\n void TimeStepping<dim>::prepare()\n  {\n TimerOutput::Scope scope(computing_timer,\n \"time_stepping - prepare scratch space\");\n \n for (auto &it : temporary_vector)\n      it.reinit(offline_data->partitioner);\n \n    dij_matrix.reinit(offline_data->sparsity_pattern);\n  }\n \n \n template <int dim>\n double TimeStepping<dim>::make_one_step(vector_type &U, const double t)\n  {\n const auto &n_locally_owned    = offline_data->n_locally_owned;\n const auto &n_locally_relevant = offline_data->n_locally_relevant;\n \n const std_cxx20::ranges::iota_view<unsigned int, unsigned int>\n      indices_owned(0, n_locally_owned);\n const std_cxx20::ranges::iota_view<unsigned int, unsigned int>\n      indices_relevant(0, n_locally_relevant);\n \n const auto &sparsity = offline_data->sparsity_pattern;\n \n const auto &lumped_mass_matrix = offline_data->lumped_mass_matrix;\n const auto &norm_matrix        = offline_data->norm_matrix;\n const auto &nij_matrix         = offline_data->nij_matrix;\n const auto &cij_matrix         = offline_data->cij_matrix;\n \n const auto &boundary_normal_map = offline_data->boundary_normal_map;\n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"time_stepping - 1 compute d_ij\");\n \n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n for (const auto i :\n std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                 *index_begin, *index_end))\n            {\n const auto U_i = gather(U, i);\n \n for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                {\n const auto j = jt->column();\n \n if (j >= i)\n continue;\n \n const auto U_j = gather(U, j);\n \n const auto   n_ij = gather_get_entry(nij_matrix, jt);\n const double norm = get_entry(norm_matrix, jt);\n \n const auto lambda_max =\n                    ProblemDescription<dim>::compute_lambda_max(U_i, U_j, n_ij);\n \n double d = norm * lambda_max;\n \n if (boundary_normal_map.count(i) != 0 &&\n                      boundary_normal_map.count(j) != 0)\n                    {\n const auto n_ji = gather(nij_matrix, j, i);\n const auto lambda_max_2 =\n                        ProblemDescription<dim>::compute_lambda_max(U_j,\n                                                                    U_i,\n                                                                    n_ji);\n const double norm_2 = norm_matrix(j, i);\n \n d = std::max(d, norm_2 * lambda_max_2);\n                    }\n \n                  set_entry(dij_matrix, jt, d);\n                  dij_matrix(j, i) = d;\n                }\n            }\n        };\n \n parallel::apply_to_subranges(indices_relevant.begin(),\n                                   indices_relevant.end(),\n                                   on_subranges,\n                                   4096);\n    }\n \n \n \n    std::atomic<double> tau_max{std::numeric_limits<double>::infinity()};\n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"time_stepping - 2 compute d_ii, and tau_max\");\n \n \n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n double tau_max_on_subrange = std::numeric_limits<double>::infinity();\n \n for (const auto i :\n std_cxx20::ranges::iota_view<unsigned int, unsigned int>(\n                 *index_begin, *index_end))\n            {\n double d_sum = 0.;\n \n for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                {\n const auto j = jt->column();\n \n if (j == i)\n continue;\n \n                  d_sum -= get_entry(dij_matrix, jt);\n                }\n \n              dij_matrix.diag_element(i) = d_sum;\n const double mass   = lumped_mass_matrix.diag_element(i);\n const double tau    = cfl_update * mass / (-2. * d_sum);\n              tau_max_on_subrange = std::min(tau_max_on_subrange, tau);\n            }\n \n double current_tau_max = tau_max.load();\n while (current_tau_max > tau_max_on_subrange &&\n                 !tau_max.compare_exchange_weak(current_tau_max,\n                                                tau_max_on_subrange))\n            ;\n        };\n \n parallel::apply_to_subranges(indices_relevant.begin(),\n                                   indices_relevant.end(),\n                                   on_subranges,\n                                   4096);\n \n \n      tau_max.store(Utilities::MPI::min(tau_max.load(), mpi_communicator));\n \n AssertThrow(\n        !std::isnan(tau_max.load()) && !std::isinf(tau_max.load()) &&\n          tau_max.load() > 0.,\n        ExcMessage(\n \"I'm sorry, Dave. I'm afraid I can't do that. - We crashed.\"));\n    }\n \n \n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"time_stepping - 3 perform update\");\n \n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n for (const auto i :\n boost::make_iterator_range(index_begin, index_end))\n            {\n Assert(i < n_locally_owned, ExcInternalError());\n \n const auto U_i = gather(U, i);\n \n const auto   f_i = ProblemDescription<dim>::flux(U_i);\n const double m_i = lumped_mass_matrix.diag_element(i);\n \n auto U_i_new = U_i;\n \n for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                {\n const auto j = jt->column();\n \n const auto U_j = gather(U, j);\n const auto f_j = ProblemDescription<dim>::flux(U_j);\n \n const auto c_ij = gather_get_entry(cij_matrix, jt);\n const auto d_ij = get_entry(dij_matrix, jt);\n \n for (unsigned int k = 0; k < n_solution_variables; ++k)\n                    {\n                      U_i_new[k] +=\n                        tau_max / m_i *\n                        (-(f_j[k] - f_i[k]) * c_ij + d_ij * (U_j[k] - U_i[k]));\n                    }\n                }\n \n scatter(temporary_vector, U_i_new, i);\n            }\n        };\n \n parallel::apply_to_subranges(indices_owned.begin(),\n                                   indices_owned.end(),\n                                   on_subranges,\n                                   4096);\n    }\n \n \n \n    {\n TimerOutput::Scope scope(computing_timer,\n \"time_stepping - 4 fix boundary states\");\n \n for (const auto &it : boundary_normal_map)\n        {\n const auto i = it.first;\n \n if (i >= n_locally_owned)\n continue;\n \n const auto &normal   = std::get<0>(it.second);\n const auto &id       = std::get<1>(it.second);\n const auto &position = std::get<2>(it.second);\n \n auto U_i = gather(temporary_vector, i);\n \n if (id == Boundaries::free_slip)\n            {\n auto m = ProblemDescription<dim>::momentum(U_i);\n              m -= (m * normal) * normal;\n for (unsigned int k = 0; k < dim; ++k)\n                U_i[k + 1] = m[k];\n            }\n \n else if (id == Boundaries::dirichlet)\n            {\n              U_i = initial_values->initial_state(position, t + tau_max);\n            }\n \n scatter(temporary_vector, U_i, i);\n        }\n    }\n \n \n for (auto &it : temporary_vector)\n      it.update_ghost_values();\n \n    U.swap(temporary_vector);\n \n return tau_max;\n  }\n \n \n template <int dim>\n  SchlierenPostprocessor<dim>::SchlierenPostprocessor(\n const MPI_Comm          mpi_communicator,\n TimerOutput            &computing_timer,\n const OfflineData<dim> &offline_data,\n const std::string      &subsection /*= \"SchlierenPostprocessor\"*/)\n    : ParameterAcceptor(subsection)\n    , mpi_communicator(mpi_communicator)\n    , computing_timer(computing_timer)\n    , offline_data(&offline_data)\n  {\n    schlieren_beta = 10.;\n    add_parameter(\"schlieren beta\",\n                  schlieren_beta,\n \"Beta factor used in Schlieren-type postprocessor\");\n \n    schlieren_index = 0;\n    add_parameter(\"schlieren index\",\n                  schlieren_index,\n \"Use the corresponding component of the state vector for the \"\n \"schlieren plot\");\n  }\n \n \n template <int dim>\n void SchlierenPostprocessor<dim>::prepare()\n  {\n TimerOutput::Scope scope(computing_timer,\n \"schlieren_postprocessor - prepare scratch space\");\n \n    r.reinit(offline_data->n_locally_relevant);\n    schlieren.reinit(offline_data->partitioner);\n  }\n \n \n template <int dim>\n void SchlierenPostprocessor<dim>::compute_schlieren(const vector_type &U)\n  {\n TimerOutput::Scope scope(\n      computing_timer, \"schlieren_postprocessor - compute schlieren plot\");\n \n const auto &sparsity            = offline_data->sparsity_pattern;\n const auto &lumped_mass_matrix  = offline_data->lumped_mass_matrix;\n const auto &cij_matrix          = offline_data->cij_matrix;\n const auto &boundary_normal_map = offline_data->boundary_normal_map;\n const auto &n_locally_owned     = offline_data->n_locally_owned;\n \n const auto indices =\n std_cxx20::ranges::iota_view<unsigned int, unsigned int>(0,\n                                                               n_locally_owned);\n \n    std::atomic<double> r_i_max{0.};\n    std::atomic<double> r_i_min{std::numeric_limits<double>::infinity()};\n \n    {\n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n double r_i_max_on_subrange = 0.;\n double r_i_min_on_subrange = std::numeric_limits<double>::infinity();\n \n for (const auto i :\n boost::make_iterator_range(index_begin, index_end))\n            {\n Assert(i < n_locally_owned, ExcInternalError());\n \n Tensor<1, dim> r_i;\n \n for (auto jt = sparsity.begin(i); jt != sparsity.end(i); ++jt)\n                {\n const auto j = jt->column();\n \n if (i == j)\n continue;\n \n const auto U_js = U[schlieren_index].local_element(j);\n const auto c_ij = gather_get_entry(cij_matrix, jt);\n                  r_i += c_ij * U_js;\n                }\n \n \n const auto bnm_it = boundary_normal_map.find(i);\n if (bnm_it != boundary_normal_map.end())\n                {\n const auto &normal = std::get<0>(bnm_it->second);\n const auto &id     = std::get<1>(bnm_it->second);\n \n if (id == Boundaries::free_slip)\n                    r_i -= 1. * (r_i * normal) * normal;\n else\n                    r_i = 0.;\n                }\n \n const double m_i    = lumped_mass_matrix.diag_element(i);\n              r[i]                = r_i.norm() / m_i;\n              r_i_max_on_subrange = std::max(r_i_max_on_subrange, r[i]);\n              r_i_min_on_subrange = std::min(r_i_min_on_subrange, r[i]);\n            }\n \n \n double current_r_i_max = r_i_max.load();\n while (current_r_i_max < r_i_max_on_subrange &&\n                 !r_i_max.compare_exchange_weak(current_r_i_max,\n                                                r_i_max_on_subrange))\n            ;\n \n double current_r_i_min = r_i_min.load();\n while (current_r_i_min > r_i_min_on_subrange &&\n                 !r_i_min.compare_exchange_weak(current_r_i_min,\n                                                r_i_min_on_subrange))\n            ;\n        };\n \n parallel::apply_to_subranges(indices.begin(),\n                                   indices.end(),\n                                   on_subranges,\n                                   4096);\n    }\n \n \n    r_i_max.store(Utilities::MPI::max(r_i_max.load(), mpi_communicator));\n    r_i_min.store(Utilities::MPI::min(r_i_min.load(), mpi_communicator));\n \n \n    {\n const auto on_subranges = \n        [&](const auto index_begin, const auto index_end) {\n for (const auto i :\n boost::make_iterator_range(index_begin, index_end))\n            {\n Assert(i < n_locally_owned, ExcInternalError());\n \n              schlieren.local_element(i) =\n                1. - std::exp(-schlieren_beta * (r[i] - r_i_min) /\n                              (r_i_max - r_i_min));\n            }\n        };\n \n parallel::apply_to_subranges(indices.begin(),\n                                   indices.end(),\n                                   on_subranges,\n                                   4096);\n    }\n \n    schlieren.update_ghost_values();\n  }\n \n \n template <int dim>\n  MainLoop<dim>::MainLoop(const MPI_Comm mpi_communicator)\n    : ParameterAcceptor(\"A - MainLoop\")\n    , mpi_communicator(mpi_communicator)\n    , computing_timer(mpi_communicator,\n                      timer_output,\n TimerOutput::never,\n TimerOutput::cpu_and_wall_times)\n    , pcout(std::cout, Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n    , discretization(mpi_communicator, computing_timer, \"B - Discretization\")\n    , offline_data(mpi_communicator,\n                   computing_timer,\n                   discretization,\n \"C - OfflineData\")\n    , initial_values(\"D - InitialValues\")\n    , time_stepping(mpi_communicator,\n                    computing_timer,\n                    offline_data,\n                    initial_values,\n \"E - TimeStepping\")\n    , schlieren_postprocessor(mpi_communicator,\n                              computing_timer,\n                              offline_data,\n \"F - SchlierenPostprocessor\")\n  {\n    base_name = \"test\";\n    add_parameter(\"basename\", base_name, \"Base name for all output files\");\n \n    t_final = 4.;\n    add_parameter(\"final time\", t_final, \"Final time\");\n \n    output_granularity = 0.02;\n    add_parameter(\"output granularity\",\n                  output_granularity,\n \"time interval for output\");\n \n    asynchronous_writeback = true;\n    add_parameter(\"asynchronous writeback\",\n                  asynchronous_writeback,\n \"Write out solution in a background thread performing IO\");\n \n    resume = false;\n    add_parameter(\"resume\", resume, \"Resume an interrupted computation.\");\n  }\n \n \n namespace\n  {\n void print_head(ConditionalOStream &pcout,\n const std::string  &header,\n const std::string  &secondary = \"\")\n    {\n const auto header_size   = header.size();\n const auto padded_header = std::string((34 - header_size) / 2, ' ') +\n                                 header +\n                                 std::string((35 - header_size) / 2, ' ');\n \n const auto secondary_size = secondary.size();\n const auto padded_secondary =\n        std::string((34 - secondary_size) / 2, ' ') + secondary +\n        std::string((35 - secondary_size) / 2, ' ');\n \n /* clang-format off */\n      pcout << std::endl;\n      pcout << \"    ####################################################\" << std::endl;\n      pcout << \"    #########                                  #########\" << std::endl;\n      pcout << \"    #########\"     <<  padded_header   <<     \"#########\" << std::endl;\n      pcout << \"    #########\"     << padded_secondary <<     \"#########\" << std::endl;\n      pcout << \"    #########                                  #########\" << std::endl;\n      pcout << \"    ####################################################\" << std::endl;\n      pcout << std::endl;\n /* clang-format on */\n    }\n  } // namespace\n \n \n template <int dim>\n void MainLoop<dim>::run()\n  {\n \n    pcout << \"Reading parameters and allocating objects... \" << std::flush;\n \n ParameterAcceptor::initialize(\"step-69.prm\");\n    pcout << \"done\" << std::endl;\n \n \n    {\n      print_head(pcout, \"create triangulation\");\n \n      discretization.setup();\n \n if (resume)\n        discretization.triangulation.load(base_name + \"-checkpoint.mesh\");\n else\n        discretization.triangulation.refine_global(discretization.refinement);\n \n      pcout << \"Number of active cells:       \"\n            << discretization.triangulation.n_global_active_cells()\n            << std::endl;\n \n      print_head(pcout, \"compute offline data\");\n      offline_data.setup();\n      offline_data.assemble();\n \n      pcout << \"Number of degrees of freedom: \"\n            << offline_data.dof_handler.n_dofs() << std::endl;\n \n      print_head(pcout, \"set up time step\");\n      time_stepping.prepare();\n      schlieren_postprocessor.prepare();\n    }\n \n \n double       t            = 0.;\n unsigned int output_cycle = 0;\n \n    vector_type U;\n for (auto &it : U)\n      it.reinit(offline_data.partitioner);\n \n \n if (resume)\n      {\n        print_head(pcout, \"resume interrupted computation\");\n \n        parallel::distributed::\n          SolutionTransfer<dim, LinearAlgebra::distributed::Vector<double>>\n            solution_transfer(offline_data.dof_handler);\n \n        std::vector<LinearAlgebra::distributed::Vector<double> *> vectors;\n        std::transform(U.begin(),\n                       U.end(),\n                       std::back_inserter(vectors),\n                       [](auto &it) { return &it; });\n        solution_transfer.deserialize(vectors);\n \n for (auto &it : U)\n          it.update_ghost_values();\n \n        std::ifstream file(base_name + \"-checkpoint.metadata\",\n                           std::ios::binary);\n \n        boost::archive::binary_iarchive ia(file);\n        ia >> t >> output_cycle;\n      }\n else\n      {\n        print_head(pcout, \"interpolate initial values\");\n        U = interpolate_initial_values();\n      }\n \n \n    output(U, base_name, t, output_cycle++);\n \n    print_head(pcout, \"enter main loop\");\n \n unsigned int timestep_number = 1;\n while (t < t_final)\n      {\n \n        std::ostringstream head;\n        std::ostringstream secondary;\n \n        head << \"Cycle  \" << Utilities::int_to_string(timestep_number, 6)\n             << \"  (\" \n             << std::fixed << std::setprecision(1) << t / t_final * 100 \n             << \"%)\";\n        secondary << \"at time t = \" << std::setprecision(8) << std::fixed << t;\n \n        print_head(pcout, head.str(), secondary.str());\n \n \n        t += time_stepping.make_one_step(U, t);\n \n \n if (t > output_cycle * output_granularity)\n          {\n            checkpoint(U, base_name, t, output_cycle);\n            output(U, base_name, t, output_cycle);\n            ++output_cycle;\n          }\n \n        ++timestep_number;\n      }\n \n if (background_thread_state.valid())\n      background_thread_state.wait();\n \n    computing_timer.print_summary();\n    pcout << timer_output.str() << std::endl;\n  }\n \n \n template <int dim>\n typename MainLoop<dim>::vector_type\n  MainLoop<dim>::interpolate_initial_values(const double t)\n  {\n    pcout << \"MainLoop<dim>::interpolate_initial_values(t = \" << t << ')'\n          << std::endl;\n TimerOutput::Scope scope(computing_timer,\n \"main_loop - setup scratch space\");\n \n    vector_type U;\n \n for (auto &it : U)\n      it.reinit(offline_data.partitioner);\n \n constexpr auto n_solution_variables =\n      ProblemDescription<dim>::n_solution_variables;\n \n for (unsigned int i = 0; i < n_solution_variables; ++i)\n VectorTools::interpolate(offline_data.dof_handler,\n ScalarFunctionFromFunctionObject<dim, double>(\n                                 [&](const Point<dim> &x) {\n                                   return initial_values.initial_state(x, t)[i];\n                                 }),\n                               U[i]);\n \n for (auto &it : U)\n      it.update_ghost_values();\n \n return U;\n  }\n \n \n \n template <int dim>\n void MainLoop<dim>::checkpoint(const typename MainLoop<dim>::vector_type &U,\n const std::string &name,\n const double       t,\n const unsigned int cycle)\n  {\n    print_head(pcout, \"checkpoint computation\");\n \n    parallel::distributed::\n      SolutionTransfer<dim, LinearAlgebra::distributed::Vector<double>>\n        solution_transfer(offline_data.dof_handler);\n \n    std::vector<const LinearAlgebra::distributed::Vector<double> *> vectors;\n    std::transform(U.begin(),\n                   U.end(),\n                   std::back_inserter(vectors),\n                   [](auto &it) { return &it; });\n \n    solution_transfer.prepare_for_serialization(vectors);\n \n    discretization.triangulation.save(name + \"-checkpoint.mesh\");\n \n if (Utilities::MPI::this_mpi_process(mpi_communicator) == 0)\n      {\n        std::ofstream file(name + \"-checkpoint.metadata\", std::ios::binary);\n        boost::archive::binary_oarchive oa(file);\n        oa << t << cycle;\n      }\n  }\n \n \n template <int dim>\n void MainLoop<dim>::output(const typename MainLoop<dim>::vector_type &U,\n const std::string                         &name,\n const double                               t,\n const unsigned int                         cycle)\n  {\n    pcout << \"MainLoop<dim>::output(t = \" << t << ')' << std::endl;\n \n \n if (background_thread_state.valid())\n      {\n TimerOutput::Scope timer(computing_timer, \"main_loop - stalled output\");\n        background_thread_state.wait();\n      }\n \n constexpr auto n_solution_variables =\n      ProblemDescription<dim>::n_solution_variables;\n \n \n for (unsigned int i = 0; i < n_solution_variables; ++i)\n      {\n        output_vector[i] = U[i];\n        output_vector[i].update_ghost_values();\n      }\n \n    schlieren_postprocessor.compute_schlieren(output_vector);\n \n    std::unique_ptr<DataOut<dim>> data_out = std::make_unique<DataOut<dim>>();\n    data_out->attach_dof_handler(offline_data.dof_handler);\n \n for (unsigned int i = 0; i < n_solution_variables; ++i)\n      data_out->add_data_vector(output_vector[i],\n                                ProblemDescription<dim>::component_names[i]);\n \n    data_out->add_data_vector(schlieren_postprocessor.schlieren,\n \"schlieren_plot\");\n \n    data_out->build_patches(discretization.mapping,\n                            discretization.finite_element.degree - 1);\n \n auto output_worker =\n      [data_out_copy = std::move(data_out), this, name, t, cycle]() {\n const DataOutBase::VtkFlags flags(\n          t, cycle, true, DataOutBase::CompressionLevel::best_speed);\n        data_out_copy->set_flags(flags);\n \n        data_out_copy->write_vtu_with_pvtu_record(\n \"\", name + \"-solution\", cycle, mpi_communicator, 6);\n      };\n \n if (asynchronous_writeback)\n      {\n        background_thread_state =\n          std::async(std::launch::async, std::move(output_worker));\n      }\n else\n      {\n        output_worker();\n      }\n  }\n \n} // namespace Step69\n \n \nint main(int argc, char *argv[])\n{\n try\n    {\n constexpr int dim = 2;\n \n using namespace dealii;\n using namespace Step69;\n \n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv);\n \n MPI_Comm      mpi_communicator(MPI_COMM_WORLD);\n      MainLoop<dim> main_loop(mpi_communicator);\n \n      main_loop.run();\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    };\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}
{"custom_id":"https://dealii.org/current/doxygen/deal.II//step_70.html","method":"POST","url":"/v1/chat/completions","body":{"model":"gpt-4.1-mini","messages":[{"role":"user","content":"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\nand the completion is the final code.\nTutorial description : \nA fluid structure interaction problem on fully distributed non-matching grids, using penalty methods, and a coupling constructed through a ParticleHandler object.\nTutorial content :\nThis tutorial depends on [step-19](step_19.html), [step-60](step_60.html).\n\n| **Table of contents** | |\n| --- | --- |\n| 1. [Introduction](#step_70-Intro)    * [Massively parallel non-matching grid simulations of fluid structure interaction problems](#step_70-Massivelyparallelnonmatchinggridsimulationsoffluidstructureinteractionproblems)      + [Co-dimension one case](#step_70-Codimensiononecase)+ [Co-dimension zero case](#step_70-Codimensionzerocase)+ [Representation of Î© and Î](#step_70-Representationofand)+ [Using particles to track Î](#step_70-Usingparticlestotrack)* [The testcase](#step_70-Thetestcase)* [More references](#step_70-Morereferences)- [The commented program](#step_70-CommProg)      * [Include files](#step_70-Includefiles)* [Run-time parameter handling](#step_70-Runtimeparameterhandling)* [The StokesImmersedProblem class declaration](#step_70-TheStokesImmersedProblemclassdeclaration)* [The StokesImmersedProblem class implementation](#step_70-TheStokesImmersedProblemclassimplementation)              + [Object construction and mesh initialization functions](#step_70-Objectconstructionandmeshinitializationfunctions)+ [Particle initialization functions](#step_70-Particleinitializationfunctions)+ [DoF initialization functions](#step_70-DoFinitializationfunctions)+ [Assembly functions](#step_70-Assemblyfunctions)+ [Solving the linear system](#step_70-Solvingthelinearsystem)+ [Mesh refinement](#step_70-Meshrefinement)+ [Creating output for visualization](#step_70-Creatingoutputforvisualization)+ [The \"run\" function](#step_70-Therunfunction)* [The main() function](#step_70-Themainfunction) | 1. [Results](#step_70-Results)    * [Two dimensional test case](#step_70-Twodimensionaltestcase) * [Three dimensional test case](#step_70-Threedimensionaltestcase) * [Possibilities for extensions](#step_70-Possibilitiesforextensions)- [The plain program](#step_70-PlainProg) |\n\n*This program was contributed by Luca Heltai (International School for Advanced Studies, Trieste), Bruno Blais (Polytechnique MontrÃ©al), and Rene GassmÃ¶ller (University of California Davis)*\n\nNote\n:   If you use this program as a basis for your own work, please consider citing it in your list of references. The initial version of this work was contributed to the deal.II project by the authors listed in the following citation: [![10.5281/zenodo.3829064](https://zenodo.org/badge/DOI/10.5281/zenodo.3829064.svg)](https://doi.org/10.5281/zenodo.3829064)\n\nIntroduction\n============\n\n### Massively parallel non-matching grid simulations of fluid structure interaction problems\n\nIn this tutorial we consider a mixing problem in the laminar flow regime. Such problems occur in a wide range of applications ranging from chemical engineering to power generation (e.g. turbomachinery). Mixing problems are particularly hard to solve numerically, because they often involve a container (with fixed boundaries, and possibly complex geometries such as baffles), represented by the domain \\(\\Omega\\), and one (or more) immersed and rotating impellers (represented by the domain \\(\\Omega^{\\text{imp}}\\)). The domain in which we would like to solve the flow equations is the (time dependent) difference between the two domains, namely: \\(\\Omega\\setminus\\Omega^{\\text{imp}}\\).\n\nFor rotating impellers, the use of Arbitrary Lagrangian Eulerian formulations (in which the fluid domain – along with the mesh! – is smoothly deformed to follow the deformations of the immersed solid) is not possible, unless only small times (i.e., small fluid domain deformations) are considered. If one wants to track the evolution of the flow across multiple rotations of the impellers, the resulting deformed grid would simply be too distorted to be useful.\n\nIn this case, a viable alternative strategy would be to use non-matching methods (similarly to what we have done in [step-60](step_60.html)), where a background fixed grid (that may or may not be locally refined in time to better capture the solid motion) is coupled with a rotating, independent, grid.\n\nIn order to maintain the same notations used in [step-60](step_60.html), we use \\(\\Omega\\) to denote the domain in \\({\\mathbb R}^{\\text{spacedim}}\\) representing the container of both the fluid and the impeller, and we use \\(\\Gamma\\) in \\({\\mathbb R}^{\\text{dim}}\\) to denote either the full impeller (when its `spacedim` measure is non-negligible, i.e., when we can represent it as a grid of dimension `dim` equal to `spacedim`), a co-dimension one representation of a thin impeller, or just the boundary of the full impeller.\n\nThe domain \\(\\Gamma\\) is embedded in \\(\\Omega\\) ( \\(\\Gamma \\subseteq \\Omega\\)) and it is non-matching: It does not, in general, align with any of the features of the volume mesh. We solve a partial differential equation on \\(\\Omega\\), enforcing some conditions on the solution of the problem on the embedded domain \\(\\Gamma\\) by some penalization techniques. In the current case, the condition is that the velocity of the fluid at points on \\(\\Gamma\\) equal the velocity of the solid impeller at that point.\n\nThe technique we describe here is presented in the literature using one of many names: the **immersed finite element method** and the **fictitious boundary method** among others. The main principle is that the discretization of the two grids are kept completely independent. In the present tutorial, this approach is used to solve for the motion of a viscous fluid, described by the Stokes equation, that is agitated by a rigid non-deformable impeller.\n\nThus, the equations solved in \\(\\Omega\\) are the Stokes equations for a creeping flow (i.e. a flow where \\(\\text{Re}\\rightarrow 0\\)) and a no-slip boundary condition is applied on the moving *embedded domain* \\(\\Gamma\\) associated with the impeller. However, this tutorial could be readily extended to other equations (e.g. the Navier-Stokes equations, linear elasticity equation, etc.). It can be seen as a natural extension of [step-60](step_60.html) that enables the solution of large problems using a distributed parallel computing architecture via MPI.\n\nHowever, contrary to [step-60](step_60.html), the Dirichlet boundary conditions on \\(\\Gamma\\) are imposed weakly instead of through the use of Lagrange multipliers, and we concentrate on dealing with the coupling of two fully distributed triangulations (a combination that was not possible in the implementation of [step-60](step_60.html)).\n\nThere are two interesting scenarios that occur when one wants to enforce conditions on the embedded domain \\(\\Gamma\\):\n\n* The geometrical dimension `dim` of the embedded domain \\(\\Gamma\\) is the same of the domain \\(\\Omega\\) (`spacedim`), that is, the spacedim-dimensional measure of \\(\\Gamma\\) is not zero. In this case, the imposition of the Dirichlet boundary boundary condition on \\(\\Gamma\\) is done through a volumetric penalization. If the applied penalization only depends on the velocity, this is often referred to as \\(\\mathcal{L}^2\\) penalization whereas if the penalization depends on both the velocity and its gradient, it is an \\(\\mathcal{H}^1\\) penalization. The case of the \\(\\mathcal{L}^2\\) penalization is very similar to a Darcy-type approach. Both \\(\\mathcal{L}^2\\) and \\(\\mathcal{H}^1\\) penalizations have been analyzed extensively (see, for example, [[4]](citelist.html#CITEREF_Angot1999)).\n* The embedded domain \\(\\Gamma\\) has an intrinsic dimension `dim` which is smaller than that of \\(\\Omega\\) (`spacedim`), thus its spacedim-dimensional measure is zero; for example it is a curve embedded in a two dimensional domain, or a surface embedded in a three-dimensional domain. This is of course physically impossible, but one may consider very thin sheets of metal moving in a fluid as essentially lower-dimensional if the thickness of the sheet is negligible. In this case, the boundary condition is imposed weakly on \\(\\Gamma\\) by applying the [Nitsche](https://en.wikipedia.org/wiki/Joachim_Nitsche) method (see [[90]](citelist.html#CITEREF_Freund1995)).\n\nBoth approaches have very similar requirements and result in highly similar formulations. Thus, we treat them almost in the same way.\n\nIn this tutorial program we are not interested in further details on \\(\\Gamma\\): we assume that the dimension of the embedded domain (`dim`) is always smaller by one or equal with respect to the dimension of the embedding domain \\(\\Omega\\) (`spacedim`).\n\nWe are going to solve the following differential problem: given a sufficiently regular function \\(g\\) on \\(\\Gamma\\), find the solution \\((\\textbf{u},p)\\) to\n\n\\begin{eqnarray\\*}\n-\\Delta \\mathbf{u} + \\nabla p &=& 0,\\\\\n-\\nabla \\cdot \\textbf{u} &=& 0,\\\\\n\\textbf{u} &=& \\textbf{g} \\text{ in } \\Gamma,\\\\\n\\textbf{u} &=& 0 \\text{ on } \\partial\\Omega.\n\\end{eqnarray\\*}\n\nThis equation, which we have normalized by scaling the time units in such a way that the viscosity has a numerical value of 1, describes slow, viscous flow such as honey or lava. The main goal of this tutorial is to show how to impose the velocity field condition \\(\\mathbf{u} = \\mathbf{g}\\) on a non-matching \\(\\Gamma\\) in a weak way, using a penalization method. A more extensive discussion of the Stokes problem including body forces, different boundary conditions, and solution strategies can be found in [step-22](step_22.html).\n\nLet us start by considering the Stokes problem alone, in the entire domain \\(\\Omega\\). We look for a velocity field \\(\\mathbf{u}\\) and a pressure field \\(p\\) that satisfy the Stokes equations with homogeneous boundary conditions on \\(\\partial\\Omega\\).\n\nThe weak form of the Stokes equations is obtained by first writing it in vector form as\n\n\\begin{eqnarray\\*}\n\\begin{pmatrix}\n{-\\Delta \\textbf{u} + \\nabla p}\n\\\\\n{-\\textrm{div}\\;\\textbf{u}}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0\n\\\\\n0\n\\end{pmatrix},\n\\end{eqnarray\\*}\n\nforming the dot product from the left with a vector-valued test function \\(\\phi = \\begin{pmatrix}\\textbf{v} \\\\ q\\end{pmatrix}\\), and integrating over the domain \\(\\Omega\\), yielding the following set of equations:\n\n\\begin{eqnarray\\*}\n(\\mathrm v,\n-\\Delta \\textbf{u} + \\nabla p)\\_{\\Omega}\n-\n(q,\\textrm{div}\\; \\textbf{u})\\_{\\Omega}\n=\n0\n\\end{eqnarray\\*}\n\nwhich has to hold for all test functions \\(\\phi = \\begin{pmatrix}\\textbf{v}\n\\\\ q\\end{pmatrix}\\).\n\nIntegrating by parts and exploiting the boundary conditions on \\(\\partial\\Omega\\), we obtain the following variational problem:\n\n\\begin{eqnarray\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega} - (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega}&=& 0\n\\end{eqnarray\\*}\n\nwhere \\((\\cdot, \\cdot)\\_{\\Omega}\\) represents the \\(L^2\\) scalar product. This is the same variational form used in [step-22](step_22.html).\n\nThis variational formulation does not take into account the embedded domain. Contrary to [step-60](step_60.html), we do not enforce strongly the constraints of \\(\\textbf{u}\\) on \\(\\Gamma\\), but enforce them weakly via a penalization term.\n\nThe analysis of this weak imposition of the boundary condition depends on the spacedim-dimensional measure of \\(\\Gamma\\) as either positive (if `dim` is equal to `spacedim`) or zero (if `dim` is smaller than `spacedim`). We discuss both scenarios.\n\n#### Co-dimension one case\n\nIn this case, we assume that \\(\\Gamma\\) is the boundary of the actual impeller, that is, a closed curve embedded in a two-dimensional domain or a closed surface in a three-dimensional domain. The idea of this method starts by considering a weak imposition of the Dirichlet boundary condition on \\(\\Gamma\\), following the Nitsche method. This is achieved by using the following modified formulation on the fluid domain, where no strong conditions on the test functions on \\(\\Gamma\\) are imposed:\n\n\\begin{multline\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega\\setminus\\Omega^{\\text{imp}}} - (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega\\setminus\\Omega^{\\text{imp}}}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega\\setminus\\Omega^{\\text{imp}}} \\\\\n- (\\textbf{v},\\nabla \\textbf{u} \\cdot \\textbf{n})\\_{\\Gamma}\n+ (\\textbf{v}\\cdot \\textbf{n},p)\\_{\\Gamma} \\\\\n- (\\nabla\\textbf{v}\\cdot \\textbf{n},\\textbf{u})\\_{\\Gamma}\n+ (q, \\textbf{u} \\cdot \\textbf{n})\\_{\\Gamma}\n+ \\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} \\\\\n= - (\\nabla\\textbf{v}\\cdot \\textbf{n},\\textbf{g})\\_{\\Gamma} + (q, \\textbf{g} \\cdot \\textbf{n})\\_{\\Gamma}\n+ \\beta (\\textbf{v},\\textbf{g})\\_{\\Gamma}.\n\\end{multline\\*}\n\nThe integrals over \\(\\Gamma\\) are lower-dimensional integrals. It can be shown (see [[90]](citelist.html#CITEREF_Freund1995)) that there exists a positive constant \\(C\\_1\\) so that if \\(\\beta > C\\_1\\), the weak imposition of the boundary will be consistent and stable. The first two additional integrals on \\(\\Gamma\\) (the second line in the equation above) appear naturally after integrating by parts, when one does not assume that \\(\\mathbf{v}\\) is zero on \\(\\Gamma\\).\n\nThe third line in the equation above contains two terms that are added to ensure consistency of the weak form, and a stabilization term, that is there to enforce the boundary condition with an error which is consistent with the approximation error. The consistency terms and the stabilization term are added to the right hand side with the actual boundary data \\(\\mathbf{g}\\).\n\nWhen \\(\\mathbf{u}\\) satisfies the condition \\(\\mathbf{u}=\\mathbf{g}\\) on \\(\\Gamma\\), all the consistency and stability integrals on \\(\\Gamma\\) cancel out, and one is left with the usual weak form of Stokes flow, that is, the above formulation is consistent.\n\nWe note that an alternative (non-symmetric) formulation can be used :\n\n\\begin{multline\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega\\setminus\\Omega^{\\text{imp}}} - (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega\\setminus\\Omega^{\\text{imp}}}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega\\setminus\\Omega^{\\text{imp}}} \\\\\n-(\\textbf{v},\\nabla \\textbf{u} \\cdot \\textbf{n})\\_{\\Gamma}\n+ (\\textbf{v}\\cdot \\textbf{n},p)\\_{\\Gamma} \\\\\n+(\\nabla\\textbf{v}\\cdot \\textbf{n},\\textbf{u})\\_{\\Gamma}\n- (q, \\textbf{u} \\cdot \\textbf{n})\\_{\\Gamma}\n+ \\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} \\\\\n= (\\nabla\\textbf{v}\\cdot \\textbf{n},\\textbf{g})\\_{\\Gamma} - (q, \\textbf{g} \\cdot \\textbf{n})\\_{\\Gamma}\n+ \\beta (\\textbf{v},\\textbf{g})\\_{\\Gamma}.\n\\end{multline\\*}\n\nNote the different sign of the first terms on the third and fourth lines. In this case, the stability and consistency conditions become \\(\\beta > 0\\). In the symmetric case, the value of \\(\\beta\\) is dependent on \\(h\\), and it is in general chosen such that \\(\\beta = C h^{-1} \\) with \\(h\\) a measure of size of the face being integrated and \\(C\\) a constant such that \\(1 \\leq C \\leq 10\\). This is as one usually does with the Nitsche penalty method to enforcing Dirichlet boundary conditions.\n\nThe non-symmetric approach, on the other hand, is related to how one enforced continuity for the non-symmetric interior penalty method for discontinuous Galerkin methods (the \"NIPG\" method [[185]](citelist.html#CITEREF_Riviere1999)). Even if the non-symmetric case seems advantageous w.r.t. possible choices of stabilization parameters, we opt for the symmetric discretization, since in this case it can be shown that the dual problem is also consistent, leading to a solution where not only the energy norm of the solution converges with the correct order, but also its \\(L^2\\) norm. Furthermore, the resulting matrix remains symmetric.\n\nThe above formulation works under the assumption that the domain is discretized exactly. However, if the deformation of the impeller is a rigid body motion, it is possible to artificially extend the solution of the Stokes problem inside the propeller itself, since a rigid body motion is also a solution to the Stokes problem. The idea is then to solve the same problem, inside \\(\\Omega^{\\text{imp}}\\), imposing the same boundary conditions on \\(\\Gamma\\), using the same penalization technique, and testing with test functions \\(\\mathbf{v}\\) which are globally continuous over \\(\\Omega\\).\n\nThis results in the following (intermediate) formulation:\n\n\\begin{multline\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega} - (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega} \\\\\n- (\\textbf{v}, \\lbrack \\nabla \\textbf{u} \\rbrack \\cdot \\textbf{n})\\_{\\Gamma}\n+ (\\textbf{v}\\cdot \\textbf{n},\\lbrack p \\rbrack )\\_{\\Gamma} \\\\\n- (\\lbrack \\nabla\\textbf{v} \\rbrack \\cdot \\textbf{n},\\textbf{u})\\_{\\Gamma}\n+ (\\lbrack q \\rbrack, \\textbf{u} \\cdot n)\\_{\\Gamma}\n+ 2\\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} \\\\\n= - (\\lbrack \\nabla\\textbf{v}\\rbrack\\cdot \\textbf{n},\\textbf{g})\\_{\\Gamma} + (\\lbrack q\\rbrack, \\textbf{g} \\cdot n)\\_{\\Gamma}\n+ 2\\beta (\\textbf{v},\\textbf{g})\\_{\\Gamma},\n\\end{multline\\*}\n\nwhere the jump terms, denoted with \\(\\lbrack \\cdot \\rbrack\\), are computed with respect to a fixed orientation of the normal vector \\(\\textbf{n}\\). The factor of 2 appears in front of \\(\\beta\\) since we see every part of \\(\\Gamma\\) twice, once from within the fluid and once from within the obstacle moving around in it. (For all of the other integrals over \\(\\Gamma\\), we visit each part of \\(\\Gamma\\) twice, but with opposite signs, and consequently get the jump terms.)\n\nHere we notice that, unlike in discontinuous Galerkin methods, the test and trial functions are continuous across \\(\\Gamma\\). Moreover, if \\(\\Gamma\\) is not aligned with cell boundaries, all the jump terms are also zero, since, in general, finite element function spaces are smooth inside each cell, and if \\(\\Gamma\\) cuts through an element intersecting its boundary only at a finite number of points, all the contributions on \\(\\Gamma\\), with the exception of the stabilization ones, can be neglected from the formulation, resulting in the following final form of the variational formulation:\n\n\\begin{multline\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega} - (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega} + 2\\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} \\\\\n= 2\\beta (\\textbf{v},\\textbf{g})\\_{\\Gamma}.\n\\end{multline\\*}\n\nIn [step-60](step_60.html), the imposition of the constraint required the addition of new variables in the form of Lagrange multipliers. This is not the case for this tutorial program. The imposition of the boundary condition using Nitsche's method only modifies the system matrix and the right-hand side without adding additional unknowns. However, the velocity vector \\(\\textbf{u}\\) on the embedded domain will not match exactly the prescribed velocity \\(\\textbf{g}\\), but only up to a numerical error which is in the same order as the interpolation error of the finite element method. Furthermore, as in [step-60](step_60.html), we still need to integrate over the non-matching embedded grid in order to construct the boundary term necessary to impose the boundary condition over \\(\\Gamma\\).\n\n#### Co-dimension zero case\n\nIn this case, \\(\\Gamma\\) has the same dimension, but is embedded into \\(\\Omega\\). We can think of this as a thick object moving around in the fluid. In the case of \\(\\mathcal{L}^2\\) penalization, the additional penalization term can be interpreted as a Darcy term within \\(\\Gamma\\), resulting in:\n\n\\begin{eqnarray\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega} - & (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega} + \\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma}\n= \\beta (\\textbf{v},\\textbf{g})\\_{\\Gamma}.\n\\end{eqnarray\\*}\n\nHere, integrals over \\(\\Gamma\\) are simply integrals over a part of the volume. The \\(\\mathcal{L}^2\\) penalization thus consists in adding a volumetric term that constrains the velocity of the fluid to adhere to the velocity of the rigid body within \\(\\Gamma\\). Also in this case, \\(\\beta\\) must be chosen sufficiently large in order to ensure that the Dirichlet boundary condition in \\(\\Gamma\\) is sufficiently respected, but not too high in order to maintain the proper conditioning of the system matrix.\n\nA \\(\\mathcal{H}^1\\) penalization may be constructed in a similar manner, with the addition of a viscous component to the penalization that dampens the velocity gradient within \\(\\Gamma\\):\n\n\\begin{eqnarray\\*}\n(\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Omega} - & (\\textrm{div}\\; \\textbf{v}, p)\\_{\\Omega}\n- (q, \\textrm{div}\\; \\textbf{u})\\_{\\Omega}\n+ \\beta\\_1 (\\textbf{v},\\textbf{u})\\_{\\Gamma}\n+ \\beta\\_2 (\\nabla \\textbf{v}, \\nabla \\textbf{u})\\_{\\Gamma}\n= \\beta\\_1 (\\textbf{v},\\textbf{g})\\_{\\Gamma}\n+ \\beta\\_2 (\\nabla \\textbf{v}, \\nabla \\textbf{g})\\_{\\Gamma}.\n\\end{eqnarray\\*}\n\nNotice that the \\(L^2\\) penalization (`dim` equal to `spacedim`) and the Nitsche penalization (`dim` equal to `spacedim-1`) result in the exact same numerical implementation, thanks to the dimension independent capabilities of deal.II.\n\n#### Representation of Î© and Î\n\nIn this tutorial, both the embedded grid \\(\\Gamma\\) and the embedding grid are described using a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html). These two triangulations can be built from functions in the [GridGenerator](namespaceGridGenerator.html) namespace or by reading a mesh file produced with another application (e.g. GMSH, see the discussion in [step-49](step_49.html)). This is slightly more general than what was previously done in [step-60](step_60.html).\n\nThe addition of the immersed boundary method, whether it is in the `dim=spacedim` or `dim<spacedim` case, only introduces additional terms in the system matrix and the right-hand side of the system which result from the integration over \\(\\Gamma\\). This does not modify the number of variables for which the problem must be solved. The challenge is thus related to the integrals that must be carried over \\(\\Gamma\\).\n\nAs usual in finite elements we split this integral into contributions from all cells of the triangulation used to discretize \\(\\Gamma\\), we transform the integral on \\(K\\) to an integral on the reference element \\(\\hat K\\), where \\(F\\_{K}\\) is the mapping from \\(\\hat K\\) to \\(K\\), and compute the integral on \\(\\hat K\\) using a quadrature formula. For example:\n\n\\[\n\\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} = \\sum\\_{K\\in \\Gamma} \\int\\_{\\hat K}\n\\hat{\\textbf{u}}(\\hat x) (\\textbf{v} \\circ F\\_{K}) (\\hat x) J\\_K (\\hat x) \\mathrm{d} \\hat x =\n\\sum\\_{K\\in \\Gamma} \\sum\\_{i=1}^{n\\_q} \\big(\\hat{\\textbf{u}}(\\hat x\\_i) (\\textbf{v} \\circ F\\_{K}) (\\hat x\\_i) J\\_K (\\hat x\\_i) w\\_i \\big)\n\\]\n\nComputing this sum is non-trivial because we have to evaluate \\((v\\_j \\circ F\\_{K})\n(\\hat x\\_i)\\). In general, if \\(\\Gamma\\) and \\(\\Omega\\) are not aligned, the point \\(y\\_i = F\\_{K}(\\hat x\\_i)\\) is completely arbitrary with respect to \\(\\Omega\\), and unless we figure out a way to interpolate all basis functions of \\(V\\_h(\\Omega)\\) on an arbitrary point on \\(\\Omega\\), we cannot compute the integral needed.\n\nTo evaluate \\((v\\_j \\circ F\\_{K}) (\\hat x\\_i)\\) the following steps needs to be taken (as shown in the picture below):\n\n* For a given cell \\(K\\) in \\(\\Gamma\\) compute the real point \\(y\\_i \\dealcoloneq F\\_{K} (\\hat\n  x\\_i)\\), where \\(x\\_i\\) is one of the quadrature points used for the integral on \\(K\n  \\subseteq \\Gamma\\). This is the easy part: [FEValues::quadrature\\_point()](classFEValuesBase.html#a7671e35e7a87a395dc9fdee0f5a7650f) gives us the real-space locations of all quadrature points.\n* Find the cell of \\(\\Omega\\) in which \\(y\\_i\\) lies. We shall call this element \\(T\\).\n* Find the reference coordinates within \\(T\\) of \\(y\\_i\\). For this, we need the inverse of the mapping \\(G\\_T\\) that transforms the reference element \\(\\hat T\\) into the element \\(T\\): \\(\\hat y\\_i = G^{-1}\\_{T} (y\\_i)\\).\n* Evaluate the basis function \\(v\\_j\\) of the \\(\\Omega\\) mesh at this point \\(\\hat y\\_i\\). This is, again, relatively simple using [FEValues](classFEValues.html).\n\n![](images/steps/developer/step-60.C_interpolation.png)\n\nIn [step-60](step_60.html), the second through fourth steps above were computed by calling, in turn,\n\n* [GridTools::find\\_active\\_cell\\_around\\_point()](namespaceGridTools.html#a2e10aeb1c8e76110a84b6945eac3aaf0), followed by\n* [Mapping::transform\\_real\\_to\\_unit\\_cell()](classMapping.html#a7e322d14c2800734d071a48a95b00d35). We then\n* construct a custom [Quadrature](classQuadrature.html) formula, containing the point in the reference cell and then\n* construct an [FEValues](classFEValues.html) object, with the given quadrature formula, and initialized with the cell obtained in the first step.\n\nAlthough this approach could work for the present case, it does not lend itself readily to parallel simulations using distributed triangulations. Indeed, since the position of the quadrature points on the cells of the embedded domain \\(\\Gamma\\) do not match that of the embedding triangulation and since \\(\\Gamma\\) is constantly moving, this would require that the triangulation representing \\(\\Gamma\\) be stored in its entirety for all of the processors. As the number of processor and the number of cells in \\(\\Gamma\\) increases, this leads to a severe bottleneck in terms of memory. Consequently, an alternative strategy is sought in this step.\n\n#### Using particles to track Î\n\nRemember that for both the penalization approach ( \\(\\mathcal{L}^2\\) or \\(\\mathcal{H}^1\\)) and the Nitsche method, we want to compute integrals that are approximated by the quadrature. That is, we need to compute\n\n\\[\n\\beta (\\textbf{v},\\textbf{u})\\_{\\Gamma} =\n\\sum\\_{K\\in \\Gamma} \\sum\\_{i=1}^{n\\_q} \\big(\\hat{\\textbf{u}}(\\hat x\\_i) (\\textbf{v} \\circ F\\_{K}) (\\hat x\\_i) J\\_K (\\hat x\\_i) w\\_i \\big)\n\\]\n\nIf you followed the discussion above, then you will recall that \\(\\textbf{u}\\) and \\(\\textbf{v}\\) are shape functions defined on the fluid mesh. The only things defined on the solid mesh are: \\(F\\_K(\\hat x\\_i)\\), which is the location of a quadrature point on a solid cell that is part of \\(\\Gamma\\), \\(J\\_K\\) is the determinant of its Jacobian, and \\(w\\_i\\) the corresponding quadrature weight.\n\nThe important part to realize is now this: \\(w\\_i\\) is a property of the quadrature formula and does not change with time. Furthermore, the Jacobian matrix of \\(F\\_K\\) itself changes as the solid obstacle moves around in the fluid, but because the solid is considered non-deforming (it only translates and rotates, but doesn't dilate), the determinant of the Jacobian remains constant. As a consequence, the product \\(J\\_K(\\hat x\\_i) w\\_i\\) (which we typically denote by `JxW`) remains constant for each quadrature point. So the only thing we need keep track of are the positions \\(x\\_i=F\\_K(\\hat x\\_i)\\) – but these move with the velocity of the solid domain.\n\nIn other words, we don't actually need to keep the solid mesh at all. All we need is the positions \\(x\\_i(t)\\) and corresponding `JxW` values. Since both of these properties are point-properties (or point-vectors) that are attached to the solid material, they can be idealized as a set of disconnected infinitesimally small \"particles\", which carry the required `JxW` information with the movement of the solid. deal.II has the ability to distribute and store such a set of particles in large-scale parallel computations in the form of the ParticleHandler class (for details on the implementation see [[93]](citelist.html#CITEREF_GLHPW2018)), and we will make use of this functionality in this tutorial.\n\nThus, the approach taken in this step is as follows:\n\n* Create a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) for the domain \\(\\Gamma\\);\n* Create [Particles::Particle](classParticles_1_1Particle.html) at the positions of the quadrature points on \\(\\Gamma\\);\n* Call the [Particles::ParticleHandler::insert\\_global\\_particles()](classParticles_1_1ParticleHandler.html#a969e872fca93e8f5609b8bfea3739d04) function, to distribute the particles across processors, *following the solid triangulation*;\n* Attach the `JxW` values as a \"property\" to each [Particles::Particle](classParticles_1_1Particle.html) object.\n\nThis structure is relatively expensive to generate, but must only be generated once per simulation. Once the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) is generated and the required information is attached to the particle, the integrals over \\(\\Gamma\\) can be carried out by exploiting the fact that particles are grouped cellwise inside ParticleHandler, allowing us to:\n\n* Looping over all cells of \\(\\Omega\\) that contain at least one particle\n* Looping over all particles in the given cell\n* Compute the integrals and fill the global matrix.\n\nSince the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) can manage the exchange of particles from one processor to the other, the embedded triangulation can be moved or deformed by displacing the particles. The only constraint associated with this displacement is that particles should be displaced by a distance that is no larger than the size of one cell. That's because that is the limit to which [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) can track which cell a particle that leaves its current cell now resides in.\n\nOnce the entire problem (the Stokes problem and the immersed boundary imposition) is assembled, the final saddle point problem is solved by an iterative solver, applied to the Schur complement \\(S\\) (whose construction is described, for example, in [step-22](step_22.html)), and we construct \\(S\\) using [LinearOperator](classLinearOperator.html) classes.\n\n### The testcase\n\nThe problem we solve here is a demonstration of the time-reversibility of Stokes flow. This is often illustrated in science education experiments with a Taylor-Couette flow and dye droplets that revert back to their original shape after the fluid has been displaced in a periodic manner.\n\nIn the present problem, a very viscous fluid is agitated by the rotation of an impeller, which, in 2D, is modeled by a rectangular grid. The impeller rotates for a given number of revolutions, after which the flow is reversed such that the same number of revolutions is carried out in the opposite direction. We recall that since the Stokes equations are self-adjoint, creeping flows are reversible. Consequently, if the impeller motion is reversed in the opposite direction, the fluid should return to its original position. In the present case, this is illustrated by inserting a circle of passive tracer particles that are advected by the fluid and which return to their original position, thus demonstrating the time-reversibility of the flow.\n\n### More references\n\nThis tutorial program uses a number of techniques on imposing velocity conditions on non-matching interfaces in the interior of the fluid. For more background material, you may want to look up the following references: [[90]](citelist.html#CITEREF_Freund1995), [[4]](citelist.html#CITEREF_Angot1999), [[98]](citelist.html#CITEREF_Glowinski1999), [[34]](citelist.html#CITEREF_Boffi2008), [[115]](citelist.html#CITEREF_Heltai2012).\n\nThe commented program\n=====================\n\n### Include files\n\nMost of these have been introduced elsewhere, we'll comment only on the new ones. The switches close to the top that allow selecting between PETSc and Trilinos linear algebra capabilities are similar to the ones in [step-40](step_40.html) and [step-50](step_50.html).\n\n```\n   #include <deal.II/base/function.h>\n   #include <deal.II/base/quadrature_lib.h>\n   #include <deal.II/base/timer.h>\n   \n   #include <deal.II/lac/block_linear_operator.h>\n   #include <deal.II/lac/generic_linear_algebra.h>\n   #include <deal.II/lac/linear_operator.h>\n   #include <deal.II/lac/linear_operator_tools.h>\n   \n   #define FORCE_USE_OF_TRILINOS\n   \n   namespace LA\n   {\n   #if defined(DEAL_II_WITH_PETSC) && !defined(DEAL_II_PETSC_WITH_COMPLEX) && \\\n     !(defined(DEAL_II_WITH_TRILINOS) && defined(FORCE_USE_OF_TRILINOS))\n     using namespace dealii::LinearAlgebraPETSc;\n   #  define USE_PETSC_LA\n   #elif defined(DEAL_II_WITH_TRILINOS)\n     using namespace dealii::LinearAlgebraTrilinos;\n   #else\n   #  error DEAL_II_WITH_PETSC or DEAL_II_WITH_TRILINOS required\n   #endif\n   } // namespace LA\n   \n   #include <deal.II/base/conditional_ostream.h>\n   #include <deal.II/base/index_set.h>\n   #include <deal.II/base/parameter_acceptor.h>\n   #include <deal.II/base/parsed_function.h>\n   #include <deal.II/base/utilities.h>\n   \n   #include <deal.II/distributed/grid_refinement.h>\n   #include <deal.II/distributed/solution_transfer.h>\n   #include <deal.II/distributed/tria.h>\n   \n   #include <deal.II/dofs/dof_handler.h>\n   #include <deal.II/dofs/dof_renumbering.h>\n   #include <deal.II/dofs/dof_tools.h>\n   \n   #include <deal.II/fe/fe_nothing.h>\n   #include <deal.II/fe/fe_q.h>\n   #include <deal.II/fe/fe_system.h>\n   #include <deal.II/fe/fe_values.h>\n   #include <deal.II/fe/mapping_fe_field.h>\n   #include <deal.II/fe/mapping_q1.h>\n   \n   #include <deal.II/grid/grid_generator.h>\n   #include <deal.II/grid/grid_in.h>\n   #include <deal.II/grid/grid_tools.h>\n   #include <deal.II/grid/manifold_lib.h>\n   \n   #include <deal.II/lac/affine_constraints.h>\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\n   #include <deal.II/lac/full_matrix.h>\n   #include <deal.II/lac/petsc_precondition.h>\n   #include <deal.II/lac/petsc_solver.h>\n   #include <deal.II/lac/petsc_sparse_matrix.h>\n   #include <deal.II/lac/petsc_vector.h>\n   #include <deal.II/lac/solver_cg.h>\n   #include <deal.II/lac/solver_gmres.h>\n   #include <deal.II/lac/solver_minres.h>\n   #include <deal.II/lac/sparsity_tools.h>\n   #include <deal.II/lac/vector.h>\n   \n   #include <deal.II/numerics/data_out.h>\n   #include <deal.II/numerics/error_estimator.h>\n   #include <deal.II/numerics/vector_tools.h>\n```\n\nThese are the only new include files with regard to [step-60](step_60.html). In this tutorial, the non-matching coupling between the solid and the fluid is computed using an intermediate data structure that keeps track of how the locations of quadrature points of the solid evolve within the fluid mesh. This data structure needs to keep track of the position of the quadrature points on each cell describing the solid domain, of the quadrature weights, and possibly of the normal vector to each point, if the solid domain is of co-dimension one.\n\nDeal.II offers these facilities in the [Particles](namespaceParticles.html) namespace, through the ParticleHandler class. ParticleHandler is a class that allows you to manage a collection of particles (objects of type [Particles::Particle](classParticles_1_1Particle.html)), representing a collection of points with some attached properties (e.g., an id) floating on a [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html). The methods and classes in the namespace [Particles](namespaceParticles.html) allows one to easily implement Particle-In-Cell methods and particle tracing on distributed triangulations.\n\nWe \"abuse\" this data structure to store information about the location of solid quadrature points embedded in the surrounding fluid grid, including integration weights, and possibly surface normals. The reason why we use this additional data structure is related to the fact that the solid and the fluid grids might be non-overlapping, and if we were using two separate triangulation objects, would be distributed independently among parallel processes.\n\nIn order to couple the two problems, we rely on the ParticleHandler class, storing in each particle the position of a solid quadrature point (which is in general not aligned to any of the fluid quadrature points), its weight, and any other information that may be required to couple the two problems. These locations are then propagated along with the (prescribed) velocity of the solid impeller.\n\nOwnership of the solid quadrature points is initially inherited from the MPI partitioning on the solid mesh itself. The [Particles](namespaceParticles.html) so generated are later distributed to the fluid mesh using the methods of the ParticleHandler class. This allows transparent exchange of information between MPI processes about the overlapping pattern between fluid cells and solid quadrature points.\n\n```\n   #include <deal.II/particles/data_out.h>\n   #include <deal.II/particles/generators.h>\n   #include <deal.II/particles/particle_handler.h>\n   #include <deal.II/particles/utilities.h>\n```\n\nWhen generating the grids, we allow reading it from a file, and if deal.II has been built with [OpenCASCADE](namespaceOpenCASCADE.html) support, we also allow reading CAD files and use them as manifold descriptors for the grid (see [step-54](step_54.html) for a detailed description of the various [Manifold](classManifold.html) descriptors that are available in the [OpenCASCADE](namespaceOpenCASCADE.html) namespace)\n\n```\n   #include <deal.II/opencascade/manifold_lib.h>\n   #include <deal.II/opencascade/utilities.h>\n   #ifdef DEAL_II_WITH_OPENCASCADE\n   #  include <TopoDS.hxx>\n   #endif\n   \n   #include <cmath>\n   #include <filesystem>\n   #include <fstream>\n   #include <iostream>\n   #include <memory>\n   \n   namespace Step70\n   {\n     using namespace dealii;\n```\n\n### Run-time parameter handling\n\nSimilarly to what we have done in [step-60](step_60.html), we set up a class that holds all the parameters of our problem and derive it from the [ParameterAcceptor](classParameterAcceptor.html) class to simplify the management and creation of parameter files.\n\nThe [ParameterAcceptor](classParameterAcceptor.html) paradigm requires all parameters to be writable by the [ParameterAcceptor](classParameterAcceptor.html) methods. In order to avoid bugs that would be very difficult to track down (such as writing things like `time = 0` instead of `time == 0`), we declare all the parameters in an external class, which is initialized before the actual `StokesImmersedProblem` class, and pass it to the main class as a `const` reference.\n\nThe constructor of the class is responsible for the connection between the members of this class and the corresponding entries in the [ParameterHandler](classParameterHandler.html). Thanks to the use of the [ParameterHandler::add\\_parameter()](classParameterHandler.html#a04b75c02037d19fd7fd781785fcefc79) method, this connection is trivial, but requires all members of this class to be writeable.\n\n```\n     template <int dim, int spacedim = dim>\n     class StokesImmersedProblemParameters : public ParameterAcceptor\n     {\n     public:\n       StokesImmersedProblemParameters();\n```\n\nhowever, since this class will be passed as a `const` reference to the StokesImmersedProblem class, we have to make sure we can still set the time correctly in the objects derived by the [Function](classFunction.html) class defined herein. In order to do so, we declare both the `StokesImmersedProblemParameters::rhs` and `StokesImmersedProblemParameters::angular_velocity` members to be `mutable`, and define the following little helper method that sets their time to the correct value.\n\n```\n       void set_time(const double &time) const\n       {\n         rhs.set_time(time);\n         angular_velocity.set_time(time);\n       }\n```\n\nThe remainder of the class consists largely of member variables that describe the details of the simulation and its discretization. The following parameters are about where output should land, the spatial and temporal discretization (the default is the \\(Q\\_2\\times Q\\_1\\) Taylor-Hood discretization which uses a polynomial degree of 2 for the velocity), and how many time steps should elapse before we generate graphical output again:\n\n```\n       std::string output_directory = \".\";\n   \n       unsigned int velocity_degree = 2;\n   \n       unsigned int number_of_time_steps = 501;\n       double       final_time           = 1.0;\n   \n       unsigned int output_frequency = 1;\n```\n\nWe allow every grid to be refined independently. In this tutorial, no physics is resolved on the solid grid, and its velocity is given as a datum. However it is relatively straightforward to incorporate some elasticity model in this tutorial, and transform it into a fully fledged FSI solver.\n\n```\n       unsigned int initial_fluid_refinement      = 5;\n       unsigned int initial_solid_refinement      = 5;\n       unsigned int particle_insertion_refinement = 3;\n```\n\nTo provide a rough description of the fluid domain, we use the method [extract\\_rtree\\_level()](rtree_8h.html#a11528a51ba44b19a2d2e515445e7e0aa) applied to the tree of bounding boxes of each locally owned cell of the fluid triangulation. The higher the level of the tree, the larger the number of extracted bounding boxes, and the more accurate is the description of the fluid domain. However, a large number of bounding boxes also implies a large communication cost, since the collection of bounding boxes is gathered by all processes.\n\n```\n       unsigned int fluid_rtree_extraction_level = 1;\n```\n\nThe only two numerical parameters used in the equations are the viscosity of the fluid, and the penalty term \\(\\beta\\) used in the Nitsche formulation:\n\n```\n       double viscosity    = 1.0;\n       double penalty_term = 100;\n```\n\nBy default, we create a hyper\\_cube without colorization, and we use homogeneous Dirichlet boundary conditions. In this set we store the boundary ids to use when setting the boundary conditions:\n\n```\n       std::list<types::boundary_id> homogeneous_dirichlet_ids{0};\n```\n\nWe illustrate here another way to create a [Triangulation](classTriangulation.html) from a parameter file, using the method [GridGenerator::generate\\_from\\_name\\_and\\_arguments()](namespaceGridGenerator.html#a1e6c4dcc63863449f08a78a22ec73747), that takes the name of a function in the [GridGenerator](namespaceGridGenerator.html) namespace, and its arguments as a single string representing the arguments as a tuple.\n\nThe mechanism with which the arguments are parsed from and to a string is explained in detail in the [Patterns::Tools::Convert](structPatterns_1_1Tools_1_1Convert.html) class, which is used to translate from strings to most of the basic STL types (vectors, maps, tuples) and basic deal.II types ([Point](classPoint.html), [Tensor](classTensor.html), [BoundingBox](classBoundingBox.html), etc.).\n\nIn general objects that can be represented by rank 1 uniform elements (i.e., std::vector<double>, Point<dim>, std::set<int>, etc.) are comma separated. Additional ranks take a semicolon, allowing you to parse strings into objects of type `std::vector<std::vector<double>>`, or, for example, `std::vector<Point<dim>>`, as `0.0, 0.1; 0.1, 0.2`. This string could be interpreted as a vector of two [Point](classPoint.html) objects, or a vector of vector of doubles.\n\nWhen the entries are not uniform, as in the tuple case, we use a colon to separate the various entries. For example, a string like `5: 0.1, 0.2` could be used to parse an object of type `std::pair<int, Point<2>>` or a `std::tuple<int, std::vector<double>>`.\n\nIn our case most of the arguments are [Point](classPoint.html) objects (representing centers, corners, subdivision elements, etc.), integer values (number of subdivisions), double values (radius, lengths, etc.), or boolean options (such as the `colorize` option that many [GridGenerator](namespaceGridGenerator.html) functions take).\n\nIn the example below, we set reasonable default values, but these can be changed at run time by selecting any other supported function of the [GridGenerator](namespaceGridGenerator.html) namespace. If the [GridGenerator](namespaceGridGenerator.html) function fails, this program will interpret the name of the grid as a vtk grid filename, and the arguments as a map from manifold\\_id to the CAD files describing the geometry of the domain. Every CAD file will be analyzed and a [Manifold](classManifold.html) of the [OpenCASCADE](namespaceOpenCASCADE.html) namespace will be generated according to the content of the CAD file itself.\n\nTo be as generic as possible, we do this for each of the generated grids: the fluid grid, the solid grid, but also the tracer particles which are also generated using a triangulation.\n\n```\n       std::string name_of_fluid_grid       = \"hyper_cube\";\n       std::string arguments_for_fluid_grid = \"-1: 1: false\";\n       std::string name_of_solid_grid       = \"hyper_rectangle\";\n       std::string arguments_for_solid_grid = spacedim == 2 ?\n                                                \"-.5, -.1: .5, .1: false\" :\n                                                \"-.5, -.1, -.1: .5, .1, .1: false\";\n       std::string name_of_particle_grid    = \"hyper_ball\";\n       std::string arguments_for_particle_grid =\n         spacedim == 2 ? \"0.3, 0.3: 0.1: false\" : \"0.3, 0.3, 0.3 : 0.1: false\";\n```\n\nSimilarly, we allow for different local refinement strategies. In particular, we limit the maximum number of refinement levels, in order to control the minimum size of the fluid grid, and guarantee that it is compatible with the solid grid. The minimum number of refinement levels is also controlled to ensured sufficient accuracy in the bulk of the flow. Additionally, we perform local refinement based on standard error estimators on the fluid velocity field.\n\nWe permit the user to choose between the two most common refinement strategies, namely `fixed_number` or `fixed_fraction`, that refer to the methods [GridRefinement::refine\\_and\\_coarsen\\_fixed\\_fraction()](namespaceGridRefinement.html#afafa5d897bd8b1e9eeee70ffcb6d1c1e) and [GridRefinement::refine\\_and\\_coarsen\\_fixed\\_number()](namespaceGridRefinement.html#a48e5395381ed87155942a61a1edd134d).\n\nRefinement may be done every few time steps, instead of continuously, and we control this value by the `refinement_frequency` parameter:\n\n```\n       int          max_level_refinement = 8;\n       int          min_level_refinement = 5;\n       std::string  refinement_strategy  = \"fixed_fraction\";\n       double       coarsening_fraction  = 0.3;\n       double       refinement_fraction  = 0.3;\n       unsigned int max_cells            = 20000;\n       int          refinement_frequency = 5;\n```\n\nFinally, the following two function objects are used to control the source term of Stokes flow and the angular velocity at which we move the solid body. In a more realistic simulation, the solid velocity or its deformation would come from the solution of an auxiliary problem on the solid domain. In this example step we leave this part aside, and simply impose a fixed rotational velocity field along the z-axis on the immersed solid, governed by a function that can be specified in the parameter file :\n\n```\n       mutable ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>> rhs;\n       mutable ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n         angular_velocity;\n     };\n```\n\nThere remains the task of declaring what run-time parameters we can accept in input files. We split the parameters in various categories, by putting them in different sections of the [ParameterHandler](classParameterHandler.html) class. We begin by declaring all the global parameters used by StokesImmersedProblem in the global scope:\n\n```\n     template <int dim, int spacedim>\n     StokesImmersedProblemParameters<dim,\n                                     spacedim>::StokesImmersedProblemParameters()\n       : ParameterAcceptor(\"Stokes Immersed Problem/\")\n       , rhs(\"Right hand side\", spacedim + 1)\n       , angular_velocity(\"Angular velocity\")\n     {\n       add_parameter(\n         \"Velocity degree\", velocity_degree, \"\", this->prm, Patterns::Integer(1));\n   \n       add_parameter(\"Number of time steps\", number_of_time_steps);\n       add_parameter(\"Output frequency\", output_frequency);\n   \n       add_parameter(\"Output directory\", output_directory);\n   \n       add_parameter(\"Final time\", final_time);\n   \n       add_parameter(\"Viscosity\", viscosity);\n   \n       add_parameter(\"Nitsche penalty term\", penalty_term);\n   \n       add_parameter(\"Initial fluid refinement\",\n                     initial_fluid_refinement,\n                     \"Initial mesh refinement used for the fluid domain Omega\");\n   \n       add_parameter(\"Initial solid refinement\",\n                     initial_solid_refinement,\n                     \"Initial mesh refinement used for the solid domain Gamma\");\n   \n       add_parameter(\"Fluid bounding boxes extraction level\",\n                     fluid_rtree_extraction_level,\n                     \"Extraction level of the rtree used to construct global \"\n                     \"bounding boxes\");\n   \n       add_parameter(\n         \"Particle insertion refinement\",\n         particle_insertion_refinement,\n         \"Refinement of the volumetric mesh used to insert the particles\");\n   \n       add_parameter(\n         \"Homogeneous Dirichlet boundary ids\",\n         homogeneous_dirichlet_ids,\n         \"Boundary Ids over which homogeneous Dirichlet boundary conditions are applied\");\n```\n\nNext section is dedicated to the parameters used to create the various grids. We will need three different triangulations: `Fluid grid` is used to define the fluid domain, `Solid grid` defines the solid domain, and `Particle grid` is used to distribute some tracer particles, that are advected with the velocity and only used as passive tracers.\n\n```\n       enter_subsection(\"Grid generation\");\n       {\n         add_parameter(\"Fluid grid generator\", name_of_fluid_grid);\n         add_parameter(\"Fluid grid generator arguments\", arguments_for_fluid_grid);\n   \n         add_parameter(\"Solid grid generator\", name_of_solid_grid);\n         add_parameter(\"Solid grid generator arguments\", arguments_for_solid_grid);\n   \n         add_parameter(\"Particle grid generator\", name_of_particle_grid);\n         add_parameter(\"Particle grid generator arguments\",\n                       arguments_for_particle_grid);\n       }\n       leave_subsection();\n   \n   \n   \n       enter_subsection(\"Refinement and remeshing\");\n       {\n         add_parameter(\"Refinement step frequency\", refinement_frequency);\n         add_parameter(\"Refinement maximal level\", max_level_refinement);\n         add_parameter(\"Refinement minimal level\", min_level_refinement);\n         add_parameter(\"Refinement strategy\",\n                       refinement_strategy,\n                       \"\",\n                       this->prm,\n                       Patterns::Selection(\"fixed_fraction|fixed_number\"));\n         add_parameter(\"Refinement coarsening fraction\", coarsening_fraction);\n         add_parameter(\"Refinement fraction\", refinement_fraction);\n         add_parameter(\"Maximum number of cells\", max_cells);\n       }\n       leave_subsection();\n```\n\nThe final task is to correct the default dimension for the right hand side function and define a meaningful default angular velocity instead of zero.\n\n```\n       rhs.declare_parameters_call_back.connect([&]() {\n         Functions::ParsedFunction<spacedim>::declare_parameters(this->prm,\n                                                                 spacedim + 1);\n       });\n       angular_velocity.declare_parameters_call_back.connect([&]() {\n         this->prm.set(\"Function expression\",\n                       \"t < .500001 ? 6.283185 : -6.283185\");\n       });\n     }\n```\n\nOnce the angular velocity is provided as a [Function](classFunction.html) object, we reconstruct the pointwise solid velocity through the following class which derives from the [Function](classFunction.html) class. It provides the value of the velocity of the solid body at a given position by assuming that the body rotates around the origin (or the \\(z\\) axis in 3d) with a given angular velocity.\n\n```\n     template <int spacedim>\n     class SolidVelocity : public Function<spacedim>\n     {\n     public:\n       static_assert(spacedim > 1,\n                     \"Cannot instantiate SolidVelocity for spacedim == 1\");\n   \n       SolidVelocity(const Functions::ParsedFunction<spacedim> &angular_velocity)\n         : angular_velocity(angular_velocity)\n       {}\n   \n       virtual double value(const Point<spacedim> &p,\n                            unsigned int           component = 0) const override\n       {\n         Tensor<1, spacedim> velocity;\n```\n\nWe assume that the angular velocity is directed along the z-axis, i.e., we model the actual angular velocity as if it was a two-dimensional rotation, irrespective of the actual value of `spacedim`.\n\n```\n         const double omega = angular_velocity.value(p);\n         velocity[0]        = -omega * p[1];\n         velocity[1]        = omega * p[0];\n   \n         return velocity[component];\n       }\n   \n     private:\n       const Functions::ParsedFunction<spacedim> &angular_velocity;\n     };\n```\n\nSimilarly, we assume that the solid position can be computed explicitly at each time step, exploiting the knowledge of the angular velocity. We compute the exact position of the solid particle assuming that the solid is rotated by an amount equal to the time step multiplied by the angular velocity computed at the point `p`:\n\n```\n     template <int spacedim>\n     class SolidPosition : public Function<spacedim>\n     {\n     public:\n       static_assert(spacedim > 1,\n                     \"Cannot instantiate SolidPosition for spacedim == 1\");\n   \n       SolidPosition(const Functions::ParsedFunction<spacedim> &angular_velocity,\n                     const double                               time_step)\n         : Function<spacedim>(spacedim)\n         , angular_velocity(angular_velocity)\n         , time_step(time_step)\n       {}\n   \n       virtual double value(const Point<spacedim> &p,\n                            unsigned int           component = 0) const override\n       {\n         Point<spacedim> new_position = p;\n   \n         double dtheta = angular_velocity.value(p) * time_step;\n   \n         new_position[0] = std::cos(dtheta) * p[0] - std::sin(dtheta) * p[1];\n         new_position[1] = std::sin(dtheta) * p[0] + std::cos(dtheta) * p[1];\n   \n         return new_position[component];\n       }\n   \n       void set_time_step(const double new_time_step)\n       {\n         time_step = new_time_step;\n       }\n   \n     private:\n       const Functions::ParsedFunction<spacedim> &angular_velocity;\n       double                                     time_step;\n     };\n```\n\n### The StokesImmersedProblem class declaration\n\nWe are now ready to introduce the main class of our tutorial program. As usual, other than the constructor, we leave a single public entry point: the `run()` method. Everything else is left `private`, and accessed through the run method itself.\n\n```\n     template <int dim, int spacedim = dim>\n     class StokesImmersedProblem\n     {\n     public:\n       StokesImmersedProblem(\n         const StokesImmersedProblemParameters<dim, spacedim> &par);\n   \n       void run();\n```\n\nThe next section contains the `private` members of the class. The first method is similar to what is present in previous example. However it not only takes care of generating the grid for the fluid, but also the grid for the solid. The second computes the largest time step that guarantees that each particle moves of at most one cell. This is important to ensure that the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) can find which cell a particle ends up in, as it can only look from one cell to its immediate neighbors (because, in a parallel setting, every MPI process only knows about the cells it owns as well as their immediate neighbors).\n\n```\n     private:\n       void make_grid();\n   \n       double compute_time_step() const;\n```\n\nThe next two functions initialize the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) objects used in this class. We have two such objects: One represents passive tracers, used to plot the trajectories of fluid particles, while the other represents material particles of the solid, which are placed at quadrature points of the solid grid.\n\n```\n       void setup_tracer_particles();\n       void setup_solid_particles();\n```\n\nThe remainder of the set up is split in two parts: The first of the following two functions creates all objects that are needed once per simulation, whereas the other sets up all objects that need to be reinitialized at every refinement step.\n\n```\n       void initial_setup();\n       void setup_dofs();\n```\n\nThe assembly routine is very similar to other Stokes assembly routines, with the exception of the Nitsche restriction part, which exploits one of the particle handlers to integrate on a non-matching part of the fluid domain, corresponding to the position of the solid. We split these two parts into two separate functions.\n\n```\n       void assemble_stokes_system();\n       void assemble_nitsche_restriction();\n```\n\nThe remaining functions solve the linear system (which looks almost identical to the one in [step-60](step_60.html)) and then postprocess the solution: The refine\\_and\\_transfer() method is called only every `refinement_frequency` steps to adapt the mesh and also make sure that all the fields that were computed on the time step before refinement are transferred correctly to the new grid. This includes vector fields, as well as particle information. Similarly, we call the two output methods only every `output_frequency` steps.\n\n```\n       void solve();\n   \n       void refine_and_transfer();\n   \n       void output_results(const unsigned int cycle, const double time) const;\n       void output_particles(const Particles::ParticleHandler<spacedim> &particles,\n                             std::string                                 fprefix,\n                             const unsigned int                          iter,\n                             const double time) const;\n```\n\nLet us then move on to the member functions of the class. The first deals with run-time parameters that are read from a parameter file. As noted before, we make sure we cannot modify this object from within this class, by making it a `const` reference.\n\n```\n       const StokesImmersedProblemParameters<dim, spacedim> &par;\n```\n\nThen there is also the MPI communicator object that we will use to let processes send information across the network if the program runs in parallel, along with the `pcout` object and timer information that has also been employed by [step-40](step_40.html), for example:\n\n```\n       MPI_Comm mpi_communicator;\n   \n       ConditionalOStream pcout;\n   \n       mutable TimerOutput computing_timer;\n```\n\nNext is one of the main novelties with regard to [step-60](step_60.html). Here we assume that both the solid and the fluid are fully distributed triangulations. This allows the problem to scale to a very large number of degrees of freedom, at the cost of communicating all the overlapping regions between non matching triangulations. This is especially tricky, since we make no assumptions on the relative position or distribution of the various subdomains of the two triangulations. In particular, we assume that every process owns only a part of the `solid_tria`, and only a part of the `fluid_tria`, not necessarily in the same physical region, and not necessarily overlapping.\n\nWe could in principle try to create the initial subdivisions in such a way that each process's subdomains overlap between the solid and the fluid regions. However, this overlap would be destroyed during the simulation, and we would have to redistribute the DoFs again and again. The approach we follow in this tutorial is more flexible, and not much more expensive. We make two all-to-all communications at the beginning of the simulation to exchange information about an (approximate) information of the geometrical occupancy of each processor (done through a collection of bounding boxes).\n\nThis information is used by the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class to exchange (using a some-to-some communication pattern) all particles, so that every process knows about the particles that live on the region occupied by the fluid subdomain that it owns.\n\nIn order to couple the overlapping regions, we exploit the facilities implemented in the ParticleHandler class.\n\n```\n       parallel::distributed::Triangulation<spacedim>      fluid_tria;\n       parallel::distributed::Triangulation<dim, spacedim> solid_tria;\n```\n\nNext come descriptions of the finite elements in use, along with the corresponding [DoFHandler](classDoFHandler.html) objects. For the current implementation, only `fluid_fe` is really necessary. For completeness, and to allow easy extension, we also keep the `solid_fe` around, which is however initialized to a [FE\\_Nothing](classFE__Nothing.html) finite element space, i.e., one that has no degrees of freedom.\n\nWe declare both finite element spaces as `std::unique_ptr` objects rather than regular member variables, to allow their generation after `StokesImmersedProblemParameters` has been initialized. In particular, they will be initialized in the `initial_setup()` method.\n\n```\n       std::unique_ptr<FiniteElement<spacedim>>      fluid_fe;\n       std::unique_ptr<FiniteElement<dim, spacedim>> solid_fe;\n   \n       DoFHandler<spacedim>      fluid_dh;\n       DoFHandler<dim, spacedim> solid_dh;\n```\n\nSimilarly to how things are done in [step-22](step_22.html), we use a block system to treat the Stokes part of the problem, and follow very closely what was done there.\n\n```\n       std::vector<IndexSet> fluid_owned_dofs;\n       std::vector<IndexSet> solid_owned_dofs;\n   \n       std::vector<IndexSet> fluid_relevant_dofs;\n       std::vector<IndexSet> solid_relevant_dofs;\n```\n\nUsing this partitioning of degrees of freedom, we can then define all of the objects necessary to describe the linear systems in question:\n\n```\n       AffineConstraints<double> constraints;\n   \n       LA::MPI::BlockSparseMatrix system_matrix;\n       LA::MPI::BlockSparseMatrix preconditioner_matrix;\n   \n       LA::MPI::BlockVector solution;\n       LA::MPI::BlockVector locally_relevant_solution;\n       LA::MPI::BlockVector system_rhs;\n```\n\nLet us move to the particles side of this program. There are two [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) objects used to couple the solid with the fluid, and to describe the passive tracers. These, in many ways, play a role similar to the [DoFHandler](classDoFHandler.html) class used in the discretization, i.e., they provide for an enumeration of particles and allow querying information about each particle.\n\n```\n       Particles::ParticleHandler<spacedim> tracer_particle_handler;\n       Particles::ParticleHandler<spacedim> solid_particle_handler;\n```\n\nFor every tracer particle, we need to compute the velocity field in its current position, and update its position using a discrete time stepping scheme. We do this using distributed linear algebra objects that store the coordinates of each particle's location or velocity. That is, these vectors have `tracer_particle_handler.n_global_particles() * spacedim` entries that we will store in a way so that parts of the vector are partitioned across all processes. (Implicitly, we here make the assumption that the `spacedim` coordinates of each particle are stored in consecutive entries of the vector.) Thus, we need to determine who the owner of each vector entry is. We set this owner to be equal to the process that generated that particle at time \\(t=0\\). This information is stored for every process in the `locally_owned_tracer_particle_coordinates` [IndexSet](classIndexSet.html).\n\nOnce the particles have been distributed around to match the process that owns the region where the particle lives, we will need read access from that process to the corresponding velocity field. We achieve this by filling a read only velocity vector field that contains the relevant information in ghost entries. This is achieved using the `locally_relevant_tracer_particle_coordinates` [IndexSet](classIndexSet.html), that keeps track of how things change during the simulation, i.e., it keeps track of where particles that the current process owns have ended up being, and who owns the particles that ended up in my subdomain.\n\nWhile this is not the most efficient strategy, we keep it this way to illustrate how things would work in a real fluid-structure interaction (FSI) problem. If a particle is linked to a specific solid degree of freedom, we are not free to choose who owns it, and we have to communicate this information around. We illustrate this here, and show that the communication pattern is point-to-point, and negligible in terms of total cost of the algorithm.\n\nThe vectors defined based on these subdivisions are then used to store the particles velocities (read-only, with ghost entries) and their displacement (read/write, no ghost entries).\n\n```\n       IndexSet locally_owned_tracer_particle_coordinates;\n       IndexSet locally_relevant_tracer_particle_coordinates;\n   \n       LA::MPI::Vector tracer_particle_velocities;\n       LA::MPI::Vector relevant_tracer_particle_displacements;\n```\n\nOne of the key points of this tutorial program is the coupling between two independent [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) objects, one of which may be moving and deforming (with possibly large deformations) with respect to the other. When both the fluid and the solid triangulations are of type [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html), every process has access only to its fraction of locally owned cells of each of the two triangulations. As mentioned above, in general, the locally owned domains are not overlapping.\n\nIn order to allow for the efficient exchange of information between non-overlapping [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) objects, some algorithms of the library require the user to provide a rough description of the area occupied by the locally owned part of the triangulation, in the form of a collection of axis-aligned bounding boxes for each process, that provide a full covering of the locally owned part of the domain. This kind of information can then be used in situations where one needs to send information to the owner of the cell surrounding a known location, without knowing who that owner may in fact be. But, if one knows a collection of bounding boxes for the geometric area or volume each process owns, then we can determine a subset of all processes that might possibly own the cell in which that location lies: namely, all of those processes whose bounding boxes contain that point. Instead of sending the information associated to that location to all processes, one can then get away with only sending it to a small subset of the processes with point-to-point communication primitives. (You will notice that this also allows for the typical time-vs-memory trade-off: The more data we are willing to store about each process's owned area – in the form of more refined bounding box information – the less communication we have to perform.)\n\nWe construct this information by gathering a vector (of length [Utilities::MPI::n\\_mpi\\_processes()](namespaceUtilities_1_1MPI.html#a4d61730f9aceb5a4ce86f90712262c46)) of vectors of [BoundingBox](classBoundingBox.html) objects. We fill this vector using the [extract\\_rtree\\_level()](rtree_8h.html#a11528a51ba44b19a2d2e515445e7e0aa) function, and allow the user to select what level of the tree to extract. The \"level\" corresponds to how coarse/fine the overlap of the area with bounding boxes should be.\n\nAs an example, this is what would be extracted by the [extract\\_rtree\\_level()](rtree_8h.html#a11528a51ba44b19a2d2e515445e7e0aa) function applied to a two dimensional hyper ball, distributed over three processes. Each image shows in green the bounding boxes associated to the locally owned cells of the triangulation on each process, and in violet the bounding boxes extracted from the rtree:\n\n![](rtree-process-0.png)\n\n![](rtree-process-1.png)\n\n![](rtree-process-2.png)\n\nWe store these boxes in a global member variable, which is updated at every refinement step:\n\n```\n       std::vector<std::vector<BoundingBox<spacedim>>> global_fluid_bounding_boxes;\n     };\n```\n\n### The StokesImmersedProblem class implementation\n\n#### Object construction and mesh initialization functions\n\nIn the constructor, we create the mpi\\_communicator as well as the triangulations and dof\\_handler for both the fluid and the solid. Using the `mpi_communicator`, both the [ConditionalOStream](classConditionalOStream.html) and [TimerOutput](classTimerOutput.html) object are constructed.\n\nIn the constructor, we also check whether the output directory specified in the input file exists and, if not, create it.\n\n```\n     template <int dim, int spacedim>\n     StokesImmersedProblem<dim, spacedim>::StokesImmersedProblem(\n       const StokesImmersedProblemParameters<dim, spacedim> &par)\n       : par(par)\n       , mpi_communicator(MPI_COMM_WORLD)\n       , pcout(std::cout,\n               (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n       , computing_timer(mpi_communicator,\n                         pcout,\n                         TimerOutput::summary,\n                         TimerOutput::wall_times)\n       , fluid_tria(mpi_communicator,\n                    typename Triangulation<spacedim>::MeshSmoothing(\n                      Triangulation<spacedim>::smoothing_on_refinement |\n                      Triangulation<spacedim>::smoothing_on_coarsening))\n       , solid_tria(mpi_communicator,\n                    typename Triangulation<dim, spacedim>::MeshSmoothing(\n                      Triangulation<dim, spacedim>::smoothing_on_refinement |\n                      Triangulation<dim, spacedim>::smoothing_on_coarsening))\n       , fluid_dh(fluid_tria)\n       , solid_dh(solid_tria)\n     {\n       if (std::filesystem::exists(par.output_directory))\n         {\n           Assert(std::filesystem::is_directory(par.output_directory),\n                  ExcMessage(\"You specified <\" + par.output_directory +\n                             \"> as the output directory in the input file, \"\n                             \"but this is not in fact a directory.\"));\n         }\n       else\n         std::filesystem::create_directory(par.output_directory);\n     }\n```\n\nIn order to generate the grid, we first try to use the functions in the deal.II [GridGenerator](namespaceGridGenerator.html) namespace, by leveraging the GridGenerator::generate\\_from\\_name\\_and\\_argument(). If this function fails, then we use the following method, where the name is interpreted as a filename, and the arguments are interpreted as a map from manifold ids to CAD files, and are converted to [Manifold](classManifold.html) descriptors using the [OpenCASCADE](namespaceOpenCASCADE.html) namespace facilities. At the top, we read the file into a triangulation:\n\n```\n     template <int dim, int spacedim>\n     void read_grid_and_cad_files(const std::string &grid_file_name,\n                                  const std::string &ids_and_cad_file_names,\n                                  Triangulation<dim, spacedim> &tria)\n     {\n       GridIn<dim, spacedim> grid_in;\n       grid_in.attach_triangulation(tria);\n       grid_in.read(grid_file_name);\n```\n\nIf we got to this point, then the [Triangulation](classTriangulation.html) has been read, and we are ready to attach to it the correct manifold descriptions. We perform the next lines of code only if deal.II has been built with [OpenCASCADE](namespaceOpenCASCADE.html) support. For each entry in the map, we try to open the corresponding CAD file, we analyze it, and according to its content, opt for either a OpenCASCADE::ArcLengthProjectionLineManifold (if the CAD file contains a single `TopoDS_Edge` or a single `TopoDS_Wire`) or a [OpenCASCADE::NURBSPatchManifold](classOpenCASCADE_1_1NURBSPatchManifold.html), if the file contains a single face. Notice that if the CAD files do not contain single wires, edges, or faces, an assertion will be throw in the generation of the [Manifold](classManifold.html).\n\nWe use the [Patterns::Tools::Convert](structPatterns_1_1Tools_1_1Convert.html) class to do the conversion from the string to a map between manifold ids and file names for us:\n\n```\n   #ifdef DEAL_II_WITH_OPENCASCADE\n       using map_type  = std::map<types::manifold_id, std::string>;\n       using Converter = Patterns::Tools::Convert<map_type>;\n   \n       for (const auto &pair : Converter::to_value(ids_and_cad_file_names))\n         {\n           const auto &manifold_id   = pair.first;\n           const auto &cad_file_name = pair.second;\n   \n           std::string extension =\n             cad_file_name.substr(cad_file_name.find_last_of('.') + 1);\n           std::transform(extension.begin(),\n                          extension.end(),\n                          extension.begin(),\n                          [](const char c) -> char { return std::tolower(c); });\n   \n           TopoDS_Shape shape;\n           if (extension == \"iges\" || extension == \"igs\")\n             shape = OpenCASCADE::read_IGES(cad_file_name);\n           else if (extension == \"step\" || extension == \"stp\")\n             shape = OpenCASCADE::read_STEP(cad_file_name);\n           else\n             AssertThrow(false,\n                         ExcNotImplemented(\"We found an extension that we \"\n                                           \"do not recognize as a CAD file \"\n                                           \"extension. Bailing out.\"));\n```\n\nNow we check how many faces are contained in the `Shape`. [OpenCASCADE](namespaceOpenCASCADE.html) is intrinsically 3d, so if this number is zero, we interpret this as a line manifold, otherwise as a [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) in `spacedim` = 3, or [OpenCASCADE::NURBSPatchManifold](classOpenCASCADE_1_1NURBSPatchManifold.html) in `spacedim` = 2.\n\n```\n           const auto n_elements = OpenCASCADE::count_elements(shape);\n           if ((std::get<0>(n_elements) == 0))\n             tria.set_manifold(\n               manifold_id,\n               OpenCASCADE::ArclengthProjectionLineManifold<dim, spacedim>(shape));\n           else if (spacedim == 3)\n             {\n```\n\nWe use this trick, because [OpenCASCADE::NormalToMeshProjectionManifold](classOpenCASCADE_1_1NormalToMeshProjectionManifold.html) is only implemented for spacedim = 3. The check above makes sure that things actually work correctly.\n\n```\n               const auto t = reinterpret_cast<Triangulation<dim, 3> *>(&tria);\n               t->set_manifold(manifold_id,\n                               OpenCASCADE::NormalToMeshProjectionManifold<dim, 3>(\n                                 shape));\n             }\n           else\n```\n\nWe also allow surface descriptions in two dimensional spaces based on single NURBS patches. For this to work, the CAD file must contain a single `TopoDS_Face`.\n\n```\n             tria.set_manifold(manifold_id,\n                               OpenCASCADE::NURBSPatchManifold<dim, spacedim>(\n                                 TopoDS::Face(shape)));\n         }\n   #else\n       (void)ids_and_cad_file_names;\n       AssertThrow(false, ExcNotImplemented(\"Generation of the grid failed.\"));\n   #endif\n     }\n```\n\nNow let's put things together, and make all the necessary grids. As mentioned above, we first try to generate the grid internally, and if we fail (i.e., if we end up in the `catch` clause), then we proceed with the above function.\n\nWe repeat this pattern for both the fluid and the solid mesh.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::make_grid()\n     {\n       try\n         {\n           GridGenerator::generate_from_name_and_arguments(\n             fluid_tria, par.name_of_fluid_grid, par.arguments_for_fluid_grid);\n         }\n       catch (...)\n         {\n           pcout << \"Generating from name and argument failed.\" << std::endl\n                 << \"Trying to read from file name.\" << std::endl;\n           read_grid_and_cad_files(par.name_of_fluid_grid,\n                                   par.arguments_for_fluid_grid,\n                                   fluid_tria);\n         }\n       fluid_tria.refine_global(par.initial_fluid_refinement);\n   \n       try\n         {\n           GridGenerator::generate_from_name_and_arguments(\n             solid_tria, par.name_of_solid_grid, par.arguments_for_solid_grid);\n         }\n       catch (...)\n         {\n           read_grid_and_cad_files(par.name_of_solid_grid,\n                                   par.arguments_for_solid_grid,\n                                   solid_tria);\n         }\n   \n       solid_tria.refine_global(par.initial_solid_refinement);\n     }\n```\n\n#### Particle initialization functions\n\nOnce the solid and fluid grids have been created, we start filling the [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) objects. The first one we take care of is the one we use to keep track of passive tracers in the fluid. These are simply transported along, and in some sense their locations are unimportant: We just want to use them to see where flow is being transported. We could use any way we choose to determine where they are initially located. A convenient one is to create the initial locations as the vertices of a mesh in a shape of our choice – a choice determined by one of the run-time parameters in the parameter file.\n\nIn this implementation, we create tracers using the support points of a [FE\\_Q](classFE__Q.html) finite element space defined on a temporary grid, which is then discarded. Of this grid, we only keep around the [Particles::Particle](classParticles_1_1Particle.html) objects (stored in a [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class) associated to the support points.\n\nThe [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class offers the possibility to insert a set of particles that live physically in the part of the domain owned by the active process. However, in this case this function would not suffice. The particles generated as the locally owned support points of an [FE\\_Q](classFE__Q.html) object on an arbitrary grid (non-matching with regard to the fluid grid) have no reasons to lie in the same physical region of the locally owned subdomain of the fluid grid. In fact this will almost never be the case, especially since we want to keep track of what is happening to the particles themselves.\n\nIn particle-in-cell methods (PIC), it is often customary to assign ownership of the particles to the process where the particles lie. In this tutorial we illustrate a different approach, which is useful if one wants to keep track of information related to the particles (for example, if a particle is associated to a given degree of freedom, which is owned by a specific process and not necessarily the same process that owns the fluid cell where the particle happens to be at any given time). In the approach used here, ownership of the particles is assigned once at the beginning, and one-to-one communication happens whenever the original owner needs information from the process that owns the cell where the particle lives. We make sure that we set ownership of the particles using the initial particle distribution, and keep the same ownership throughout the execution of the program.\n\nWith this overview out of the way, let us see what the function does. At the top, we create a temporary triangulation and [DoFHandler](classDoFHandler.html) object from which we will take the node locations for initial particle locations:\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::setup_tracer_particles()\n     {\n       parallel::distributed::Triangulation<spacedim> particle_insert_tria(\n         mpi_communicator);\n       GridGenerator::generate_from_name_and_arguments(\n         particle_insert_tria,\n         par.name_of_particle_grid,\n         par.arguments_for_particle_grid);\n       particle_insert_tria.refine_global(par.particle_insertion_refinement);\n   \n       const FE_Q<spacedim> particles_fe(1);\n       DoFHandler<spacedim> particles_dof_handler(particle_insert_tria);\n       particles_dof_handler.distribute_dofs(particles_fe);\n```\n\nThis is where things start to get complicated. Since we may run this program in a parallel environment, every parallel process will now have created these temporary triangulations and DoFHandlers. But, in fully distributed triangulations, the active process only knows about the locally owned cells, and has no idea of how other processes have distributed their own cells. This is true for both the temporary triangulation created above as well as the fluid triangulation into which we want to embed the particles below. On the other hand, these locally known portions of the two triangulations will, in general, not overlap. That is, the locations of the particles we will create from the node locations of the temporary mesh are arbitrary, and may fall within a region of the fluid triangulation that the current process doesn't have access to (i.e., a region of the fluid domain where cells are artificial). In order to understand who to send those particles to, we need to have a (rough) idea of how the fluid grid is distributed among processors.\n\nWe construct this information by first building an index tree of boxes bounding the locally owned cells, and then extracting one of the first levels of the tree:\n\n```\n       std::vector<BoundingBox<spacedim>> all_boxes;\n       all_boxes.reserve(fluid_tria.n_locally_owned_active_cells());\n       for (const auto &cell : fluid_tria.active_cell_iterators())\n         if (cell->is_locally_owned())\n           all_boxes.emplace_back(cell->bounding_box());\n   \n       const auto tree = pack_rtree(all_boxes);\n       const auto local_boxes =\n         extract_rtree_level(tree, par.fluid_rtree_extraction_level);\n```\n\nEach process now has a collection of bounding boxes that completely enclose all locally owned processes (but that may overlap the bounding boxes of other processes). We then exchange this information between all participating processes so that every process knows the bounding boxes of all other processes.\n\nEquipped with this knowledge, we can then initialize the `tracer_particle_handler` to the fluid mesh and generate the particles from the support points of the (temporary) tracer particles triangulation. This function call uses the `global_bounding_boxes` object we just constructed to figure out where to send the particles whose locations were derived from the locally owned part of the `particles_dof_handler`. At the end of this call, every particle will have been distributed to the correct process (i.e., the process that owns the fluid cell where the particle lives). We also output their number to the screen at this point.\n\n```\n       global_fluid_bounding_boxes =\n         Utilities::MPI::all_gather(mpi_communicator, local_boxes);\n   \n       tracer_particle_handler.initialize(fluid_tria,\n                                          StaticMappingQ1<spacedim>::mapping);\n   \n       Particles::Generators::dof_support_points(particles_dof_handler,\n                                                 global_fluid_bounding_boxes,\n                                                 tracer_particle_handler);\n   \n       pcout << \"Tracer particles: \"\n             << tracer_particle_handler.n_global_particles() << std::endl;\n```\n\nEach particle so created has a unique ID. At some point in the algorithm below, we will need vectors containing position and velocity information for each particle. This vector will have size `n_particles * spacedim`, and we will have to store the elements of this vector in a way so that each parallel process \"owns\" those elements that correspond to coordinates of the particles it owns. In other words, we have to partition the index space between zero and `n_particles * spacedim` among all processes. We can do this by querying the `tracer_particle_handler` for the IDs of its locally relevant particles, and construct the indices that would be needed to store in a (parallel distributed) vector of the position and velocity of all particles where we implicitly assume that we store the coordinates of each location or velocity in `spacedim` successive vector elements (this is what the IndexSet::tensor\\_priduct() function does).\n\n```\n       locally_owned_tracer_particle_coordinates =\n         tracer_particle_handler.locally_owned_particle_ids().tensor_product(\n           complete_index_set(spacedim));\n```\n\nAt the beginning of the simulation, all particles are in their original position. When particles move, they may traverse to a part of the domain which is owned by another process. If this happens, the current process keeps formally \"ownership\" of the particles, but may need read access from the process where the particle has landed. We keep this information in another index set, which stores the indices of all particles that are currently on the current process's subdomain, independently if they have always been here or not.\n\nKeeping this index set around allows us to leverage linear algebra classes for all communications regarding positions and velocities of the particles. This mimics what would happen in the case where another problem was solved in the solid domain (as in fluid-structure interaction. In this latter case, additional DOFs on the solid domain would be coupled to what is occurring in the fluid domain.\n\n```\n       locally_relevant_tracer_particle_coordinates =\n         locally_owned_tracer_particle_coordinates;\n     }\n```\n\nSimilarly to what we have done for passive tracers, we next set up the particles that track the quadrature points of the solid mesh. The main difference here is that we also want to attach a weight value (the \"JxW\" value of the quadrature point) to each of particle, so that we can compute integrals even without direct access to the original solid grid.\n\nThis is achieved by leveraging the \"properties\" concept of the [Particles::Particle](classParticles_1_1Particle.html) class. It is possible to store (in a memory efficient way) an arbitrary number of `double` numbers for each of the [Particles::Particle](classParticles_1_1Particle.html) objects inside a [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) object. We use this possibility to store the JxW values of the quadrature points of the solid grid.\n\nIn our case, we only need to store one property per particle: the JxW value of the integration on the solid grid. This is passed at construction time to the solid\\_particle\\_handler object as the last argument\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::setup_solid_particles()\n     {\n       const QGauss<dim> quadrature(fluid_fe->degree + 1);\n   \n       const unsigned int n_properties = 1;\n       solid_particle_handler.initialize(fluid_tria,\n                                         StaticMappingQ1<spacedim>::mapping,\n                                         n_properties);\n```\n\nThe number of particles that we generate locally is equal to the total number of locally owned cells times the number of quadrature points used in each cell. We store all these points in a vector, and their corresponding properties in a vector of vectors:\n\n```\n       std::vector<Point<spacedim>> quadrature_points_vec;\n       quadrature_points_vec.reserve(quadrature.size() *\n                                     solid_tria.n_locally_owned_active_cells());\n   \n       std::vector<std::vector<double>> properties;\n       properties.reserve(quadrature.size() *\n                          solid_tria.n_locally_owned_active_cells());\n   \n       FEValues<dim, spacedim> fe_v(*solid_fe,\n                                    quadrature,\n                                    update_JxW_values | update_quadrature_points);\n       for (const auto &cell : solid_dh.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             fe_v.reinit(cell);\n             const auto &points = fe_v.get_quadrature_points();\n             const auto &JxW    = fe_v.get_JxW_values();\n   \n             for (unsigned int q = 0; q < points.size(); ++q)\n               {\n                 quadrature_points_vec.emplace_back(points[q]);\n                 properties.emplace_back(\n                   std::vector<double>(n_properties, JxW[q]));\n               }\n           }\n```\n\nWe proceed in the same way we did with the tracer particles, reusing the computed bounding boxes. However, we first check that the `global_fluid_bounding_boxes` object has been actually filled. This should certainly be the case here, since this method is called after the one that initializes the tracer particles. However, we want to make sure that if in the future someone decides (for whatever reason) to initialize first the solid particle handler, or to copy just this part of the tutorial, a meaningful exception is thrown when things don't work as expected\n\nSince we have already stored the position of the quadrature points, we can use these positions to insert the particles directly using the `solid_particle_handler` instead of having to go through a [Particles::Generators](namespaceParticles_1_1Generators.html) function:\n\n```\n       Assert(!global_fluid_bounding_boxes.empty(),\n              ExcInternalError(\n                \"I was expecting the \"\n                \"global_fluid_bounding_boxes to be filled at this stage. \"\n                \"Make sure you fill this vector before trying to use it \"\n                \"here. Bailing out.\"));\n   \n       solid_particle_handler.insert_global_particles(quadrature_points_vec,\n                                                      global_fluid_bounding_boxes,\n                                                      properties);\n   \n       pcout << \"Solid particles: \" << solid_particle_handler.n_global_particles()\n             << std::endl;\n     }\n```\n\n#### DoF initialization functions\n\nWe set up the finite element space and the quadrature formula to be used throughout the step. For the fluid, we use Taylor-Hood elements (e.g. \\(Q\\_k \\times Q\\_{k-1}\\)). Since we do not solve any equation on the solid domain, an empty finite element space is generated. A natural extension of this program would be to solve a fluid structure interaction problem, which would require that the `solid_fe` use more useful [FiniteElement](classFiniteElement.html) class.\n\nLike for many other functions, we store the time necessary to carry out the operations we perform here. The current function puts its timing information into a section with label \"Initial setup\". Numerous other calls to this timer are made in various functions. They allow to monitor the absolute and relative cost of each individual function to identify bottlenecks.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::initial_setup()\n     {\n       TimerOutput::Scope t(computing_timer, \"Initial setup\");\n   \n       fluid_fe = std::make_unique<FESystem<spacedim>>(\n         FE_Q<spacedim>(par.velocity_degree) ^ spacedim,\n         FE_Q<spacedim>(par.velocity_degree - 1));\n   \n   \n       solid_fe = std::make_unique<FE_Nothing<dim, spacedim>>();\n       solid_dh.distribute_dofs(*solid_fe);\n     }\n```\n\nWe next construct the distributed block matrices and vectors which are used to solve the linear equations that arise from the problem. This function is adapted from [step-55](step_55.html) and we refer to this step for a thorough explanation.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::setup_dofs()\n     {\n       TimerOutput::Scope t(computing_timer, \"Setup dofs\");\n   \n       fluid_dh.distribute_dofs(*fluid_fe);\n   \n       std::vector<unsigned int> stokes_sub_blocks(spacedim + 1, 0);\n       stokes_sub_blocks[spacedim] = 1;\n       DoFRenumbering::component_wise(fluid_dh, stokes_sub_blocks);\n   \n       auto dofs_per_block =\n         DoFTools::count_dofs_per_fe_block(fluid_dh, stokes_sub_blocks);\n   \n       const unsigned int n_u = dofs_per_block[0], n_p = dofs_per_block[1];\n   \n       pcout << \"   Number of degrees of freedom: \" << fluid_dh.n_dofs() << \" (\"\n             << n_u << '+' << n_p << \" -- \"\n             << solid_particle_handler.n_global_particles() << '+'\n             << tracer_particle_handler.n_global_particles() << ')' << std::endl;\n   \n       fluid_owned_dofs.resize(2);\n       fluid_owned_dofs[0] = fluid_dh.locally_owned_dofs().get_view(0, n_u);\n       fluid_owned_dofs[1] =\n         fluid_dh.locally_owned_dofs().get_view(n_u, n_u + n_p);\n   \n       const IndexSet locally_relevant_dofs =\n         DoFTools::extract_locally_relevant_dofs(fluid_dh);\n       fluid_relevant_dofs.resize(2);\n       fluid_relevant_dofs[0] = locally_relevant_dofs.get_view(0, n_u);\n       fluid_relevant_dofs[1] = locally_relevant_dofs.get_view(n_u, n_u + n_p);\n   \n       {\n         constraints.reinit(fluid_dh.locally_owned_dofs(), locally_relevant_dofs);\n   \n         const FEValuesExtractors::Vector velocities(0);\n         DoFTools::make_hanging_node_constraints(fluid_dh, constraints);\n         VectorTools::interpolate_boundary_values(\n           fluid_dh,\n           0,\n           Functions::ZeroFunction<spacedim>(spacedim + 1),\n           constraints,\n           fluid_fe->component_mask(velocities));\n         constraints.close();\n       }\n   \n       const auto locally_owned_dofs_per_processor =\n         Utilities::MPI::all_gather(mpi_communicator,\n                                    fluid_dh.locally_owned_dofs());\n       {\n         system_matrix.clear();\n   \n         Table<2, DoFTools::Coupling> coupling(spacedim + 1, spacedim + 1);\n         for (unsigned int c = 0; c < spacedim + 1; ++c)\n           for (unsigned int d = 0; d < spacedim + 1; ++d)\n             if (c == spacedim && d == spacedim)\n               coupling[c][d] = DoFTools::none;\n             else if (c == spacedim || d == spacedim || c == d)\n               coupling[c][d] = DoFTools::always;\n             else\n               coupling[c][d] = DoFTools::none;\n   \n         BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n   \n         DoFTools::make_sparsity_pattern(\n           fluid_dh, coupling, dsp, constraints, false);\n   \n         SparsityTools::distribute_sparsity_pattern(\n           dsp,\n           locally_owned_dofs_per_processor,\n           mpi_communicator,\n           locally_relevant_dofs);\n   \n         system_matrix.reinit(fluid_owned_dofs, dsp, mpi_communicator);\n       }\n   \n       {\n         preconditioner_matrix.clear();\n   \n         Table<2, DoFTools::Coupling> coupling(spacedim + 1, spacedim + 1);\n         for (unsigned int c = 0; c < spacedim + 1; ++c)\n           for (unsigned int d = 0; d < spacedim + 1; ++d)\n             if (c == spacedim && d == spacedim)\n               coupling[c][d] = DoFTools::always;\n             else\n               coupling[c][d] = DoFTools::none;\n   \n         BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n   \n         DoFTools::make_sparsity_pattern(\n           fluid_dh, coupling, dsp, constraints, false);\n         SparsityTools::distribute_sparsity_pattern(\n           dsp,\n           locally_owned_dofs_per_processor,\n           mpi_communicator,\n           locally_relevant_dofs);\n         preconditioner_matrix.reinit(fluid_owned_dofs, dsp, mpi_communicator);\n       }\n   \n       locally_relevant_solution.reinit(fluid_owned_dofs,\n                                        fluid_relevant_dofs,\n                                        mpi_communicator);\n       system_rhs.reinit(fluid_owned_dofs, mpi_communicator);\n       solution.reinit(fluid_owned_dofs, mpi_communicator);\n     }\n```\n\n#### Assembly functions\n\nWe assemble the system matrix, the preconditioner matrix, and the right hand side. The code is adapted from [step-55](step_55.html), which is essentially what [step-27](step_27.html) also has, and is pretty standard if you know what the Stokes equations look like.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::assemble_stokes_system()\n     {\n       system_matrix         = 0;\n       preconditioner_matrix = 0;\n       system_rhs            = 0;\n   \n       TimerOutput::Scope t(computing_timer, \"Assemble Stokes terms\");\n   \n       const QGauss<spacedim> quadrature_formula(fluid_fe->degree + 1);\n       FEValues<spacedim>     fe_values(*fluid_fe,\n                                    quadrature_formula,\n                                    update_values | update_gradients |\n                                      update_quadrature_points |\n                                      update_JxW_values);\n   \n       const unsigned int dofs_per_cell = fluid_fe->n_dofs_per_cell();\n       const unsigned int n_q_points    = quadrature_formula.size();\n   \n       FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n       FullMatrix<double> cell_matrix2(dofs_per_cell, dofs_per_cell);\n       Vector<double>     cell_rhs(dofs_per_cell);\n   \n       std::vector<Vector<double>> rhs_values(n_q_points,\n                                              Vector<double>(spacedim + 1));\n   \n       std::vector<Tensor<2, spacedim>> grad_phi_u(dofs_per_cell);\n       std::vector<double>              div_phi_u(dofs_per_cell);\n       std::vector<double>              phi_p(dofs_per_cell);\n   \n       std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n       const FEValuesExtractors::Vector     velocities(0);\n       const FEValuesExtractors::Scalar     pressure(spacedim);\n   \n       for (const auto &cell : fluid_dh.active_cell_iterators())\n         if (cell->is_locally_owned())\n           {\n             cell_matrix  = 0;\n             cell_matrix2 = 0;\n             cell_rhs     = 0;\n   \n             fe_values.reinit(cell);\n             par.rhs.vector_value_list(fe_values.get_quadrature_points(),\n                                       rhs_values);\n             for (unsigned int q = 0; q < n_q_points; ++q)\n               {\n                 for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                   {\n                     grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                     div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                     phi_p[k]      = fe_values[pressure].value(k, q);\n                   }\n   \n                 for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                   {\n                     for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                       {\n                         cell_matrix(i, j) +=\n                           (par.viscosity *\n                              scalar_product(grad_phi_u[i], grad_phi_u[j]) -\n                            div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j]) *\n                           fe_values.JxW(q);\n   \n                         cell_matrix2(i, j) += 1.0 / par.viscosity * phi_p[i] *\n                                               phi_p[j] * fe_values.JxW(q);\n                       }\n   \n                     const unsigned int component_i =\n                       fluid_fe->system_to_component_index(i).first;\n                     cell_rhs(i) += fe_values.shape_value(i, q) *\n                                    rhs_values[q](component_i) * fe_values.JxW(q);\n                   }\n               }\n   \n   \n             cell->get_dof_indices(local_dof_indices);\n             constraints.distribute_local_to_global(cell_matrix,\n                                                    cell_rhs,\n                                                    local_dof_indices,\n                                                    system_matrix,\n                                                    system_rhs);\n   \n             constraints.distribute_local_to_global(cell_matrix2,\n                                                    local_dof_indices,\n                                                    preconditioner_matrix);\n           }\n   \n       system_matrix.compress(VectorOperation::add);\n       preconditioner_matrix.compress(VectorOperation::add);\n       system_rhs.compress(VectorOperation::add);\n     }\n```\n\nThe following method is then the one that deals with the penalty terms that result from imposing the velocity on the impeller. It is, in a sense, the heart of the tutorial, but it is relatively straightforward. Here we exploit the `solid_particle_handler` to compute the Nitsche restriction or the penalization in the embedded domain.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::assemble_nitsche_restriction()\n     {\n       TimerOutput::Scope t(computing_timer, \"Assemble Nitsche terms\");\n   \n       const FEValuesExtractors::Vector velocities(0);\n       const FEValuesExtractors::Scalar pressure(spacedim);\n   \n       SolidVelocity<spacedim> solid_velocity(par.angular_velocity);\n   \n       std::vector<types::global_dof_index> fluid_dof_indices(\n         fluid_fe->n_dofs_per_cell());\n   \n       FullMatrix<double> local_matrix(fluid_fe->n_dofs_per_cell(),\n                                       fluid_fe->n_dofs_per_cell());\n       Vector<double>     local_rhs(fluid_fe->n_dofs_per_cell());\n   \n       const auto penalty_parameter =\n         1.0 / GridTools::minimal_cell_diameter(fluid_tria);\n```\n\nWe loop over all the local particles. Although this could be achieved directly by looping over all the cells, this would force us to loop over numerous cells which do not contain particles. Consequently, we loop over all the particles, but, we get the reference of the cell in which the particle lies and then loop over all particles within that cell. This enables us to skip the cells which do not contain particles, yet to assemble the local matrix and rhs of each cell to apply the Nitsche restriction. Once we are done with all particles on one cell, we advance the `particle` iterator to the particle past the end of the ones on the current cell (this is the last line of the `while` loop's body).\n\n```\n       auto particle = solid_particle_handler.begin();\n       while (particle != solid_particle_handler.end())\n         {\n           local_matrix = 0;\n           local_rhs    = 0;\n```\n\nWe get an iterator to the cell within which the particle lies from the particle itself. We can then assemble the additional terms in the system matrix and the right hand side as we would normally.\n\n```\n           const auto &cell = particle->get_surrounding_cell();\n           const auto &dh_cell =\n             typename DoFHandler<spacedim>::cell_iterator(*cell, &fluid_dh);\n           dh_cell->get_dof_indices(fluid_dof_indices);\n```\n\nSo then let us get the collection of cells that are located on this cell and iterate over them. From each particle we gather the location and the reference location of the particle as well as the additional information that is attached to the particle. In the present case, this information is the \"JxW\" of the quadrature points which were used to generate the particles.\n\nUsing this information, we can add the contribution of the quadrature point to the local\\_matrix and local\\_rhs. We can evaluate the value of the shape function at the position of each particle easily by using its reference location.\n\n```\n           const auto pic = solid_particle_handler.particles_in_cell(cell);\n           Assert(pic.begin() == particle, ExcInternalError());\n           for (const auto &p : pic)\n             {\n               const Point<spacedim> ref_q  = p.get_reference_location();\n               const Point<spacedim> real_q = p.get_location();\n               const double          JxW    = p.get_properties()[0];\n   \n               for (unsigned int i = 0; i < fluid_fe->n_dofs_per_cell(); ++i)\n                 {\n                   const auto comp_i =\n                     fluid_fe->system_to_component_index(i).first;\n                   if (comp_i < spacedim)\n                     {\n                       for (unsigned int j = 0; j < fluid_fe->n_dofs_per_cell();\n                            ++j)\n                         {\n                           const auto comp_j =\n                             fluid_fe->system_to_component_index(j).first;\n                           if (comp_i == comp_j)\n                             local_matrix(i, j) +=\n                               penalty_parameter * par.penalty_term *\n                               fluid_fe->shape_value(i, ref_q) *\n                               fluid_fe->shape_value(j, ref_q) * JxW;\n                         }\n                       local_rhs(i) += penalty_parameter * par.penalty_term *\n                                       solid_velocity.value(real_q, comp_i) *\n                                       fluid_fe->shape_value(i, ref_q) * JxW;\n                     }\n                 }\n             }\n   \n           constraints.distribute_local_to_global(local_matrix,\n                                                  local_rhs,\n                                                  fluid_dof_indices,\n                                                  system_matrix,\n                                                  system_rhs);\n           particle = pic.end();\n         }\n   \n       system_matrix.compress(VectorOperation::add);\n       system_rhs.compress(VectorOperation::add);\n     }\n```\n\n#### Solving the linear system\n\nThis function solves the linear system with FGMRES with a block diagonal preconditioner and an algebraic multigrid (AMG) method for the diagonal blocks. The preconditioner applies a V cycle to the \\((0,0)\\) (i.e., the velocity-velocity) block and a CG with the [mass matrix](DEALGlossary.html#GlossMassMatrix) for the \\((1,1)\\) block (which is our approximation to the Schur complement: the pressure mass matrix assembled above).\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::solve()\n     {\n       TimerOutput::Scope t(computing_timer, \"Solve\");\n   \n       LA::MPI::PreconditionAMG prec_A;\n       {\n         LA::MPI::PreconditionAMG::AdditionalData data;\n   \n   #ifdef USE_PETSC_LA\n         data.symmetric_operator = true;\n   #endif\n         prec_A.initialize(system_matrix.block(0, 0), data);\n       }\n   \n       LA::MPI::PreconditionAMG prec_S;\n       {\n         LA::MPI::PreconditionAMG::AdditionalData data;\n   \n   #ifdef USE_PETSC_LA\n         data.symmetric_operator = true;\n   #endif\n         prec_S.initialize(preconditioner_matrix.block(1, 1), data);\n       }\n   \n       const auto A = linear_operator<LA::MPI::Vector>(system_matrix.block(0, 0));\n       const auto amgA = linear_operator(A, prec_A);\n   \n       const auto S =\n         linear_operator<LA::MPI::Vector>(preconditioner_matrix.block(1, 1));\n       const auto amgS = linear_operator(S, prec_S);\n   \n       ReductionControl          inner_solver_control(100,\n                                             1e-8 * system_rhs.l2_norm(),\n                                             1.e-2);\n       SolverCG<LA::MPI::Vector> cg(inner_solver_control);\n   \n       const auto invS = inverse_operator(S, cg, amgS);\n   \n       const auto P = block_diagonal_operator<2, LA::MPI::BlockVector>(\n         std::array<LinearOperator<typename LA::MPI::BlockVector::BlockType>, 2>{\n           {amgA, amgS}});\n   \n       SolverControl solver_control(system_matrix.m(),\n                                    1e-10 * system_rhs.l2_norm());\n   \n       SolverFGMRES<LA::MPI::BlockVector> solver(solver_control);\n   \n       constraints.set_zero(solution);\n   \n       solver.solve(system_matrix, solution, system_rhs, P);\n   \n   \n       pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n             << std::endl;\n   \n       constraints.distribute(solution);\n   \n       locally_relevant_solution = solution;\n       const double mean_pressure =\n         VectorTools::compute_mean_value(fluid_dh,\n                                         QGauss<spacedim>(par.velocity_degree + 2),\n                                         locally_relevant_solution,\n                                         spacedim);\n       solution.block(1).add(-mean_pressure);\n       locally_relevant_solution.block(1) = solution.block(1);\n     }\n```\n\n#### Mesh refinement\n\nWe deal with mesh refinement in a completely standard way, except we now also transfer the particles of the two particle handlers from the existing to the refined mesh. When performing local refinement or coarsening, particles will land in another cell. We could in principle redistribute all particles after refining, however this would be overly expensive.\n\nThe [Particles::ParticleHandler](classParticles_1_1ParticleHandler.html) class has a way to transfer information from a cell to its children or to its parent upon refinement, without the need to reconstruct the entire data structure. This is done similarly to the [SolutionTransfer](classSolutionTransfer.html) class by calling two functions, one to prepare for refinement, and one to transfer the information after refinement.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::refine_and_transfer()\n     {\n       TimerOutput::Scope               t(computing_timer, \"Refine\");\n       const FEValuesExtractors::Vector velocity(0);\n   \n       Vector<float> error_per_cell(fluid_tria.n_active_cells());\n       KellyErrorEstimator<spacedim>::estimate(fluid_dh,\n                                               QGauss<spacedim - 1>(\n                                                 par.velocity_degree + 1),\n                                               {},\n                                               locally_relevant_solution,\n                                               error_per_cell,\n                                               fluid_fe->component_mask(velocity));\n   \n       if (par.refinement_strategy == \"fixed_fraction\")\n         {\n           parallel::distributed::GridRefinement::\n             refine_and_coarsen_fixed_fraction(fluid_tria,\n                                               error_per_cell,\n                                               par.refinement_fraction,\n                                               par.coarsening_fraction);\n         }\n       else if (par.refinement_strategy == \"fixed_number\")\n         {\n           parallel::distributed::GridRefinement::refine_and_coarsen_fixed_number(\n             fluid_tria,\n             error_per_cell,\n             par.refinement_fraction,\n             par.coarsening_fraction,\n             par.max_cells);\n         }\n   \n       for (const auto &cell : fluid_tria.active_cell_iterators())\n         {\n           if (cell->refine_flag_set() &&\n               cell->level() == par.max_level_refinement)\n             cell->clear_refine_flag();\n           if (cell->coarsen_flag_set() &&\n               cell->level() == par.min_level_refinement)\n             cell->clear_coarsen_flag();\n         }\n   \n       parallel::distributed::SolutionTransfer<spacedim, LA::MPI::BlockVector>\n         transfer(fluid_dh);\n   \n       fluid_tria.prepare_coarsening_and_refinement();\n       transfer.prepare_for_coarsening_and_refinement(locally_relevant_solution);\n       tracer_particle_handler.prepare_for_coarsening_and_refinement();\n       solid_particle_handler.prepare_for_coarsening_and_refinement();\n   \n       fluid_tria.execute_coarsening_and_refinement();\n   \n       setup_dofs();\n   \n       transfer.interpolate(solution);\n       tracer_particle_handler.unpack_after_coarsening_and_refinement();\n       solid_particle_handler.unpack_after_coarsening_and_refinement();\n   \n       constraints.distribute(solution);\n       locally_relevant_solution = solution;\n     }\n```\n\n#### Creating output for visualization\n\nWe output the results (velocity and pressure) on the fluid domain using the standard parallel capabilities of deal.II. A single compressed vtu file is written that agglomerates the information of all processors. An additional `.pvd` record is written to associate the physical time to the vtu files.\n\n```\n     template <int dim, int spacedim>\n     void\n     StokesImmersedProblem<dim, spacedim>::output_results(const unsigned int cycle,\n                                                          double time) const\n     {\n       TimerOutput::Scope t(computing_timer, \"Output fluid\");\n   \n       std::vector<std::string> solution_names(spacedim, \"velocity\");\n       solution_names.emplace_back(\"pressure\");\n       std::vector<DataComponentInterpretation::DataComponentInterpretation>\n         data_component_interpretation(\n           spacedim, DataComponentInterpretation::component_is_part_of_vector);\n       data_component_interpretation.push_back(\n         DataComponentInterpretation::component_is_scalar);\n   \n       DataOut<spacedim> data_out;\n       data_out.attach_dof_handler(fluid_dh);\n       data_out.add_data_vector(locally_relevant_solution,\n                                solution_names,\n                                DataOut<spacedim>::type_dof_data,\n                                data_component_interpretation);\n   \n   \n       Vector<float> subdomain(fluid_tria.n_active_cells());\n       for (unsigned int i = 0; i < subdomain.size(); ++i)\n         subdomain(i) = fluid_tria.locally_owned_subdomain();\n       data_out.add_data_vector(subdomain, \"subdomain\");\n   \n       data_out.build_patches();\n   \n       const std::string filename =\n         \"solution-\" + Utilities::int_to_string(cycle) + \".vtu\";\n       data_out.write_vtu_in_parallel(par.output_directory + \"/\" + filename,\n                                      mpi_communicator);\n   \n       static std::vector<std::pair<double, std::string>> times_and_names;\n       times_and_names.emplace_back(time, filename);\n       std::ofstream ofile(par.output_directory + \"/\" + \"solution.pvd\");\n       DataOutBase::write_pvd_record(ofile, times_and_names);\n     }\n```\n\nSimilarly, we write the particles (either from the solid or the tracers) as a single compressed vtu file through the [Particles::DataOut](classParticles_1_1DataOut.html) object. This simple object does not write the additional information attached as \"properties\" to the particles, but only writes their id – but then, we don't care about the \"JxW\" values of these particle locations anyway, so no information that we may have wanted to visualize is lost.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::output_particles(\n       const Particles::ParticleHandler<spacedim> &particles,\n       std::string                                 fprefix,\n       const unsigned int                          iter,\n       const double                                time) const\n     {\n       Particles::DataOut<spacedim> particles_out;\n       particles_out.build_patches(particles);\n       const std::string filename =\n         (fprefix + \"-\" + Utilities::int_to_string(iter) + \".vtu\");\n       particles_out.write_vtu_in_parallel(par.output_directory + \"/\" + filename,\n                                           mpi_communicator);\n   \n   \n       static std::map<std::string, std::vector<std::pair<double, std::string>>>\n         times_and_names;\n       if (times_and_names.find(fprefix) != times_and_names.end())\n         times_and_names[fprefix].emplace_back(time, filename);\n       else\n         times_and_names[fprefix] = {std::make_pair(time, filename)};\n       std::ofstream ofile(par.output_directory + \"/\" + fprefix + \".pvd\");\n       DataOutBase::write_pvd_record(ofile, times_and_names[fprefix]);\n     }\n```\n\n#### The \"run\" function\n\nThis function now orchestrates the entire simulation. It is very similar to the other time dependent tutorial programs – take [step-21](step_21.html) or [step-26](step_26.html) as an example. At the beginning, we output some status information and also save all current parameters to a file in the output directory, for reproducibility.\n\n```\n     template <int dim, int spacedim>\n     void StokesImmersedProblem<dim, spacedim>::run()\n     {\n   #ifdef USE_PETSC_LA\n       pcout << \"Running StokesImmersedProblem<\"\n             << Utilities::dim_string(dim, spacedim) << \"> using PETSc.\"\n             << std::endl;\n   #else\n       pcout << \"Running StokesImmersedProblem<\"\n             << Utilities::dim_string(dim, spacedim) << \"> using Trilinos.\"\n             << std::endl;\n   #endif\n       par.prm.print_parameters(par.output_directory + \"/\" + \"used_parameters_\" +\n                                  std::to_string(dim) + std::to_string(spacedim) +\n                                  \".prm\",\n                                ParameterHandler::Short);\n```\n\nWe then start the time loop. We initialize all the elements of the simulation in the first cycle\n\n```\n       const double time_step    = par.final_time / (par.number_of_time_steps - 1);\n       double       time         = 0;\n       unsigned int output_cycle = 0;\n   \n       for (unsigned int cycle = 0; cycle < par.number_of_time_steps;\n            ++cycle, time += time_step)\n         {\n           par.set_time(time);\n           pcout << \"Cycle \" << cycle << ':' << std::endl\n                 << \"Time : \" << time << \", time step: \" << time_step << std::endl;\n   \n           if (cycle == 0)\n             {\n               make_grid();\n               initial_setup();\n               setup_dofs();\n               setup_tracer_particles();\n               setup_solid_particles();\n               tracer_particle_velocities.reinit(\n                 locally_owned_tracer_particle_coordinates, mpi_communicator);\n               output_results(output_cycle, time);\n               {\n                 TimerOutput::Scope t(computing_timer, \"Output tracer particles\");\n                 output_particles(tracer_particle_handler,\n                                  \"tracer\",\n                                  output_cycle,\n                                  time);\n               }\n               {\n                 TimerOutput::Scope t(computing_timer, \"Output solid particles\");\n                 output_particles(solid_particle_handler,\n                                  \"solid\",\n                                  output_cycle,\n                                  time);\n               }\n             }\n```\n\nAfter the first time step, we displace the solid body at the beginning of each time step to take into account the fact that is has moved.\n\n```\n           else\n             {\n               TimerOutput::Scope t(computing_timer,\n                                    \"Set solid particle position\");\n   \n               SolidPosition<spacedim> solid_position(par.angular_velocity,\n                                                      time_step);\n               solid_particle_handler.set_particle_positions(solid_position,\n                                                             false);\n             }\n```\n\nIn order to update the state of the system, we first interpolate the fluid velocity at the position of the tracer particles and, with a naive explicit Euler scheme, advect the massless tracer particles.\n\n```\n           {\n             TimerOutput::Scope t(computing_timer, \"Set tracer particle motion\");\n             Particles::Utilities::interpolate_field_on_particles(\n               fluid_dh,\n               tracer_particle_handler,\n               locally_relevant_solution,\n               tracer_particle_velocities,\n               fluid_fe->component_mask(FEValuesExtractors::Vector(0)));\n   \n             tracer_particle_velocities *= time_step;\n   \n             locally_relevant_tracer_particle_coordinates =\n               tracer_particle_handler.locally_owned_particle_ids().tensor_product(\n                 complete_index_set(spacedim));\n   \n             relevant_tracer_particle_displacements.reinit(\n               locally_owned_tracer_particle_coordinates,\n               locally_relevant_tracer_particle_coordinates,\n               mpi_communicator);\n   \n             relevant_tracer_particle_displacements = tracer_particle_velocities;\n   \n             tracer_particle_handler.set_particle_positions(\n               relevant_tracer_particle_displacements);\n           }\n```\n\nUsing these new locations, we can then assemble the Stokes system and solve it.\n\n```\n           assemble_stokes_system();\n           assemble_nitsche_restriction();\n           solve();\n```\n\nWith the appropriate frequencies, we then write the information of the solid particles, the tracer particles, and the fluid domain into files for visualization, and end the time step by adapting the mesh.\n\n```\n           if (cycle % par.output_frequency == 0)\n             {\n               output_results(output_cycle, time);\n               {\n                 TimerOutput::Scope t(computing_timer, \"Output tracer particles\");\n                 output_particles(tracer_particle_handler,\n                                  \"tracer\",\n                                  output_cycle,\n                                  time);\n               }\n               {\n                 TimerOutput::Scope t(computing_timer, \"Output solid particles\");\n                 output_particles(solid_particle_handler,\n                                  \"solid\",\n                                  output_cycle,\n                                  time);\n               }\n               ++output_cycle;\n             }\n           if (cycle % par.refinement_frequency == 0 &&\n               cycle != par.number_of_time_steps - 1)\n             refine_and_transfer();\n         }\n     }\n   \n   } // namespace Step70\n```\n\n### The main() function\n\nThe remainder of the code, the `main()` function, is standard, with the exception of the handling of input parameter files. We allow the user to specify an optional parameter file as an argument to the program. If nothing is specified, we use the default file \"parameters.prm\", which is created if non existent. The file name is scanned for the string \"23\" first, and \"3\" afterwards. If the filename contains the string \"23\", the problem classes are instantiated with template arguments 2 and 3 respectively. If only the string \"3\" is found, then both template arguments are set to 3, otherwise both are set to 2.\n\nIf the program is called without any command line arguments (i.e., `argc==1`), then we just use \"parameters.prm\" by default.\n\n```\n   int main(int argc, char *argv[])\n   {\n     using namespace Step70;\n     using namespace dealii;\n     deallog.depth_console(1);\n     try\n       {\n         Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n   \n         std::string prm_file;\n         if (argc > 1)\n           prm_file = argv[1];\n         else\n           prm_file = \"parameters.prm\";\n   \n         if (prm_file.find(\"23\") != std::string::npos)\n           {\n             StokesImmersedProblemParameters<2, 3> par;\n             ParameterAcceptor::initialize(prm_file);\n   \n             StokesImmersedProblem<2, 3> problem(par);\n             problem.run();\n           }\n         else if (prm_file.find('3') != std::string::npos)\n           {\n             StokesImmersedProblemParameters<3> par;\n             ParameterAcceptor::initialize(prm_file);\n   \n             StokesImmersedProblem<3> problem(par);\n             problem.run();\n           }\n         else\n           {\n             StokesImmersedProblemParameters<2> par;\n             ParameterAcceptor::initialize(prm_file);\n   \n             StokesImmersedProblem<2> problem(par);\n             problem.run();\n           }\n       }\n     catch (std::exception &exc)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Exception on processing: \" << std::endl\n                   << exc.what() << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n   \n         return 1;\n       }\n     catch (...)\n       {\n         std::cerr << std::endl\n                   << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         std::cerr << \"Unknown exception!\" << std::endl\n                   << \"Aborting!\" << std::endl\n                   << \"----------------------------------------------------\"\n                   << std::endl;\n         return 1;\n       }\n   \n     return 0;\n   }\n```\n\nResults\n=======\n\nThe directory in which this program is run contains a number of sample parameter files that you can use to reproduce the results presented in this section. If you do not specify a parameter file as an argument on the command line, the program will try to read the file \"`parameters.prm`\" by default, and will execute the two dimensional version of the code. As explained in the discussion of the source code, if your file name contains the string \"23\", then the program will run a three dimensional problem, with immersed solid of co-dimension one. If it contains the string \"3\", it will run a three dimensional problem, with immersed solid of co-dimension zero, otherwise it will run a two dimensional problem with immersed solid of co-dimension zero.\n\nRegardless of the specific parameter file name, if the specified file does not exist, when you execute the program you will get an exception that no such file can be found:\n\n```\n----------------------------------------------------\nException on processing:\n \n--------------------------------------------------------\nAn error occurred in line <74> of file <../source/base/parameter_acceptor.cc> in function\n static void ::ParameterAcceptor::initialize(const std::string &, const std::string &, const ParameterHandler::OutputStyle, ::ParameterHandler &)\nThe violated condition was:\n false\nAdditional information:\n    You specified <parameters.prm> as input parameter file, but it does not exist. We created it for you.\n--------------------------------------------------------\n \nAborting!\n----------------------------------------------------\n```\n\nHowever, as the error message already states, the code that triggers the exception will also generate the specified file (\"`parameters.prm`\" in this case) that simply contains the default values for all parameters this program cares about (for the correct dimension and co-dimension, according to the whether a string \"23\" or \"3\" is contained in the file name). By inspection of the default parameter file, we see the following:\n\n```\n# Listing of Parameters\n# ---------------------\nsubsection Stokes Immersed Problem\n  set Final time                            = 1\n  # Extraction level of the rtree used to construct global bounding boxes\n  set Fluid bounding boxes extraction level = 1\n \n  # Boundary Ids over which homogeneous Dirichlet boundary conditions are\n  # applied\n  set Homogeneous Dirichlet boundary ids    = 0\n \n  # Initial mesh refinement used for the fluid domain Omega\n  set Initial fluid refinement              = 5\n \n  # Initial mesh refinement used for the solid domain Gamma\n  set Initial solid refinement              = 5\n  set Nitsche penalty term                  = 100\n  set Number of time steps                  = 501\n  set Output directory                      = .\n  set Output frequency                      = 1\n \n  # Refinement of the volumetric mesh used to insert the particles\n  set Particle insertion refinement         = 3\n  set Velocity degree                       = 2\n  set Viscosity                             = 1\n \n \n  subsection Angular velocity\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  =\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = t < .500001 ? 6.283185 : -6.283185 # default: 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \n  subsection Grid generation\n    set Fluid grid generator              = hyper_cube\n    set Fluid grid generator arguments    = -1: 1: false\n    set Particle grid generator           = hyper_ball\n    set Particle grid generator arguments = 0.3, 0.3: 0.1: false\n    set Solid grid generator              = hyper_rectangle\n    set Solid grid generator arguments    = -.5, -.1: .5, .1: false\n  end\n \n  subsection Refinement and remeshing\n    set Maximum number of cells        = 20000\n    set Refinement coarsening fraction = 0.3\n    set Refinement fraction            = 0.3\n    set Refinement maximal level       = 8\n    set Refinement minimal level       = 5\n    set Refinement step frequency      = 5\n    set Refinement strategy            = fixed_fraction\n  end\n \n  subsection Right hand side\n    # Sometimes it is convenient to use symbolic constants in the expression\n    # that describes the function, rather than having to use its numeric value\n    # everywhere the constant appears. These values can be defined using this\n    # parameter, in the form `var1=value1, var2=value2, ...'.\n    #\n    # A typical example would be to set this runtime parameter to\n    # `pi=3.1415926536' and then use `pi' in the expression of the actual\n    # formula. (That said, for convenience this class actually defines both\n    # `pi' and `Pi' by default, but you get the idea.)\n    set Function constants  =\n \n    # The formula that denotes the function you want to evaluate for\n    # particular values of the independent variables. This expression may\n    # contain any of the usual operations such as addition or multiplication,\n    # as well as all of the common functions such as `sin' or `cos'. In\n    # addition, it may contain expressions like `if(x>0, 1, -1)' where the\n    # expression evaluates to the second argument if the first argument is\n    # true, and to the third argument otherwise. For a full overview of\n    # possible expressions accepted see the documentation of the muparser\n    # library at http://muparser.beltoforion.de/.\n    #\n    # If the function you are describing represents a vector-valued function\n    # with multiple components, then separate the expressions for individual\n    # components by a semicolon.\n    set Function expression = 0; 0; 0\n \n    # The names of the variables as they will be used in the function,\n    # separated by commas. By default, the names of variables at which the\n    # function will be evaluated are `x' (in 1d), `x,y' (in 2d) or `x,y,z' (in\n    # 3d) for spatial coordinates and `t' for time. You can then use these\n    # variable names in your function expression and they will be replaced by\n    # the values of these variables at which the function is currently\n    # evaluated. However, you can also choose a different set of names for the\n    # independent variables at which to evaluate your function expression. For\n    # example, if you work in spherical coordinates, you may wish to set this\n    # input parameter to `r,phi,theta,t' and then use these variable names in\n    # your function expression.\n    set Variable names      = x,y,t\n  end\n \nend\n```\n\nIf you now run the program, you will get a file called `parameters_22.prm` in the directory specified by the parameter `Output directory` (which defaults to the current directory) containing a shorter version of the above parameters (without comments and documentation), documenting all parameters that were used to run your program:\n\n```\nsubsection Stokes Immersed Problem\n  set Final time                            = 1\n  set Fluid bounding boxes extraction level = 1\n  set Homogeneous Dirichlet boundary ids    = 0\n  set Initial fluid refinement              = 5\n  set Initial solid refinement              = 5\n  set Nitsche penalty term                  = 100\n  set Number of time steps                  = 501\n  set Output directory                      = .\n  set Output frequency                      = 1\n  set Particle insertion refinement         = 3\n  set Velocity degree                       = 2\n  set Viscosity                             = 1\n  subsection Angular velocity\n    set Function constants  =\n    set Function expression = t < .500001 ? 6.283185 : -6.283185\n    set Variable names      = x,y,t\n  end\n  subsection Grid generation\n    set Fluid grid generator              = hyper_cube\n    set Fluid grid generator arguments    = -1: 1: false\n    set Particle grid generator           = hyper_ball\n    set Particle grid generator arguments = 0.3, 0.3: 0.1: false\n    set Solid grid generator              = hyper_rectangle\n    set Solid grid generator arguments    = -.5, -.1: .5, .1: false\n  end\n  subsection Refinement and remeshing\n    set Maximum number of cells        = 20000\n    set Refinement coarsening fraction = 0.3\n    set Refinement fraction            = 0.3\n    set Refinement maximal level       = 8\n    set Refinement minimal level       = 5\n    set Refinement step frequency      = 5\n    set Refinement strategy            = fixed_fraction\n  end\n  subsection Right hand side\n    set Function constants  =\n    set Function expression = 0; 0; 0\n    set Variable names      = x,y,t\n  end\nend\n```\n\nThe rationale behind creating first `parameters.prm` file (the first time the program is run) and then a `output/parameters_22.prm` (every time you run the program with an existing input file), is because you may want to leave most parameters to their default values, and only modify a handful of them, while still being able to reproduce the results and inspect what parameters were used for a specific simulation. It is generally good scientific practice to store the parameter file you used for a simulation along with the simulation output so that you can repeat the exact same run at a later time if necessary.\n\nAnother reason is because the input file may only contain those parameters that differ from their defaults. For example, you could use the following (perfectly valid) parameter file with this tutorial program:\n\n```\nsubsection Stokes Immersed Problem\n  set Final time                         = 1\n  set Nitsche penalty term               = 10\n  set Number of time steps               = 101\n  set Velocity degree                    = 3\nend\n```\n\nand you would run the program with Q3/Q2 Taylor-Hood finite elements, for 101 steps, using a Nitsche penalty of `10`, and leaving all the other parameters to their default value. The output directory then contains a record of not just these parameters, but indeed all parameters used in the simulation. You can inspect all the other parameters in the produced file `parameters_22.prm`.\n\n### Two dimensional test case\n\nThe default problem generates a co-dimension zero impeller, consisting of a rotating rectangular grid, where the rotation is for half a time unit in one direction, and half a time unit in the opposite direction, with constant angular velocity equal to \\(\\approx 2\\pi \\frac{\\text{rad}}{\\text{time unit}}\\). Consequently, the impeller does half a rotation and returns to its original position. The following animation displays the velocity magnitude, the motion of the solid impeller and of the tracer particles.\n\n![](images/steps/developer/step-70.2d_tracing.gif)\n\nOn one core, the output of the program will look like the following:\n\n```\nbash@f$ mpirun -np 1 ./step-70 test.prm\nRunning StokesImmersedProblem<2> using Trilinos.\nCycle 0:\nTime : 0, time step: 0.002\n   Number of degrees of freedom: 9539 (8450+1089 -- 0+0)\nTracer particles: 337\nSolid particles: 9216\n   Solved in 158 iterations.\n   Number of degrees of freedom: 9845 (8722+1123 -- 9216+337)\nCycle 1:\nTime : 0.002, time step: 0.002\n   Solved in 142 iterations.\nCycle 2:\nTime : 0.004, time step: 0.002\n   Solved in 121 iterations.\nCycle 3:\nTime : 0.006, time step: 0.002\n   Solved in 121 iterations.\n \n...\n \nCycle 499:\nTime : 0.998, time step: 0.002\n   Solved in 199 iterations.\nCycle 500:\nTime : 1, time step: 0.002\n   Solved in 196 iterations.\n \n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |       302s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble Nitsche terms          |       501 |      43.3s |        14% |\n| Assemble Stokes terms           |       501 |      21.5s |       7.1% |\n| Initial setup                   |         1 |  0.000792s |         0% |\n| Output fluid                    |       502 |      31.8s |        11% |\n| Output solid particles          |       502 |      32.2s |        11% |\n| Output tracer particles         |       502 |      0.61s |       0.2% |\n| Refine                          |       100 |      4.68s |       1.5% |\n| Set solid particle position     |       500 |      3.34s |       1.1% |\n| Set tracer particle motion      |       501 |     0.729s |      0.24% |\n| Setup dofs                      |       101 |       2.2s |      0.73% |\n| Solve                           |       501 |       164s |        54% |\n+---------------------------------+-----------+------------+------------+\n```\n\nYou may notice that assembling the coupling system is more expensive than assembling the Stokes part. This depends highly on the number of Gauss points (solid particles) that are used to apply the Nitsche restriction. In the present case, a relatively low number of tracer particles are used. Consequently, tracking their motion is relatively cheap.\n\nThe following movie shows the evolution of the solution over time:\n\nThe movie shows the rotating obstacle in gray (actually a superposition of the solid particles plotted with large enough dots that they overlap), [streamlines of the fluid flow](https://en.wikipedia.org/wiki/Streamlines,_streaklines,_and_pathlines) in light colors (including the corner vertices that form at specific times during the simulation), and the tracer particles in bluish tones.\n\nThe simulation shows that at the end time, the tracer particles have somewhat returned to their original position, although they have been distorted by the flow field. The following image compares the initial and the final position of the particles after one time unit of flow.\n\n![](images/steps/developer/step-70.tracer_comparison.png)\n\nIn this case, we see that the tracer particles that were outside of the swept volume of the impeller have returned very close to their initial position, whereas those in the swept volume were slightly more deformed. This deformation is non-physical. It is caused by the numerical error induced by the explicit Euler scheme used to advect the particles, by the loss of accuracy due to the fictitious domain and, finally, by the discretization error on the Stokes equations. The first two errors are the leading cause of this deformation and they could be alleviated by the use of a finer mesh and a lower time step.\n\n### Three dimensional test case\n\nTo play around a little bit, we complicate the fictitious domain (taken from <https://grabcad.com/library/lungstors-blower-1>), and run a co-dimension one simulation in three space dimensions, using the following \"`parameters\\_23.prm`\" file :\n\n```\nsubsection Stokes Immersed Problem\n  set Final time                            = 1\n  set Homogeneous Dirichlet boundary ids    = 0\n  set Fluid bounding boxes extraction level = 1\n  set Initial fluid refinement              = 3\n  set Initial solid refinement              = 0\n  set Nitsche penalty term                  = 10\n  set Number of time steps                  = 101\n  set Output frequency                      = 1\n  set Particle insertion refinement         = 3\n  set Velocity degree                       = 2\n  set Viscosity                             = 1\n  subsection Angular velocity\n    set Function constants  =\n    set Function expression = t < .500001 ? 5 : -5\n    set Variable names      = x,y,z,t\n  end\n  subsection Grid generation\n    set Fluid grid generator              = hyper_rectangle\n    set Fluid grid generator arguments    = -50,-50, -10: 50, 50, 40: false\n    set Solid grid generator              = impeller.vtk\n    set Solid grid generator arguments    = 1:impeller.step\n    set Particle grid generator           = hyper_ball\n    set Particle grid generator arguments = 30, 30, 20: 10: false\n  end\n  subsection Refinement and remeshing\n    set Maximum number of cells        = 100000\n    set Refinement coarsening fraction = 0.3\n    set Refinement fraction            = 0.3\n    set Refinement maximal level       = 6\n    set Refinement step frequency      = 5\n    set Refinement strategy            = fixed_fraction\n  end\n  subsection Right hand side\n    set Function constants  =\n    set Function expression = 0; 0; 0; 0\n    set Variable names      = x,y,z,t\n  end\nend\n```\n\nIn this case, the timing outputs are a bit different:\n\n```\n+---------------------------------------------+------------+------------+\n| Total wallclock time elapsed since start    |  5.54e+03s |            |\n|                                             |            |            |\n| Section                         | no. calls |  wall time | % of total |\n+---------------------------------+-----------+------------+------------+\n| Assemble Nitsche terms          |       101 |       111s |         2% |\n| Assemble Stokes terms           |       101 |       208s |       3.8% |\n| Initial setup                   |         1 |   0.00187s |         0% |\n| Output fluid                    |       102 |      15.5s |      0.28% |\n| Output solid particles          |       102 |      2.63s |         0% |\n| Output tracer particles         |       102 |      2.49s |         0% |\n| Refine                          |        20 |      18.4s |      0.33% |\n| Set solid particle position     |       100 |       6.1s |      0.11% |\n| Set tracer particle motion      |       101 |      10.8s |       0.2% |\n| Setup dofs                      |        21 |      13.9s |      0.25% |\n| Solve                           |       101 |  5.16e+03s |        93% |\n+---------------------------------+-----------+------------+------------+\n```\n\nNow, the solver is taking most of the solution time in three dimensions, and the particle motion and Nitsche assembly remain relatively unimportant as far as run time is concerned.\n\n### Possibilities for extensions\n\nThe current tutorial program shows a one-way coupling between the fluid and the solid, where the solid motion is imposed (and not solved for), and read in the solid domain by exploiting the location and the weights of the solid quadrature points.\n\nThe structure of the code already allows one to implement a two-way coupling, by exploiting the possibility to read values of the fluid velocity on the quadrature points of the solid grid. For this to be more efficient in terms of MPI communication patterns, one should maintain ownership of the quadrature points on the solid processor that owns the cells where they have been created. In the current code, it is sufficient to define the [IndexSet](classIndexSet.html) of the vectors used to exchange information of the quadrature points by using the solid partition instead of the initial fluid partition.\n\nThis allows the combination of the technique used in this tutorial program with those presented in the tutorial [step-60](step_60.html) to solve a fluid structure interaction problem with distributed Lagrange multipliers, on [parallel::distributed::Triangulation](classparallel_1_1distributed_1_1Triangulation.html) objects.\n\nThe timings above show that the current preconditioning strategy does not work well for Nitsche penalization, and we should come up with a better preconditioner if we want to aim at larger problems. Moreover, a checkpoint restart strategy should be implemented to allow for longer simulations to be interrupted and restored, as it is done for example in the [step-69](step_69.html) tutorial.\n\nThe plain program\n=================\n\n```\n/* ------------------------------------------------------------------------\n *\n * SPDX-License-Identifier: LGPL-2.1-or-later\n * Copyright (C) 2020 - 2024 by the deal.II authors\n *\n * This file is part of the deal.II library.\n *\n * Part of the source code is dual licensed under Apache-2.0 WITH\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n * governing the source code and code contributions can be found in\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n *\n * ------------------------------------------------------------------------\n *\n * Authors: Luca Heltai, Bruno Blais, Rene Gassmoeller, 2020\n */\n \n \n#include <deal.II/base/function.h>\n#include <deal.II/base/quadrature_lib.h>\n#include <deal.II/base/timer.h>\n \n#include <deal.II/lac/block_linear_operator.h>\n#include <deal.II/lac/generic_linear_algebra.h>\n#include <deal.II/lac/linear_operator.h>\n#include <deal.II/lac/linear_operator_tools.h>\n \n#define FORCE_USE_OF_TRILINOS\n \nnamespace LA\n{\n#if defined(DEAL_II_WITH_PETSC) && !defined(DEAL_II_PETSC_WITH_COMPLEX) && \\\n  !(defined(DEAL_II_WITH_TRILINOS) && defined(FORCE_USE_OF_TRILINOS))\n using namespace dealii::LinearAlgebraPETSc;\n#  define USE_PETSC_LA\n#elif defined(DEAL_II_WITH_TRILINOS)\n using namespace dealii::LinearAlgebraTrilinos;\n#else\n#  error DEAL_II_WITH_PETSC or DEAL_II_WITH_TRILINOS required\n#endif\n} // namespace LA\n \n#include <deal.II/base/conditional_ostream.h>\n#include <deal.II/base/index_set.h>\n#include <deal.II/base/parameter_acceptor.h>\n#include <deal.II/base/parsed_function.h>\n#include <deal.II/base/utilities.h>\n \n#include <deal.II/distributed/grid_refinement.h>\n#include <deal.II/distributed/solution_transfer.h>\n#include <deal.II/distributed/tria.h>\n \n#include <deal.II/dofs/dof_handler.h>\n#include <deal.II/dofs/dof_renumbering.h>\n#include <deal.II/dofs/dof_tools.h>\n \n#include <deal.II/fe/fe_nothing.h>\n#include <deal.II/fe/fe_q.h>\n#include <deal.II/fe/fe_system.h>\n#include <deal.II/fe/fe_values.h>\n#include <deal.II/fe/mapping_fe_field.h>\n#include <deal.II/fe/mapping_q1.h>\n \n#include <deal.II/grid/grid_generator.h>\n#include <deal.II/grid/grid_in.h>\n#include <deal.II/grid/grid_tools.h>\n#include <deal.II/grid/manifold_lib.h>\n \n#include <deal.II/lac/affine_constraints.h>\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\n#include <deal.II/lac/full_matrix.h>\n#include <deal.II/lac/petsc_precondition.h>\n#include <deal.II/lac/petsc_solver.h>\n#include <deal.II/lac/petsc_sparse_matrix.h>\n#include <deal.II/lac/petsc_vector.h>\n#include <deal.II/lac/solver_cg.h>\n#include <deal.II/lac/solver_gmres.h>\n#include <deal.II/lac/solver_minres.h>\n#include <deal.II/lac/sparsity_tools.h>\n#include <deal.II/lac/vector.h>\n \n#include <deal.II/numerics/data_out.h>\n#include <deal.II/numerics/error_estimator.h>\n#include <deal.II/numerics/vector_tools.h>\n \n#include <deal.II/particles/data_out.h>\n#include <deal.II/particles/generators.h>\n#include <deal.II/particles/particle_handler.h>\n#include <deal.II/particles/utilities.h>\n \n#include <deal.II/opencascade/manifold_lib.h>\n#include <deal.II/opencascade/utilities.h>\n#ifdef DEAL_II_WITH_OPENCASCADE\n#  include <TopoDS.hxx>\n#endif\n \n#include <cmath>\n#include <filesystem>\n#include <fstream>\n#include <iostream>\n#include <memory>\n \nnamespace Step70\n{\n using namespace dealii;\n \n \n template <int dim, int spacedim = dim>\n class StokesImmersedProblemParameters : public ParameterAcceptor\n  {\n public:\n    StokesImmersedProblemParameters();\n \n void set_time(const double &time) const\n {\n      rhs.set_time(time);\n      angular_velocity.set_time(time);\n    }\n \n    std::string output_directory = \".\";\n \n unsigned int velocity_degree = 2;\n \n unsigned int number_of_time_steps = 501;\n double       final_time           = 1.0;\n \n unsigned int output_frequency = 1;\n \n unsigned int initial_fluid_refinement      = 5;\n unsigned int initial_solid_refinement      = 5;\n unsigned int particle_insertion_refinement = 3;\n \n unsigned int fluid_rtree_extraction_level = 1;\n \n double viscosity    = 1.0;\n double penalty_term = 100;\n \n    std::list<types::boundary_id> homogeneous_dirichlet_ids{0};\n \n    std::string name_of_fluid_grid       = \"hyper_cube\";\n    std::string arguments_for_fluid_grid = \"-1: 1: false\";\n    std::string name_of_solid_grid       = \"hyper_rectangle\";\n    std::string arguments_for_solid_grid = spacedim == 2 ?\n \"-.5, -.1: .5, .1: false\" :\n \"-.5, -.1, -.1: .5, .1, .1: false\";\n    std::string name_of_particle_grid    = \"hyper_ball\";\n    std::string arguments_for_particle_grid =\n      spacedim == 2 ? \"0.3, 0.3: 0.1: false\" : \"0.3, 0.3, 0.3 : 0.1: false\";\n \n int          max_level_refinement = 8;\n int          min_level_refinement = 5;\n    std::string  refinement_strategy  = \"fixed_fraction\";\n double       coarsening_fraction  = 0.3;\n double       refinement_fraction  = 0.3;\n unsigned int max_cells            = 20000;\n int          refinement_frequency = 5;\n \n mutable ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>> rhs;\n mutable ParameterAcceptorProxy<Functions::ParsedFunction<spacedim>>\n      angular_velocity;\n  };\n \n \n \n template <int dim, int spacedim>\n  StokesImmersedProblemParameters<dim,\n                                  spacedim>::StokesImmersedProblemParameters()\n    : ParameterAcceptor(\"Stokes Immersed Problem/\")\n    , rhs(\"Right hand side\", spacedim + 1)\n    , angular_velocity(\"Angular velocity\")\n  {\n    add_parameter(\n \"Velocity degree\", velocity_degree, \"\", this->prm, Patterns::Integer(1));\n \n    add_parameter(\"Number of time steps\", number_of_time_steps);\n    add_parameter(\"Output frequency\", output_frequency);\n \n    add_parameter(\"Output directory\", output_directory);\n \n    add_parameter(\"Final time\", final_time);\n \n    add_parameter(\"Viscosity\", viscosity);\n \n    add_parameter(\"Nitsche penalty term\", penalty_term);\n \n    add_parameter(\"Initial fluid refinement\",\n                  initial_fluid_refinement,\n \"Initial mesh refinement used for the fluid domain Omega\");\n \n    add_parameter(\"Initial solid refinement\",\n                  initial_solid_refinement,\n \"Initial mesh refinement used for the solid domain Gamma\");\n \n    add_parameter(\"Fluid bounding boxes extraction level\",\n                  fluid_rtree_extraction_level,\n \"Extraction level of the rtree used to construct global \"\n \"bounding boxes\");\n \n    add_parameter(\n \"Particle insertion refinement\",\n      particle_insertion_refinement,\n \"Refinement of the volumetric mesh used to insert the particles\");\n \n    add_parameter(\n \"Homogeneous Dirichlet boundary ids\",\n      homogeneous_dirichlet_ids,\n \"Boundary Ids over which homogeneous Dirichlet boundary conditions are applied\");\n \n    enter_subsection(\"Grid generation\");\n    {\n      add_parameter(\"Fluid grid generator\", name_of_fluid_grid);\n      add_parameter(\"Fluid grid generator arguments\", arguments_for_fluid_grid);\n \n      add_parameter(\"Solid grid generator\", name_of_solid_grid);\n      add_parameter(\"Solid grid generator arguments\", arguments_for_solid_grid);\n \n      add_parameter(\"Particle grid generator\", name_of_particle_grid);\n      add_parameter(\"Particle grid generator arguments\",\n                    arguments_for_particle_grid);\n    }\n    leave_subsection();\n \n \n \n    enter_subsection(\"Refinement and remeshing\");\n    {\n      add_parameter(\"Refinement step frequency\", refinement_frequency);\n      add_parameter(\"Refinement maximal level\", max_level_refinement);\n      add_parameter(\"Refinement minimal level\", min_level_refinement);\n      add_parameter(\"Refinement strategy\",\n                    refinement_strategy,\n \"\",\n                    this->prm,\n Patterns::Selection(\"fixed_fraction|fixed_number\"));\n      add_parameter(\"Refinement coarsening fraction\", coarsening_fraction);\n      add_parameter(\"Refinement fraction\", refinement_fraction);\n      add_parameter(\"Maximum number of cells\", max_cells);\n    }\n    leave_subsection();\n \n    rhs.declare_parameters_call_back.connect([&]() {\n Functions::ParsedFunction<spacedim>::declare_parameters(this->prm,\n                                                              spacedim + 1);\n    });\n    angular_velocity.declare_parameters_call_back.connect([&]() {\n      this->prm.set(\"Function expression\",\n \"t < .500001 ? 6.283185 : -6.283185\");\n    });\n  }\n \n \n template <int spacedim>\n class SolidVelocity : public Function<spacedim>\n  {\n public:\n static_assert(spacedim > 1,\n \"Cannot instantiate SolidVelocity for spacedim == 1\");\n \n    SolidVelocity(const Functions::ParsedFunction<spacedim> &angular_velocity)\n      : angular_velocity(angular_velocity)\n    {}\n \n virtual double value(const Point<spacedim> &p,\n unsigned int           component = 0) const override\n {\n Tensor<1, spacedim> velocity;\n \n const double omega = angular_velocity.value(p);\n      velocity[0]        = -omega * p[1];\n      velocity[1]        = omega * p[0];\n \n return velocity[component];\n    }\n \n private:\n const Functions::ParsedFunction<spacedim> &angular_velocity;\n  };\n \n \n template <int spacedim>\n class SolidPosition : public Function<spacedim>\n  {\n public:\n static_assert(spacedim > 1,\n \"Cannot instantiate SolidPosition for spacedim == 1\");\n \n    SolidPosition(const Functions::ParsedFunction<spacedim> &angular_velocity,\n const double                               time_step)\n      : Function<spacedim>(spacedim)\n      , angular_velocity(angular_velocity)\n      , time_step(time_step)\n    {}\n \n virtual double value(const Point<spacedim> &p,\n unsigned int           component = 0) const override\n {\n Point<spacedim> new_position = p;\n \n double dtheta = angular_velocity.value(p) * time_step;\n \n      new_position[0] = std::cos(dtheta) * p[0] - std::sin(dtheta) * p[1];\n      new_position[1] = std::sin(dtheta) * p[0] + std::cos(dtheta) * p[1];\n \n return new_position[component];\n    }\n \n void set_time_step(const double new_time_step)\n    {\n      time_step = new_time_step;\n    }\n \n private:\n const Functions::ParsedFunction<spacedim> &angular_velocity;\n double                                     time_step;\n  };\n \n \n \n template <int dim, int spacedim = dim>\n class StokesImmersedProblem\n  {\n public:\n    StokesImmersedProblem(\n const StokesImmersedProblemParameters<dim, spacedim> &par);\n \n void run();\n \n private:\n void make_grid();\n \n double compute_time_step() const;\n \n void setup_tracer_particles();\n void setup_solid_particles();\n \n void initial_setup();\n void setup_dofs();\n \n void assemble_stokes_system();\n void assemble_nitsche_restriction();\n \n void solve();\n \n void refine_and_transfer();\n \n void output_results(const unsigned int cycle, const double time) const;\n void output_particles(const Particles::ParticleHandler<spacedim> &particles,\n                          std::string                                 fprefix,\n const unsigned int                          iter,\n const double time) const;\n \n const StokesImmersedProblemParameters<dim, spacedim> &par;\n \n MPI_Comm mpi_communicator;\n \n ConditionalOStream pcout;\n \n mutable TimerOutput computing_timer;\n \n parallel::distributed::Triangulation<spacedim>      fluid_tria;\n parallel::distributed::Triangulation<dim, spacedim> solid_tria;\n \n    std::unique_ptr<FiniteElement<spacedim>>      fluid_fe;\n    std::unique_ptr<FiniteElement<dim, spacedim>> solid_fe;\n \n DoFHandler<spacedim>      fluid_dh;\n DoFHandler<dim, spacedim> solid_dh;\n \n    std::vector<IndexSet> fluid_owned_dofs;\n    std::vector<IndexSet> solid_owned_dofs;\n \n    std::vector<IndexSet> fluid_relevant_dofs;\n    std::vector<IndexSet> solid_relevant_dofs;\n \n AffineConstraints<double> constraints;\n \n    LA::MPI::BlockSparseMatrix system_matrix;\n    LA::MPI::BlockSparseMatrix preconditioner_matrix;\n \n    LA::MPI::BlockVector solution;\n    LA::MPI::BlockVector locally_relevant_solution;\n    LA::MPI::BlockVector system_rhs;\n \n Particles::ParticleHandler<spacedim> tracer_particle_handler;\n Particles::ParticleHandler<spacedim> solid_particle_handler;\n \n IndexSet locally_owned_tracer_particle_coordinates;\n IndexSet locally_relevant_tracer_particle_coordinates;\n \n    LA::MPI::Vector tracer_particle_velocities;\n    LA::MPI::Vector relevant_tracer_particle_displacements;\n \n    std::vector<std::vector<BoundingBox<spacedim>>> global_fluid_bounding_boxes;\n  };\n \n \n \n \n \n template <int dim, int spacedim>\n  StokesImmersedProblem<dim, spacedim>::StokesImmersedProblem(\n const StokesImmersedProblemParameters<dim, spacedim> &par)\n    : par(par)\n    , mpi_communicator(MPI_COMM_WORLD)\n    , pcout(std::cout,\n            (Utilities::MPI::this_mpi_process(mpi_communicator) == 0))\n    , computing_timer(mpi_communicator,\n                      pcout,\n TimerOutput::summary,\n TimerOutput::wall_times)\n    , fluid_tria(mpi_communicator,\n                 typename Triangulation<spacedim>::MeshSmoothing(\n Triangulation<spacedim>::smoothing_on_refinement |\n Triangulation<spacedim>::smoothing_on_coarsening))\n    , solid_tria(mpi_communicator,\n                 typename Triangulation<dim, spacedim>::MeshSmoothing(\n Triangulation<dim, spacedim>::smoothing_on_refinement |\n Triangulation<dim, spacedim>::smoothing_on_coarsening))\n    , fluid_dh(fluid_tria)\n    , solid_dh(solid_tria)\n  {\n if (std::filesystem::exists(par.output_directory))\n      {\n Assert(std::filesystem::is_directory(par.output_directory),\n               ExcMessage(\"You specified <\" + par.output_directory +\n \"> as the output directory in the input file, \"\n \"but this is not in fact a directory.\"));\n      }\n else\n      std::filesystem::create_directory(par.output_directory);\n  }\n \n \n template <int dim, int spacedim>\n void read_grid_and_cad_files(const std::string &grid_file_name,\n const std::string &ids_and_cad_file_names,\n Triangulation<dim, spacedim> &tria)\n  {\n GridIn<dim, spacedim> grid_in;\n    grid_in.attach_triangulation(tria);\n    grid_in.read(grid_file_name);\n \n#ifdef DEAL_II_WITH_OPENCASCADE\n using map_type  = std::map<types::manifold_id, std::string>;\n using Converter = Patterns::Tools::Convert<map_type>;\n \n for (const auto &pair : Converter::to_value(ids_and_cad_file_names))\n      {\n const auto &manifold_id   = pair.first;\n const auto &cad_file_name = pair.second;\n \n        std::string extension =\n          cad_file_name.substr(cad_file_name.find_last_of('.') + 1);\n        std::transform(extension.begin(),\n                       extension.end(),\n                       extension.begin(),\n                       [](const char c) -> char { return std::tolower(c); });\n \n        TopoDS_Shape shape;\n if (extension == \"iges\" || extension == \"igs\")\n          shape = OpenCASCADE::read_IGES(cad_file_name);\n else if (extension == \"step\" || extension == \"stp\")\n          shape = OpenCASCADE::read_STEP(cad_file_name);\n else\n AssertThrow(false,\n                      ExcNotImplemented(\"We found an extension that we \"\n \"do not recognize as a CAD file \"\n \"extension. Bailing out.\"));\n \n const auto n_elements = OpenCASCADE::count_elements(shape);\n if ((std::get<0>(n_elements) == 0))\n          tria.set_manifold(\n            manifold_id,\n OpenCASCADE::ArclengthProjectionLineManifold<dim, spacedim>(shape));\n else if (spacedim == 3)\n          {\n const auto t = reinterpret_cast<Triangulation<dim, 3> *>(&tria);\n            t->set_manifold(manifold_id,\n OpenCASCADE::NormalToMeshProjectionManifold<dim, 3>(\n                              shape));\n          }\n else\n          tria.set_manifold(manifold_id,\n OpenCASCADE::NURBSPatchManifold<dim, spacedim>(\n                              TopoDS::Face(shape)));\n      }\n#else\n    (void)ids_and_cad_file_names;\n AssertThrow(false, ExcNotImplemented(\"Generation of the grid failed.\"));\n#endif\n  }\n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::make_grid()\n  {\n try\n      {\n GridGenerator::generate_from_name_and_arguments(\n          fluid_tria, par.name_of_fluid_grid, par.arguments_for_fluid_grid);\n      }\n catch (...)\n      {\n        pcout << \"Generating from name and argument failed.\" << std::endl\n              << \"Trying to read from file name.\" << std::endl;\n        read_grid_and_cad_files(par.name_of_fluid_grid,\n                                par.arguments_for_fluid_grid,\n                                fluid_tria);\n      }\n    fluid_tria.refine_global(par.initial_fluid_refinement);\n \n try\n      {\n GridGenerator::generate_from_name_and_arguments(\n          solid_tria, par.name_of_solid_grid, par.arguments_for_solid_grid);\n      }\n catch (...)\n      {\n        read_grid_and_cad_files(par.name_of_solid_grid,\n                                par.arguments_for_solid_grid,\n                                solid_tria);\n      }\n \n    solid_tria.refine_global(par.initial_solid_refinement);\n  }\n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::setup_tracer_particles()\n  {\n parallel::distributed::Triangulation<spacedim> particle_insert_tria(\n      mpi_communicator);\n GridGenerator::generate_from_name_and_arguments(\n      particle_insert_tria,\n      par.name_of_particle_grid,\n      par.arguments_for_particle_grid);\n    particle_insert_tria.refine_global(par.particle_insertion_refinement);\n \n const FE_Q<spacedim> particles_fe(1);\n DoFHandler<spacedim> particles_dof_handler(particle_insert_tria);\n    particles_dof_handler.distribute_dofs(particles_fe);\n \n    std::vector<BoundingBox<spacedim>> all_boxes;\n    all_boxes.reserve(fluid_tria.n_locally_owned_active_cells());\n for (const auto &cell : fluid_tria.active_cell_iterators())\n      if (cell->is_locally_owned())\n        all_boxes.emplace_back(cell->bounding_box());\n \n const auto tree = pack_rtree(all_boxes);\n const auto local_boxes =\n extract_rtree_level(tree, par.fluid_rtree_extraction_level);\n \n    global_fluid_bounding_boxes =\n Utilities::MPI::all_gather(mpi_communicator, local_boxes);\n \n    tracer_particle_handler.initialize(fluid_tria,\n StaticMappingQ1<spacedim>::mapping);\n \n Particles::Generators::dof_support_points(particles_dof_handler,\n                                              global_fluid_bounding_boxes,\n                                              tracer_particle_handler);\n \n    pcout << \"Tracer particles: \"\n          << tracer_particle_handler.n_global_particles() << std::endl;\n \n    locally_owned_tracer_particle_coordinates =\n      tracer_particle_handler.locally_owned_particle_ids().tensor_product(\n complete_index_set(spacedim));\n \n    locally_relevant_tracer_particle_coordinates =\n      locally_owned_tracer_particle_coordinates;\n  }\n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::setup_solid_particles()\n  {\n const QGauss<dim> quadrature(fluid_fe->degree + 1);\n \n const unsigned int n_properties = 1;\n    solid_particle_handler.initialize(fluid_tria,\n StaticMappingQ1<spacedim>::mapping,\n                                      n_properties);\n \n    std::vector<Point<spacedim>> quadrature_points_vec;\n    quadrature_points_vec.reserve(quadrature.size() *\n                                  solid_tria.n_locally_owned_active_cells());\n \n    std::vector<std::vector<double>> properties;\n    properties.reserve(quadrature.size() *\n                       solid_tria.n_locally_owned_active_cells());\n \n FEValues<dim, spacedim> fe_v(*solid_fe,\n                                 quadrature,\n update_JxW_values | update_quadrature_points);\n for (const auto &cell : solid_dh.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n          fe_v.reinit(cell);\n const auto &points = fe_v.get_quadrature_points();\n const auto &JxW    = fe_v.get_JxW_values();\n \n for (unsigned int q = 0; q < points.size(); ++q)\n            {\n              quadrature_points_vec.emplace_back(points[q]);\n              properties.emplace_back(\n                std::vector<double>(n_properties, JxW[q]));\n            }\n        }\n \n Assert(!global_fluid_bounding_boxes.empty(),\n           ExcInternalError(\n \"I was expecting the \"\n \"global_fluid_bounding_boxes to be filled at this stage. \"\n \"Make sure you fill this vector before trying to use it \"\n \"here. Bailing out.\"));\n \n    solid_particle_handler.insert_global_particles(quadrature_points_vec,\n                                                   global_fluid_bounding_boxes,\n                                                   properties);\n \n    pcout << \"Solid particles: \" << solid_particle_handler.n_global_particles()\n          << std::endl;\n  }\n \n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::initial_setup()\n  {\n TimerOutput::Scope t(computing_timer, \"Initial setup\");\n \n    fluid_fe = std::make_unique<FESystem<spacedim>>(\n FE_Q<spacedim>(par.velocity_degree) ^ spacedim,\n FE_Q<spacedim>(par.velocity_degree - 1));\n \n \n    solid_fe = std::make_unique<FE_Nothing<dim, spacedim>>();\n    solid_dh.distribute_dofs(*solid_fe);\n  }\n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::setup_dofs()\n  {\n TimerOutput::Scope t(computing_timer, \"Setup dofs\");\n \n    fluid_dh.distribute_dofs(*fluid_fe);\n \n    std::vector<unsigned int> stokes_sub_blocks(spacedim + 1, 0);\n    stokes_sub_blocks[spacedim] = 1;\n DoFRenumbering::component_wise(fluid_dh, stokes_sub_blocks);\n \n auto dofs_per_block =\n DoFTools::count_dofs_per_fe_block(fluid_dh, stokes_sub_blocks);\n \n const unsigned int n_u = dofs_per_block[0], n_p = dofs_per_block[1];\n \n    pcout << \"   Number of degrees of freedom: \" << fluid_dh.n_dofs() << \" (\"\n          << n_u << '+' << n_p << \" -- \"\n          << solid_particle_handler.n_global_particles() << '+'\n          << tracer_particle_handler.n_global_particles() << ')' << std::endl;\n \n    fluid_owned_dofs.resize(2);\n    fluid_owned_dofs[0] = fluid_dh.locally_owned_dofs().get_view(0, n_u);\n    fluid_owned_dofs[1] =\n      fluid_dh.locally_owned_dofs().get_view(n_u, n_u + n_p);\n \n const IndexSet locally_relevant_dofs =\n DoFTools::extract_locally_relevant_dofs(fluid_dh);\n    fluid_relevant_dofs.resize(2);\n    fluid_relevant_dofs[0] = locally_relevant_dofs.get_view(0, n_u);\n    fluid_relevant_dofs[1] = locally_relevant_dofs.get_view(n_u, n_u + n_p);\n \n    {\n      constraints.reinit(fluid_dh.locally_owned_dofs(), locally_relevant_dofs);\n \n const FEValuesExtractors::Vector velocities(0);\n DoFTools::make_hanging_node_constraints(fluid_dh, constraints);\n VectorTools::interpolate_boundary_values(\n        fluid_dh,\n        0,\n Functions::ZeroFunction<spacedim>(spacedim + 1),\n        constraints,\n        fluid_fe->component_mask(velocities));\n      constraints.close();\n    }\n \n const auto locally_owned_dofs_per_processor =\n Utilities::MPI::all_gather(mpi_communicator,\n                                 fluid_dh.locally_owned_dofs());\n    {\n      system_matrix.clear();\n \n Table<2, DoFTools::Coupling> coupling(spacedim + 1, spacedim + 1);\n for (unsigned int c = 0; c < spacedim + 1; ++c)\n for (unsigned int d = 0; d < spacedim + 1; ++d)\n if (c == spacedim && d == spacedim)\n            coupling[c][d] = DoFTools::none;\n else if (c == spacedim || d == spacedim || c == d)\n            coupling[c][d] = DoFTools::always;\n else\n            coupling[c][d] = DoFTools::none;\n \n BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n \n DoFTools::make_sparsity_pattern(\n        fluid_dh, coupling, dsp, constraints, false);\n \n SparsityTools::distribute_sparsity_pattern(\n        dsp,\n        locally_owned_dofs_per_processor,\n        mpi_communicator,\n        locally_relevant_dofs);\n \n      system_matrix.reinit(fluid_owned_dofs, dsp, mpi_communicator);\n    }\n \n    {\n      preconditioner_matrix.clear();\n \n Table<2, DoFTools::Coupling> coupling(spacedim + 1, spacedim + 1);\n for (unsigned int c = 0; c < spacedim + 1; ++c)\n for (unsigned int d = 0; d < spacedim + 1; ++d)\n if (c == spacedim && d == spacedim)\n            coupling[c][d] = DoFTools::always;\n else\n            coupling[c][d] = DoFTools::none;\n \n BlockDynamicSparsityPattern dsp(dofs_per_block, dofs_per_block);\n \n DoFTools::make_sparsity_pattern(\n        fluid_dh, coupling, dsp, constraints, false);\n SparsityTools::distribute_sparsity_pattern(\n        dsp,\n        locally_owned_dofs_per_processor,\n        mpi_communicator,\n        locally_relevant_dofs);\n      preconditioner_matrix.reinit(fluid_owned_dofs, dsp, mpi_communicator);\n    }\n \n    locally_relevant_solution.reinit(fluid_owned_dofs,\n                                     fluid_relevant_dofs,\n                                     mpi_communicator);\n    system_rhs.reinit(fluid_owned_dofs, mpi_communicator);\n    solution.reinit(fluid_owned_dofs, mpi_communicator);\n  }\n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::assemble_stokes_system()\n  {\n    system_matrix         = 0;\n    preconditioner_matrix = 0;\n    system_rhs            = 0;\n \n TimerOutput::Scope t(computing_timer, \"Assemble Stokes terms\");\n \n const QGauss<spacedim> quadrature_formula(fluid_fe->degree + 1);\n FEValues<spacedim>     fe_values(*fluid_fe,\n                                 quadrature_formula,\n update_values | update_gradients |\n update_quadrature_points |\n update_JxW_values);\n \n const unsigned int dofs_per_cell = fluid_fe->n_dofs_per_cell();\n const unsigned int n_q_points    = quadrature_formula.size();\n \n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\n FullMatrix<double> cell_matrix2(dofs_per_cell, dofs_per_cell);\n Vector<double>     cell_rhs(dofs_per_cell);\n \n    std::vector<Vector<double>> rhs_values(n_q_points,\n Vector<double>(spacedim + 1));\n \n    std::vector<Tensor<2, spacedim>> grad_phi_u(dofs_per_cell);\n    std::vector<double>              div_phi_u(dofs_per_cell);\n    std::vector<double>              phi_p(dofs_per_cell);\n \n    std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\n const FEValuesExtractors::Vector     velocities(0);\n const FEValuesExtractors::Scalar     pressure(spacedim);\n \n for (const auto &cell : fluid_dh.active_cell_iterators())\n      if (cell->is_locally_owned())\n        {\n cell_matrix  = 0;\n          cell_matrix2 = 0;\n          cell_rhs     = 0;\n \n          fe_values.reinit(cell);\n          par.rhs.vector_value_list(fe_values.get_quadrature_points(),\n                                    rhs_values);\n for (unsigned int q = 0; q < n_q_points; ++q)\n            {\n for (unsigned int k = 0; k < dofs_per_cell; ++k)\n                {\n                  grad_phi_u[k] = fe_values[velocities].gradient(k, q);\n                  div_phi_u[k]  = fe_values[velocities].divergence(k, q);\n                  phi_p[k]      = fe_values[pressure].value(k, q);\n                }\n \n for (unsigned int i = 0; i < dofs_per_cell; ++i)\n                {\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\n                    {\n cell_matrix(i, j) +=\n                        (par.viscosity *\n                           scalar_product(grad_phi_u[i], grad_phi_u[j]) -\n                         div_phi_u[i] * phi_p[j] - phi_p[i] * div_phi_u[j]) *\n                        fe_values.JxW(q);\n \n                      cell_matrix2(i, j) += 1.0 / par.viscosity * phi_p[i] *\n                                            phi_p[j] * fe_values.JxW(q);\n                    }\n \n const unsigned int component_i =\n                    fluid_fe->system_to_component_index(i).first;\n                  cell_rhs(i) += fe_values.shape_value(i, q) *\n                                 rhs_values[q](component_i) * fe_values.JxW(q);\n                }\n            }\n \n \n          cell->get_dof_indices(local_dof_indices);\n          constraints.distribute_local_to_global(cell_matrix,\n                                                 cell_rhs,\n                                                 local_dof_indices,\n                                                 system_matrix,\n                                                 system_rhs);\n \n          constraints.distribute_local_to_global(cell_matrix2,\n                                                 local_dof_indices,\n                                                 preconditioner_matrix);\n        }\n \n    system_matrix.compress(VectorOperation::add);\n    preconditioner_matrix.compress(VectorOperation::add);\n    system_rhs.compress(VectorOperation::add);\n  }\n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::assemble_nitsche_restriction()\n  {\n TimerOutput::Scope t(computing_timer, \"Assemble Nitsche terms\");\n \n const FEValuesExtractors::Vector velocities(0);\n const FEValuesExtractors::Scalar pressure(spacedim);\n \n    SolidVelocity<spacedim> solid_velocity(par.angular_velocity);\n \n    std::vector<types::global_dof_index> fluid_dof_indices(\n      fluid_fe->n_dofs_per_cell());\n \n FullMatrix<double> local_matrix(fluid_fe->n_dofs_per_cell(),\n                                    fluid_fe->n_dofs_per_cell());\n Vector<double>     local_rhs(fluid_fe->n_dofs_per_cell());\n \n const auto penalty_parameter =\n      1.0 / GridTools::minimal_cell_diameter(fluid_tria);\n \n auto particle = solid_particle_handler.begin();\n while (particle != solid_particle_handler.end())\n      {\n        local_matrix = 0;\n        local_rhs    = 0;\n \n const auto &cell = particle->get_surrounding_cell();\n const auto &dh_cell =\n typename DoFHandler<spacedim>::cell_iterator(*cell, &fluid_dh);\n        dh_cell->get_dof_indices(fluid_dof_indices);\n \n const auto pic = solid_particle_handler.particles_in_cell(cell);\n Assert(pic.begin() == particle, ExcInternalError());\n for (const auto &p : pic)\n          {\n const Point<spacedim> ref_q  = p.get_reference_location();\n const Point<spacedim> real_q = p.get_location();\n const double          JxW    = p.get_properties()[0];\n \n for (unsigned int i = 0; i < fluid_fe->n_dofs_per_cell(); ++i)\n              {\n const auto comp_i =\n                  fluid_fe->system_to_component_index(i).first;\n if (comp_i < spacedim)\n                  {\n for (unsigned int j = 0; j < fluid_fe->n_dofs_per_cell();\n                         ++j)\n                      {\n const auto comp_j =\n                          fluid_fe->system_to_component_index(j).first;\n if (comp_i == comp_j)\n                          local_matrix(i, j) +=\n                            penalty_parameter * par.penalty_term *\n                            fluid_fe->shape_value(i, ref_q) *\n                            fluid_fe->shape_value(j, ref_q) * JxW;\n                      }\n                    local_rhs(i) += penalty_parameter * par.penalty_term *\n                                    solid_velocity.value(real_q, comp_i) *\n                                    fluid_fe->shape_value(i, ref_q) * JxW;\n                  }\n              }\n          }\n \n        constraints.distribute_local_to_global(local_matrix,\n                                               local_rhs,\n                                               fluid_dof_indices,\n                                               system_matrix,\n                                               system_rhs);\n        particle = pic.end();\n      }\n \n    system_matrix.compress(VectorOperation::add);\n    system_rhs.compress(VectorOperation::add);\n  }\n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::solve()\n  {\n TimerOutput::Scope t(computing_timer, \"Solve\");\n \n    LA::MPI::PreconditionAMG prec_A;\n    {\n      LA::MPI::PreconditionAMG::AdditionalData data;\n \n#ifdef USE_PETSC_LA\n      data.symmetric_operator = true;\n#endif\n      prec_A.initialize(system_matrix.block(0, 0), data);\n    }\n \n    LA::MPI::PreconditionAMG prec_S;\n    {\n      LA::MPI::PreconditionAMG::AdditionalData data;\n \n#ifdef USE_PETSC_LA\n      data.symmetric_operator = true;\n#endif\n      prec_S.initialize(preconditioner_matrix.block(1, 1), data);\n    }\n \n const auto A = linear_operator<LA::MPI::Vector>(system_matrix.block(0, 0));\n const auto amgA = linear_operator(A, prec_A);\n \n const auto S =\n linear_operator<LA::MPI::Vector>(preconditioner_matrix.block(1, 1));\n const auto amgS = linear_operator(S, prec_S);\n \n ReductionControl          inner_solver_control(100,\n                                          1e-8 * system_rhs.l2_norm(),\n                                          1.e-2);\n SolverCG<LA::MPI::Vector> cg(inner_solver_control);\n \n const auto invS = inverse_operator(S, cg, amgS);\n \n const auto P = block_diagonal_operator<2, LA::MPI::BlockVector>(\n      std::array<LinearOperator<typename LA::MPI::BlockVector::BlockType>, 2>{\n        {amgA, amgS}});\n \n SolverControl solver_control(system_matrix.m(),\n                                 1e-10 * system_rhs.l2_norm());\n \n SolverFGMRES<LA::MPI::BlockVector> solver(solver_control);\n \n    constraints.set_zero(solution);\n \n    solver.solve(system_matrix, solution, system_rhs, P);\n \n \n    pcout << \"   Solved in \" << solver_control.last_step() << \" iterations.\"\n          << std::endl;\n \n    constraints.distribute(solution);\n \n    locally_relevant_solution = solution;\n const double mean_pressure =\n VectorTools::compute_mean_value(fluid_dh,\n QGauss<spacedim>(par.velocity_degree + 2),\n                                      locally_relevant_solution,\n                                      spacedim);\n    solution.block(1).add(-mean_pressure);\n    locally_relevant_solution.block(1) = solution.block(1);\n  }\n \n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::refine_and_transfer()\n  {\n TimerOutput::Scope               t(computing_timer, \"Refine\");\n const FEValuesExtractors::Vector velocity(0);\n \n Vector<float> error_per_cell(fluid_tria.n_active_cells());\n KellyErrorEstimator<spacedim>::estimate(fluid_dh,\n QGauss<spacedim - 1>(\n                                              par.velocity_degree + 1),\n                                            {},\n                                            locally_relevant_solution,\n                                            error_per_cell,\n                                            fluid_fe->component_mask(velocity));\n \n if (par.refinement_strategy == \"fixed_fraction\")\n      {\n parallel::distributed::GridRefinement::\n          refine_and_coarsen_fixed_fraction(fluid_tria,\n                                            error_per_cell,\n                                            par.refinement_fraction,\n                                            par.coarsening_fraction);\n      }\n else if (par.refinement_strategy == \"fixed_number\")\n      {\n parallel::distributed::GridRefinement::refine_and_coarsen_fixed_number(\n          fluid_tria,\n          error_per_cell,\n          par.refinement_fraction,\n          par.coarsening_fraction,\n          par.max_cells);\n      }\n \n for (const auto &cell : fluid_tria.active_cell_iterators())\n      {\n if (cell->refine_flag_set() &&\n            cell->level() == par.max_level_refinement)\n          cell->clear_refine_flag();\n if (cell->coarsen_flag_set() &&\n            cell->level() == par.min_level_refinement)\n          cell->clear_coarsen_flag();\n      }\n \n parallel::distributed::SolutionTransfer<spacedim, LA::MPI::BlockVector>\n      transfer(fluid_dh);\n \n    fluid_tria.prepare_coarsening_and_refinement();\n    transfer.prepare_for_coarsening_and_refinement(locally_relevant_solution);\n    tracer_particle_handler.prepare_for_coarsening_and_refinement();\n    solid_particle_handler.prepare_for_coarsening_and_refinement();\n \n    fluid_tria.execute_coarsening_and_refinement();\n \n    setup_dofs();\n \n    transfer.interpolate(solution);\n    tracer_particle_handler.unpack_after_coarsening_and_refinement();\n    solid_particle_handler.unpack_after_coarsening_and_refinement();\n \n    constraints.distribute(solution);\n    locally_relevant_solution = solution;\n  }\n \n \n \n template <int dim, int spacedim>\n void\n  StokesImmersedProblem<dim, spacedim>::output_results(const unsigned int cycle,\n double time) const\n {\n TimerOutput::Scope t(computing_timer, \"Output fluid\");\n \n    std::vector<std::string> solution_names(spacedim, \"velocity\");\n    solution_names.emplace_back(\"pressure\");\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\n      data_component_interpretation(\n        spacedim, DataComponentInterpretation::component_is_part_of_vector);\n    data_component_interpretation.push_back(\n DataComponentInterpretation::component_is_scalar);\n \n DataOut<spacedim> data_out;\n    data_out.attach_dof_handler(fluid_dh);\n    data_out.add_data_vector(locally_relevant_solution,\n                             solution_names,\n DataOut<spacedim>::type_dof_data,\n                             data_component_interpretation);\n \n \n Vector<float> subdomain(fluid_tria.n_active_cells());\n for (unsigned int i = 0; i < subdomain.size(); ++i)\n      subdomain(i) = fluid_tria.locally_owned_subdomain();\n    data_out.add_data_vector(subdomain, \"subdomain\");\n \n    data_out.build_patches();\n \n const std::string filename =\n \"solution-\" + Utilities::int_to_string(cycle) + \".vtu\";\n    data_out.write_vtu_in_parallel(par.output_directory + \"/\" + filename,\n                                   mpi_communicator);\n \n static std::vector<std::pair<double, std::string>> times_and_names;\n    times_and_names.emplace_back(time, filename);\n    std::ofstream ofile(par.output_directory + \"/\" + \"solution.pvd\");\n DataOutBase::write_pvd_record(ofile, times_and_names);\n  }\n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::output_particles(\n const Particles::ParticleHandler<spacedim> &particles,\n    std::string                                 fprefix,\n const unsigned int                          iter,\n const double                                time) const\n {\n Particles::DataOut<spacedim> particles_out;\n    particles_out.build_patches(particles);\n const std::string filename =\n      (fprefix + \"-\" + Utilities::int_to_string(iter) + \".vtu\");\n    particles_out.write_vtu_in_parallel(par.output_directory + \"/\" + filename,\n                                        mpi_communicator);\n \n \n static std::map<std::string, std::vector<std::pair<double, std::string>>>\n      times_and_names;\n if (times_and_names.find(fprefix) != times_and_names.end())\n      times_and_names[fprefix].emplace_back(time, filename);\n else\n      times_and_names[fprefix] = {std::make_pair(time, filename)};\n    std::ofstream ofile(par.output_directory + \"/\" + fprefix + \".pvd\");\n DataOutBase::write_pvd_record(ofile, times_and_names[fprefix]);\n  }\n \n \n \n template <int dim, int spacedim>\n void StokesImmersedProblem<dim, spacedim>::run()\n  {\n#ifdef USE_PETSC_LA\n    pcout << \"Running StokesImmersedProblem<\"\n          << Utilities::dim_string(dim, spacedim) << \"> using PETSc.\"\n          << std::endl;\n#else\n    pcout << \"Running StokesImmersedProblem<\"\n          << Utilities::dim_string(dim, spacedim) << \"> using Trilinos.\"\n          << std::endl;\n#endif\n    par.prm.print_parameters(par.output_directory + \"/\" + \"used_parameters_\" +\n                               std::to_string(dim) + std::to_string(spacedim) +\n \".prm\",\n ParameterHandler::Short);\n \n const double time_step    = par.final_time / (par.number_of_time_steps - 1);\n double       time         = 0;\n unsigned int output_cycle = 0;\n \n for (unsigned int cycle = 0; cycle < par.number_of_time_steps;\n         ++cycle, time += time_step)\n      {\n        par.set_time(time);\n        pcout << \"Cycle \" << cycle << ':' << std::endl\n              << \"Time : \" << time << \", time step: \" << time_step << std::endl;\n \n if (cycle == 0)\n          {\n            make_grid();\n            initial_setup();\n            setup_dofs();\n            setup_tracer_particles();\n            setup_solid_particles();\n            tracer_particle_velocities.reinit(\n              locally_owned_tracer_particle_coordinates, mpi_communicator);\n            output_results(output_cycle, time);\n            {\n TimerOutput::Scope t(computing_timer, \"Output tracer particles\");\n              output_particles(tracer_particle_handler,\n \"tracer\",\n                               output_cycle,\n                               time);\n            }\n            {\n TimerOutput::Scope t(computing_timer, \"Output solid particles\");\n              output_particles(solid_particle_handler,\n \"solid\",\n                               output_cycle,\n                               time);\n            }\n          }\n else\n          {\n TimerOutput::Scope t(computing_timer,\n \"Set solid particle position\");\n \n            SolidPosition<spacedim> solid_position(par.angular_velocity,\n                                                   time_step);\n            solid_particle_handler.set_particle_positions(solid_position,\n false);\n          }\n \n        {\n TimerOutput::Scope t(computing_timer, \"Set tracer particle motion\");\n Particles::Utilities::interpolate_field_on_particles(\n            fluid_dh,\n            tracer_particle_handler,\n            locally_relevant_solution,\n            tracer_particle_velocities,\n            fluid_fe->component_mask(FEValuesExtractors::Vector(0)));\n \n          tracer_particle_velocities *= time_step;\n \n          locally_relevant_tracer_particle_coordinates =\n            tracer_particle_handler.locally_owned_particle_ids().tensor_product(\n complete_index_set(spacedim));\n \n          relevant_tracer_particle_displacements.reinit(\n            locally_owned_tracer_particle_coordinates,\n            locally_relevant_tracer_particle_coordinates,\n            mpi_communicator);\n \n          relevant_tracer_particle_displacements = tracer_particle_velocities;\n \n          tracer_particle_handler.set_particle_positions(\n            relevant_tracer_particle_displacements);\n        }\n \n        assemble_stokes_system();\n        assemble_nitsche_restriction();\n        solve();\n \n if (cycle % par.output_frequency == 0)\n          {\n            output_results(output_cycle, time);\n            {\n TimerOutput::Scope t(computing_timer, \"Output tracer particles\");\n              output_particles(tracer_particle_handler,\n \"tracer\",\n                               output_cycle,\n                               time);\n            }\n            {\n TimerOutput::Scope t(computing_timer, \"Output solid particles\");\n              output_particles(solid_particle_handler,\n \"solid\",\n                               output_cycle,\n                               time);\n            }\n            ++output_cycle;\n          }\n if (cycle % par.refinement_frequency == 0 &&\n            cycle != par.number_of_time_steps - 1)\n          refine_and_transfer();\n      }\n  }\n \n} // namespace Step70\n \n \n \nint main(int argc, char *argv[])\n{\n using namespace Step70;\n using namespace dealii;\n deallog.depth_console(1);\n try\n    {\n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\n \n      std::string prm_file;\n if (argc > 1)\n        prm_file = argv[1];\n else\n        prm_file = \"parameters.prm\";\n \n if (prm_file.find(\"23\") != std::string::npos)\n        {\n          StokesImmersedProblemParameters<2, 3> par;\n ParameterAcceptor::initialize(prm_file);\n \n          StokesImmersedProblem<2, 3> problem(par);\n          problem.run();\n        }\n else if (prm_file.find('3') != std::string::npos)\n        {\n          StokesImmersedProblemParameters<3> par;\n ParameterAcceptor::initialize(prm_file);\n \n          StokesImmersedProblem<3> problem(par);\n          problem.run();\n        }\n else\n        {\n          StokesImmersedProblemParameters<2> par;\n ParameterAcceptor::initialize(prm_file);\n \n          StokesImmersedProblem<2> problem(par);\n          problem.run();\n        }\n    }\n catch (std::exception &exc)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Exception on processing: \" << std::endl\n                << exc.what() << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n \n return 1;\n    }\n catch (...)\n    {\n      std::cerr << std::endl\n                << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n      std::cerr << \"Unknown exception!\" << std::endl\n                << \"Aborting!\" << std::endl\n                << \"----------------------------------------------------\"\n                << std::endl;\n return 1;\n    }\n \n return 0;\n}\n```\n"}],"temperature":0.2,"response_format":{"type":"json_schema","json_schema":{"name":"finetune_prompt-completion_pair","strict":true,"description":"A pair of prompt and completion for finetuning a code LLM","schema":{"type":"object","properties":{"prompt":{"type":"string","description":"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)"},"completion":{"type":"string","description":"The final code completion"}},"additionalProperties":false,"required":["prompt","completion"]}}}}}