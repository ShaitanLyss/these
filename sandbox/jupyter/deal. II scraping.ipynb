{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0d6a5b-6bfa-4900-a55c-ef9e5e0ca22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json as JSON\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from markdownify import markdownify\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "import html\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89765860-accd-4b5c-acec-2bb8e407748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.dealii.org\"\n",
    "DOC_URL = \"https://dealii.org/current/doxygen/deal.II/\"\n",
    "TUTORIAL_INDEX = \"https://dealii.org/current/doxygen/deal.II/Tutorial.html\"\n",
    "TUTO_LIST_TITLE = \"Tutorial programs listed by number\"\n",
    "CODE_TITLE = \"The plain program\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b40576-a312-43b9-9647-bbfc5f72dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = requests.get(TUTORIAL_INDEX)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "title = soup.find(\"h3\", string=TUTO_LIST_TITLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07901761-a4af-4015-bd21-5f3bfbc0d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86 deal.II tutorials.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (86, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num</th><th>name</th><th>link</th><th>description</th><th>keywords</th></tr><tr><td>u8</td><td>str</td><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>1</td><td>&quot;step-1&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Creating a grid. A simple way …</td><td>[&quot;Triangulation&quot;, &quot;GridGenerator::hyper_cube()&quot;, … &quot;Triangulation::execute_coarsening_and_refinement()&quot;]</td></tr><tr><td>2</td><td>&quot;step-2&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Associate degrees of freedom t…</td><td>[&quot;FE_Q&quot;, &quot;DynamicSparsityPattern&quot;, … &quot;SparsityPattern&quot;]</td></tr><tr><td>3</td><td>&quot;step-3&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Actually solve Laplace&#x27;s probl…</td><td>[&quot;FEValues&quot;, &quot;VectorTools::interpolate_boundary_values()&quot;, … &quot;DataOut&quot;]</td></tr><tr><td>4</td><td>&quot;step-4&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;This example is programmed in …</td><td>[&quot;VectorTools::point_value()&quot;, &quot;VectorTools::compute_mean_value()&quot;]</td></tr><tr><td>5</td><td>&quot;step-5&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Computations on successively r…</td><td>[&quot;PreconditionSSOR&quot;, &quot;GridIn&quot;, &quot;SphericalManifold&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>85</td><td>&quot;step-85&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Solving the Poisson equation u…</td><td>[&quot;FEInterfaceValues&quot;, &quot;NonMatching::FEImmersedSurfaceValues&quot;]</td></tr><tr><td>86</td><td>&quot;step-86&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;The heat equation, solved with…</td><td>[&quot;PETScWrappers::TimeStepper&quot;]</td></tr><tr><td>87</td><td>&quot;step-87&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Evaluation of finite element s…</td><td>[&quot;Utilities::MPI::RemotePointEvaluation&quot;, &quot;VectorTools::point_values()&quot;]</td></tr><tr><td>89</td><td>&quot;step-89&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Matrix-free operator evaluatio…</td><td>[&quot;FERemoteEvaluation&quot;]</td></tr><tr><td>90</td><td>&quot;step-90&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Solving the Laplace-Beltrami e…</td><td>[&quot;MeshWorker::mesh_loop()&quot;, &quot;NonMatching::FEImmersedSurfaceValues&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (86, 5)\n",
       "┌─────┬─────────┬───────────────────────────┬───────────────────────────┬──────────────────────────┐\n",
       "│ num ┆ name    ┆ link                      ┆ description               ┆ keywords                 │\n",
       "│ --- ┆ ---     ┆ ---                       ┆ ---                       ┆ ---                      │\n",
       "│ u8  ┆ str     ┆ str                       ┆ str                       ┆ list[str]                │\n",
       "╞═════╪═════════╪═══════════════════════════╪═══════════════════════════╪══════════════════════════╡\n",
       "│ 1   ┆ step-1  ┆ https://dealii.org/curren ┆ Creating a grid. A simple ┆ [\"Triangulation\",        │\n",
       "│     ┆         ┆ t/dox…                    ┆ way …                     ┆ \"GridGenerat…            │\n",
       "│ 2   ┆ step-2  ┆ https://dealii.org/curren ┆ Associate degrees of      ┆ [\"FE_Q\",                 │\n",
       "│     ┆         ┆ t/dox…                    ┆ freedom t…                ┆ \"DynamicSparsityPatte…   │\n",
       "│ 3   ┆ step-3  ┆ https://dealii.org/curren ┆ Actually solve Laplace's  ┆ [\"FEValues\",             │\n",
       "│     ┆         ┆ t/dox…                    ┆ probl…                    ┆ \"VectorTools::int…       │\n",
       "│ 4   ┆ step-4  ┆ https://dealii.org/curren ┆ This example is           ┆ [\"VectorTools::point_val │\n",
       "│     ┆         ┆ t/dox…                    ┆ programmed in …           ┆ ue()\",…                  │\n",
       "│ 5   ┆ step-5  ┆ https://dealii.org/curren ┆ Computations on           ┆ [\"PreconditionSSOR\",     │\n",
       "│     ┆         ┆ t/dox…                    ┆ successively r…           ┆ \"GridIn\",…               │\n",
       "│ …   ┆ …       ┆ …                         ┆ …                         ┆ …                        │\n",
       "│ 85  ┆ step-85 ┆ https://dealii.org/curren ┆ Solving the Poisson       ┆ [\"FEInterfaceValues\",    │\n",
       "│     ┆         ┆ t/dox…                    ┆ equation u…               ┆ \"NonMatc…                │\n",
       "│ 86  ┆ step-86 ┆ https://dealii.org/curren ┆ The heat equation, solved ┆ [\"PETScWrappers::TimeSte │\n",
       "│     ┆         ┆ t/dox…                    ┆ with…                     ┆ pper\"]                   │\n",
       "│ 87  ┆ step-87 ┆ https://dealii.org/curren ┆ Evaluation of finite      ┆ [\"Utilities::MPI::Remote │\n",
       "│     ┆         ┆ t/dox…                    ┆ element s…                ┆ PointE…                  │\n",
       "│ 89  ┆ step-89 ┆ https://dealii.org/curren ┆ Matrix-free operator      ┆ [\"FERemoteEvaluation\"]   │\n",
       "│     ┆         ┆ t/dox…                    ┆ evaluatio…                ┆                          │\n",
       "│ 90  ┆ step-90 ┆ https://dealii.org/curren ┆ Solving the               ┆ [\"MeshWorker::mesh_loop( │\n",
       "│     ┆         ┆ t/dox…                    ┆ Laplace-Beltrami e…       ┆ )\", \"N…                  │\n",
       "└─────┴─────────┴───────────────────────────┴───────────────────────────┴──────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tutorial:\n",
    "    name: str\n",
    "    link: str\n",
    "    description: str\n",
    "    keywords: list[str]\n",
    "\n",
    "tutorials = []\n",
    "for tr in title.find_next_sibling(\"table\").find_all(\"tr\"):\n",
    "    \n",
    "    name_td, descr_td = tr.find_all(\"td\")\n",
    "\n",
    "    link = DOC_URL + \"/\" + name_td.find(\"a\").get(\"href\")\n",
    "    name = name_td.get_text(strip=True)\n",
    "    descr_w_keywords = descr_td.get_text(strip=True).split(\"Keywords:\")\n",
    "    descr = descr_w_keywords[0].strip()\n",
    "    \n",
    "    if len(descr_w_keywords) > 1:\n",
    "        keywords = descr_w_keywords[1].strip()\n",
    "        keywords = [k.strip() for k in keywords.split(\",\")]\n",
    "    else:\n",
    "        keywords = []\n",
    "        \n",
    "    tutorials.append({\"name\": name, \"link\": link, \"description\": descr, \"keywords\": keywords})\n",
    "    \n",
    "tutorials = pl.DataFrame(tutorials).lazy() \\\n",
    "             .with_columns(pl.col(\"name\").str.split(\"-\").list.get(1).cast(pl.UInt8).alias(\"num\"))  \\\n",
    "             .select(pl.col(\"num\"), pl.all().exclude(\"num\"))  \\\n",
    "             .collect()\n",
    "print(f\"Found {len(tutorials)} deal.II tutorials.\")\n",
    "\n",
    "tutorials\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb28a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tutorials are missing on the website : 73, 80, 84, 88.\n"
     ]
    }
   ],
   "source": [
    "missing_tutorials = (\n",
    "    tutorials.lazy()\n",
    "    .select(pl.col(\"num\"), pl.col(\"num\").diff().alias(\"diff\") )\n",
    "    .filter(pl.col(\"diff\") == 2)\n",
    "    .select(pl.col(\"num\") - 1)\n",
    "        .collect()\n",
    ").to_series().to_list()\n",
    "\n",
    "print(f\"The following tutorials are missing on the website : {\", \".join(map(str, missing_tutorials))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d46d91",
   "metadata": {},
   "source": [
    "It turns out that there is a [list](https://github.com/dealii/dealii/issues/11998) of unfinished tutorial programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b437f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted code\n",
      "--------------\n",
      "\n",
      "#include <deal.II/base/conditional_ostream.h>\n",
      "#include <deal.II/base/function_lib.h>\n",
      "#include <deal.II/base/function_signed_distance.h>\n",
      "#include <deal.II/base/mpi.h>\n",
      "#include <deal.II/base/mpi.templates.h>\n",
      "...\n",
      " Utilities::MPI::MPI_InitFinalize mpi(argc, argv, 1);\n",
      "  std::cout.precision(5);\n",
      " \n",
      " if (Utilities::MPI::this_mpi_process(MPI_COMM_WORLD) == 0)\n",
      "    Step87::example_0(); // only run on root process\n",
      " \n",
      "  Step87::example_1();\n",
      "  Step87::example_2();\n",
      "  Step87::example_3();\n",
      "}\n",
      "\n",
      "Saved step-87 content to step_87.md\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "STEP_NUM = 87\n",
    "STEP_URL = f\"https://dealii.org/current/doxygen/deal.II/step_{STEP_NUM}.html\"\n",
    "r = requests.get(STEP_URL)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "content = soup.select_one(\"div.contents\")\n",
    "\n",
    "# Replace all div.fragment with pre elements\n",
    "for div in content.find_all(\"div\", class_=\"fragment\"):\n",
    "    for to_remove in div.select(\".ttc\"):\n",
    "        to_remove.decompose()\n",
    "    pre = soup.new_tag(\"pre\")\n",
    "    pre.string = div.get_text().replace(\"Â\", \" \").lstrip(\"\\n\").rstrip()\n",
    "    div.replace_with(pre)\n",
    "\n",
    "text = markdownify(str(content))\n",
    "code = content.find(\"h1\", string=CODE_TITLE).find_next_sibling(\"pre\").getText()\n",
    "\n",
    "\n",
    "# remove first c++ docstring\n",
    "file_docstring_pattern = re.compile(r\"^\\s*\\/\\*.*?\\*\\/\\s*\", re.DOTALL)\n",
    "code = file_docstring_pattern.sub(\"\", code)\n",
    "lines = code.splitlines()\n",
    "print(\"Extracted code\", \"--------------\\n\", *lines[0:5], '...', *lines[-10:], sep=\"\\n\")\n",
    "# print(str(text))\n",
    "\n",
    "# Save the text to a file\n",
    "with open(f\"step_{STEP_NUM}.md\", \"w\") as f:\n",
    "    f.write(text)\n",
    "    print(f\"\\nSaved step-{STEP_NUM} content to step_{STEP_NUM}.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71a0ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 86/86 [01:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (86, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num</th><th>name</th><th>link</th><th>description</th><th>keywords</th><th>content</th></tr><tr><td>u8</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;step-1&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Creating a grid. A simple way …</td><td>[&quot;Triangulation&quot;, &quot;GridGenerator::hyper_cube()&quot;, … &quot;Triangulation::execute_coarsening_and_refinement()&quot;]</td><td>&quot;| **Table of contents** | |\n",
       "| …</td></tr><tr><td>2</td><td>&quot;step-2&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Associate degrees of freedom t…</td><td>[&quot;FE_Q&quot;, &quot;DynamicSparsityPattern&quot;, … &quot;SparsityPattern&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>3</td><td>&quot;step-3&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Actually solve Laplace&#x27;s probl…</td><td>[&quot;FEValues&quot;, &quot;VectorTools::interpolate_boundary_values()&quot;, … &quot;DataOut&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>4</td><td>&quot;step-4&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;This example is programmed in …</td><td>[&quot;VectorTools::point_value()&quot;, &quot;VectorTools::compute_mean_value()&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>5</td><td>&quot;step-5&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Computations on successively r…</td><td>[&quot;PreconditionSSOR&quot;, &quot;GridIn&quot;, &quot;SphericalManifold&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>85</td><td>&quot;step-85&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Solving the Poisson equation u…</td><td>[&quot;FEInterfaceValues&quot;, &quot;NonMatching::FEImmersedSurfaceValues&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>86</td><td>&quot;step-86&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;The heat equation, solved with…</td><td>[&quot;PETScWrappers::TimeStepper&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>87</td><td>&quot;step-87&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Evaluation of finite element s…</td><td>[&quot;Utilities::MPI::RemotePointEvaluation&quot;, &quot;VectorTools::point_values()&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>89</td><td>&quot;step-89&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Matrix-free operator evaluatio…</td><td>[&quot;FERemoteEvaluation&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr><tr><td>90</td><td>&quot;step-90&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Solving the Laplace-Beltrami e…</td><td>[&quot;MeshWorker::mesh_loop()&quot;, &quot;NonMatching::FEImmersedSurfaceValues&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (86, 6)\n",
       "┌─────┬─────────┬────────────────────┬────────────────────┬────────────────────┬───────────────────┐\n",
       "│ num ┆ name    ┆ link               ┆ description        ┆ keywords           ┆ content           │\n",
       "│ --- ┆ ---     ┆ ---                ┆ ---                ┆ ---                ┆ ---               │\n",
       "│ u8  ┆ str     ┆ str                ┆ str                ┆ list[str]          ┆ str               │\n",
       "╞═════╪═════════╪════════════════════╪════════════════════╪════════════════════╪═══════════════════╡\n",
       "│ 1   ┆ step-1  ┆ https://dealii.org ┆ Creating a grid. A ┆ [\"Triangulation\",  ┆ | **Table of      │\n",
       "│     ┆         ┆ /current/dox…      ┆ simple way …       ┆ \"GridGenerat…      ┆ contents** | |    │\n",
       "│     ┆         ┆                    ┆                    ┆                    ┆ | …               │\n",
       "│ 2   ┆ step-2  ┆ https://dealii.org ┆ Associate degrees  ┆ [\"FE_Q\", \"DynamicS ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ of freedom t…      ┆ parsityPatte…      ┆ depends on [step… │\n",
       "│ 3   ┆ step-3  ┆ https://dealii.org ┆ Actually solve     ┆ [\"FEValues\",       ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ Laplace's probl…   ┆ \"VectorTools::int… ┆ depends on [step… │\n",
       "│ 4   ┆ step-4  ┆ https://dealii.org ┆ This example is    ┆ [\"VectorTools::poi ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ programmed in …    ┆ nt_value()\",…      ┆ depends on [step… │\n",
       "│ 5   ┆ step-5  ┆ https://dealii.org ┆ Computations on    ┆ [\"PreconditionSSOR ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ successively r…    ┆ \", \"GridIn\",…      ┆ depends on [step… │\n",
       "│ …   ┆ …       ┆ …                  ┆ …                  ┆ …                  ┆ …                 │\n",
       "│ 85  ┆ step-85 ┆ https://dealii.org ┆ Solving the        ┆ [\"FEInterfaceValue ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ Poisson equation   ┆ s\", \"NonMatc…      ┆ depends on [step… │\n",
       "│     ┆         ┆                    ┆ u…                 ┆                    ┆                   │\n",
       "│ 86  ┆ step-86 ┆ https://dealii.org ┆ The heat equation, ┆ [\"PETScWrappers::T ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ solved with…       ┆ imeStepper\"]       ┆ depends on [step… │\n",
       "│ 87  ┆ step-87 ┆ https://dealii.org ┆ Evaluation of      ┆ [\"Utilities::MPI:: ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ finite element s…  ┆ RemotePointE…      ┆ depends on [step… │\n",
       "│ 89  ┆ step-89 ┆ https://dealii.org ┆ Matrix-free        ┆ [\"FERemoteEvaluati ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ operator           ┆ on\"]               ┆ depends on [step… │\n",
       "│     ┆         ┆                    ┆ evaluatio…         ┆                    ┆                   │\n",
       "│ 90  ┆ step-90 ┆ https://dealii.org ┆ Solving the        ┆ [\"MeshWorker::mesh ┆ This tutorial     │\n",
       "│     ┆         ┆ /current/dox…      ┆ Laplace-Beltrami   ┆ _loop()\", \"N…      ┆ depends on [step… │\n",
       "│     ┆         ┆                    ┆ e…                 ┆                    ┆                   │\n",
       "└─────┴─────────┴────────────────────┴────────────────────┴────────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tutorial_content(link: str):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    content = soup.select_one(\"div.contents\")\n",
    "\n",
    "    # Replace all div.fragment with pre elements\n",
    "    for div in content.find_all(\"div\", class_=\"fragment\"):\n",
    "        for to_remove in div.select(\".ttc\"):\n",
    "            to_remove.decompose()\n",
    "        pre = soup.new_tag(\"pre\")\n",
    "        pre.string = div.get_text().replace(\"Â\", \" \").lstrip(\"\\n\").rstrip()\n",
    "        div.replace_with(pre)\n",
    "\n",
    "    text = markdownify(str(content))\n",
    "    \n",
    "    return text\n",
    "    \n",
    "with tqdm(total=len(tutorials)) as pbar:\n",
    "    def foo(link: str):\n",
    "        content = get_tutorial_content(link)\n",
    "        pbar.update(1)\n",
    "        return content\n",
    "\n",
    "    tutorials = (tutorials.lazy()\n",
    "        .with_columns(pl.col(\"link\").alias(\"content\").map_elements(foo, return_dtype=pl.String))\n",
    "    ).collect()\n",
    "tutorials.write_parquet(\"tutorials.parquet\")\n",
    "tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0932eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tutorial depends on [step-1](step_1.html).\n",
      "\n",
      "| **Table of contents** | |\n",
      "| --- | --- |\n",
      "| 1. [Introduction](#step_2-Intro)    * [Enumerating degrees of freedom](#step_2-Enumeratingdegreesoffreedom) * [Sparsity](#step_2-Sparsity) * [How degrees of freedom are enumerated](#step_2-Howdegreesoffreedomareenumerated)- [The commented program](#step_2-CommProg)      * [Mesh generation](#step_2-Meshgeneration)* [Outputting the location of degrees of freedom](#step_2-Outputtingthelocationofdegreesoffreedom)* [Creation of a DoFHandler](#step_2-CreationofaDoFHandler)* [Renumbering of DoFs](#step_2-RenumberingofDoFs)* [The main function](#step_2-Themainfunction) | 1. [Results](#step_2-Results)    * [Possibilities for extensions](#step_2-Possibilitiesforextensions)- [The plain program](#step_2-PlainProg) |\n",
      "\n",
      "Introduction\n",
      "============\n",
      "\n",
      "Note\n",
      ":   The material presented here is also discussed in [video lecture 9](https://www.math.colostate.edu/~bangerth/videos.676.9.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\n",
      "\n",
      "The finite element method is based on approximating the solution \\(u\\) of a differential equation such as \\(-\\Delta u=f\\) by a function \\(u\\_h\\) that is \"piecewise\" polynomial; that is, we subdivide the domain \\(\\Omega\\) on which the equation is posed into small cells that in the documentation we will generally denote by the symbol \\(K\\). On each cell \\(K\\), the approximating function \\(u\\_h\\) we seek is then a polynomial. (Or, strictly speaking, a function that is the image of a polynomial from a \"reference cell\", but let us not make things more complicated than necessary for now.)\n",
      "\n",
      "In the previous tutorial program (in [step-1](step_1.html)), we showed how we should think of the subdivision of the domain into cells as a \"mesh\" represented by the [Triangulation](classTriangulation.html) class, and how this looks like in code. In the current tutorial program, we now show how one represents piecewise polynomial functions through the concept of degrees of freedom defined on this mesh. For this example, we will use the lowest order ( \\(Q\\_1\\)) finite elements, that is the approximating function \\(u\\_h\\) we are looking for will be \"bi-linear\" on each quadrilateral cell \\(K\\) of the mesh. (They would be linear if we would work on triangles.)\n",
      "\n",
      "In practice, we represent the function as a linear combination of shape functions \\(\\varphi\\_j(\\mathbf x)\\) with multipliers \\(U\\_j\\) that we call the \"degrees of freedom\". For the bi-linear functions we consider here, each of these shape functions and degrees of freedom is associated with a vertex of the mesh. Later examples will demonstrate higher order elements where degrees of freedom are not necessarily associated with vertices any more, but can be associated with edges, faces, or cells.\n",
      "\n",
      "The term \"degree of freedom\" is commonly used in the finite element community to indicate two slightly different, but related things. The first is that we'd like to represent the finite element solution as a linear combination of shape functions, in the form \\(u\\_h(\\mathbf x) = \\sum\\_{j=0}^{N-1} U\\_j \\varphi\\_j(\\mathbf\n",
      "x)\\). Here, \\(U\\_j\\) is a vector of expansion coefficients. Because we don't know their values yet (we will compute them as the solution of a linear or nonlinear system), they are called \"unknowns\" or \"degrees of freedom\". The second meaning of the term can be explained as follows: A mathematical description of finite element problems is often to say that we are looking for a finite dimensional function \\(u\\_h \\in V\\_h\\) that satisfies some set of equations (e.g. \\(a(u\\_h,\\varphi\\_h)=(f,\\varphi\\_h)\\) for all test functions \\(\\varphi\\_h\\in\n",
      "V\\_h\\)). In other words, all we say here is that the solution needs to lie in some space \\(V\\_h\\). However, to actually solve this problem on a computer we need to choose a basis of this space; this is the set of shape functions \\(\\varphi\\_j(\\mathbf x)\\) we have used above in the expansion of \\(u\\_h(\\mathbf x)\\) with coefficients \\(U\\_j\\). There are of course many bases of the space \\(V\\_h\\), but we will specifically choose the one that is described by the finite element functions that are traditionally defined locally on the cells of the mesh.\n",
      "\n",
      "### Enumerating degrees of freedom\n",
      "\n",
      "Describing \"degrees of freedom\" in this context requires us to simply *enumerate* the basis functions of the space \\(V\\_h\\). For \\(Q\\_1\\) elements this means simply enumerating the vertices of the mesh in some way, but for higher order elements, one also has to enumerate the shape functions that are associated with edges, faces, or cell interiors of the mesh. In other words, the enumeration of degrees of freedom is an entirely separate thing from the indices we use for vertices. The class that provides this enumeration of the basis functions of \\(V\\_h\\) is called [DoFHandler](classDoFHandler.html).\n",
      "\n",
      "Defining degrees of freedom (\"DoF\"s in short) on a mesh is, in practice, a rather simple task, since the library does all the work for you. Essentially, all you have to do is create a finite element object (from one of the many finite element classes deal.II already has, see for example the [Finite element space descriptions](group__fe.html) documentation) and give it to a [DoFHandler](classDoFHandler.html) object through the [DoFHandler::distribute\\_dofs()](classDoFHandler.html#a553ca864aaf70330d9be86bc78f36d1e) function (\"distributing DoFs\" is the term we use to describe the process of *enumerating* the basis functions as discussed above). The [DoFHandler](classDoFHandler.html) is a class that knows which degrees of freedom live where, i.e., it can answer questions like \"how many degrees of freedom are there globally\" and \"on this cell, give me the global indices of the shape functions that\n",
      "live here\". This is the sort of information you need when determining how big your system matrix should be, and when copying the contributions of a single cell into the global matrix.\n",
      "\n",
      "The first task of the current program is therefore to take a mesh and a finite element, and enumerate the degrees of freedom. In the current context, this means simply giving each vertex of the mesh a DoF index. Once that has happened, we will output in a picture which vertex ended up with which DoF index. You can find the corresponding pictures in the [results section](#Results) of this tutorial.\n",
      "\n",
      "It is probably worth pointing out that where each DoF is geometrically located is not a question we typically ask in finite element codes. Most often, we only care about the fact that there *is* an enumeration of all degrees of freedom, but not which DoF is where. (We will also come back to this below where we talk about renumbering degrees of freedom.) At the same time, it is probably instructive to see this once, and so this program shows such a figure.\n",
      "\n",
      "### Sparsity\n",
      "\n",
      "The next step would then be to compute a matrix and right hand side corresponding to a particular differential equation using this finite element and mesh. We will keep this step for the [step-3](step_3.html) program and rather talk about one practical aspect of a finite element program, namely that finite element matrices are always very sparse: almost all entries in these matrices are zero.\n",
      "\n",
      "To be more precise, we say that a matrix is sparse if the number of nonzero entries *per row* in the matrix is bounded by a number that is independent of the overall number of degrees of freedom. For example, the simple 5-point stencil of a finite difference approximation of the Laplace equation leads to a sparse matrix since the number of nonzero entries per row is five, and therefore independent of the total size of the matrix. For more complicated problems – say, the Stokes problem of [step-22](step_22.html) – and in particular in 3d, the number of entries per row may be several hundred. But the important point is that this number is independent of the overall size of the problem: If you refine the mesh, the maximal number of unknowns per row remains the same.\n",
      "\n",
      "Sparsity is one of the distinguishing features of the finite element method compared to, say, approximating the solution of a partial differential equation using a Taylor expansion and matching coefficients, or using a Fourier basis.\n",
      "\n",
      "In practical terms, it is the sparsity of matrices that enables us to solve problems with millions or billions of unknowns. To understand this, note that a matrix with \\(N\\) rows, each with a fixed upper bound for the number of nonzero entries, requires \\({\\cal O}(N)\\) memory locations for storage, and a matrix-vector multiplication also requires only \\({\\cal O}(N)\\) operations. Consequently, if we had a linear solver that requires only a fixed number of matrix-vector multiplications to come up with the solution of a linear system with this matrix, then we would have a solver that can find the values of all \\(N\\) unknowns with optimal complexity, i.e., with a total of \\({\\cal O}(N)\\) operations. It is clear that this wouldn't be possible if the matrix were not sparse (because then the number of entries in the matrix would have to be \\({\\cal O}(N^s)\\) with some \\(s>1\\), and doing a fixed number of matrix-vector products would take \\({\\cal O}(N^s)\\) operations), but it also requires very specialized solvers such as multigrid methods to satisfy the requirement that the solution requires only a fixed number of matrix-vector multiplications. We will frequently look at the question of what solver to use in the remaining programs of this tutorial.\n",
      "\n",
      "The sparsity is generated by the fact that finite element shape functions are defined *locally* on individual cells, rather than globally, and that the local differential operators in the bilinear form only couple shape functions whose support overlaps. (The \"support\" of a function is the area where it is nonzero. For the finite element method, the support of a shape function is generally the cells adjacent to the vertex, edge, or face it is defined on.) In other words, degrees of freedom \\(i\\) and \\(j\\) that are not defined on the same cell do not overlap, and consequently the matrix entry \\(A\\_{ij}\\) will be zero. (In some cases such as the Discontinuous Galerkin method, shape functions may also connect to neighboring cells through face integrals. But finite element methods do not generally couple shape functions beyond the immediate neighbors of a cell on which the function is defined.)\n",
      "\n",
      "### How degrees of freedom are enumerated\n",
      "\n",
      "By default, the [DoFHandler](classDoFHandler.html) class enumerates degrees of freedom on a mesh using an algorithm that is difficult to describe and leads to results that do look right if you know what it is doing but otherwise appears rather random; consequently, the sparsity pattern is also not optimized for any particular purpose. To show this, the code below will demonstrate a simple way to output the \"sparsity pattern\" that corresponds to a [DoFHandler](classDoFHandler.html), i.e., an object that represents all of the potentially nonzero elements of a matrix one may build when discretizing a partial differential equation on a mesh and its [DoFHandler](classDoFHandler.html). This lack of structure in the sparsity pattern will be apparent from the pictures we show below.\n",
      "\n",
      "For most applications and algorithms, the exact way in which degrees of freedom are numbered does not matter. For example, the Conjugate Gradient method we use to solve linear systems does not care. On the other hand, some algorithms do care: in particular, some preconditioners such as SSOR will work better if they can walk through degrees of freedom in a particular order, and it would be nice if we could just sort them in such a way that SSOR can iterate through them from zero to \\(N\\) in this order. Other examples include computing incomplete LU or Cholesky factorizations, or if we care about the block structure of matrices (see [step-20](step_20.html) for an example). deal.II therefore has algorithms that can re-enumerate degrees of freedom in particular ways in namespace [DoFRenumbering](namespaceDoFRenumbering.html). Renumbering can be thought of as choosing a different, permuted basis of the finite element space. The sparsity pattern and matrices that result from this renumbering are therefore also simply a permutation of rows and columns compared to the ones we would get without explicit renumbering.\n",
      "\n",
      "In the program below, we will use the algorithm of Cuthill and McKee to do so. We will show the sparsity pattern for both the original enumeration of degrees of freedom and of the renumbered version below, in the [results section](#Results).\n",
      "\n",
      "The commented program\n",
      "=====================\n",
      "\n",
      "The first few includes are just like in the previous program, so do not require additional comments:\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/grid/tria.h>\n",
      "Â  #include <deal.II/grid/grid_generator.h>\n",
      "Â  #include <deal.II/grid/grid_out.h>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "However, the next file is new. We need this include file for the association of degrees of freedom (\"DoF\"s) to vertices, lines, and cells:\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/dofs/dof_handler.h>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "The following include contains the description of the bilinear finite element, including the facts that it has one degree of freedom on each vertex of the triangulation, but none on faces and none in the interior of the cells.\n",
      "\n",
      "(In fact, the file contains the description of Lagrange elements in general, i.e. also the quadratic, cubic, etc versions, and not only for 2d but also 1d and 3d.)\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/fe/fe_q.h>\n",
      "\n",
      "```\n",
      "\n",
      "In the following file, several tools for manipulating degrees of freedom can be found, and the one after it is necessary to call one of the functions imported from `dof_tools.h`:\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/dofs/dof_tools.h>\n",
      "Â  #include <deal.II/fe/mapping_q1.h>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "We will use a sparse matrix to visualize the pattern of nonzero entries resulting from the distribution of degrees of freedom on the grid. That class can be found here:\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/lac/sparse_matrix.h>\n",
      "\n",
      "```\n",
      "\n",
      "We will also need to use an intermediate sparsity pattern structure, which is found in this file :\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/lac/dynamic_sparsity_pattern.h>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "We will want to use a special algorithm to renumber degrees of freedom. It is declared here:\n",
      "\n",
      "```\n",
      "Â  #include <deal.II/dofs/dof_renumbering.h>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "And this is again needed for C++ output:\n",
      "\n",
      "```\n",
      "Â  #include <fstream>\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "Finally, as in [step-1](step_1.html), we import the deal.II namespace into the global scope:\n",
      "\n",
      "```\n",
      "Â  using namespace dealii;\n",
      "Â  \n",
      "Â  \n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "### Mesh generation\n",
      "\n",
      "This is the function that produced the circular grid in the previous [step-1](step_1.html) example program with fewer refinements steps. The sole difference is that it returns the grid it produces via its argument.\n",
      "\n",
      "At the end of the function, we also output this mesh into a file. We will use this as one piece of information when visualizing the location of degrees of freedom. To output a mesh, we use the [GridOut](classGridOut.html) class that you have already seen in [step-1](step_1.html); the difference is only that we use gnuplot rather than SVG format, because gnuplot is the program we will use to visualize DoF locations.\n",
      "\n",
      "```\n",
      "Â  void make_grid(Triangulation<2> &triangulation)\n",
      "Â  {\n",
      "Â    const Point<2> center(1, 0);\n",
      "Â    const double   inner_radius = 0.5, outer_radius = 1.0;\n",
      "Â    GridGenerator::hyper_shell(\n",
      "Â      triangulation, center, inner_radius, outer_radius, 5);\n",
      "Â  \n",
      "Â    for (unsigned int step = 0; step < 3; ++step)\n",
      "Â      {\n",
      "Â        for (const auto &cell : triangulation.active_cell_iterators())\n",
      "Â          for (const auto v : cell->vertex_indices())\n",
      "Â            {\n",
      "Â              const double distance_from_center =\n",
      "Â                center.distance(cell->vertex(v));\n",
      "Â  \n",
      "Â              if (std::fabs(distance_from_center - inner_radius) <=\n",
      "Â                  1e-6 * inner_radius)\n",
      "Â                {\n",
      "Â                  cell->set_refine_flag();\n",
      "Â                  break;\n",
      "Â                }\n",
      "Â            }\n",
      "Â  \n",
      "Â        triangulation.execute_coarsening_and_refinement();\n",
      "Â      }\n",
      "Â  \n",
      "Â    std::ofstream mesh_file(\"mesh.gnuplot\");\n",
      "Â    GridOut().write_gnuplot(triangulation, mesh_file);\n",
      "Â  }\n",
      "Â  \n",
      "Â  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "### Outputting the location of degrees of freedom\n",
      "\n",
      "The next function outputs the locations of degrees of freedom for later visualization. Where each DoF is located is something the [DoFHandler](classDoFHandler.html) object knows, so that is one of the arguments to this function. Since we want to do all of this twice (once for the original enumeration and once for the renumbered set of degrees of freedom), the function also takes as a second argument the name of the file into which we want the output to be written.\n",
      "\n",
      "In order to learn deal.II, it is probably not terribly important to understand exactly what this function does, and you can skip over it. But if you would like to know anyway: We want to call the function [DoFTools::map\\_dofs\\_to\\_support\\_points()](namespaceDoFTools.html#a621c66a6f7e56cb56faac0e64014ece8) that returns a list of locations. It does so in the form of a map through which we can query (in a statement such as `dof_location_map[42]`) where the DoF is located (in the example, where the 42nd DoF is). It puts this information into the `dof_location_map` object.\n",
      "\n",
      "We then use the function [DoFTools::write\\_gnuplot\\_dof\\_support\\_point\\_info()](namespaceDoFTools.html#a69d19d6d574269cc6e69fa5c5b2d89e2) to write this information into a file in a format that is understandable to the gnuplot program that we will use for visualization in the results section.\n",
      "\n",
      "```\n",
      "Â  void write_dof_locations(const DoFHandler<2> &dof_handler,\n",
      "Â                           const std::string   &filename)\n",
      "Â  {\n",
      "Â    const std::map<types::global_dof_index, Point<2>> dof_location_map =\n",
      "Â      DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\n",
      "Â  \n",
      "Â    std::ofstream dof_location_file(filename);\n",
      "Â    DoFTools::write_gnuplot_dof_support_point_info(dof_location_file,\n",
      "Â                                                   dof_location_map);\n",
      "Â  }\n",
      "Â  \n",
      "Â  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "### Creation of a [DoFHandler](classDoFHandler.html)\n",
      "\n",
      "Up to now, we only have a grid, i.e. some geometrical (the position of the vertices) and some topological information (how vertices are connected to lines, and lines to cells, as well as which cells neighbor which other cells). To use numerical algorithms, one needs some logic information in addition to that: we would like to associate degree of freedom numbers to each vertex (or line, or cell, in case we were using higher order elements) to later generate matrices and vectors which describe a finite element field on the triangulation.\n",
      "\n",
      "This function shows how to do this. The object to consider is the `DoFHandler` class template. Before we do so, however, we first need something that describes how many degrees of freedom are to be associated to each of these objects. Since this is one aspect of the definition of a finite element space, the finite element base class stores this information. In the present context, we therefore create an object of the derived class `FE_Q` that describes Lagrange elements. Its constructor takes one argument that states the polynomial degree of the element, which here is one (indicating a bi-linear element); this then corresponds to one degree of freedom for each vertex, while there are none on lines and inside the quadrilateral. A value of, say, three given to the constructor would instead give us a bi-cubic element with one degree of freedom per vertex, two per line, and four inside the cell. In general, `FE_Q` denotes the family of continuous elements with complete polynomials (i.e. tensor-product polynomials) up to the specified order.\n",
      "\n",
      "We first need to create an object of this class and then pass it on to the `DoFHandler` object to allocate storage for the degrees of freedom (in deal.II lingo: we *distribute degrees of freedom*).\n",
      "\n",
      "```\n",
      "Â  void distribute_dofs(DoFHandler<2> &dof_handler)\n",
      "Â  {\n",
      "Â    const FE_Q<2> finite_element(1);\n",
      "Â    dof_handler.distribute_dofs(finite_element);\n",
      "Â  \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "Now that we have associated a degree of freedom with a global number to each vertex, Let us output this information using the function above:\n",
      "\n",
      "```\n",
      "Â    write_dof_locations(dof_handler, \"dof-locations-1.gnuplot\");\n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "In practice, we do not often care about where a degree of freedom is geometrically located, and so other than seeing it once via the call above is not practically useful. But where two degrees of freedom are in relation to each other matters in other ways.\n",
      "\n",
      "Associated with each vertex of the triangulation is a shape function. Assume we want to solve something like Laplace's equation, then the different matrix entries will be the integrals over the gradient of each pair of such shape functions. Obviously, since the shape functions are nonzero only on the cells adjacent to the vertex they are associated with, matrix entries will be nonzero only if the supports of the shape functions associated to that column and row numbers intersect. This is only the case for adjacent shape functions, and therefore only for adjacent vertices. Now, since the vertices are numbered more or less randomly by the above function ([DoFHandler::distribute\\_dofs](classDoFHandler.html#a553ca864aaf70330d9be86bc78f36d1e)), the pattern of nonzero entries in the matrix will be somewhat ragged, and we will take a look at it now.\n",
      "\n",
      "First we have to create a structure which we use to store the places of nonzero elements. This can then later be used by one or more sparse matrix objects that store the values of the entries in the locations stored by this sparsity pattern. The class that stores the locations is the [SparsityPattern](classSparsityPattern.html) class. As it turns out, however, this class has some drawbacks when we try to fill it right away: its data structures are set up in such a way that we need to have an estimate for the maximal number of entries we may wish to have in each row. In two space dimensions, reasonable values for this estimate are available through the [DoFHandler::max\\_couplings\\_between\\_dofs()](classDoFHandler.html#a198c25ff9747d228eb9afa998e716f18) function, but in three dimensions the function almost always severely overestimates the true number, leading to a lot of wasted memory, sometimes too much for the machine used, even if the unused memory can be released immediately after computing the sparsity pattern. In order to avoid this, we use an intermediate object of type [DynamicSparsityPattern](classDynamicSparsityPattern.html) that uses a different internal data structure and that we can later copy into the [SparsityPattern](classSparsityPattern.html) object without much overhead. (Some more information on these data structures can be found in the [Sparsity patterns](group__Sparsity.html) topic.) In order to initialize this intermediate data structure, we have to give it the size of the matrix, which in our case will be square with as many rows and columns as there are degrees of freedom on the grid:\n",
      "\n",
      "```\n",
      "Â    DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\n",
      "Â                                                    dof_handler.n_dofs());\n",
      "Â  \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "We then fill this object with the places where nonzero elements will be located given the present numbering of degrees of freedom:\n",
      "\n",
      "```\n",
      "Â    DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      "Â  \n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "Now we are ready to create the actual sparsity pattern that we could later use for our matrix. It will just contain the data already assembled in the [DynamicSparsityPattern](classDynamicSparsityPattern.html).\n",
      "\n",
      "```\n",
      "Â    SparsityPattern sparsity_pattern;\n",
      "Â    sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      "Â  \n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "With this, we can now write the results to a file :\n",
      "\n",
      "```\n",
      "Â    std::ofstream out(\"sparsity-pattern-1.svg\");\n",
      "Â    sparsity_pattern.print_svg(out);\n",
      "\n",
      "```\n",
      "\n",
      "The result is stored in an `.svg` file, where each nonzero entry in the matrix corresponds with a red square in the image. The output will be shown below.\n",
      "\n",
      "If you look at it, you will note that the sparsity pattern is symmetric. This should not come as a surprise, since we have not given the `DoFTools::make_sparsity_pattern` any information that would indicate that our bilinear form may couple shape functions in a non-symmetric way. You will also note that it has several distinct region, which stem from the fact that the numbering starts from the coarsest cells and moves on to the finer ones; since they are all distributed symmetrically around the origin, this shows up again in the sparsity pattern.\n",
      "\n",
      "```\n",
      "Â  }\n",
      "Â  \n",
      "Â  \n",
      "\n",
      "```\n",
      "\n",
      "### Renumbering of DoFs\n",
      "\n",
      "In the sparsity pattern produced above, the nonzero entries extended quite far off from the diagonal. For some algorithms, for example for incomplete LU decompositions or Gauss-Seidel preconditioners, this is unfavorable, and we will show a simple way how to improve this situation.\n",
      "\n",
      "Remember that for an entry \\((i,j)\\) in the matrix to be nonzero, the supports of the shape functions i and j needed to intersect (otherwise in the integral, the integrand would be zero everywhere since either the one or the other shape function is zero at some point). However, the supports of shape functions intersected only if they were adjacent to each other, so in order to have the nonzero entries clustered around the diagonal (where \\(i\\) equals \\(j\\)), we would like to have adjacent shape functions to be numbered with indices (DoF numbers) that differ not too much.\n",
      "\n",
      "This can be accomplished by a simple front marching algorithm, where one starts at a given vertex and gives it the index zero. Then, its neighbors are numbered successively, making their indices close to the original one. Then, their neighbors, if not yet numbered, are numbered, and so on.\n",
      "\n",
      "One algorithm that adds a little bit of sophistication along these lines is the one by Cuthill and McKee. We will use it in the following function to renumber the degrees of freedom such that the resulting sparsity pattern is more localized around the diagonal. The only interesting part of the function is the first call to `DoFRenumbering::Cuthill_McKee`, the rest is essentially as before:\n",
      "\n",
      "```\n",
      "Â  void renumber_dofs(DoFHandler<2> &dof_handler)\n",
      "Â  {\n",
      "Â    DoFRenumbering::Cuthill_McKee(dof_handler);\n",
      "Â  \n",
      "Â    write_dof_locations(dof_handler, \"dof-locations-2.gnuplot\");\n",
      "Â  \n",
      "Â  \n",
      "Â    DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\n",
      "Â                                                    dof_handler.n_dofs());\n",
      "Â    DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      "Â  \n",
      "Â    SparsityPattern sparsity_pattern;\n",
      "Â    sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      "Â  \n",
      "Â    std::ofstream out(\"sparsity-pattern-2.svg\");\n",
      "Â    sparsity_pattern.print_svg(out);\n",
      "Â  }\n",
      "Â  \n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "Again, the output is shown below. Note that the nonzero entries are clustered far better around the diagonal than before. This effect is even more distinguished for larger matrices (the present one has 1260 rows and columns, but large matrices often have several 100,000s).\n",
      "\n",
      "It is worth noting that the `DoFRenumbering` class offers a number of other algorithms as well to renumber degrees of freedom. For example, it would of course be ideal if all couplings were in the lower or upper triangular part of a matrix, since then solving the linear system would amount to only forward or backward substitution. This is of course unachievable for symmetric sparsity patterns, but in some special situations involving transport equations, this is possible by enumerating degrees of freedom from the inflow boundary along streamlines to the outflow boundary. Not surprisingly, `DoFRenumbering` also has algorithms for this.\n",
      "\n",
      "### The main function\n",
      "\n",
      "Finally, this is the main program. The only thing it does is to allocate and create the triangulation, then create a `DoFHandler` object and associate it to the triangulation, and finally call above two functions on it:\n",
      "\n",
      "```\n",
      "Â  int main()\n",
      "Â  {\n",
      "Â    Triangulation<2> triangulation;\n",
      "Â    make_grid(triangulation);\n",
      "Â  \n",
      "Â    DoFHandler<2> dof_handler(triangulation);\n",
      "Â  \n",
      "Â    distribute_dofs(dof_handler);\n",
      "Â    renumber_dofs(dof_handler);\n",
      "Â  }\n",
      "\n",
      "```\n",
      "\n",
      "Results\n",
      "=======\n",
      "\n",
      "The program has, after having been run, produced two files of DoF locations and sparsity patterns each (once for the original numbering and once after renumbering), along with one mesh file.\n",
      "\n",
      "Let us start with the DoF locations. There is no particularly convenient program to visualize this kind of information, but we can resort to [GNUPLOT](http://www.gnuplot.info/) (one of the simpler visualization programs; maybe not the easiest to use since it is command line driven, but also universally available on all Linux and other Unix-like systems). The command that produces the following pictures reads as follows:\n",
      "\n",
      "```\n",
      "plot [-0.1:2.1][-1.1:1.1] \"mesh.gnuplot\" with lines, \"dof-locations-1.gnuplot\" using 1:2:3 with labels point offset .3,.2 font \"4,6\"\n",
      "\n",
      "```\n",
      "\n",
      "This may be cryptic, but what exactly this does is also not particularly important and you shouldn't spend too much time understanding what it does. Rather, the important part is to look at what we get as output:\n",
      "\n",
      "|  |  |\n",
      "| --- | --- |\n",
      "|  |  |\n",
      "\n",
      "What these figures show is (i) a numeric label attached to each vertex – the DoF index, and (ii) that the original enumeration on the left differs from the renumbered one on the right. Which of the two is \"better\" is of course a different question (with the answer depending on what we want to do with these degrees of freedom); the important point is that for the same mesh, one can come up with many different enumerations of the degrees of freedom.\n",
      "\n",
      "As for the sparsity patterns, we can visualize these by opening the `.svg` files in a web browser. The pictures below represent the matrix, and every red square denotes an entry which might be nonzero. (Whether the entry actually is zero or not depends on the equation under consideration, but the indicated positions in the matrix tell us which shape functions can and which can't couple when discretizing a local, i.e. differential, equation.)\n",
      "\n",
      "|  |  |\n",
      "| --- | --- |\n",
      "|  |  |\n",
      "\n",
      "The different regions in the left picture, indicated by kinks in the lines and single dots on the left and top, represent the degrees of freedom on the different refinement levels of the triangulation. As can be seen in the right picture, the sparsity pattern is much better clustered around the main diagonal of the matrix after renumbering. Although this might not be apparent, the number of nonzero entries is the same in both pictures, of course.\n",
      "\n",
      "### Possibilities for extensions\n",
      "\n",
      "Just as with [step-1](step_1.html), you may want to play with the program a bit to familiarize yourself with deal.II. For example, in the `distribute_dofs` function, we use linear finite elements (that's what the argument \"1\" to the [FE\\_Q](classFE__Q.html) object is). Explore how the sparsity pattern changes if you use higher order elements, for example cubic or quintic ones (by using 3 and 5 as the respective arguments). You might also want to see where DoFs are now located – but for that you likely want to work with a mesh with fewer cells because DoFs are now also located on edges and in the interior of cells.\n",
      "\n",
      "You could also explore how the sparsity pattern changes by refining the mesh. You will see that not only the size of the matrix changes, but also its bandwidth (the distance from the diagonal of those nonzero elements of the matrix that are farthest away from the diagonal), though the ratio of bandwidth to size typically shrinks, i.e. the matrix clusters more around the diagonal.\n",
      "\n",
      "Another idea of experiments would be to try other renumbering strategies than Cuthill-McKee from the [DoFRenumbering](namespaceDoFRenumbering.html) namespace and see how they affect the sparsity pattern.\n",
      "\n",
      "You can also visualize the output using [GNUPLOT](http://www.gnuplot.info/) (which we have already used above) by changing from `print_svg()` to `print_gnuplot()` in `distribute_dofs()` and `renumber_dofs()` (and using the file ending `.gnuplot` instead of `.svg`):\n",
      "\n",
      "```\n",
      "examples/step-2> gnuplot\n",
      " \n",
      "        G N U P L O T\n",
      "        Version 3.7 patchlevel 3\n",
      "        last modified Thu Dec 12 13:00:00 GMT 2002\n",
      "        System: Linux 2.6.11.4-21.10-default\n",
      " \n",
      "        Copyright(C) 1986 - 1993, 1998 - 2002\n",
      "        Thomas Williams, Colin Kelley and many others\n",
      " \n",
      "        Type `help` to access the on-line reference manual\n",
      "        The gnuplot FAQ is available from\n",
      "        http://www.gnuplot.info/gnuplot-faq.html\n",
      " \n",
      "        Send comments and requests for help to <info-gnuplot@dartmouth.edu>\n",
      "        Send bugs, suggestions and mods to <bug-gnuplot@dartmouth.edu>\n",
      " \n",
      " \n",
      "Terminal type set to 'x11'\n",
      "gnuplot> set style data points\n",
      "gnuplot> plot \"sparsity-pattern-1.gnuplot\"\n",
      "\n",
      "```\n",
      "\n",
      "The plain program\n",
      "=================\n",
      "\n",
      "```\n",
      "/* ------------------------------------------------------------------------\n",
      " *\n",
      " * SPDX-License-Identifier: LGPL-2.1-or-later\n",
      " * Copyright (C) 1999 - 2024 by the deal.II authors\n",
      " *\n",
      " * This file is part of the deal.II library.\n",
      " *\n",
      " * Part of the source code is dual licensed under Apache-2.0 WITH\n",
      " * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\n",
      " * governing the source code and code contributions can be found in\n",
      " * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\n",
      " *\n",
      " * ------------------------------------------------------------------------\n",
      " */\n",
      " \n",
      " \n",
      "#include <deal.II/grid/tria.h>\n",
      "#include <deal.II/grid/grid_generator.h>\n",
      "#include <deal.II/grid/grid_out.h>\n",
      " \n",
      "#include <deal.II/dofs/dof_handler.h>\n",
      " \n",
      "#include <deal.II/fe/fe_q.h>\n",
      "#include <deal.II/dofs/dof_tools.h>\n",
      "#include <deal.II/fe/mapping_q1.h>\n",
      " \n",
      "#include <deal.II/lac/sparse_matrix.h>\n",
      "#include <deal.II/lac/dynamic_sparsity_pattern.h>\n",
      " \n",
      "#include <deal.II/dofs/dof_renumbering.h>\n",
      " \n",
      "#include <fstream>\n",
      " \n",
      "using namespace dealii;\n",
      " \n",
      " \n",
      " \n",
      "void make_grid(Triangulation<2> &triangulation)\n",
      "{\n",
      " const Point<2> center(1, 0);\n",
      " const double   inner_radius = 0.5, outer_radius = 1.0;\n",
      " GridGenerator::hyper_shell(\n",
      " triangulation, center, inner_radius, outer_radius, 5);\n",
      " \n",
      " for (unsigned int step = 0; step < 3; ++step)\n",
      "    {\n",
      " for (const auto &cell : triangulation.active_cell_iterators())\n",
      "        for (const auto v : cell->vertex_indices())\n",
      "          {\n",
      " const double distance_from_center =\n",
      " center.distance(cell->vertex(v));\n",
      " \n",
      " if (std::fabs(distance_from_center - inner_radius) <=\n",
      "                1e-6 * inner_radius)\n",
      "              {\n",
      "                cell->set_refine_flag();\n",
      " break;\n",
      "              }\n",
      "          }\n",
      " \n",
      " triangulation.execute_coarsening_and_refinement();\n",
      "    }\n",
      " \n",
      "  std::ofstream mesh_file(\"mesh.gnuplot\");\n",
      " GridOut().write_gnuplot(triangulation, mesh_file);\n",
      "}\n",
      " \n",
      " \n",
      " \n",
      "void write_dof_locations(const DoFHandler<2> &dof_handler,\n",
      " const std::string   &filename)\n",
      "{\n",
      " const std::map<types::global_dof_index, Point<2>> dof_location_map =\n",
      " DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\n",
      " \n",
      "  std::ofstream dof_location_file(filename);\n",
      " DoFTools::write_gnuplot_dof_support_point_info(dof_location_file,\n",
      "                                                 dof_location_map);\n",
      "}\n",
      " \n",
      " \n",
      " \n",
      "void distribute_dofs(DoFHandler<2> &dof_handler)\n",
      "{\n",
      " const FE_Q<2> finite_element(1);\n",
      "  dof_handler.distribute_dofs(finite_element);\n",
      " \n",
      "  write_dof_locations(dof_handler, \"dof-locations-1.gnuplot\");\n",
      " \n",
      " DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\n",
      "                                                  dof_handler.n_dofs());\n",
      " \n",
      " DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      " \n",
      " SparsityPattern sparsity_pattern;\n",
      "  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      " \n",
      "  std::ofstream out(\"sparsity-pattern-1.svg\");\n",
      "  sparsity_pattern.print_svg(out);\n",
      "}\n",
      " \n",
      " \n",
      " \n",
      "void renumber_dofs(DoFHandler<2> &dof_handler)\n",
      "{\n",
      " DoFRenumbering::Cuthill_McKee(dof_handler);\n",
      " \n",
      "  write_dof_locations(dof_handler, \"dof-locations-2.gnuplot\");\n",
      " \n",
      " \n",
      " DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\n",
      "                                                  dof_handler.n_dofs());\n",
      " DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      " \n",
      " SparsityPattern sparsity_pattern;\n",
      "  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      " \n",
      "  std::ofstream out(\"sparsity-pattern-2.svg\");\n",
      "  sparsity_pattern.print_svg(out);\n",
      "}\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "int main()\n",
      "{\n",
      " Triangulation<2> triangulation;\n",
      "  make_grid(triangulation);\n",
      " \n",
      " DoFHandler<2> dof_handler(triangulation);\n",
      " \n",
      "  distribute_dofs(dof_handler);\n",
      "  renumber_dofs(dof_handler);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "tutorial_content = tutorials[1, \"content\"]\n",
    "print(tutorial_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6da4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_key = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "404561fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=oai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb8f2604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"prompt\": \"Enumerate the degrees of freedom for a finite element approximation of the Laplace equation on a 2D circular domain using lowest order (Q1) elements, visualize the sparsity pattern of the resulting system matrix, and improve the sparsity pattern by renumbering the degrees of freedom using the Cuthill-McKee algorithm.\",\n",
      "  \"completion\": \"#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n\\n#include <deal.II/dofs/dof_handler.h>\\n\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/mapping_q1.h>\\n\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n\\n#include <deal.II/dofs/dof_renumbering.h>\\n\\n#include <fstream>\\n\\nusing namespace dealii;\\n\\nvoid make_grid(Triangulation<2> &triangulation)\\n{\\n  const Point<2> center(1, 0);\\n  const double inner_radius = 0.5, outer_radius = 1.0;\\n  GridGenerator::hyper_shell(triangulation, center, inner_radius, outer_radius, 5);\\n\\n  for (unsigned int step = 0; step < 3; ++step)\\n  {\\n    for (const auto &cell : triangulation.active_cell_iterators())\\n      for (const auto v : cell->vertex_indices())\\n      {\\n        const double distance_from_center = center.distance(cell->vertex(v));\\n        if (std::fabs(distance_from_center - inner_radius) <= 1e-6 * inner_radius)\\n        {\\n          cell->set_refine_flag();\\n          break;\\n        }\\n      }\\n    triangulation.execute_coarsening_and_refinement();\\n  }\\n\\n  std::ofstream mesh_file(\\\"mesh.gnuplot\\\");\\n  GridOut().write_gnuplot(triangulation, mesh_file);\\n}\\n\\nvoid write_dof_locations(const DoFHandler<2> &dof_handler, const std::string &filename)\\n{\\n  const std::map<types::global_dof_index, Point<2>> dof_location_map =\\n    DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\\n\\n  std::ofstream dof_location_file(filename);\\n  DoFTools::write_gnuplot_dof_support_point_info(dof_location_file, dof_location_map);\\n}\\n\\nvoid distribute_dofs(DoFHandler<2> &dof_handler)\\n{\\n  const FE_Q<2> finite_element(1);\\n  dof_handler.distribute_dofs(finite_element);\\n\\n  write_dof_locations(dof_handler, \\\"dof-locations-1.gnuplot\\\");\\n\\n  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\\n  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n\\n  SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n\\n  std::ofstream out(\\\"sparsity-pattern-1.svg\\\");\\n  sparsity_pattern.print_svg(out);\\n}\\n\\nvoid renumber_dofs(DoFHandler<2> &dof_handler)\\n{\\n  DoFRenumbering::Cuthill_McKee(dof_handler);\\n\\n  write_dof_locations(dof_handler, \\\"dof-locations-2.gnuplot\\\");\\n\\n  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\\n  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n\\n  SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n\\n  std::ofstream out(\\\"sparsity-pattern-2.svg\\\");\\n  sparsity_pattern.print_svg(out);\\n}\\n\\nint main()\\n{\\n  Triangulation<2> triangulation;\\n  make_grid(triangulation);\\n\\n  DoFHandler<2> dof_handler(triangulation);\\n\\n  distribute_dofs(dof_handler);\\n  renumber_dofs(dof_handler);\\n}\\n\"\n",
      "}\n",
      "```{'prompt': 'Enumerate the degrees of freedom for a finite element approximation of the Laplace equation on a 2D circular domain using lowest order (Q1) elements, visualize the sparsity pattern of the resulting system matrix, and improve the sparsity pattern by renumbering the degrees of freedom using the Cuthill-McKee algorithm.', 'completion': '#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n\\n#include <deal.II/dofs/dof_handler.h>\\n\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/mapping_q1.h>\\n\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n\\n#include <deal.II/dofs/dof_renumbering.h>\\n\\n#include <fstream>\\n\\nusing namespace dealii;\\n\\nvoid make_grid(Triangulation<2> &triangulation)\\n{\\n  const Point<2> center(1, 0);\\n  const double inner_radius = 0.5, outer_radius = 1.0;\\n  GridGenerator::hyper_shell(triangulation, center, inner_radius, outer_radius, 5);\\n\\n  for (unsigned int step = 0; step < 3; ++step)\\n  {\\n    for (const auto &cell : triangulation.active_cell_iterators())\\n      for (const auto v : cell->vertex_indices())\\n      {\\n        const double distance_from_center = center.distance(cell->vertex(v));\\n        if (std::fabs(distance_from_center - inner_radius) <= 1e-6 * inner_radius)\\n        {\\n          cell->set_refine_flag();\\n          break;\\n        }\\n      }\\n    triangulation.execute_coarsening_and_refinement();\\n  }\\n\\n  std::ofstream mesh_file(\"mesh.gnuplot\");\\n  GridOut().write_gnuplot(triangulation, mesh_file);\\n}\\n\\nvoid write_dof_locations(const DoFHandler<2> &dof_handler, const std::string &filename)\\n{\\n  const std::map<types::global_dof_index, Point<2>> dof_location_map =\\n    DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\\n\\n  std::ofstream dof_location_file(filename);\\n  DoFTools::write_gnuplot_dof_support_point_info(dof_location_file, dof_location_map);\\n}\\n\\nvoid distribute_dofs(DoFHandler<2> &dof_handler)\\n{\\n  const FE_Q<2> finite_element(1);\\n  dof_handler.distribute_dofs(finite_element);\\n\\n  write_dof_locations(dof_handler, \"dof-locations-1.gnuplot\");\\n\\n  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\\n  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n\\n  SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n\\n  std::ofstream out(\"sparsity-pattern-1.svg\");\\n  sparsity_pattern.print_svg(out);\\n}\\n\\nvoid renumber_dofs(DoFHandler<2> &dof_handler)\\n{\\n  DoFRenumbering::Cuthill_McKee(dof_handler);\\n\\n  write_dof_locations(dof_handler, \"dof-locations-2.gnuplot\");\\n\\n  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\\n  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n\\n  SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n\\n  std::ofstream out(\"sparsity-pattern-2.svg\");\\n  sparsity_pattern.print_svg(out);\\n}\\n\\nint main()\\n{\\n  Triangulation<2> triangulation;\\n  make_grid(triangulation);\\n\\n  DoFHandler<2> dof_handler(triangulation);\\n\\n  distribute_dofs(dof_handler);\\n  renumber_dofs(dof_handler);\\n}\\n'}\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4.1-mini\"\n",
    "prompt_template = f\"\"\"You are an AI expert in C++. Your task is to analyze the following Deal.II tutorial content, \n",
    "and provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format. \n",
    "The prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II).\n",
    "(example: Solve the scalar wave equation with Dirichlet boundary conditions),\n",
    "and the completion is the final code.\n",
    "Tutorial content :\n",
    "{tutorial_content}\n",
    "\"\"\"\n",
    "stream = client.responses.create(model=model, input=prompt_template, stream=True, temperature=0.2)\n",
    "response = \"\"\n",
    "for event in stream:\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        response += event.delta\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "        \n",
    "# Extract the JSON from the response\n",
    "# import re\n",
    "# json_match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n",
    "# json = json_match.group(0) if json_match else None\n",
    "\n",
    "# if json is None:\n",
    "#     raise ValueError(\"No JSON found in the response\")\n",
    "\n",
    "# Write to file\n",
    "# with open(\"step_1.json\", \"w\") as f:\n",
    "#     f.write(response)\n",
    "    \n",
    "pair = JSON.loads(\"\\n\".join(response.split(\"\\n\")[1:-1]))\n",
    "print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d81a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Enumerate the degrees of freedom for a finite element approximation of the '\n",
      " 'Laplace equation on a 2D circular domain using lowest order (Q1) elements, '\n",
      " 'visualize the sparsity pattern of the resulting system matrix, and improve '\n",
      " 'the sparsity pattern by renumbering the degrees of freedom using the '\n",
      " 'Cuthill-McKee algorithm.')\n",
      "#include <deal.II/grid/tria.h>\n",
      "#include <deal.II/grid/grid_generator.h>\n",
      "#include <deal.II/grid/grid_out.h>\n",
      "\n",
      "#include <deal.II/dofs/dof_handler.h>\n",
      "\n",
      "#include <deal.II/fe/fe_q.h>\n",
      "#include <deal.II/dofs/dof_tools.h>\n",
      "#include <deal.II/fe/mapping_q1.h>\n",
      "\n",
      "#include <deal.II/lac/sparse_matrix.h>\n",
      "#include <deal.II/lac/dynamic_sparsity_pattern.h>\n",
      "\n",
      "#include <deal.II/dofs/dof_renumbering.h>\n",
      "\n",
      "#include <fstream>\n",
      "\n",
      "using namespace dealii;\n",
      "\n",
      "void make_grid(Triangulation<2> &triangulation)\n",
      "{\n",
      "  const Point<2> center(1, 0);\n",
      "  const double inner_radius = 0.5, outer_radius = 1.0;\n",
      "  GridGenerator::hyper_shell(triangulation, center, inner_radius, outer_radius, 5);\n",
      "\n",
      "  for (unsigned int step = 0; step < 3; ++step)\n",
      "  {\n",
      "    for (const auto &cell : triangulation.active_cell_iterators())\n",
      "      for (const auto v : cell->vertex_indices())\n",
      "      {\n",
      "        const double distance_from_center = center.distance(cell->vertex(v));\n",
      "        if (std::fabs(distance_from_center - inner_radius) <= 1e-6 * inner_radius)\n",
      "        {\n",
      "          cell->set_refine_flag();\n",
      "          break;\n",
      "        }\n",
      "      }\n",
      "    triangulation.execute_coarsening_and_refinement();\n",
      "  }\n",
      "\n",
      "  std::ofstream mesh_file(\"mesh.gnuplot\");\n",
      "  GridOut().write_gnuplot(triangulation, mesh_file);\n",
      "}\n",
      "\n",
      "void write_dof_locations(const DoFHandler<2> &dof_handler, const std::string &filename)\n",
      "{\n",
      "  const std::map<types::global_dof_index, Point<2>> dof_location_map =\n",
      "    DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\n",
      "\n",
      "  std::ofstream dof_location_file(filename);\n",
      "  DoFTools::write_gnuplot_dof_support_point_info(dof_location_file, dof_location_map);\n",
      "}\n",
      "\n",
      "void distribute_dofs(DoFHandler<2> &dof_handler)\n",
      "{\n",
      "  const FE_Q<2> finite_element(1);\n",
      "  dof_handler.distribute_dofs(finite_element);\n",
      "\n",
      "  write_dof_locations(dof_handler, \"dof-locations-1.gnuplot\");\n",
      "\n",
      "  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\n",
      "  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      "\n",
      "  SparsityPattern sparsity_pattern;\n",
      "  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      "\n",
      "  std::ofstream out(\"sparsity-pattern-1.svg\");\n",
      "  sparsity_pattern.print_svg(out);\n",
      "}\n",
      "\n",
      "void renumber_dofs(DoFHandler<2> &dof_handler)\n",
      "{\n",
      "  DoFRenumbering::Cuthill_McKee(dof_handler);\n",
      "\n",
      "  write_dof_locations(dof_handler, \"dof-locations-2.gnuplot\");\n",
      "\n",
      "  DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(), dof_handler.n_dofs());\n",
      "  DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\n",
      "\n",
      "  SparsityPattern sparsity_pattern;\n",
      "  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\n",
      "\n",
      "  std::ofstream out(\"sparsity-pattern-2.svg\");\n",
      "  sparsity_pattern.print_svg(out);\n",
      "}\n",
      "\n",
      "int main()\n",
      "{\n",
      "  Triangulation<2> triangulation;\n",
      "  make_grid(triangulation);\n",
      "\n",
      "  DoFHandler<2> dof_handler(triangulation);\n",
      "\n",
      "  distribute_dofs(dof_handler);\n",
      "  renumber_dofs(dof_handler);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pprint(pair[\"prompt\"])\n",
    "print(pair[\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59f674ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the completion to a file\n",
    "with open(\"step_1_completion.cpp\", \"w\") as f:\n",
    "    f.write(pair[\"completion\"])\n",
    "# Save the prompt to a file\n",
    "with open(\"step_1_prompt.txt\", \"w\") as f:\n",
    "    f.write(pair[\"prompt\"])\n",
    "# Save the pair to a JSON file\n",
    "with open(\"step_1_pair.json\", \"w\") as f:\n",
    "    JSON.dump(pair, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "257357c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptCompletionPair(prompt='Solve the Poisson equation \\\\(-\\\\Delta u = 1\\\\) on the square domain \\\\([-1,1]^2\\\\) with homogeneous Dirichlet boundary conditions \\\\(u=0\\\\) on \\\\(\\\\partial \\\\Omega\\\\), using the finite element method with bilinear elements. Assemble the system matrix and right hand side vector by integrating over the domain, apply the boundary conditions, solve the resulting linear system using the Conjugate Gradient method, and output the solution for visualization.', completion='#include <deal.II/grid/tria.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/matrix_tools.h>\\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_cg.h>\\n#include <deal.II/lac/precondition.h>\\n#include <deal.II/numerics/data_out.h>\\n#include <fstream>\\n#include <iostream>\\n\\nusing namespace dealii;\\n\\nclass PoissonProblem\\n{\\npublic:\\n  PoissonProblem();\\n  void run();\\n\\nprivate:\\n  void make_grid();\\n  void setup_system();\\n  void assemble_system();\\n  void solve();\\n  void output_results() const;\\n\\n  Triangulation<2> triangulation;\\n  FE_Q<2>          fe;\\n  DoFHandler<2>    dof_handler;\\n\\n  SparsityPattern      sparsity_pattern;\\n  SparseMatrix<double> system_matrix;\\n\\n  Vector<double> solution;\\n  Vector<double> system_rhs;\\n};\\n\\nPoissonProblem::PoissonProblem()\\n  : fe(1)\\n  , dof_handler(triangulation)\\n{}\\n\\nvoid PoissonProblem::make_grid()\\n{\\n  GridGenerator::hyper_cube(triangulation, -1, 1);\\n  triangulation.refine_global(5);\\n  std::cout << \"Number of active cells: \" << triangulation.n_active_cells() << std::endl;\\n}\\n\\nvoid PoissonProblem::setup_system()\\n{\\n  dof_handler.distribute_dofs(fe);\\n  std::cout << \"Number of degrees of freedom: \" << dof_handler.n_dofs() << std::endl;\\n\\n  DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n  DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n  sparsity_pattern.copy_from(dsp);\\n\\n  system_matrix.reinit(sparsity_pattern);\\n\\n  solution.reinit(dof_handler.n_dofs());\\n  system_rhs.reinit(dof_handler.n_dofs());\\n}\\n\\nvoid PoissonProblem::assemble_system()\\n{\\n  QGauss<2> quadrature_formula(fe.degree + 1);\\n  FEValues<2> fe_values(fe, quadrature_formula,\\n                        update_values | update_gradients | update_JxW_values);\\n\\n  const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n\\n  FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n  Vector<double>     cell_rhs(dofs_per_cell);\\n\\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n\\n  for (const auto &cell : dof_handler.active_cell_iterators())\\n  {\\n    fe_values.reinit(cell);\\n    cell_matrix = 0;\\n    cell_rhs = 0;\\n\\n    for (unsigned int q_index = 0; q_index < quadrature_formula.size(); ++q_index)\\n    {\\n      for (unsigned int i = 0; i < dofs_per_cell; ++i)\\n      {\\n        for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n          cell_matrix(i, j) += fe_values.shape_grad(i, q_index) *\\n                               fe_values.shape_grad(j, q_index) *\\n                               fe_values.JxW(q_index);\\n\\n        cell_rhs(i) += fe_values.shape_value(i, q_index) * 1.0 * fe_values.JxW(q_index);\\n      }\\n    }\\n\\n    cell->get_dof_indices(local_dof_indices);\\n    for (unsigned int i = 0; i < dofs_per_cell; ++i)\\n    {\\n      for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n        system_matrix.add(local_dof_indices[i], local_dof_indices[j], cell_matrix(i, j));\\n      system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n    }\\n  }\\n\\n  std::map<types::global_dof_index, double> boundary_values;\\n  VectorTools::interpolate_boundary_values(dof_handler, 0, Functions::ZeroFunction<2>(), boundary_values);\\n  MatrixTools::apply_boundary_values(boundary_values, system_matrix, solution, system_rhs);\\n}\\n\\nvoid PoissonProblem::solve()\\n{\\n  SolverControl solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n  SolverCG<Vector<double>> solver(solver_control);\\n  solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n\\n  std::cout << solver_control.last_step() << \" CG iterations needed to obtain convergence.\" << std::endl;\\n}\\n\\nvoid PoissonProblem::output_results() const\\n{\\n  DataOut<2> data_out;\\n  data_out.attach_dof_handler(dof_handler);\\n  data_out.add_data_vector(solution, \"solution\");\\n  data_out.build_patches();\\n\\n  std::ofstream output(\"solution.vtk\");\\n  data_out.write_vtk(output);\\n  std::cout << \"Output written to solution.vtk\" << std::endl;\\n}\\n\\nvoid PoissonProblem::run()\\n{\\n  make_grid();\\n  setup_system();\\n  assemble_system();\\n  solve();\\n  output_results();\\n}\\n\\nint main()\\n{\\n  PoissonProblem problem;\\n  problem.run();\\n  return 0;\\n}\\n')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class PromptCompletionPair(BaseModel):\n",
    "    prompt: str\n",
    "    completion: str\n",
    "    \n",
    "prompt_template = \"\"\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\n",
    "and provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\n",
    "The prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n",
    "(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\n",
    "and the completion is the final code.\n",
    "Tutorial description : \n",
    "{description}\n",
    "Tutorial content :\n",
    "{content}\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt_and_completion(content, description) -> PromptCompletionPair:\n",
    "    client = OpenAI(api_key=oai_key)\n",
    "    model = \"gpt-4.1-mini\"\n",
    "\n",
    "    response = client.responses.parse(model=model, input=prompt_template.format(content=content, description=description), text_format=PromptCompletionPair, temperature=0.2).output_parsed\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# get_prompt_and_completion(tutorial_content)\n",
    "get_prompt_and_completion(*pl.scan_parquet(\"tutorials.parquet\").filter(pl.col(\"num\") == 3).select_seq(\"content\", \"description\").collect().row(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ccf4634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num</th><th>name</th><th>link</th><th>description</th><th>keywords</th><th>content</th></tr><tr><td>u8</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>3</td><td>&quot;step-3&quot;</td><td>&quot;https://dealii.org/current/dox…</td><td>&quot;Actually solve Laplace&#x27;s probl…</td><td>[&quot;FEValues&quot;, &quot;VectorTools::interpolate_boundary_values()&quot;, … &quot;DataOut&quot;]</td><td>&quot;This tutorial depends on [step…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "┌─────┬────────┬────────────────────┬────────────────────┬────────────────────┬────────────────────┐\n",
       "│ num ┆ name   ┆ link               ┆ description        ┆ keywords           ┆ content            │\n",
       "│ --- ┆ ---    ┆ ---                ┆ ---                ┆ ---                ┆ ---                │\n",
       "│ u8  ┆ str    ┆ str                ┆ str                ┆ list[str]          ┆ str                │\n",
       "╞═════╪════════╪════════════════════╪════════════════════╪════════════════════╪════════════════════╡\n",
       "│ 3   ┆ step-3 ┆ https://dealii.org ┆ Actually solve     ┆ [\"FEValues\",       ┆ This tutorial      │\n",
       "│     ┆        ┆ /current/dox…      ┆ Laplace's probl…   ┆ \"VectorTools::int… ┆ depends on [step…  │\n",
       "└─────┴────────┴────────────────────┴────────────────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorials.filter(pl.col(\"num\") == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b26c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_prompts_and_completions(tutorials: pl.DataFrame) -> pl.DataFrame:\n",
    "    with tqdm(total=len(tutorials)) as pbar:\n",
    "        pbar.set_description(\"Processing tutorials to generate prompt/completion pairs\")\n",
    "        def foo(content: str):\n",
    "            res = get_prompt_and_completion(content[:len(content) // 4])\n",
    "            pbar.update()\n",
    "            return OrderedDict(res)\n",
    "        tutorials = (\n",
    "        tutorials.lazy().head(1)\n",
    "        .with_columns(pl.col(\"content\").alias(\"prompt/completion\").map_elements(foo, return_dtype=pl.Struct({\"prompt\": pl.String, \"completion\": pl.String})).struct.unnest())\n",
    "        .select(pl.all().exclude(\"prompt/completion\"))\n",
    "         .collect()\n",
    "        )\n",
    "    return tutorials\n",
    "\n",
    "#res = with_prompts_and_completions(tutorials)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5030e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 2100.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"custom_id\":\"https://dealii.org/current/doxygen/deal.II//step_1.html\",\"method\":\"POST\",\"url\":\"/v1/chat/completions\",\"body\":{\"model\":\"gpt-4.1-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nCreating a grid. A simple way to write it to a file.\\nTutorial content :\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_1-Intro)    * [About the tutorial](#step_1-Aboutthetutorial) * [Video lectures on tutorial programs](#step_1-Videolecturesontutorialprograms) * [What this program does](#step_1-Whatthisprogramdoes) * [About scientific computing in general](#step_1-Aboutscientificcomputingingeneral)- [The commented program](#step_1-CommProg)      * [Include files](#step_1-Includefiles)* [Creating the first mesh](#step_1-Creatingthefirstmesh)* [Creating the second mesh](#step_1-Creatingthesecondmesh)* [The main function](#step_1-Themainfunction) | 1. [Results](#step_1-Results)    * [Possibilities for extensions](#step_1-Possibilitiesforextensions)       + [Use triangles](#step_1-Usetriangles) + [Different adaptive refinement strategies](#step_1-Differentadaptiverefinementstrategies) + [Different geometries](#step_1-Differentgeometries) + [Comments about programming and debugging](#step_1-Commentsaboutprogramminganddebugging) + [More about graphical output](#step_1-Moreaboutgraphicaloutput)- [The plain program](#step_1-PlainProg) |\\n\\nIntroduction\\n============\\n\\n### About the tutorial\\n\\nSince this is the first tutorial program, let us comment first on how this tutorial and the rest of the deal.II documentation is supposed to work. The documentation for deal.II comes essentially at three different levels:\\n\\n* The tutorial: This is a collection of programs that shows how deal.II is used in practice. It doesn't typically discuss individual functions at the level of individual arguments, but rather wants to give the big picture of how things work together. In other words, it discusses \\\"concepts\\\": what are the building blocks of deal.II and how are they used together in finite element programs.\\n* The manual: This is the documentation of every single class and every single (member) function in deal.II. You get there if, for example, you click on the \\\"Main page\\\" or \\\"Classes\\\" tab at the top of this page. This is the place where you would look up what the second argument of [Triangulation::create\\\\_triangulation()](classTriangulation.html#a5b6edd805a4d8b91d016080bf43233c1) means, to give just one example. You need this level of documentation for when you know what you want to do, but forgot how exactly the function was named, what its arguments are, or what it returns. Note that you also get into the manual whenever you read through the tutorial and click on any of the class or function names, i.e. the tutorial contains a great many links into the manual for whenever you need a more detailed description of a function or class. On the other hand, the manual is not a good place to learn deal.II since it gives you a microscopic view of things without telling you how a function might fit into the bigger picture.\\n* Topics: These are groups of classes and functions that work together or have related functionality. If you click on the \\\"Topics\\\" tab at the top of this page, you end up on a page that lists a number of such groups. Each topic discusses the underlying principles of these classes; for example, the [Sparsity patterns](group__Sparsity.html) topic talks about all sorts of different issues related to storing sparsity patterns of matrices. This is documentation at an intermediate level: they give you an overview of what's there in a particular area. For example when you wonder what finite element classes exist, you would take a look at the [Finite element space descriptions](group__fe.html) topic. The topics are, of course, also cross-linked to the manual (and, at times, to the tutorial); if you click on a class name, say on [Triangulation](classTriangulation.html), you will also at the very top right under the class name get a link to the topics this class is a member of if you want to learn more about its context.\\n\\nLet's come back to the tutorial, since you are looking at the first program (or \\\"step\\\") of it. Each tutorial program is subdivided into the following sections:\\n\\n1. **Introduction:** This is a discussion of what the program does, including the mathematical model, and what programming techniques are new compared to previous tutorial programs.\\n2. **The commented program:** An extensively documented listing of the source code. Here, we often document individual lines, or blocks of code, and discuss what they do, how they do it, and why. The comments frequently reference the introduction, i.e. you have to understand *what* the program wants to achieve (a goal discussed in the introduction) before you can understand *how* it intends to get there.\\n3. **Results:** The output of the program, with comments and interpretation. This section also frequently has a subsection that gives suggestions on how to extend the program in various direction; in the earlier programs, this is intended to give you directions for little experiments designed to make you familiar with deal.II, while in later programs it is more about how to use more advanced numerical techniques.\\n4. **The plain program:** The source code stripped of all comments. This is useful if you want to see the \\\"big\\n   picture\\\" of the code, since the commented version of the program has so much text in between that it is often difficult to see the entire code of a single function on the screen at once.\\n\\nThe tutorials are not only meant to be static documentation, but you should play with them. To this end, go to the `examples/step-1` directory (or whatever the number of the tutorial is that you're interested in) and type\\n\\n```\\ncmake .\\nmake\\nmake run\\n```\\n\\nThe first command sets up the files that describe which include files this tutorial program depends on, how to compile it and how to run it. This command should find the installed deal.II libraries as well as those that were generated when you compiled and installed everything as described in the [README](../../readme.html) file. If this command should fail to find the deal.II library, then you need to provide the path to the installation using the command\\n\\n```\\ncmake -DDEAL_II_DIR=/path/to/installed/deal.II .\\n```\\n\\ninstead.\\n\\nThe second of the commands above compiles the sources into an executable, while the last one executes it (strictly speaking, `make run` will also compile the code if the executable doesn't exist yet, so you could have skipped the second command if you wanted). This is all that's needed to run the code and produce the output that is discussed in the \\\"Results\\\" section of the tutorial programs. This sequence needs to be repeated in all of the tutorial directories you want to play with.\\n\\nWhen learning the library, you need to play with it and see what happens. To this end, open the `examples/step-1/step-1.cc` source file with your favorite editor and modify it in some way, save it and run it as above. A few suggestions for possibly modifications are given at the end of the results section of this program, where we also provide a few links to other useful pieces of information.\\n\\n### Video lectures on tutorial programs\\n\\nThis and several of the other tutorial programs are also discussed and demonstrated in [Wolfgang Bangerth's video lectures](http://www.math.colostate.edu/~bangerth/videos.html) on deal.II and computational science. In particular, you can see the steps he executes to run this and other programs, and you will get a much better idea of the tools that can be used to work with deal.II. In particular, lectures 2 and 4 give an overview of deal.II and of the building blocks of any finite element code. (See also [video lecture 2](https://www.math.colostate.edu/~bangerth/videos.676.2.html), [video lecture 4](https://www.math.colostate.edu/~bangerth/videos.676.4.html).)\\n\\nIf you are not yet familiar with using Linux and running things on the command line, you may be interested in watching lectures 2.9 and 2.91. (See also [video lecture 2.9](https://www.math.colostate.edu/~bangerth/videos.676.2.9.html), [video lecture 2.91](https://www.math.colostate.edu/~bangerth/videos.676.2.91.html).) These give overviews over the command line and on what happens when compiling programs, respectively.\\n\\nNote that deal.II is actively developed, and in the course of this development we occasionally rename or deprecate functions or classes that are still referenced in these video lectures. For example, the [step-1](step_1.html) code shown in video lecture 5 uses a class HyperShellBoundary which was replaced with [SphericalManifold](classSphericalManifold.html) class later on. Additionally, as of deal.II version 9.0, [GridGenerator::hyper\\\\_shell()](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) now automatically attaches a [SphericalManifold](classSphericalManifold.html) to the [Triangulation](classTriangulation.html). Otherwise the rest of the lecture material is relevant.\\n\\n### What this program does\\n\\nLet's come back to [step-1](step_1.html), the current program. The goal of this program is to introduce you to the [Triangulation](classTriangulation.html) class that is at the core of every finite element program. The name \\\"triangulation\\\" in this context is mostly historical: To finite element practitioners, the terms \\\"triangulation\\\", \\\"mesh\\\", and \\\"grid\\\" are all synonymous and describe a subdivision of a domain on which a differential equation is posed into cells of some kind. If the domain is two-dimensional, these cells may indeed be triangles, but they could also be quadrilaterals (four-sided objects such as squares and rectangles, and their deformations). In one space dimension, the cells are line segments. In three space dimensions, they can be tetrahedra, hexahedra (deformed cubes), pyramids (a four-sided base with three triangles connecting to a point at the top), and \\\"wedges\\\" (two triangles at the bottom and top, connected by three quadrilaterals; wedges are often also called \\\"(triangular) prisms\\\", for example in [this wikipedia article about types of meshes](https://en.wikipedia.org/wiki/Types_of_mesh)). Collections of any such cells are \\\"triangulations\\\" in common usage of the word even though they may not actually have triangles in them. All of them are also \\\"grids\\\" in common usage of the word even though the usual meaning of the word \\\"grid\\\" would be something where the vertices are in neat rows parallel to the coordinate axes (which would then be a \\\"structured grid\\\" in the finite element context). In other words, whenever you read any of the three terms in the tutorials or the library's documentation, consider them equivalent.\\n\\nWhat this program shows, then, is how to create a [Triangulation](classTriangulation.html) object, and to operate on it. The underlying concept of a [Triangulation](classTriangulation.html) is that it is a *container*, i.e., a class that stores a collection of cells\\\\*. As is common in modern programming languages, the key operation on containers is that one can *iterate* over its elements, and that's exactly what we will do below.\\n\\nSpecifically, in the program we create two grids, one which is a regularly refined square (not very exciting, but a common starting grid for many problems), and one that is a more geometric attempt: a ring-shaped domain that is refined towards the inner edge. The process of refining the mesh in this way will illustrate how we iterate (i.e., loop) over the elements of the triangulation (i.e., the cells of the mesh). You will see many more such loops throughout the remainder of the tutorial. (Since there are so many loops over cells in finite element programs, the [Iterators on mesh-like containers](group__Iterators.html) topic talks about them in more detail.)\\n\\nThe program is otherwise small enough that it doesn't need a whole lot of introduction.\\n\\nNote\\n:   The material presented here is also discussed in [video lecture 5](https://www.math.colostate.edu/~bangerth/videos.676.5.html), [video lecture 6](https://www.math.colostate.edu/~bangerth/videos.676.6.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\\n\\n### About scientific computing in general\\n\\nIf you are reading through this tutorial program, chances are that you are interested in continuing to use deal.II for your own projects. Thus, you are about to embark on an exercise in programming using a large-scale scientific computing library. Unless you are already an experienced user of large-scale programming methods, this may be new territory for you — with all the new rules that go along with it such as the fact that you will have to deal with code written by others, that you may have to think about documenting your own code because you may not remember what exactly it is doing a year down the road (or because others will be using it as well), or coming up with ways to test that your program is doing the right thing. None of this is something that we typically train mathematicians, engineers, or scientists to do but that is important when you start writing software of more than a few hundred lines. Remember: Producing software is not the same as just writing code.\\n\\nTo make your life easier on this journey let us point to some resources that are worthwhile browsing through before you start any large-scale programming:\\n\\n* The [deal.II FAQ](https://github.com/dealii/dealii/wiki/Frequently-Asked-Questions) has a good number of answers to questions about particular aspects of deal.II, but also to more general questions such as \\\"How\\n  do I debug scientific computing codes?\\\" or \\\"Can I train myself to write code\\n  that has fewer bugs?\\\".\\n* You will benefit from becoming a better programmer. An excellent resource to this end is the book [Code Complete](https://www.oreilly.com/library/view/code-complete-2nd/0735619670/) by Steve McConnell [[151]](citelist.html#CITEREF_CodeComplete) . It's already a few years old, with the last edition published in 2004, but it has lost none of its appeal as a guide to good programming practices, and some of the principal developers use it as a group reading project with every generation of their research group members. Another good programming book is [Refactoring: Improving the Design of Existing Code](https://martinfowler.com/books/refactoring.html) by Martin Fowler that is a great introduction and resource for how to continuously transform existing code to make it fit for future extension [[88]](citelist.html#CITEREF_Refactoring) .\\n* The [Software Carpentry project](http://software-carpentry.org/) that provides introductions to many topics that are important to dealing with software, such as version control, make files, testing, etc. It is specifically written for scientists and engineers, not for computer scientists, and has a focus on short, practical lessons.\\n* The [Better Scientific Software project](https://bssw.io/) has a lot of resources (and interesting blog posts) that cover many aspects of writing scientific software.\\n* The [IDEAS project](https://ideas-productivity.org/) also has resources on software development, in particular for parallel computing. In the \\\"Events\\\" section on that site are recorded tutorials and webinars that cover many interesting topics.\\n* An article a few of us wrote, called [I'm stuck! How to efficiently debug computational solid mechanics models so you can enjoy the beauty of simulations](https://doi.org/10.1016/j.euromechsol.2022.104845) [[65]](citelist.html#CITEREF_Comellas_2023) . This article discusses in great detail what you do if a code doesn't work. It is also available on [arXiv](https://arxiv.org/abs/2209.04198).\\n* An article on [Best Practices for Scientific Computing](http://arxiv.org/abs/1210.0530) that gives an introduction to many of the ways by which you can make sure you are an efficient programmer writing programs that work.\\n\\nAs a general recommendation: If you expect to spend more than a few days writing software in the future, do yourself the favor of learning tools that can make your life more productive, in particular debuggers and integrated development environments. (See also [video lecture 7](https://www.math.colostate.edu/~bangerth/videos.676.7.html), [video lecture 8](https://www.math.colostate.edu/~bangerth/videos.676.8.html), [video lecture 8.01](https://www.math.colostate.edu/~bangerth/videos.676.8.01.html), [video lecture 25](https://www.math.colostate.edu/~bangerth/videos.676.25.html).) You will find that you will get the time spent learning these tools back severalfold soon by being more productive! Several of the video lectures referenced above show how to use tools such as integrated development environments or debuggers.\\n\\nThe commented program\\n=====================\\n\\n### Include files\\n\\nThe most fundamental class in the library is the [Triangulation](classTriangulation.html) class, which is declared here:\\n\\n```\\n   #include <deal.II/grid/tria.h>\\n```\\n\\nHere are some functions to generate standard grids:\\n\\n```\\n   #include <deal.II/grid/grid_generator.h>\\n```\\n\\nOutput of grids in various graphics formats:\\n\\n```\\n   #include <deal.II/grid/grid_out.h>\\n```\\n\\nThis is needed for C++ output:\\n\\n```\\n   #include <iostream>\\n   #include <fstream>\\n```\\n\\nAnd this for the declarations of the `std::sqrt` and `std::fabs` functions:\\n\\n```\\n   #include <cmath>\\n```\\n\\nThe final step in importing deal.II is this: All deal.II functions and classes are in a namespace `dealii`, to make sure they don't clash with symbols from other libraries you may want to use in conjunction with deal.II. One could use these functions and classes by prefixing every use of these names by `::`, but that would quickly become cumbersome and annoying. Rather, we simply import the entire deal.II namespace for general use:\\n\\n```\\n   using namespace dealii;\\n```\\n\\n### Creating the first mesh\\n\\nIn the following, first function, we simply use the unit square as domain and produce a globally refined grid from it.\\n\\n```\\n   void first_grid()\\n   {\\n```\\n\\nThe first thing to do is to define an object for a triangulation of a two-dimensional domain:\\n\\n```\\n     Triangulation<2> triangulation;\\n```\\n\\nHere and in many following cases, the string \\\"<2>\\\" after a class name indicates that this is an object that shall work in two space dimensions. Likewise, there are versions of the triangulation class that are working in one (\\\"<1>\\\") and three (\\\"<3>\\\") space dimensions. The way this works is through some template magic that we will investigate in some more detail in later example programs; there, we will also see how to write programs in an essentially dimension independent way.\\n\\nNext, we want to fill the triangulation with a single cell for a square domain. The triangulation is the refined four times, to yield \\\\(4^4=256\\\\) cells in total:\\n\\n```\\n     GridGenerator::hyper_cube(triangulation);\\n     triangulation.refine_global(4);\\n```\\n\\nNow we want to write a graphical representation of the mesh to an output file. The [GridOut](classGridOut.html) class of deal.II can do that in a number of different output formats; here, we choose scalable vector graphics (SVG) format that you can visualize using the web browser of your choice:\\n\\n```\\n     std::ofstream out(\\\"grid-1.svg\\\");\\n     GridOut       grid_out;\\n     grid_out.write_svg(triangulation, out);\\n     std::cout << \\\"Grid written to grid-1.svg\\\" << std::endl;\\n   }\\n```\\n\\n### Creating the second mesh\\n\\nThe grid in the following, second function is slightly more complicated in that we use a ring domain and refine the result once globally.\\n\\n```\\n   void second_grid()\\n   {\\n```\\n\\nWe start again by defining an object for a triangulation of a two-dimensional domain:\\n\\n```\\n     Triangulation<2> triangulation;\\n```\\n\\nWe then fill it with a ring domain. The center of the ring shall be the point (1,0), and inner and outer radius shall be 0.5 and 1. The number of circumferential cells could be adjusted automatically by this function, but we choose to set it explicitly to 10 as the last argument:\\n\\n```\\n     const Point<2> center(1, 0);\\n     const double   inner_radius = 0.5, outer_radius = 1.0;\\n     GridGenerator::hyper_shell(\\n       triangulation, center, inner_radius, outer_radius, 10);\\n```\\n\\nBy default, the triangulation assumes that all boundaries are straight lines, and all cells are bi-linear quads or tri-linear hexes, and that they are defined by the cells of the coarse grid (which we just created). Unless we do something special, when new points need to be introduced the domain is assumed to be delineated by the straight lines of the coarse mesh, and new points will simply be in the middle of the surrounding ones. Here, however, we know that the domain is curved, and we would like to have the [Triangulation](classTriangulation.html) place new points according to the underlying geometry. Fortunately, some good soul implemented an object which describes a spherical domain, of which the ring is a section; it only needs the center of the ring and automatically figures out how to instruct the [Triangulation](classTriangulation.html) where to place the new points. The way this works in deal.II is that you tag parts of the triangulation you want to be curved with a number that is usually referred to as \\\"manifold indicator\\\" and then tell the triangulation to use a particular \\\"manifold object\\\" for all places with this manifold indicator. How exactly this works is not important at this point (you can read up on it in [step-53](step_53.html) and [Manifold description for triangulations](group__manifold.html)). The functions in [GridGenerator](namespaceGridGenerator.html) handle this for us in most circumstances: they attach the correct manifold to a domain so that when the triangulation is refined new cells are placed in the correct places. In the present case [GridGenerator::hyper\\\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) attaches a [SphericalManifold](classSphericalManifold.html) to all cells: this causes cells to be refined with calculations in spherical coordinates (so new cells have edges that are either radial or lie along concentric circles around the origin).\\n\\nBy default (i.e., for a [Triangulation](classTriangulation.html) created by hand or without a call to a [GridGenerator](namespaceGridGenerator.html) function like [GridGenerator::hyper\\\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) or [GridGenerator::hyper\\\\_ball](namespaceGridGenerator.html#a533c4778cbc9bcbed365dcab42ca4418)), all cells and faces of the [Triangulation](classTriangulation.html) have their manifold\\\\_id set to [numbers::flat\\\\_manifold\\\\_id](namespacenumbers.html#a9c39a5de95e4d11173378431dc2131fe), which is the default if you want a manifold that produces straight edges, but you can change this number for individual cells and faces. In that case, the curved manifold thus associated with number zero will not apply to those parts with a non-zero manifold indicator, but other manifold description objects can be associated with those non-zero indicators. If no manifold description is associated with a particular manifold indicator, a manifold that produces straight edges is implied. ([Manifold](classManifold.html) indicators are a slightly complicated topic; if you're confused about what exactly is happening here, you may want to look at the [glossary entry on this topic](DEALGlossary.html#GlossManifoldIndicator).) Since the default chosen by [GridGenerator::hyper\\\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) is reasonable we leave things alone.\\n\\nIn order to demonstrate how to write a loop over all cells, we will refine the grid in five steps towards the inner circle of the domain:\\n\\n```\\n     for (unsigned int step = 0; step < 5; ++step)\\n       {\\n```\\n\\nNext, we need to loop over the active cells of the triangulation. You can think of a triangulation as a collection of cells. If it were an array, you would just get a pointer that you increment from one element to the next using the operator `++`. The cells of a triangulation aren't stored as a simple array, but the concept of an *iterator* generalizes how pointers work to arbitrary collections of objects (see [wikipedia](http://en.wikipedia.org/wiki/Iterator#C.2B.2B) for more information). Typically, any container type in C++ will return an iterator pointing to the start of the collection with a method called `begin`, and an iterator point to 1 past the end of the collection with a method called `end`. We can increment an iterator `it` with the operator `++it`, dereference it to get the underlying data with `*it`, and check to see if we're done by comparing `it != collection.end()`.\\n\\nThe second important piece is that we only need the active cells. Active cells are those that are not further refined, and the only ones that can be marked for further refinement. deal.II provides iterator categories that allow us to iterate over *all* cells (including the parent cells of active ones) or only over the active cells. Because we want the latter, we need to call the method [Triangulation::active\\\\_cell\\\\_iterators()](group__CPP11.html#ga9bd9f259f5b6c617c9ed88aa8b140ee8).\\n\\nPutting all of this together, we can loop over all the active cells of a triangulation with\\n\\n```\\nfor (auto it = triangulation.active_cell_iterators().begin();\\n     it != triangulation.active_cell_iterators().end();\\n     ++it)\\n  {\\n auto cell = *it;\\n // Then a miracle occurs...\\n  }\\n```\\n\\nIn the initializer of this loop, we've used the `auto` keyword for the type of the iterator `it`. The `auto` keyword means that the type of the object being declared will be inferred from the context. This keyword is useful when the actual type names are long or possibly even redundant. If you're unsure of what the type is and want to look up what operations the result supports, you can go to the documentation for the method [Triangulation::active\\\\_cell\\\\_iterators()](group__CPP11.html#ga9bd9f259f5b6c617c9ed88aa8b140ee8). In this case, the type of `it` is `Triangulation::active_cell_iterator`.\\n\\nWhile the `auto` keyword can save us from having to type out long names of data types, we still have to type a lot of redundant declarations about the start and end iterator and how to increment it. Instead of doing that, we'll use [range- based for loops](http://en.cppreference.com/w/cpp/language/range-for), which wrap up all of the syntax shown above into a much shorter form:\\n\\n```\\n         for (const auto &cell : triangulation.active_cell_iterators())\\n           {\\n```\\n\\nNote\\n:   See [Iterators on mesh-like containers](group__Iterators.html) for more information about the iterator classes used in deal.II, and [deal.II and Modern C++ standards](group__CPP11.html) for more information about range-based for loops and the `auto` keyword.\\n\\nNext, we loop over all vertices of the cells. For that purpose we query an iterator over the vertex indices (in 2d, this is an array that contains the elements `{0,1,2,3}`, but since `cell->vertex_indices()` knows the dimension the cell lives in, the array so returned is correct in all dimensions and this enables this code to be correct whether we run it in 2d or 3d, i.e., it enables \\\"dimension-independent programming\\\" – a big part of what we will discuss in [step-4](step_4.html)).\\n\\n```\\n             for (const auto v : cell->vertex_indices())\\n               {\\n```\\n\\nIf this cell is at the inner boundary, then at least one of its vertices must sit on the inner ring and therefore have a radial distance from the center of exactly 0.5, up to floating point accuracy. So we compute this distance, and if we find a vertex with this property, we flag this cell for later refinement. We can then also break the loop over all vertices and move on to the next cell.\\n\\nBecause the distance from the center is computed as a floating point number, we have to expect that whatever we compute is only accurate to within [round-off](https://en.wikipedia.org/wiki/Round-off_error). As a consequence, we can never expect to compare the distance with the inner radius by equality: A statement such as `if (distance_from_center == inner_radius)` will fail unless we get exceptionally lucky. Rather, we need to do this comparison with a certain tolerance, and the usual way to do this is to write it as `if (std::abs(distance_from_center - inner_radius) <= tolerance)` where `tolerance` is some small number larger than round-off. The question is how to choose it: We could just pick, say, `1e-10`, but this is only appropriate if the objects we compare are of size one. If we had created a mesh with cells of size `1e+10`, then `1e-10` would be far lower than round-off and, as before, the comparison will only succeed if we get exceptionally lucky. Rather, it is almost always useful to make the tolerance *relative* to a typical \\\"scale\\\" of the objects being compared. Here, the \\\"scale\\\" would be the inner radius, or maybe the diameter of cells. We choose the former and set the tolerance equal to \\\\(10^{-6}\\\\) times the inner radius of the annulus.\\n\\n```\\n                 const double distance_from_center =\\n                   center.distance(cell->vertex(v));\\n   \\n                 if (std::fabs(distance_from_center - inner_radius) <=\\n                     1e-6 * inner_radius)\\n                   {\\n                     cell->set_refine_flag();\\n                     break;\\n                   }\\n               }\\n           }\\n```\\n\\nNow that we have marked all the cells that we want refined, we let the triangulation actually do this refinement. The function that does so owes its long name to the fact that one can also mark cells for coarsening, and the function does coarsening and refinement all at once:\\n\\n```\\n         triangulation.execute_coarsening_and_refinement();\\n       }\\n```\\n\\nFinally, after these five iterations of refinement, we want to again write the resulting mesh to a file, again in SVG format. This works just as above:\\n\\n```\\n     std::ofstream out(\\\"grid-2.svg\\\");\\n     GridOut       grid_out;\\n     grid_out.write_svg(triangulation, out);\\n   \\n     std::cout << \\\"Grid written to grid-2.svg\\\" << std::endl;\\n   }\\n```\\n\\n### The main function\\n\\nFinally, the main function. There isn't much to do here, only to call the two subfunctions, which produce the two grids.\\n\\n```\\n   int main()\\n   {\\n     first_grid();\\n     second_grid();\\n   }\\n```\\n\\nResults\\n=======\\n\\nRunning the program produces graphics of two grids (grid-1.svg and grid-2.svg). You can open these with most every web browser – in the simplest case, just open the current directory in your file system explorer and click on the file. If you like working on the command line, you call your web browser with the file: `firefox grid-1.svg`, `google-chrome grid-1.svg`, or whatever the name of your browser is. If you do this, the two meshes should look like this:\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nThe left one, well, is not very exciting. The right one is — at least — unconventional. The pictures color-code the \\\"refinement level\\\" of each cell: How many times did a coarse mesh cell have to be subdivided to obtain the given cell. In the left image, this is boring since the mesh was refined globally a number of times, i.e., *every* cell was refined the same number of times.\\n\\n(While the second mesh is entirely artificial and made-up, and certainly not very practical in applications, to everyone's surprise it has found its way into the literature: see [[157]](citelist.html#CITEREF_Mu05). Apparently it is good for some things at least.)\\n\\n### Possibilities for extensions\\n\\n#### Use triangles\\n\\nFor the first 20 or so years of its existence, deal.II only supported hypercube elements (i.e., quadrilaterals in 2d, and hexahedra in 3d). It now also supports triangles in 2d; and tetrahedra, pyramids, and wedges in 3d. A consequence of this history is that nearly all of the tutorial programs you will see exclusively use quadrilaterals and hexahedra, and you may be forgiven that that is all that's supported. But you can try out other types of cells yourself here already. For example, here are two ideas:\\n\\n* You could create a triangular triangulation meshing a triangular domain. To do this, you would replace the call to `GridGenerator::hyper_cube(triangulation);` in the `first_grid()` function by `GridGenerator::reference_cell(triangulation,\\n  ReferenceCells::Triangle);`. This will give you the following output in `grid-1.svg`: ![](images/steps/developer/step-1.grid-1-triangle.png)\\n* You can start with a quadrilateral mesh and convert it to a triangular mesh. For example, in the `first_grid()` function, replace the code\\n\\n  ```\\n  Triangulation<2> triangulation;\\n  GridGenerator::hyper_cube(triangulation);\\n  ```\\n\\n  by the following, which first creates a temporary mesh `triangulation_quad` consisting of quadrilaterals, and then converts it into the `triangulation` object that then only consists of triangles:\\n\\n  ```\\n  Triangulation<2> triangulation_quad;\\n  GridGenerator::hyper_cube(triangulation_quad);\\n  Triangulation<2> triangulation;\\n  GridGenerator::convert_hypercube_to_simplex_mesh (triangulation_quad,\\n   triangulation);\\n  ```\\n\\n  This produces the following mesh: ![](images/steps/developer/step-1.grid-1-triangle-2.png)\\n\\n  You can do the same in the `second_grid()` function by replacing\\n\\n  ```\\n  Triangulation<2> triangulation;\\n   \\n  const Point<2> center(1, 0);\\n  const double   inner_radius = 0.5, outer_radius = 1.0;\\n  GridGenerator::hyper_shell(\\n   triangulation, center, inner_radius, outer_radius, 10);\\n  ```\\n\\n  by the following (that includes some magic at the bottom we're perhaps not quite ready to explain in detail yet, but that is mentioned in the documentation of [GridGenerator::convert\\\\_hypercube\\\\_to\\\\_simplex\\\\_mesh()](namespaceGridGenerator.html#ac7515d2b17c025dddc0e37286fb8d216)):\\n\\n  ```\\n  Triangulation<2> triangulation_quad;\\n   \\n  const Point<2> center(1, 0);\\n  const double   inner_radius = 0.5, outer_radius = 1.0;\\n  GridGenerator::hyper_shell(\\n    triangulation_quad, center, inner_radius, outer_radius, 10);\\n   \\n  Triangulation<2> triangulation;\\n  GridGenerator::convert_hypercube_to_simplex_mesh (triangulation_quad,\\n   triangulation);\\n  for (const auto i : triangulation_quad.get_manifold_ids())\\n    if (i != numbers::flat_manifold_id)\\n   triangulation.set_manifold(i, triangulation_quad.get_manifold(i));\\n  ```\\n\\n  This results in this picture: This produces the following mesh: ![](images/steps/developer/step-1.grid-2-triangle.png)\\n\\n#### Different adaptive refinement strategies\\n\\nThis program obviously does not have a whole lot of functionality, but in particular the `second_grid` function has a bunch of places where you can play with it. For example, you could modify the criterion by which we decide which cells to refine. An example would be to change the condition to this:\\n\\n```\\nfor (auto &cell: triangulation.active_cell_iterators())\\n  if (cell->center()[1] > 0)\\n    cell->set_refine_flag ();\\n```\\n\\nThis would refine all cells for which the \\\\(y\\\\)-coordinate of the cell's center is greater than zero (the `TriaAccessor::center` function that we call by dereferencing the `cell` iterator returns a [Point<2>](classPoint.html) object; subscripting `[0]` would give the \\\\(x\\\\)-coordinate, subscripting `[1]` the \\\\(y\\\\)-coordinate). By looking at the functions that [TriaAccessor](classTriaAccessor.html) provides, you can also use more complicated criteria for refinement.\\n\\nIn general, what you can do with operations of the form `cell->something()` is a bit difficult to find in the documentation because `cell` is not a pointer but an iterator. The functions you can call on a cell can be found in the documentation of the classes `TriaAccessor` (which has functions that can also be called on faces of cells or, more generally, all sorts of geometric objects that appear in a triangulation), and `CellAccessor` (which adds a few functions that are specific to *cells*).\\n\\nA more thorough description of the whole iterator concept can be found in the [Iterators on mesh-like containers](group__Iterators.html) documentation topic.\\n\\n#### Different geometries\\n\\nAnother possibility would be to generate meshes of entirely different geometries altogether. While for complex geometries there is no way around using meshes obtained from mesh generators, there is a good number of geometries for which deal.II can create meshes using the functions in the [GridGenerator](namespaceGridGenerator.html) namespace. Many of these geometries (such as the one used in this example program) contain cells with curved faces: put another way, we expect the new vertices placed on the boundary to lie along a circle. deal.II handles complex geometries with the [Manifold](classManifold.html) class (and classes inheriting from it); in particular, the functions in [GridGenerator](namespaceGridGenerator.html) corresponding to non-Cartesian grids (such as [GridGenerator::hyper\\\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3) or [GridGenerator::truncated\\\\_cone](namespaceGridGenerator.html#ae63c93351f77276c20de07c91d3c1e48)) attach a [Manifold](classManifold.html) object to the part of the triangulation that should be curved ([SphericalManifold](classSphericalManifold.html) and [CylindricalManifold](classCylindricalManifold.html), respectively) and use another manifold on the parts that should be flat ([FlatManifold](classFlatManifold.html)). See the documentation of [Manifold](classManifold.html) or the [manifold topic](group__manifold.html) for descriptions of the design philosophy and interfaces of these classes. Take a look at what they provide and see how they could be used in a program like this.\\n\\nWe also discuss a variety of other ways to create and manipulate meshes (and describe the process of attaching [Manifolds](namespaceManifolds.html)) in [step-49](step_49.html).\\n\\n#### Comments about programming and debugging\\n\\nWe close with a comment about modifying or writing programs with deal.II in general. When you start working with tutorial programs or your own applications, you will find that mistakes happen: your program will contain code that either aborts the program right away or bugs that simply lead to wrong results. In either case, you will find it extremely helpful to know how to work with a debugger: you may get by for a while by just putting debug output into your program, compiling it, and running it, but ultimately finding bugs with a debugger is much faster, much more convenient, and more reliable because you don't have to recompile the program all the time and because you can inspect the values of variables and how they change.\\n\\nRather than postponing learning how to use a debugger till you really can't see any other way to find a bug, here's the one piece of advice we will provide in this program: learn how to use a debugger as soon as possible. It will be time well invested. (See also [video lecture 25](https://www.math.colostate.edu/~bangerth/videos.676.25.html).) The deal.II Frequently Asked Questions (FAQ) page linked to from the top-level [deal.II webpage](http://www.dealii.org/) also provides a good number of hints on debugging deal.II programs.\\n\\n#### More about graphical output\\n\\nIt is often useful to include meshes into your theses or publications. For this, it may not be very useful to color-code the cells by refinement level, and to print the cell number onto each cell. But it doesn't have to be that way – the [GridOut](classGridOut.html) class allows setting flags for each possible output format (see the classes in the [GridOutFlags](namespaceGridOutFlags.html) namespace) that control how exactly a mesh is plotted. You can of course also choose other output file formats such as VTK or VTU; this is particularly useful for 3d meshes where a 2d format such as SVG is not particular useful because it fixes a particular viewpoint onto the 3d object. As a consequence, you might want to explore other options in the [GridOut](classGridOut.html) class.\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 1999 - 2023 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n */\\n \\n \\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n \\n#include <iostream>\\n#include <fstream>\\n#include <cmath>\\n \\nusing namespace dealii;\\n \\n \\nvoid first_grid()\\n{\\n Triangulation<2> triangulation;\\n \\n GridGenerator::hyper_cube(triangulation);\\n triangulation.refine_global(4);\\n \\n  std::ofstream out(\\\"grid-1.svg\\\");\\n GridOut       grid_out;\\n  grid_out.write_svg(triangulation, out);\\n  std::cout << \\\"Grid written to grid-1.svg\\\" << std::endl;\\n}\\n \\n \\n \\n \\nvoid second_grid()\\n{\\n Triangulation<2> triangulation;\\n \\n const Point<2> center(1, 0);\\n const double   inner_radius = 0.5, outer_radius = 1.0;\\n GridGenerator::hyper_shell(\\n triangulation, center, inner_radius, outer_radius, 10);\\n for (unsigned int step = 0; step < 5; ++step)\\n    {\\n for (const auto &cell : triangulation.active_cell_iterators())\\n        {\\n for (const auto v : cell->vertex_indices())\\n            {\\n const double distance_from_center =\\n center.distance(cell->vertex(v));\\n \\n if (std::fabs(distance_from_center - inner_radius) <=\\n                  1e-6 * inner_radius)\\n                {\\n                  cell->set_refine_flag();\\n break;\\n                }\\n            }\\n        }\\n \\n triangulation.execute_coarsening_and_refinement();\\n    }\\n \\n \\n  std::ofstream out(\\\"grid-2.svg\\\");\\n GridOut       grid_out;\\n  grid_out.write_svg(triangulation, out);\\n \\n  std::cout << \\\"Grid written to grid-2.svg\\\" << std::endl;\\n}\\n \\n \\n \\n \\nint main()\\n{\\n  first_grid();\\n  second_grid();\\n}\\n```\\n\"}],\"temperature\":0.2,\"response_format\":{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"finetune_prompt-completion_pair\",\"strict\":true,\"description\":\"A pair of prompt and completion for finetuning a code LLM\",\"schema\":{\"type\":\"object\",\"properties\":{\"prompt\":{\"type\":\"string\",\"description\":\"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\"},\"completion\":{\"type\":\"string\",\"description\":\"The final code completion\"}},\"additionalProperties\":false,\"required\":[\"prompt\",\"completion\"]}}}}}\n",
      "{\"custom_id\":\"https://dealii.org/current/doxygen/deal.II//step_2.html\",\"method\":\"POST\",\"url\":\"/v1/chat/completions\",\"body\":{\"model\":\"gpt-4.1-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nAssociate degrees of freedom to each vertex and compute the resulting sparsity pattern of matrices. Show that renumbering reduces the bandwidth of matrices significantly, i.e. clusters nonzero entries around the diagonal.\\nTutorial content :\\nThis tutorial depends on [step-1](step_1.html).\\n\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_2-Intro)    * [Enumerating degrees of freedom](#step_2-Enumeratingdegreesoffreedom) * [Sparsity](#step_2-Sparsity) * [How degrees of freedom are enumerated](#step_2-Howdegreesoffreedomareenumerated)- [The commented program](#step_2-CommProg)      * [Mesh generation](#step_2-Meshgeneration)* [Outputting the location of degrees of freedom](#step_2-Outputtingthelocationofdegreesoffreedom)* [Creation of a DoFHandler](#step_2-CreationofaDoFHandler)* [Renumbering of DoFs](#step_2-RenumberingofDoFs)* [The main function](#step_2-Themainfunction) | 1. [Results](#step_2-Results)    * [Possibilities for extensions](#step_2-Possibilitiesforextensions)- [The plain program](#step_2-PlainProg) |\\n\\nIntroduction\\n============\\n\\nNote\\n:   The material presented here is also discussed in [video lecture 9](https://www.math.colostate.edu/~bangerth/videos.676.9.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\\n\\nThe finite element method is based on approximating the solution \\\\(u\\\\) of a differential equation such as \\\\(-\\\\Delta u=f\\\\) by a function \\\\(u\\\\_h\\\\) that is \\\"piecewise\\\" polynomial; that is, we subdivide the domain \\\\(\\\\Omega\\\\) on which the equation is posed into small cells that in the documentation we will generally denote by the symbol \\\\(K\\\\). On each cell \\\\(K\\\\), the approximating function \\\\(u\\\\_h\\\\) we seek is then a polynomial. (Or, strictly speaking, a function that is the image of a polynomial from a \\\"reference cell\\\", but let us not make things more complicated than necessary for now.)\\n\\nIn the previous tutorial program (in [step-1](step_1.html)), we showed how we should think of the subdivision of the domain into cells as a \\\"mesh\\\" represented by the [Triangulation](classTriangulation.html) class, and how this looks like in code. In the current tutorial program, we now show how one represents piecewise polynomial functions through the concept of degrees of freedom defined on this mesh. For this example, we will use the lowest order ( \\\\(Q\\\\_1\\\\)) finite elements, that is the approximating function \\\\(u\\\\_h\\\\) we are looking for will be \\\"bi-linear\\\" on each quadrilateral cell \\\\(K\\\\) of the mesh. (They would be linear if we would work on triangles.)\\n\\nIn practice, we represent the function as a linear combination of shape functions \\\\(\\\\varphi\\\\_j(\\\\mathbf x)\\\\) with multipliers \\\\(U\\\\_j\\\\) that we call the \\\"degrees of freedom\\\". For the bi-linear functions we consider here, each of these shape functions and degrees of freedom is associated with a vertex of the mesh. Later examples will demonstrate higher order elements where degrees of freedom are not necessarily associated with vertices any more, but can be associated with edges, faces, or cells.\\n\\nThe term \\\"degree of freedom\\\" is commonly used in the finite element community to indicate two slightly different, but related things. The first is that we'd like to represent the finite element solution as a linear combination of shape functions, in the form \\\\(u\\\\_h(\\\\mathbf x) = \\\\sum\\\\_{j=0}^{N-1} U\\\\_j \\\\varphi\\\\_j(\\\\mathbf\\nx)\\\\). Here, \\\\(U\\\\_j\\\\) is a vector of expansion coefficients. Because we don't know their values yet (we will compute them as the solution of a linear or nonlinear system), they are called \\\"unknowns\\\" or \\\"degrees of freedom\\\". The second meaning of the term can be explained as follows: A mathematical description of finite element problems is often to say that we are looking for a finite dimensional function \\\\(u\\\\_h \\\\in V\\\\_h\\\\) that satisfies some set of equations (e.g. \\\\(a(u\\\\_h,\\\\varphi\\\\_h)=(f,\\\\varphi\\\\_h)\\\\) for all test functions \\\\(\\\\varphi\\\\_h\\\\in\\nV\\\\_h\\\\)). In other words, all we say here is that the solution needs to lie in some space \\\\(V\\\\_h\\\\). However, to actually solve this problem on a computer we need to choose a basis of this space; this is the set of shape functions \\\\(\\\\varphi\\\\_j(\\\\mathbf x)\\\\) we have used above in the expansion of \\\\(u\\\\_h(\\\\mathbf x)\\\\) with coefficients \\\\(U\\\\_j\\\\). There are of course many bases of the space \\\\(V\\\\_h\\\\), but we will specifically choose the one that is described by the finite element functions that are traditionally defined locally on the cells of the mesh.\\n\\n### Enumerating degrees of freedom\\n\\nDescribing \\\"degrees of freedom\\\" in this context requires us to simply *enumerate* the basis functions of the space \\\\(V\\\\_h\\\\). For \\\\(Q\\\\_1\\\\) elements this means simply enumerating the vertices of the mesh in some way, but for higher order elements, one also has to enumerate the shape functions that are associated with edges, faces, or cell interiors of the mesh. In other words, the enumeration of degrees of freedom is an entirely separate thing from the indices we use for vertices. The class that provides this enumeration of the basis functions of \\\\(V\\\\_h\\\\) is called [DoFHandler](classDoFHandler.html).\\n\\nDefining degrees of freedom (\\\"DoF\\\"s in short) on a mesh is, in practice, a rather simple task, since the library does all the work for you. Essentially, all you have to do is create a finite element object (from one of the many finite element classes deal.II already has, see for example the [Finite element space descriptions](group__fe.html) documentation) and give it to a [DoFHandler](classDoFHandler.html) object through the [DoFHandler::distribute\\\\_dofs()](classDoFHandler.html#a553ca864aaf70330d9be86bc78f36d1e) function (\\\"distributing DoFs\\\" is the term we use to describe the process of *enumerating* the basis functions as discussed above). The [DoFHandler](classDoFHandler.html) is a class that knows which degrees of freedom live where, i.e., it can answer questions like \\\"how many degrees of freedom are there globally\\\" and \\\"on this cell, give me the global indices of the shape functions that\\nlive here\\\". This is the sort of information you need when determining how big your system matrix should be, and when copying the contributions of a single cell into the global matrix.\\n\\nThe first task of the current program is therefore to take a mesh and a finite element, and enumerate the degrees of freedom. In the current context, this means simply giving each vertex of the mesh a DoF index. Once that has happened, we will output in a picture which vertex ended up with which DoF index. You can find the corresponding pictures in the [results section](#Results) of this tutorial.\\n\\nIt is probably worth pointing out that where each DoF is geometrically located is not a question we typically ask in finite element codes. Most often, we only care about the fact that there *is* an enumeration of all degrees of freedom, but not which DoF is where. (We will also come back to this below where we talk about renumbering degrees of freedom.) At the same time, it is probably instructive to see this once, and so this program shows such a figure.\\n\\n### Sparsity\\n\\nThe next step would then be to compute a matrix and right hand side corresponding to a particular differential equation using this finite element and mesh. We will keep this step for the [step-3](step_3.html) program and rather talk about one practical aspect of a finite element program, namely that finite element matrices are always very sparse: almost all entries in these matrices are zero.\\n\\nTo be more precise, we say that a matrix is sparse if the number of nonzero entries *per row* in the matrix is bounded by a number that is independent of the overall number of degrees of freedom. For example, the simple 5-point stencil of a finite difference approximation of the Laplace equation leads to a sparse matrix since the number of nonzero entries per row is five, and therefore independent of the total size of the matrix. For more complicated problems – say, the Stokes problem of [step-22](step_22.html) – and in particular in 3d, the number of entries per row may be several hundred. But the important point is that this number is independent of the overall size of the problem: If you refine the mesh, the maximal number of unknowns per row remains the same.\\n\\nSparsity is one of the distinguishing features of the finite element method compared to, say, approximating the solution of a partial differential equation using a Taylor expansion and matching coefficients, or using a Fourier basis.\\n\\nIn practical terms, it is the sparsity of matrices that enables us to solve problems with millions or billions of unknowns. To understand this, note that a matrix with \\\\(N\\\\) rows, each with a fixed upper bound for the number of nonzero entries, requires \\\\({\\\\cal O}(N)\\\\) memory locations for storage, and a matrix-vector multiplication also requires only \\\\({\\\\cal O}(N)\\\\) operations. Consequently, if we had a linear solver that requires only a fixed number of matrix-vector multiplications to come up with the solution of a linear system with this matrix, then we would have a solver that can find the values of all \\\\(N\\\\) unknowns with optimal complexity, i.e., with a total of \\\\({\\\\cal O}(N)\\\\) operations. It is clear that this wouldn't be possible if the matrix were not sparse (because then the number of entries in the matrix would have to be \\\\({\\\\cal O}(N^s)\\\\) with some \\\\(s>1\\\\), and doing a fixed number of matrix-vector products would take \\\\({\\\\cal O}(N^s)\\\\) operations), but it also requires very specialized solvers such as multigrid methods to satisfy the requirement that the solution requires only a fixed number of matrix-vector multiplications. We will frequently look at the question of what solver to use in the remaining programs of this tutorial.\\n\\nThe sparsity is generated by the fact that finite element shape functions are defined *locally* on individual cells, rather than globally, and that the local differential operators in the bilinear form only couple shape functions whose support overlaps. (The \\\"support\\\" of a function is the area where it is nonzero. For the finite element method, the support of a shape function is generally the cells adjacent to the vertex, edge, or face it is defined on.) In other words, degrees of freedom \\\\(i\\\\) and \\\\(j\\\\) that are not defined on the same cell do not overlap, and consequently the matrix entry \\\\(A\\\\_{ij}\\\\) will be zero. (In some cases such as the Discontinuous Galerkin method, shape functions may also connect to neighboring cells through face integrals. But finite element methods do not generally couple shape functions beyond the immediate neighbors of a cell on which the function is defined.)\\n\\n### How degrees of freedom are enumerated\\n\\nBy default, the [DoFHandler](classDoFHandler.html) class enumerates degrees of freedom on a mesh using an algorithm that is difficult to describe and leads to results that do look right if you know what it is doing but otherwise appears rather random; consequently, the sparsity pattern is also not optimized for any particular purpose. To show this, the code below will demonstrate a simple way to output the \\\"sparsity pattern\\\" that corresponds to a [DoFHandler](classDoFHandler.html), i.e., an object that represents all of the potentially nonzero elements of a matrix one may build when discretizing a partial differential equation on a mesh and its [DoFHandler](classDoFHandler.html). This lack of structure in the sparsity pattern will be apparent from the pictures we show below.\\n\\nFor most applications and algorithms, the exact way in which degrees of freedom are numbered does not matter. For example, the Conjugate Gradient method we use to solve linear systems does not care. On the other hand, some algorithms do care: in particular, some preconditioners such as SSOR will work better if they can walk through degrees of freedom in a particular order, and it would be nice if we could just sort them in such a way that SSOR can iterate through them from zero to \\\\(N\\\\) in this order. Other examples include computing incomplete LU or Cholesky factorizations, or if we care about the block structure of matrices (see [step-20](step_20.html) for an example). deal.II therefore has algorithms that can re-enumerate degrees of freedom in particular ways in namespace [DoFRenumbering](namespaceDoFRenumbering.html). Renumbering can be thought of as choosing a different, permuted basis of the finite element space. The sparsity pattern and matrices that result from this renumbering are therefore also simply a permutation of rows and columns compared to the ones we would get without explicit renumbering.\\n\\nIn the program below, we will use the algorithm of Cuthill and McKee to do so. We will show the sparsity pattern for both the original enumeration of degrees of freedom and of the renumbered version below, in the [results section](#Results).\\n\\nThe commented program\\n=====================\\n\\nThe first few includes are just like in the previous program, so do not require additional comments:\\n\\n```\\n   #include <deal.II/grid/tria.h>\\n   #include <deal.II/grid/grid_generator.h>\\n   #include <deal.II/grid/grid_out.h>\\n```\\n\\nHowever, the next file is new. We need this include file for the association of degrees of freedom (\\\"DoF\\\"s) to vertices, lines, and cells:\\n\\n```\\n   #include <deal.II/dofs/dof_handler.h>\\n```\\n\\nThe following include contains the description of the bilinear finite element, including the facts that it has one degree of freedom on each vertex of the triangulation, but none on faces and none in the interior of the cells.\\n\\n(In fact, the file contains the description of Lagrange elements in general, i.e. also the quadratic, cubic, etc versions, and not only for 2d but also 1d and 3d.)\\n\\n```\\n   #include <deal.II/fe/fe_q.h>\\n```\\n\\nIn the following file, several tools for manipulating degrees of freedom can be found, and the one after it is necessary to call one of the functions imported from `dof_tools.h`:\\n\\n```\\n   #include <deal.II/dofs/dof_tools.h>\\n   #include <deal.II/fe/mapping_q1.h>\\n```\\n\\nWe will use a sparse matrix to visualize the pattern of nonzero entries resulting from the distribution of degrees of freedom on the grid. That class can be found here:\\n\\n```\\n   #include <deal.II/lac/sparse_matrix.h>\\n```\\n\\nWe will also need to use an intermediate sparsity pattern structure, which is found in this file :\\n\\n```\\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n```\\n\\nWe will want to use a special algorithm to renumber degrees of freedom. It is declared here:\\n\\n```\\n   #include <deal.II/dofs/dof_renumbering.h>\\n```\\n\\nAnd this is again needed for C++ output:\\n\\n```\\n   #include <fstream>\\n```\\n\\nFinally, as in [step-1](step_1.html), we import the deal.II namespace into the global scope:\\n\\n```\\n   using namespace dealii;\\n```\\n\\n### Mesh generation\\n\\nThis is the function that produced the circular grid in the previous [step-1](step_1.html) example program with fewer refinements steps. The sole difference is that it returns the grid it produces via its argument.\\n\\nAt the end of the function, we also output this mesh into a file. We will use this as one piece of information when visualizing the location of degrees of freedom. To output a mesh, we use the [GridOut](classGridOut.html) class that you have already seen in [step-1](step_1.html); the difference is only that we use gnuplot rather than SVG format, because gnuplot is the program we will use to visualize DoF locations.\\n\\n```\\n   void make_grid(Triangulation<2> &triangulation)\\n   {\\n     const Point<2> center(1, 0);\\n     const double   inner_radius = 0.5, outer_radius = 1.0;\\n     GridGenerator::hyper_shell(\\n       triangulation, center, inner_radius, outer_radius, 5);\\n   \\n     for (unsigned int step = 0; step < 3; ++step)\\n       {\\n         for (const auto &cell : triangulation.active_cell_iterators())\\n           for (const auto v : cell->vertex_indices())\\n             {\\n               const double distance_from_center =\\n                 center.distance(cell->vertex(v));\\n   \\n               if (std::fabs(distance_from_center - inner_radius) <=\\n                   1e-6 * inner_radius)\\n                 {\\n                   cell->set_refine_flag();\\n                   break;\\n                 }\\n             }\\n   \\n         triangulation.execute_coarsening_and_refinement();\\n       }\\n   \\n     std::ofstream mesh_file(\\\"mesh.gnuplot\\\");\\n     GridOut().write_gnuplot(triangulation, mesh_file);\\n   }\\n```\\n\\n### Outputting the location of degrees of freedom\\n\\nThe next function outputs the locations of degrees of freedom for later visualization. Where each DoF is located is something the [DoFHandler](classDoFHandler.html) object knows, so that is one of the arguments to this function. Since we want to do all of this twice (once for the original enumeration and once for the renumbered set of degrees of freedom), the function also takes as a second argument the name of the file into which we want the output to be written.\\n\\nIn order to learn deal.II, it is probably not terribly important to understand exactly what this function does, and you can skip over it. But if you would like to know anyway: We want to call the function [DoFTools::map\\\\_dofs\\\\_to\\\\_support\\\\_points()](namespaceDoFTools.html#a621c66a6f7e56cb56faac0e64014ece8) that returns a list of locations. It does so in the form of a map through which we can query (in a statement such as `dof_location_map[42]`) where the DoF is located (in the example, where the 42nd DoF is). It puts this information into the `dof_location_map` object.\\n\\nWe then use the function [DoFTools::write\\\\_gnuplot\\\\_dof\\\\_support\\\\_point\\\\_info()](namespaceDoFTools.html#a69d19d6d574269cc6e69fa5c5b2d89e2) to write this information into a file in a format that is understandable to the gnuplot program that we will use for visualization in the results section.\\n\\n```\\n   void write_dof_locations(const DoFHandler<2> &dof_handler,\\n                            const std::string   &filename)\\n   {\\n     const std::map<types::global_dof_index, Point<2>> dof_location_map =\\n       DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\\n   \\n     std::ofstream dof_location_file(filename);\\n     DoFTools::write_gnuplot_dof_support_point_info(dof_location_file,\\n                                                    dof_location_map);\\n   }\\n```\\n\\n### Creation of a [DoFHandler](classDoFHandler.html)\\n\\nUp to now, we only have a grid, i.e. some geometrical (the position of the vertices) and some topological information (how vertices are connected to lines, and lines to cells, as well as which cells neighbor which other cells). To use numerical algorithms, one needs some logic information in addition to that: we would like to associate degree of freedom numbers to each vertex (or line, or cell, in case we were using higher order elements) to later generate matrices and vectors which describe a finite element field on the triangulation.\\n\\nThis function shows how to do this. The object to consider is the `DoFHandler` class template. Before we do so, however, we first need something that describes how many degrees of freedom are to be associated to each of these objects. Since this is one aspect of the definition of a finite element space, the finite element base class stores this information. In the present context, we therefore create an object of the derived class `FE_Q` that describes Lagrange elements. Its constructor takes one argument that states the polynomial degree of the element, which here is one (indicating a bi-linear element); this then corresponds to one degree of freedom for each vertex, while there are none on lines and inside the quadrilateral. A value of, say, three given to the constructor would instead give us a bi-cubic element with one degree of freedom per vertex, two per line, and four inside the cell. In general, `FE_Q` denotes the family of continuous elements with complete polynomials (i.e. tensor-product polynomials) up to the specified order.\\n\\nWe first need to create an object of this class and then pass it on to the `DoFHandler` object to allocate storage for the degrees of freedom (in deal.II lingo: we *distribute degrees of freedom*).\\n\\n```\\n   void distribute_dofs(DoFHandler<2> &dof_handler)\\n   {\\n     const FE_Q<2> finite_element(1);\\n     dof_handler.distribute_dofs(finite_element);\\n```\\n\\nNow that we have associated a degree of freedom with a global number to each vertex, Let us output this information using the function above:\\n\\n```\\n     write_dof_locations(dof_handler, \\\"dof-locations-1.gnuplot\\\");\\n```\\n\\nIn practice, we do not often care about where a degree of freedom is geometrically located, and so other than seeing it once via the call above is not practically useful. But where two degrees of freedom are in relation to each other matters in other ways.\\n\\nAssociated with each vertex of the triangulation is a shape function. Assume we want to solve something like Laplace's equation, then the different matrix entries will be the integrals over the gradient of each pair of such shape functions. Obviously, since the shape functions are nonzero only on the cells adjacent to the vertex they are associated with, matrix entries will be nonzero only if the supports of the shape functions associated to that column and row numbers intersect. This is only the case for adjacent shape functions, and therefore only for adjacent vertices. Now, since the vertices are numbered more or less randomly by the above function ([DoFHandler::distribute\\\\_dofs](classDoFHandler.html#a553ca864aaf70330d9be86bc78f36d1e)), the pattern of nonzero entries in the matrix will be somewhat ragged, and we will take a look at it now.\\n\\nFirst we have to create a structure which we use to store the places of nonzero elements. This can then later be used by one or more sparse matrix objects that store the values of the entries in the locations stored by this sparsity pattern. The class that stores the locations is the [SparsityPattern](classSparsityPattern.html) class. As it turns out, however, this class has some drawbacks when we try to fill it right away: its data structures are set up in such a way that we need to have an estimate for the maximal number of entries we may wish to have in each row. In two space dimensions, reasonable values for this estimate are available through the [DoFHandler::max\\\\_couplings\\\\_between\\\\_dofs()](classDoFHandler.html#a198c25ff9747d228eb9afa998e716f18) function, but in three dimensions the function almost always severely overestimates the true number, leading to a lot of wasted memory, sometimes too much for the machine used, even if the unused memory can be released immediately after computing the sparsity pattern. In order to avoid this, we use an intermediate object of type [DynamicSparsityPattern](classDynamicSparsityPattern.html) that uses a different internal data structure and that we can later copy into the [SparsityPattern](classSparsityPattern.html) object without much overhead. (Some more information on these data structures can be found in the [Sparsity patterns](group__Sparsity.html) topic.) In order to initialize this intermediate data structure, we have to give it the size of the matrix, which in our case will be square with as many rows and columns as there are degrees of freedom on the grid:\\n\\n```\\n     DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\\n                                                     dof_handler.n_dofs());\\n```\\n\\nWe then fill this object with the places where nonzero elements will be located given the present numbering of degrees of freedom:\\n\\n```\\n     DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n```\\n\\nNow we are ready to create the actual sparsity pattern that we could later use for our matrix. It will just contain the data already assembled in the [DynamicSparsityPattern](classDynamicSparsityPattern.html).\\n\\n```\\n     SparsityPattern sparsity_pattern;\\n     sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n```\\n\\nWith this, we can now write the results to a file :\\n\\n```\\n     std::ofstream out(\\\"sparsity-pattern-1.svg\\\");\\n     sparsity_pattern.print_svg(out);\\n```\\n\\nThe result is stored in an `.svg` file, where each nonzero entry in the matrix corresponds with a red square in the image. The output will be shown below.\\n\\nIf you look at it, you will note that the sparsity pattern is symmetric. This should not come as a surprise, since we have not given the `DoFTools::make_sparsity_pattern` any information that would indicate that our bilinear form may couple shape functions in a non-symmetric way. You will also note that it has several distinct region, which stem from the fact that the numbering starts from the coarsest cells and moves on to the finer ones; since they are all distributed symmetrically around the origin, this shows up again in the sparsity pattern.\\n\\n```\\n   }\\n```\\n\\n### Renumbering of DoFs\\n\\nIn the sparsity pattern produced above, the nonzero entries extended quite far off from the diagonal. For some algorithms, for example for incomplete LU decompositions or Gauss-Seidel preconditioners, this is unfavorable, and we will show a simple way how to improve this situation.\\n\\nRemember that for an entry \\\\((i,j)\\\\) in the matrix to be nonzero, the supports of the shape functions i and j needed to intersect (otherwise in the integral, the integrand would be zero everywhere since either the one or the other shape function is zero at some point). However, the supports of shape functions intersected only if they were adjacent to each other, so in order to have the nonzero entries clustered around the diagonal (where \\\\(i\\\\) equals \\\\(j\\\\)), we would like to have adjacent shape functions to be numbered with indices (DoF numbers) that differ not too much.\\n\\nThis can be accomplished by a simple front marching algorithm, where one starts at a given vertex and gives it the index zero. Then, its neighbors are numbered successively, making their indices close to the original one. Then, their neighbors, if not yet numbered, are numbered, and so on.\\n\\nOne algorithm that adds a little bit of sophistication along these lines is the one by Cuthill and McKee. We will use it in the following function to renumber the degrees of freedom such that the resulting sparsity pattern is more localized around the diagonal. The only interesting part of the function is the first call to `DoFRenumbering::Cuthill_McKee`, the rest is essentially as before:\\n\\n```\\n   void renumber_dofs(DoFHandler<2> &dof_handler)\\n   {\\n     DoFRenumbering::Cuthill_McKee(dof_handler);\\n   \\n     write_dof_locations(dof_handler, \\\"dof-locations-2.gnuplot\\\");\\n   \\n   \\n     DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\\n                                                     dof_handler.n_dofs());\\n     DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n   \\n     SparsityPattern sparsity_pattern;\\n     sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n   \\n     std::ofstream out(\\\"sparsity-pattern-2.svg\\\");\\n     sparsity_pattern.print_svg(out);\\n   }\\n```\\n\\nAgain, the output is shown below. Note that the nonzero entries are clustered far better around the diagonal than before. This effect is even more distinguished for larger matrices (the present one has 1260 rows and columns, but large matrices often have several 100,000s).\\n\\nIt is worth noting that the `DoFRenumbering` class offers a number of other algorithms as well to renumber degrees of freedom. For example, it would of course be ideal if all couplings were in the lower or upper triangular part of a matrix, since then solving the linear system would amount to only forward or backward substitution. This is of course unachievable for symmetric sparsity patterns, but in some special situations involving transport equations, this is possible by enumerating degrees of freedom from the inflow boundary along streamlines to the outflow boundary. Not surprisingly, `DoFRenumbering` also has algorithms for this.\\n\\n### The main function\\n\\nFinally, this is the main program. The only thing it does is to allocate and create the triangulation, then create a `DoFHandler` object and associate it to the triangulation, and finally call above two functions on it:\\n\\n```\\n   int main()\\n   {\\n     Triangulation<2> triangulation;\\n     make_grid(triangulation);\\n   \\n     DoFHandler<2> dof_handler(triangulation);\\n   \\n     distribute_dofs(dof_handler);\\n     renumber_dofs(dof_handler);\\n   }\\n```\\n\\nResults\\n=======\\n\\nThe program has, after having been run, produced two files of DoF locations and sparsity patterns each (once for the original numbering and once after renumbering), along with one mesh file.\\n\\nLet us start with the DoF locations. There is no particularly convenient program to visualize this kind of information, but we can resort to [GNUPLOT](http://www.gnuplot.info/) (one of the simpler visualization programs; maybe not the easiest to use since it is command line driven, but also universally available on all Linux and other Unix-like systems). The command that produces the following pictures reads as follows:\\n\\n```\\nplot [-0.1:2.1][-1.1:1.1] \\\"mesh.gnuplot\\\" with lines, \\\"dof-locations-1.gnuplot\\\" using 1:2:3 with labels point offset .3,.2 font \\\"4,6\\\"\\n```\\n\\nThis may be cryptic, but what exactly this does is also not particularly important and you shouldn't spend too much time understanding what it does. Rather, the important part is to look at what we get as output:\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nWhat these figures show is (i) a numeric label attached to each vertex – the DoF index, and (ii) that the original enumeration on the left differs from the renumbered one on the right. Which of the two is \\\"better\\\" is of course a different question (with the answer depending on what we want to do with these degrees of freedom); the important point is that for the same mesh, one can come up with many different enumerations of the degrees of freedom.\\n\\nAs for the sparsity patterns, we can visualize these by opening the `.svg` files in a web browser. The pictures below represent the matrix, and every red square denotes an entry which might be nonzero. (Whether the entry actually is zero or not depends on the equation under consideration, but the indicated positions in the matrix tell us which shape functions can and which can't couple when discretizing a local, i.e. differential, equation.)\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nThe different regions in the left picture, indicated by kinks in the lines and single dots on the left and top, represent the degrees of freedom on the different refinement levels of the triangulation. As can be seen in the right picture, the sparsity pattern is much better clustered around the main diagonal of the matrix after renumbering. Although this might not be apparent, the number of nonzero entries is the same in both pictures, of course.\\n\\n### Possibilities for extensions\\n\\nJust as with [step-1](step_1.html), you may want to play with the program a bit to familiarize yourself with deal.II. For example, in the `distribute_dofs` function, we use linear finite elements (that's what the argument \\\"1\\\" to the [FE\\\\_Q](classFE__Q.html) object is). Explore how the sparsity pattern changes if you use higher order elements, for example cubic or quintic ones (by using 3 and 5 as the respective arguments). You might also want to see where DoFs are now located – but for that you likely want to work with a mesh with fewer cells because DoFs are now also located on edges and in the interior of cells.\\n\\nYou could also explore how the sparsity pattern changes by refining the mesh. You will see that not only the size of the matrix changes, but also its bandwidth (the distance from the diagonal of those nonzero elements of the matrix that are farthest away from the diagonal), though the ratio of bandwidth to size typically shrinks, i.e. the matrix clusters more around the diagonal.\\n\\nAnother idea of experiments would be to try other renumbering strategies than Cuthill-McKee from the [DoFRenumbering](namespaceDoFRenumbering.html) namespace and see how they affect the sparsity pattern.\\n\\nYou can also visualize the output using [GNUPLOT](http://www.gnuplot.info/) (which we have already used above) by changing from `print_svg()` to `print_gnuplot()` in `distribute_dofs()` and `renumber_dofs()` (and using the file ending `.gnuplot` instead of `.svg`):\\n\\n```\\nexamples/step-2> gnuplot\\n \\n        G N U P L O T\\n        Version 3.7 patchlevel 3\\n        last modified Thu Dec 12 13:00:00 GMT 2002\\n        System: Linux 2.6.11.4-21.10-default\\n \\n        Copyright(C) 1986 - 1993, 1998 - 2002\\n        Thomas Williams, Colin Kelley and many others\\n \\n        Type `help` to access the on-line reference manual\\n        The gnuplot FAQ is available from\\n        http://www.gnuplot.info/gnuplot-faq.html\\n \\n        Send comments and requests for help to <info-gnuplot@dartmouth.edu>\\n        Send bugs, suggestions and mods to <bug-gnuplot@dartmouth.edu>\\n \\n \\nTerminal type set to 'x11'\\ngnuplot> set style data points\\ngnuplot> plot \\\"sparsity-pattern-1.gnuplot\\\"\\n```\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 1999 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n */\\n \\n \\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_out.h>\\n \\n#include <deal.II/dofs/dof_handler.h>\\n \\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/mapping_q1.h>\\n \\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n \\n#include <deal.II/dofs/dof_renumbering.h>\\n \\n#include <fstream>\\n \\nusing namespace dealii;\\n \\n \\n \\nvoid make_grid(Triangulation<2> &triangulation)\\n{\\n const Point<2> center(1, 0);\\n const double   inner_radius = 0.5, outer_radius = 1.0;\\n GridGenerator::hyper_shell(\\n triangulation, center, inner_radius, outer_radius, 5);\\n \\n for (unsigned int step = 0; step < 3; ++step)\\n    {\\n for (const auto &cell : triangulation.active_cell_iterators())\\n        for (const auto v : cell->vertex_indices())\\n          {\\n const double distance_from_center =\\n center.distance(cell->vertex(v));\\n \\n if (std::fabs(distance_from_center - inner_radius) <=\\n                1e-6 * inner_radius)\\n              {\\n                cell->set_refine_flag();\\n break;\\n              }\\n          }\\n \\n triangulation.execute_coarsening_and_refinement();\\n    }\\n \\n  std::ofstream mesh_file(\\\"mesh.gnuplot\\\");\\n GridOut().write_gnuplot(triangulation, mesh_file);\\n}\\n \\n \\n \\nvoid write_dof_locations(const DoFHandler<2> &dof_handler,\\n const std::string   &filename)\\n{\\n const std::map<types::global_dof_index, Point<2>> dof_location_map =\\n DoFTools::map_dofs_to_support_points(MappingQ1<2>(), dof_handler);\\n \\n  std::ofstream dof_location_file(filename);\\n DoFTools::write_gnuplot_dof_support_point_info(dof_location_file,\\n                                                 dof_location_map);\\n}\\n \\n \\n \\nvoid distribute_dofs(DoFHandler<2> &dof_handler)\\n{\\n const FE_Q<2> finite_element(1);\\n  dof_handler.distribute_dofs(finite_element);\\n \\n  write_dof_locations(dof_handler, \\\"dof-locations-1.gnuplot\\\");\\n \\n DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\\n                                                  dof_handler.n_dofs());\\n \\n DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n \\n SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n \\n  std::ofstream out(\\\"sparsity-pattern-1.svg\\\");\\n  sparsity_pattern.print_svg(out);\\n}\\n \\n \\n \\nvoid renumber_dofs(DoFHandler<2> &dof_handler)\\n{\\n DoFRenumbering::Cuthill_McKee(dof_handler);\\n \\n  write_dof_locations(dof_handler, \\\"dof-locations-2.gnuplot\\\");\\n \\n \\n DynamicSparsityPattern dynamic_sparsity_pattern(dof_handler.n_dofs(),\\n                                                  dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dynamic_sparsity_pattern);\\n \\n SparsityPattern sparsity_pattern;\\n  sparsity_pattern.copy_from(dynamic_sparsity_pattern);\\n \\n  std::ofstream out(\\\"sparsity-pattern-2.svg\\\");\\n  sparsity_pattern.print_svg(out);\\n}\\n \\n \\n \\n \\n \\nint main()\\n{\\n Triangulation<2> triangulation;\\n  make_grid(triangulation);\\n \\n DoFHandler<2> dof_handler(triangulation);\\n \\n  distribute_dofs(dof_handler);\\n  renumber_dofs(dof_handler);\\n}\\n```\\n\"}],\"temperature\":0.2,\"response_format\":{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"finetune_prompt-completion_pair\",\"strict\":true,\"description\":\"A pair of prompt and completion for finetuning a code LLM\",\"schema\":{\"type\":\"object\",\"properties\":{\"prompt\":{\"type\":\"string\",\"description\":\"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\"},\"completion\":{\"type\":\"string\",\"description\":\"The final code completion\"}},\"additionalProperties\":false,\"required\":[\"prompt\",\"completion\"]}}}}}\n",
      "{\"custom_id\":\"https://dealii.org/current/doxygen/deal.II//step_3.html\",\"method\":\"POST\",\"url\":\"/v1/chat/completions\",\"body\":{\"model\":\"gpt-4.1-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nActually solve Laplace's problem. Object-orientation. Assembling matrices and vectors. Boundary values.\\nTutorial content :\\nThis tutorial depends on [step-2](step_2.html).\\n\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_3-Intro)    * [The basic set up of finite element methods](#step_3-Thebasicsetupoffiniteelementmethods)* [Should we multiply by a test function from the left or from the right?](#step_3-Shouldwemultiplybyatestfunctionfromtheleftorfromtheright) * [\\\\*Assembling\\\\* the matrix and right hand side vector](#step_3-Assemblingthematrixandrighthandsidevector) * [Solving the linear system](#step_3-Solvingthelinearsystem) * [About the implementation](#step_3-Abouttheimplementation)* [A note on types](#step_3-Anoteontypes)- [The commented program](#step_3-CommProg)      * [Many new include files](#step_3-Manynewincludefiles)* [The `Step3` class](#step_3-ThecodeStep3codeclass)          + [Step3::Step3](#step_3-Step3Step3)+ [Step3::make\\\\_grid](#step_3-Step3make_grid)+ [Step3::setup\\\\_system](#step_3-Step3setup_system)+ [Step3::assemble\\\\_system](#step_3-Step3assemble_system)+ [Step3::solve](#step_3-Step3solve)+ [Step3::output\\\\_results](#step_3-Step3output_results)+ [Step3::run](#step_3-Step3run)* [The `main` function](#step_3-Thecodemaincodefunction) | 1. [Results](#step_3-Results)    * [Possibilities for extensions](#step_3-Possibilitiesforextensions)* [Using HDF5 to output the solution and additional data](#step_3-UsingHDF5tooutputthesolutionandadditionaldata)        + [Changing the output to .h5](#step_3-Changingtheoutputtoh5)+ [Adding the point value and the mean (see extension above) into the .h5 file](#step_3-Addingthepointvalueandthemeanseeextensionaboveintotheh5file)* [Using R and ggplot2 to generate plots](#step_3-UsingRandggplot2togenerateplots)* [Using python to generate plots](#step_3-Usingpythontogenerateplots)- [The plain program](#step_3-PlainProg) |\\n\\nIntroduction\\n============\\n\\nNote\\n:   The material presented here is also discussed in [video lecture 10](https://www.math.colostate.edu/~bangerth/videos.676.10.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\\n\\n### The basic set up of finite element methods\\n\\nThis is the first example where we actually use finite elements to compute something. We will solve a simple version of Poisson's equation with zero boundary values, but a nonzero right hand side:\\n\\n\\\\begin{align\\\\*}\\n-\\\\Delta u &= f \\\\qquad\\\\qquad & \\\\text{in}\\\\ \\\\Omega,\\n\\\\\\\\\\nu &= 0 \\\\qquad\\\\qquad & \\\\text{on}\\\\ \\\\partial\\\\Omega.\\n\\\\end{align\\\\*}\\n\\nWe will solve this equation on the square, \\\\(\\\\Omega=[-1,1]^2\\\\), for which you've already learned how to generate a mesh in [step-1](step_1.html) and [step-2](step_2.html). In this program, we will also only consider the particular case \\\\(f(\\\\mathbf x)=1\\\\) and come back to how to implement the more general case in the next tutorial program, [step-4](step_4.html).\\n\\nIf you've learned about the basics of the finite element method, you will remember the steps we need to take to approximate the solution \\\\(u\\\\) by a finite dimensional approximation. Specifically, we first need to derive the weak form of the equation above, which we obtain by multiplying the equation by a test function \\\\(\\\\varphi\\\\) *from the left* (we will come back to the reason for multiplying from the left and not from the right below) and integrating over the domain \\\\(\\\\Omega\\\\):\\n\\n\\\\begin{align\\\\*}\\n-\\\\int\\\\_\\\\Omega \\\\varphi \\\\Delta u = \\\\int\\\\_\\\\Omega \\\\varphi f.\\n\\\\end{align\\\\*}\\n\\nThis can be integrated by parts:\\n\\n\\\\begin{align\\\\*}\\n\\\\int\\\\_\\\\Omega \\\\nabla\\\\varphi \\\\cdot \\\\nabla u\\n-\\n\\\\int\\\\_{\\\\partial\\\\Omega} \\\\varphi \\\\mathbf{n}\\\\cdot \\\\nabla u\\n= \\\\int\\\\_\\\\Omega \\\\varphi f.\\n\\\\end{align\\\\*}\\n\\nThe test function \\\\(\\\\varphi\\\\) has to satisfy the same kind of boundary conditions (in mathematical terms: it needs to come from the tangent space of the set in which we seek the solution), so on the boundary \\\\(\\\\varphi=0\\\\) and consequently the weak form we are looking for reads\\n\\n\\\\begin{align\\\\*}\\n(\\\\nabla\\\\varphi, \\\\nabla u)\\n= (\\\\varphi, f),\\n\\\\end{align\\\\*}\\n\\nwhere we have used the common notation \\\\((a,b)=\\\\int\\\\_\\\\Omega a\\\\; b\\\\). The problem then asks for a function \\\\(u\\\\) for which this statement is true for all test functions \\\\(\\\\varphi\\\\) from the appropriate space (which here is the space \\\\(H^1\\\\)).\\n\\nOf course we can't find such a function on a computer in the general case, and instead we seek an approximation \\\\(u\\\\_h(\\\\mathbf x)=\\\\sum\\\\_j U\\\\_j \\\\varphi\\\\_j(\\\\mathbf\\nx)\\\\), where the \\\\(U\\\\_j\\\\) are unknown expansion coefficients we need to determine (the \\\"degrees of freedom\\\" of this problem), and \\\\(\\\\varphi\\\\_i(\\\\mathbf x)\\\\) are the finite element shape functions we will use. To define these shape functions, we need the following:\\n\\n* A mesh on which to define shape functions. You have already seen how to generate and manipulate the objects that describe meshes in [step-1](step_1.html) and [step-2](step_2.html).\\n* A finite element that describes the shape functions we want to use on the reference cell (which in deal.II is always the unit interval \\\\([0,1]\\\\), the unit square \\\\([0,1]^2\\\\) or the unit cube \\\\([0,1]^3\\\\), depending on which space dimension you work in). In [step-2](step_2.html), we had already used an object of type FE\\\\_Q<2>, which denotes the usual Lagrange elements that define shape functions by interpolation on support points. The simplest one is FE\\\\_Q<2>(1), which uses polynomial degree 1. In 2d, these are often referred to as *bilinear*, since they are linear in each of the two coordinates of the reference cell. (In 1d, they would be *linear* and in 3d *tri-linear*; however, in the deal.II documentation, we will frequently not make this distinction and simply always call these functions \\\"linear\\\".)\\n* A [DoFHandler](classDoFHandler.html) object that enumerates all the degrees of freedom on the mesh, taking the reference cell description the finite element object provides as the basis. You've also already seen how to do this in [step-2](step_2.html).\\n* A mapping that tells how the shape functions on the real cell are obtained from the shape functions defined by the finite element class on the reference cell. By default, unless you explicitly say otherwise, deal.II will use a (bi-, tri-)linear mapping for this, so in most cases you don't have to worry about this step.\\n\\nThrough these steps, we now have a set of functions \\\\(\\\\varphi\\\\_i\\\\), and we can define the weak form of the discrete problem: Find a function \\\\(u\\\\_h\\\\), i.e., find the expansion coefficients \\\\(U\\\\_j\\\\) mentioned above, so that\\n\\n\\\\begin{align\\\\*}\\n(\\\\nabla\\\\varphi\\\\_i, \\\\nabla u\\\\_h)\\n= (\\\\varphi\\\\_i, f),\\n\\\\qquad\\\\qquad\\ni=0\\\\ldots N-1.\\n\\\\end{align\\\\*}\\n\\nNote that we here follow the convention that everything is counted starting at zero, as common in C and C++. This equation can be rewritten as a linear system if you insert the representation \\\\(u\\\\_h(\\\\mathbf x)=\\\\sum\\\\_j U\\\\_j\\n\\\\varphi\\\\_j(\\\\mathbf x)\\\\) and then observe that\\n\\n\\\\begin{align\\\\*}\\n(\\\\nabla\\\\varphi\\\\_i, \\\\nabla u\\\\_h)\\n&= \\\\left(\\\\nabla\\\\varphi\\\\_i, \\\\nabla \\\\Bigl[\\\\sum\\\\_j U\\\\_j \\\\varphi\\\\_j\\\\Bigr]\\\\right)\\n\\\\\\\\\\n&= \\\\sum\\\\_j \\\\left(\\\\nabla\\\\varphi\\\\_i, \\\\nabla \\\\left[U\\\\_j \\\\varphi\\\\_j\\\\right]\\\\right)\\n\\\\\\\\\\n&= \\\\sum\\\\_j \\\\left(\\\\nabla\\\\varphi\\\\_i, \\\\nabla \\\\varphi\\\\_j \\\\right) U\\\\_j.\\n\\\\end{align\\\\*}\\n\\nWith this, the problem reads: Find a vector \\\\(U\\\\) so that\\n\\n\\\\begin{align\\\\*}\\nA U = F,\\n\\\\end{align\\\\*}\\n\\nwhere the matrix \\\\(A\\\\) and the right hand side \\\\(F\\\\) are defined as\\n\\n\\\\begin{align\\\\*}\\nA\\\\_{ij} &= (\\\\nabla\\\\varphi\\\\_i, \\\\nabla \\\\varphi\\\\_j),\\n\\\\\\\\\\nF\\\\_i &= (\\\\varphi\\\\_i, f).\\n\\\\end{align\\\\*}\\n\\n### Should we multiply by a test function from the left or from the right?\\n\\nBefore we move on with describing how these quantities can be computed, note that if we had multiplied the original equation from the *right* by a test function rather than from the left, then we would have obtained a linear system of the form\\n\\n\\\\begin{align\\\\*}\\nU^T A = F^T\\n\\\\end{align\\\\*}\\n\\nwith a row vector \\\\(F^T\\\\). By transposing this system, this is of course equivalent to solving\\n\\n\\\\begin{align\\\\*}\\nA^T U = F\\n\\\\end{align\\\\*}\\n\\nwhich here is the same as above since \\\\(A=A^T\\\\). But in general is not, and in order to avoid any sort of confusion, experience has shown that simply getting into the habit of multiplying the equation from the left rather than from the right (as is often done in the mathematical literature) avoids a common class of errors as the matrix is automatically correct and does not need to be transposed when comparing theory and implementation. See [step-9](step_9.html) for the first example in this tutorial where we have a non-symmetric bilinear form for which it makes a difference whether we multiply from the right or from the left.\\n\\n### *Assembling* the matrix and right hand side vector\\n\\nNow we know what we need (namely: objects that hold the matrix and vectors, as well as ways to compute \\\\(A\\\\_{ij},F\\\\_i\\\\)), and we can look at what it takes to make that happen:\\n\\n* The object for \\\\(A\\\\) is of type [SparseMatrix](classSparseMatrix.html) while those for \\\\(U\\\\) and \\\\(F\\\\) are of type [Vector](classVector.html). We will see in the program below what classes are used to solve linear systems.\\n* We need a way to form the integrals. In the finite element method, this is most commonly done using quadrature, i.e. the integrals are replaced by a weighted sum over a set of *quadrature points* on each cell. That is, we first split the integral over \\\\(\\\\Omega\\\\) into integrals over all cells,\\n\\n  \\\\begin{align\\\\*}\\n  A\\\\_{ij} &= (\\\\nabla\\\\varphi\\\\_i, \\\\nabla \\\\varphi\\\\_j)\\n  = \\\\sum\\\\_{K \\\\in {\\\\mathbb T}} \\\\int\\\\_K \\\\nabla\\\\varphi\\\\_i \\\\cdot \\\\nabla \\\\varphi\\\\_j,\\n  \\\\\\\\\\n  F\\\\_i &= (\\\\varphi\\\\_i, f)\\n  = \\\\sum\\\\_{K \\\\in {\\\\mathbb T}} \\\\int\\\\_K \\\\varphi\\\\_i f,\\n  \\\\end{align\\\\*}\\n\\n  and then approximate each cell's contribution by quadrature:\\n\\n  \\\\begin{align\\\\*}\\n  A^K\\\\_{ij} &=\\n  \\\\int\\\\_K \\\\nabla\\\\varphi\\\\_i \\\\cdot \\\\nabla \\\\varphi\\\\_j\\n  \\\\approx\\n  \\\\sum\\\\_q \\\\nabla\\\\varphi\\\\_i(\\\\mathbf x^K\\\\_q) \\\\cdot \\\\nabla\\n  \\\\varphi\\\\_j(\\\\mathbf x^K\\\\_q) w\\\\_q^K,\\n  \\\\\\\\\\n  F^K\\\\_i &=\\n  \\\\int\\\\_K \\\\varphi\\\\_i f\\n  \\\\approx\\n  \\\\sum\\\\_q \\\\varphi\\\\_i(\\\\mathbf x^K\\\\_q) f(\\\\mathbf x^K\\\\_q) w^K\\\\_q,\\n  \\\\end{align\\\\*}\\n\\n  where \\\\(\\\\mathbb{T} \\\\approx \\\\Omega\\\\) is a [Triangulation](classTriangulation.html) approximating the domain, \\\\(\\\\mathbf x^K\\\\_q\\\\) is the \\\\(q\\\\)th quadrature point on cell \\\\(K\\\\), and \\\\(w^K\\\\_q\\\\) the \\\\(q\\\\)th quadrature weight. There are different parts to what is needed in doing this, and we will discuss them in turn next.\\n* First, we need a way to describe the location \\\\(\\\\mathbf x\\\\_q^K\\\\) of quadrature points and their weights \\\\(w^K\\\\_q\\\\). They are usually mapped from the reference cell in the same way as shape functions, i.e., implicitly using the [MappingQ1](classMappingQ1.html) class or, if you explicitly say so, through one of the other classes derived from [Mapping](classMapping.html \\\"Abstract base class for mapping classes.\\\"). The locations and weights on the reference cell are described by objects derived from the [Quadrature](classQuadrature.html) base class. Typically, one chooses a quadrature formula (i.e. a set of points and weights) so that the quadrature exactly equals the integral in the matrix; this can be achieved because all factors in the integral are polynomial, and is done by Gaussian quadrature formulas, implemented in the [QGauss](classQGauss.html) class.\\n* We then need something that can help us evaluate \\\\(\\\\varphi\\\\_i(\\\\mathbf x^K\\\\_q)\\\\) on cell \\\\(K\\\\). This is what the [FEValues](classFEValues.html) class does: it takes a finite element objects to describe \\\\(\\\\varphi\\\\) on the reference cell, a quadrature object to describe the quadrature points and weights, and a mapping object (or implicitly takes the [MappingQ1](classMappingQ1.html) class) and provides values and derivatives of the shape functions on the real cell \\\\(K\\\\) as well as all sorts of other information needed for integration, at the quadrature points located on \\\\(K\\\\).\\n\\nThe process of computing the matrix and right hand side as a sum over all cells (and then a sum over quadrature points) is usually called *assembling the linear system*, or *assembly* for short, using the meaning of the word related to [assembly line](https://en.wikipedia.org/wiki/Assembly_line), meaning [\\\"the act of putting together a set of pieces, fragments, or elements\\\"](https://en.wiktionary.org/wiki/assembly).\\n\\n[FEValues](classFEValues.html) really is the central class in the assembly process. One way you can view it is as follows: The [FiniteElement](classFiniteElement.html) and derived classes describe shape *functions*, i.e., infinite dimensional objects: functions have values at every point. We need this for theoretical reasons because we want to perform our analysis with integrals over functions. However, for a computer, this is a very difficult concept, since they can in general only deal with a finite amount of information, and so we replace integrals by sums over quadrature points that we obtain by mapping (the [Mapping](classMapping.html \\\"Abstract base class for mapping classes.\\\") object) using points defined on a reference cell (the [Quadrature](classQuadrature.html) object) onto points on the real cell. In essence, we reduce the problem to one where we only need a finite amount of information, namely shape function values and derivatives, quadrature weights, normal vectors, etc, exclusively at a finite set of points. The [FEValues](classFEValues.html) class is the one that brings the three components together and provides this finite set of information on a particular cell \\\\(K\\\\). You will see it in action when we assemble the linear system below.\\n\\nIt is noteworthy that all of this could also be achieved if you simply created these three objects yourself in an application program, and juggled the information yourself. However, this would neither be simpler (the [FEValues](classFEValues.html) class provides exactly the kind of information you actually need) nor faster: the [FEValues](classFEValues.html) class is highly optimized to only compute on each cell the particular information you need; if anything can be re-used from the previous cell, then it will do so, and there is a lot of code in that class to make sure things are cached wherever this is advantageous.\\n\\nThe final piece of this introduction is to mention that after a linear system is obtained, it is solved using an iterative solver and then postprocessed: we create an output file using the [DataOut](classDataOut.html) class that can then be visualized using one of the common visualization programs.\\n\\nNote\\n:   The preceding overview of all the important steps of any finite element implementation has its counterpart in deal.II: The library can naturally be grouped into a number of \\\"topics\\\" that cover the basic concepts just outlined. You can access these topics through the \\\"Topics\\\" tab at the top of this page. An overview of the most fundamental groups of concepts is also available on the [front page of the deal.II manual](index.html).\\n\\n### Solving the linear system\\n\\nFor a finite element program, the linear system we end up with here is relatively small: The matrix has size \\\\(1089 \\\\times 1089\\\\), owing to the fact that the mesh we use is \\\\(32\\\\times 32\\\\) and so there are \\\\(33^2=1089\\\\) vertices in the mesh. In many of the later tutorial programs, matrix sizes in the range of tens of thousands to hundreds of thousands will not be uncommon, and with codes such as [ASPECT](https://aspect.geodynamics.org) that build on deal.II, we regularly solve problems with more than a hundred million equations (albeit using parallel computers). In any case, even for the small system here, the matrix is much larger than what one typically encounters in an undergraduate or most graduate courses, and so the question arises how we can solve such linear systems.\\n\\nThe first method one typically learns for solving linear systems is [Gaussian elimination](https://en.wikipedia.org/wiki/Gaussian_elimination). The problem with this method is that it requires a number of operations that is proportional to \\\\(N^3\\\\), where \\\\(N\\\\) is the number of equations or unknowns in the linear system – more specifically, the number of operations is \\\\(\\\\frac 23 N^3\\\\), give or take a few. With \\\\(N=1089\\\\), this means that we would have to do around \\\\(861\\\\) million operations. This is a number that is quite feasible and it would take modern processors less than 0.1 seconds to do this. But it is clear that this isn't going to scale: If we have twenty times as many equations in the linear system (that is, twenty times as many unknowns), then it would already take 1000-10,000 seconds or on the order of an hour. Make the linear system another ten times larger, and it is clear that we can not solve it any more on a single computer.\\n\\nOne can rescue the situation somewhat by realizing that only a relatively small number of entries in the matrix are nonzero – that is, the matrix is [sparse](https://en.wikipedia.org/wiki/Sparse_matrix). Variations of Gaussian elimination can exploit this, making the process substantially faster; we will use one such method – implemented in the [SparseDirectUMFPACK](classSparseDirectUMFPACK.html) class – in [step-29](step_29.html) for the first time, among several others than come after that. These variations of Gaussian elimination might get us to problem sizes on the order of 100,000 or 200,000, but not all that much beyond that.\\n\\nInstead, what we will do here is take up an idea from 1952: the [Conjugate Gradient method](https://en.wikipedia.org/wiki/Conjugate_gradient_method), or in short \\\"CG\\\". CG is an \\\"iterative\\\" solver in that it forms a sequence of vectors that *converge* to the exact solution; in fact, after \\\\(N\\\\) such iterations in the absence of roundoff errors it finds the exact solution if the matrix is symmetric and positive definite. The method was originally developed as another way to solve a linear system exactly, like Gaussian elimination, but as such it had few advantages and was largely forgotten for a few decades. But, when computers became powerful enough to solve problems of a size where Gaussian elimination doesn't work well any more (sometime in the 1980s), CG was rediscovered as people realized that it is well suited for large and sparse systems like the ones we get from the finite element method. This is because (i) the vectors it computes *converge* to the exact solution, and consequently we do not actually have to do all \\\\(N\\\\) iterations to find the exact solution as long as we're happy with reasonably good approximations; and (ii) it only ever requires matrix-vector products, which is very useful for sparse matrices because a sparse matrix has, by definition, only \\\\({\\\\cal O}(N)\\\\) entries and so a matrix-vector product can be done with \\\\({\\\\cal O}(N)\\\\) effort whereas it costs \\\\(N^2\\\\) operations to do the same for dense matrices. As a consequence, we can hope to solve linear systems with at most \\\\({\\\\cal O}(N^2)\\\\) operations, and in many cases substantially fewer.\\n\\nFinite element codes therefore almost always use iterative solvers such as CG for the solution of the linear systems, and we will do so in this code as well. (We note that the CG method is only usable for matrices that are symmetric and positive definite; for other equations, the matrix may not have these properties and we will have to use other variations of iterative solvers such as [BiCGStab](https://en.wikipedia.org/wiki/Biconjugate_gradient_stabilized_method) or [GMRES](https://en.wikipedia.org/wiki/Generalized_minimal_residual_method) that are applicable to more general matrices.)\\n\\nAn important component of these iterative solvers is that we specify the *tolerance* with which we want to solve the linear system – in essence, a statement about the error we are willing to accept in our approximate solution. The error in an approximate solution \\\\(\\\\tilde x\\\\) obtained to the exact solution \\\\(x\\\\) of a linear system \\\\(Ax=b\\\\) is defined as \\\\(\\\\|x-\\\\tilde x\\\\|\\\\), but this is a quantity we cannot compute because we don't know the exact solution \\\\(x\\\\). Instead, we typically consider the *residual*, defined as \\\\(\\\\|b-A\\\\tilde x\\\\|=\\\\|A(x-\\\\tilde x)\\\\|\\\\), as a computable measure. We then let the iterative solver compute more and more accurate solutions \\\\(\\\\tilde x\\\\), until \\\\(\\\\|b-A\\\\tilde x\\\\|\\\\le \\\\tau\\\\). A practical question is what value \\\\(\\\\tau\\\\) should have. In most applications, setting\\n\\n\\\\begin{align\\\\*}\\n\\\\tau = 10^{-6} \\\\|b\\\\|\\n\\\\end{align\\\\*}\\n\\nis a reasonable choice. The fact that we make \\\\(\\\\tau\\\\) proportional to the size (norm) of \\\\(b\\\\) makes sure that our expectations of the accuracy in the solution are relative to the size of the solution. This makes sense: If we make the right hand side \\\\(b\\\\) ten times larger, then the solution \\\\(x\\\\) of \\\\(Ax=b\\\\) will also be ten times larger, and so will \\\\(\\\\tilde x\\\\); we want the same number of accurate digits in \\\\(\\\\tilde x\\\\) as before, which means that we should also terminate when the residual \\\\(\\\\|b-A\\\\tilde x\\\\|\\\\) is ten times the original size – which is exactly what we get if we make \\\\(\\\\tau\\\\) proportional to \\\\(\\\\|b\\\\|\\\\).\\n\\nAll of this will be implemented in the `Step3::solve()` function in this program. As you will see, it is quite simple to set up linear solvers with deal.II: The whole function will have only three lines.\\n\\n### About the implementation\\n\\nAlthough this is the simplest possible equation you can solve using the finite element method, this program shows the basic structure of most finite element programs and also serves as the template that almost all of the following programs will essentially follow. Specifically, the main class of this program looks like this:\\n\\n```\\nclass Step3\\n{\\n public:\\n    Step3 ();\\n void run ();\\n \\n private:\\n void make_grid ();\\n void setup_system ();\\n void assemble_system ();\\n void solve ();\\n void output_results () const;\\n \\n Triangulation<2> triangulation;\\n FE_Q<2>              fe;\\n DoFHandler<2>        dof_handler;\\n \\n SparsityPattern      sparsity_pattern;\\n SparseMatrix<double> system_matrix;\\n Vector<double>       solution;\\n Vector<double>       system_rhs;\\n};\\n```\\n\\nThis follows the object oriented programming mantra of [data encapsulation](http://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming)), i.e. we do our best to hide almost all internal details of this class in private members that are not accessible to the outside.\\n\\nLet's start with the member variables: These follow the building blocks we have outlined above in the bullet points, namely we need a [Triangulation](classTriangulation.html) and a [DoFHandler](classDoFHandler.html) object, and a finite element object that describes the kinds of shape functions we want to use. The second group of objects relate to the linear algebra: the system matrix and right hand side as well as the solution vector, and an object that describes the sparsity pattern of the matrix. This is all this class needs (and the essentials that any solver for a stationary PDE requires) and that needs to survive throughout the entire program. In contrast to this, the [FEValues](classFEValues.html) object we need for assembly is only required throughout assembly, and so we create it as a local object in the function that does that and destroy it again at its end.\\n\\nSecondly, let's look at the member functions. These, as well, already form the common structure that almost all following tutorial programs will use:\\n\\n* `make_grid()`: This is what one could call a *preprocessing function*. As its name suggests, it sets up the object that stores the triangulation. In later examples, it could also deal with boundary conditions, geometries, etc.\\n* `setup_system()`: This then is the function in which all the other data structures are set up that are needed to solve the problem. In particular, it will initialize the [DoFHandler](classDoFHandler.html) object and correctly size the various objects that have to do with the linear algebra. This function is often separated from the preprocessing function above because, in a time dependent program, it may be called at least every few time steps whenever the mesh is adaptively refined (something we will see how to do in [step-6](step_6.html)). On the other hand, setting up the mesh itself in the preprocessing function above is done only once at the beginning of the program and is, therefore, separated into its own function.\\n* `assemble_system()`: This, then is where the contents of the matrix and right hand side are computed, as discussed at length in the introduction above. Since doing something with this linear system is conceptually very different from computing its entries, we separate it from the following function.\\n* `solve()`: This then is the function in which we compute the solution \\\\(U\\\\) of the linear system \\\\(AU=F\\\\). In the current program, this is a simple task since the matrix is so simple, but it will become a significant part of a program's size whenever the problem is not so trivial any more (see, for example, [step-20](step_20.html), [step-22](step_22.html), or [step-31](step_31.html) once you've learned a bit more about the library).\\n* `output_results()`: Finally, when you have computed a solution, you probably want to do something with it. For example, you may want to output it in a format that can be visualized, or you may want to compute quantities you are interested in: say, heat fluxes in a heat exchanger, air friction coefficients of a wing, maximum bridge loads, or simply the value of the numerical solution at a point. This function is therefore the place for postprocessing your solution.\\n\\nAll of this is held together by the single public function (other than the constructor), namely the `run()` function. It is the one that is called from the place where an object of this type is created, and it is the one that calls all the other functions in their proper order. Encapsulating this operation into the `run()` function, rather than calling all the other functions from `main()` makes sure that you can change how the separation of concerns within this class is implemented. For example, if one of the functions becomes too big, you can split it up into two, and the only places you have to be concerned about changing as a consequence are within this very same class, and not anywhere else.\\n\\nAs mentioned above, you will see this general structure — sometimes with variants in spelling of the functions' names, but in essentially this order of separation of functionality — again in many of the following tutorial programs.\\n\\n### A note on types\\n\\ndeal.II defines a number of integral types via alias in namespace [types](namespacetypes.html). (In the previous sentence, the word \\\"integral\\\" is used as the *adjective* that corresponds to the noun \\\"integer\\\". It shouldn't be confused with the *noun* \\\"integral\\\" that represents the area or volume under a curve or surface. The adjective \\\"integral\\\" is widely used in the C++ world in contexts such as \\\"integral type\\\", \\\"integral constant\\\", etc.) In particular, in this program you will see [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) in a couple of places: an integer type that is used to denote the *global* index of a degree of freedom, i.e., the index of a particular degree of freedom within the [DoFHandler](classDoFHandler.html) object that is defined on top of a triangulation (as opposed to the index of a particular degree of freedom within a particular cell). For the current program (as well as almost all of the tutorial programs), you will have a few thousand to maybe a few million unknowns globally (and, for \\\\(Q\\\\_1\\\\) elements, you will have 4 *locally on each cell* in 2d and 8 in 3d). Consequently, a data type that allows to store sufficiently large numbers for global DoF indices is `unsigned int` given that it allows to store numbers between 0 and slightly more than 4 billion (on most systems, where integers are 32-bit). In fact, this is what [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) is.\\n\\nSo, why not just use `unsigned int` right away? deal.II used to do this until version 7.3. However, deal.II supports very large computations (via the framework discussed in [step-40](step_40.html)) that may have more than 4 billion unknowns when spread across a few thousand processors. Consequently, there are situations where `unsigned int` is not sufficiently large and we need a 64-bit unsigned integral type. To make this possible, we introduced [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) which by default is defined as simply `unsigned int` whereas it is possible to define it as `unsigned long long int` if necessary, by passing a particular flag during configuration (see the ReadMe file).\\n\\nThis covers the technical aspect. But there is also a documentation purpose: everywhere in the library and codes that are built on it, if you see a place using the data type [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58), you immediately know that the quantity that is being referenced is, in fact, a global dof index. No such meaning would be apparent if we had just used `unsigned int` (which may also be a local index, a boundary indicator, a material id, etc.). Immediately knowing what a variable refers to also helps avoid errors: it's quite clear that there must be a bug if you see an object of type [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) being assigned to variable of type [types::subdomain\\\\_id](namespacetypes.html#a198fcb9cfd43905f5c4f8c6ad7397330), even though they are both represented by unsigned integers and the compiler will, consequently, not complain.\\n\\nIn more practical terms what the presence of this type means is that during assembly, we create a \\\\(4\\\\times 4\\\\) matrix (in 2d, using a \\\\(Q\\\\_1\\\\) element) of the contributions of the cell we are currently sitting on, and then we need to add the elements of this matrix to the appropriate elements of the global (system) matrix. For this, we need to get at the global indices of the degrees of freedom that are local to the current cell, for which we will always use the following piece of the code:\\n\\n```\\ncell->get_dof_indices (local_dof_indices);\\n```\\n\\nwhere `local_dof_indices` is declared as\\n\\n```\\nstd::vector<types::global_dof_index> local_dof_indices (fe.n_dofs_per_cell());\\n```\\n\\nThe name of this variable might be a bit of a misnomer – it stands for \\\"the\\nglobal indices of those degrees of freedom locally defined on the current\\ncell\\\" – but variables that hold this information are universally named this way throughout the library.\\n\\nNote\\n:   [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58) is not the only type defined in this namespace. Rather, there is a whole family, including [types::subdomain\\\\_id](namespacetypes.html#a198fcb9cfd43905f5c4f8c6ad7397330), [types::boundary\\\\_id](namespacetypes.html#a10c23e1699231bd1fac0ebdd1890095d), and [types::material\\\\_id](namespacetypes.html#a00b2c29d714a8e9097b7d67b828bb19c). All of these are alias for integer data types but, as explained above, they are used throughout the library so that (i) the intent of a variable becomes more easily discerned, and (ii) so that it becomes possible to change the actual type to a larger one if necessary without having to go through the entire library and figure out whether a particular use of `unsigned int` corresponds to, say, a material indicator.\\n\\nThe commented program\\n=====================\\n\\n### Many new include files\\n\\nThese include files are already known to you. They declare the classes which handle triangulations and enumeration of degrees of freedom:\\n\\n```\\n   #include <deal.II/grid/tria.h>\\n   #include <deal.II/dofs/dof_handler.h>\\n```\\n\\nAnd this is the file in which the functions are declared that create grids:\\n\\n```\\n   #include <deal.II/grid/grid_generator.h>\\n```\\n\\nThis file contains the description of the Lagrange interpolation finite element:\\n\\n```\\n   #include <deal.II/fe/fe_q.h>\\n```\\n\\nAnd this file is needed for the creation of sparsity patterns of sparse matrices, as shown in previous examples:\\n\\n```\\n   #include <deal.II/dofs/dof_tools.h>\\n```\\n\\nThe next two files are needed for assembling the matrix using quadrature on each cell. The classes declared in them will be explained below:\\n\\n```\\n   #include <deal.II/fe/fe_values.h>\\n   #include <deal.II/base/quadrature_lib.h>\\n```\\n\\nThe following three include files we need for the treatment of boundary values:\\n\\n```\\n   #include <deal.II/base/function.h>\\n   #include <deal.II/numerics/vector_tools.h>\\n   #include <deal.II/numerics/matrix_tools.h>\\n```\\n\\nWe're now almost to the end. The second to last group of include files is for the linear algebra which we employ to solve the system of equations arising from the finite element discretization of the Laplace equation. We will use vectors and full matrices for assembling the system of equations locally on each cell, and transfer the results into a sparse matrix. We will then use a Conjugate Gradient solver to solve the problem, for which we need a preconditioner (in this program, we use the identity preconditioner which does nothing, but we need to include the file anyway):\\n\\n```\\n   #include <deal.II/lac/vector.h>\\n   #include <deal.II/lac/full_matrix.h>\\n   #include <deal.II/lac/sparse_matrix.h>\\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n   #include <deal.II/lac/solver_cg.h>\\n   #include <deal.II/lac/precondition.h>\\n```\\n\\nFinally, this is for output to a file and to the console:\\n\\n```\\n   #include <deal.II/numerics/data_out.h>\\n   #include <fstream>\\n   #include <iostream>\\n```\\n\\n...and this is to import the deal.II namespace into the global scope:\\n\\n```\\n   using namespace dealii;\\n```\\n\\n### The `Step3` class\\n\\nInstead of the procedural programming of previous examples, we encapsulate everything into a class for this program. The class consists of functions which each perform certain aspects of a finite element program, a `main` function which controls what is done first and what is done next, and a list of member variables.\\n\\nThe public part of the class is rather short: it has a constructor and a function `run` that is called from the outside and acts as something like the `main` function: it coordinates which operations of this class shall be run in which order. Everything else in the class, i.e. all the functions that actually do anything, are in the private section of the class:\\n\\n```\\n   class Step3\\n   {\\n   public:\\n     Step3();\\n   \\n     void run();\\n```\\n\\nThen there are the member functions that mostly do what their names suggest and whose have been discussed in the introduction already. Since they do not need to be called from outside, they are made private to this class.\\n\\n```\\n   private:\\n     void make_grid();\\n     void setup_system();\\n     void assemble_system();\\n     void solve();\\n     void output_results() const;\\n```\\n\\nAnd finally we have some member variables. There are variables describing the triangulation and the global numbering of the degrees of freedom (we will specify the exact polynomial degree of the finite element in the constructor of this class)...\\n\\n```\\n     Triangulation<2> triangulation;\\n     const FE_Q<2>    fe;\\n     DoFHandler<2>    dof_handler;\\n```\\n\\n...variables for the sparsity pattern and values of the system matrix resulting from the discretization of the Laplace equation...\\n\\n```\\n     SparsityPattern      sparsity_pattern;\\n     SparseMatrix<double> system_matrix;\\n```\\n\\n...and variables which will hold the right hand side and solution vectors.\\n\\n```\\n     Vector<double> solution;\\n     Vector<double> system_rhs;\\n   };\\n```\\n\\n#### Step3::Step3\\n\\nHere comes the constructor. It does not much more than first to specify that we want bi-linear elements (denoted by the parameter to the finite element object, which indicates the polynomial degree), and to associate the dof\\\\_handler variable to the triangulation we use. (Note that the triangulation isn't set up with a mesh at all at the present time, but the [DoFHandler](classDoFHandler.html) doesn't care: it only wants to know which triangulation it will be associated with, and it only starts to care about an actual mesh once you try to distribute degree of freedom on the mesh using the distribute\\\\_dofs() function.) All the other member variables of the Step3 class have a default constructor which does all we want.\\n\\n```\\n   Step3::Step3()\\n     : fe(/* polynomial degree = */ 1)\\n     , dof_handler(triangulation)\\n   {}\\n```\\n\\n#### Step3::make\\\\_grid\\n\\nNow, the first thing we've got to do is to generate the triangulation on which we would like to do our computation and number each vertex with a degree of freedom. We have seen these two steps in [step-1](step_1.html) and [step-2](step_2.html) before, respectively.\\n\\nThis function does the first part, creating the mesh. We create the grid and refine all cells five times. Since the initial grid (which is the square \\\\([-1,1] \\\\times [-1,1]\\\\)) consists of only one cell, the final grid has 32 times 32 cells, for a total of 1024.\\n\\nUnsure that 1024 is the correct number? We can check that by outputting the number of cells using the `n_active_cells()` function on the triangulation.\\n\\n```\\n   void Step3::make_grid()\\n   {\\n     GridGenerator::hyper_cube(triangulation, -1, 1);\\n     triangulation.refine_global(5);\\n   \\n     std::cout << \\\"Number of active cells: \\\" << triangulation.n_active_cells()\\n               << std::endl;\\n   }\\n```\\n\\nNote\\n:   We call the [Triangulation::n\\\\_active\\\\_cells()](classTriangulation.html#a5ea5c9957dbb566a562bbe2c0f3971e9) function, rather than [Triangulation::n\\\\_cells()](classTriangulation.html#abea687f123f3f5a8b09d7485cf03be72). Here, *active* means the cells that aren't refined any further. We stress the adjective \\\"active\\\" since there are more cells, namely the parent cells of the finest cells, their parents, etc, up to the one cell which made up the initial grid. Of course, on the next coarser level, the number of cells is one quarter that of the cells on the finest level, i.e. 256, then 64, 16, 4, and 1. If you called `triangulation.n_cells()` instead in the code above, you would consequently get a value of 1365 instead. On the other hand, the number of cells (as opposed to the number of active cells) is not typically of much interest, so there is no good reason to print it.\\n\\n#### Step3::setup\\\\_system\\n\\nNext we enumerate all the degrees of freedom and set up matrix and vector objects to hold the system data. Enumerating is done by using [DoFHandler::distribute\\\\_dofs()](classDoFHandler.html#a553ca864aaf70330d9be86bc78f36d1e), as we have seen in the [step-2](step_2.html) example. Since we use the [FE\\\\_Q](classFE__Q.html) class and have set the polynomial degree to 1 in the constructor, i.e. bilinear elements, this associates one degree of freedom with each vertex. While we're at generating output, let us also take a look at how many degrees of freedom are generated:\\n\\n```\\n   void Step3::setup_system()\\n   {\\n     dof_handler.distribute_dofs(fe);\\n     std::cout << \\\"Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n               << std::endl;\\n```\\n\\nThere should be one DoF for each vertex. Since we have a 32 times 32 grid, the number of DoFs should be 33 times 33, or 1089.\\n\\nAs we have seen in the previous example, we set up a sparsity pattern by first creating a temporary structure, tagging those entries that might be nonzero, and then copying the data over to the [SparsityPattern](classSparsityPattern.html) object that can then be used by the system matrix.\\n\\n```\\n     DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n     DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n     sparsity_pattern.copy_from(dsp);\\n```\\n\\nNote that the [SparsityPattern](classSparsityPattern.html) object does not hold the values of the matrix, it only stores the places where entries are. The entries themselves are stored in objects of type [SparseMatrix](classSparseMatrix.html), of which our variable system\\\\_matrix is one.\\n\\nThe distinction between sparsity pattern and matrix was made to allow several matrices to use the same sparsity pattern. This may not seem relevant here, but when you consider the size which matrices can have, and that it may take some time to build the sparsity pattern, this becomes important in large-scale problems if you have to store several matrices in your program.\\n\\n```\\n     system_matrix.reinit(sparsity_pattern);\\n```\\n\\nThe last thing to do in this function is to set the sizes of the right hand side vector and the solution vector to the right values:\\n\\n```\\n     solution.reinit(dof_handler.n_dofs());\\n     system_rhs.reinit(dof_handler.n_dofs());\\n   }\\n```\\n\\n#### Step3::assemble\\\\_system\\n\\nThe next step is to compute the entries of the matrix and right hand side that form the linear system from which we compute the solution. This is the central function of each finite element program and we have discussed the primary steps in the introduction already.\\n\\nThe general approach to assemble matrices and vectors is to loop over all cells, and on each cell compute the contribution of that cell to the global matrix and right hand side by quadrature. The point to realize now is that we need the values of the shape functions at the locations of quadrature points on the real cell. However, both the finite element shape functions as well as the quadrature points are only defined on the reference cell. They are therefore of little help to us, and we will in fact hardly ever query information about finite element shape functions or quadrature points from these objects directly.\\n\\nRather, what is required is a way to map this data from the reference cell to the real cell. Classes that can do that are derived from the [Mapping](classMapping.html \\\"Abstract base class for mapping classes.\\\") class, though one again often does not have to deal with them directly: many functions in the library can take a mapping object as argument, but when it is omitted they simply resort to the standard bilinear Q1 mapping. We will go this route, and not bother with it for the moment (we come back to this in [step-10](step_10.html), [step-11](step_11.html), and [step-12](step_12.html)).\\n\\nSo what we now have is a collection of three classes to deal with: finite element, quadrature, and mapping objects. That's too much, so there is one type of class that orchestrates information exchange between these three: the [FEValues](classFEValues.html) class. If given one instance of each three of these objects (or two, and an implicit linear mapping), it will be able to provide you with information about values and gradients of shape functions at quadrature points on a real cell.\\n\\nUsing all this, we will assemble the linear system for this problem in the following function:\\n\\n```\\n   void Step3::assemble_system()\\n   {\\n```\\n\\nOk, let's start: we need a quadrature formula for the evaluation of the integrals on each cell. Let's take a Gauss formula with two quadrature points in each direction, i.e. a total of four points since we are in 2d. This quadrature formula integrates polynomials of degrees up to three exactly (in 1d). It is easy to check that this is sufficient for the present problem:\\n\\n```\\n     const QGauss<2> quadrature_formula(fe.degree + 1);\\n```\\n\\nAnd we initialize the object which we have briefly talked about above. It needs to be told which finite element we want to use, and the quadrature points and their weights (jointly described by a [Quadrature](classQuadrature.html) object). As mentioned, we use the implied Q1 mapping, rather than specifying one ourselves explicitly. Finally, we have to tell it what we want it to compute on each cell: we need the values of the shape functions at the quadrature points (for the right hand side \\\\((\\\\varphi\\\\_i,f)\\\\)), their gradients (for the matrix entries \\\\((\\\\nabla \\\\varphi\\\\_i, \\\\nabla\\n\\\\varphi\\\\_j)\\\\)), and also the weights of the quadrature points and the determinants of the Jacobian transformations from the reference cell to the real cells.\\n\\nThis list of what kind of information we actually need is given as a collection of flags as the third argument to the constructor of [FEValues](classFEValues.html). Since these values have to be recomputed, or updated, every time we go to a new cell, all of these flags start with the prefix `update_` and then indicate what it actually is that we want updated. The flag to give if we want the values of the shape functions computed is [update\\\\_values](group__feaccess.html#ggaa94b67d2fdcc390690c523f28019e52fa4057ca2f127aa619c65886a9d3ad4aea \\\"Shape function values.\\\"); for the gradients it is [update\\\\_gradients](group__feaccess.html#ggaa94b67d2fdcc390690c523f28019e52facbcc430975fa6af05f75ca786dc6fe20 \\\"Shape function gradients.\\\"). The determinants of the Jacobians and the quadrature weights are always used together, so only the products (Jacobians times weights, or short `JxW`) are computed; since we need them, we have to list [update\\\\_JxW\\\\_values](group__feaccess.html#ggaa94b67d2fdcc390690c523f28019e52fa714204722e9eeb43aadbd0d5ddc48c85 \\\"Transformed quadrature weights.\\\") as well:\\n\\n```\\n     FEValues<2> fe_values(fe,\\n                           quadrature_formula,\\n                           update_values | update_gradients | update_JxW_values);\\n```\\n\\nThe advantage of this approach is that we can specify what kind of information we actually need on each cell. It is easily understandable that this approach can significantly speed up finite element computations, compared to approaches where everything, including second derivatives, normal vectors to cells, etc are computed on each cell, regardless of whether they are needed or not.\\n\\nNote\\n:   The syntax `update_values | update_gradients | update_JxW_values` is not immediately obvious to anyone not used to programming bit operations in C for years already. First, `operator|` is the *bitwise or operator*, i.e., it takes two integer arguments that are interpreted as bit patterns and returns an integer in which every bit is set for which the corresponding bit is set in at least one of the two arguments. For example, consider the operation `9|10`. In binary, `9=0b1001` (where the prefix `0b` indicates that the number is to be interpreted as a binary number) and `10=0b1010`. Going through each bit and seeing whether it is set in one of the argument, we arrive at `0b1001|0b1010=0b1011` or, in decimal notation, `9|10=11`. The second piece of information you need to know is that the various `update_*` flags are all integers that have *exactly one bit set*. For example, assume that `update_values=0b00001=1`, `update_gradients=0b00010=2`, `update_JxW_values=0b10000=16`. Then `update_values | update_gradients | update_JxW_values = 0b10011 = 19`. In other words, we obtain a number that *encodes a binary mask representing all of the operations you want to happen*, where each operation corresponds to exactly one bit in the integer that, if equal to one, means that a particular piece should be updated on each cell and, if it is zero, means that we need not compute it. In other words, even though `operator|` is the *bitwise OR operation*, what it really represents is *I want this AND that AND the other*. Such binary masks are quite common in C programming, but maybe not so in higher level languages like C++, but serve the current purpose quite well.\\n\\nFor use further down below, we define a shortcut for a value that will be used very frequently. Namely, an abbreviation for the number of degrees of freedom on each cell (since we are in 2d and degrees of freedom are associated with vertices only, this number is four, but we rather want to write the definition of this variable in a way that does not preclude us from later choosing a different finite element that has a different number of degrees of freedom per cell, or work in a different space dimension).\\n\\nIn general, it is a good idea to use a symbolic name instead of hard-coding these numbers even if you know them, since for example, you may want to change the finite element at some time. Changing the element would have to be done in a different function and it is easy to forget to make a corresponding change in another part of the program. It is better to not rely on your own calculations, but instead ask the right object for the information: Here, we ask the finite element to tell us about the number of degrees of freedom per cell and we will get the correct number regardless of the space dimension or polynomial degree we may have chosen elsewhere in the program.\\n\\nThe shortcut here, defined primarily to discuss the basic concept and not because it saves a lot of typing, will then make the following loops a bit more readable. You will see such shortcuts in many places in larger programs, and `dofs_per_cell` is one that is more or less the conventional name for this kind of object.\\n\\n```\\n     const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n```\\n\\nNow, we said that we wanted to assemble the global matrix and vector cell-by-cell. We could write the results directly into the global matrix, but this is not very efficient since access to the elements of a sparse matrix is slow. Rather, we first compute the contribution of each cell in a small matrix with the degrees of freedom on the present cell, and only transfer them to the global matrix when the computations are finished for this cell. We do the same for the right hand side vector. So let's first allocate these objects (these being local objects, all degrees of freedom are coupling with all others, and we should use a full matrix object rather than a sparse one for the local operations; everything will be transferred to a global sparse matrix later on):\\n\\n```\\n     FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n     Vector<double>     cell_rhs(dofs_per_cell);\\n```\\n\\nWhen assembling the contributions of each cell, we do this with the local numbering of the degrees of freedom (i.e. the number running from zero through dofs\\\\_per\\\\_cell-1). However, when we transfer the result into the global matrix, we have to know the global numbers of the degrees of freedom. When we query them, we need a scratch (temporary) array for these numbers (see the discussion at the end of the introduction for the type, [types::global\\\\_dof\\\\_index](namespacetypes.html#a83963f61f227516480be27a60c507a58), used here):\\n\\n```\\n     std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n```\\n\\nNow for the loop over all cells. We have seen before how this works for a triangulation. A [DoFHandler](classDoFHandler.html) has cell iterators that are exactly analogous to those of a [Triangulation](classTriangulation.html), but with extra information about the degrees of freedom for the finite element you're using. Looping over the active cells of a degree-of-freedom handler works the same as for a triangulation.\\n\\nNote that we declare the type of the cell as `const auto &` instead of `auto` this time around. In step 1, we were modifying the cells of the triangulation by flagging them with refinement indicators. Here we're only examining the cells without modifying them, so it's good practice to declare `cell` as `const` in order to enforce this invariant.\\n\\n```\\n     for (const auto &cell : dof_handler.active_cell_iterators())\\n       {\\n```\\n\\nWe are now sitting on one cell, and we would like the values and gradients of the shape functions be computed, as well as the determinants of the Jacobian matrices of the mapping between reference cell and true cell, at the quadrature points. Since all these values depend on the geometry of the cell, we have to have the [FEValues](classFEValues.html) object re-compute them on each cell:\\n\\n```\\n         fe_values.reinit(cell);\\n```\\n\\nNext, reset the local cell's contributions to global matrix and global right hand side to zero, before we fill them:\\n\\n```\\n         cell_matrix = 0;\\n         cell_rhs    = 0;\\n```\\n\\nNow it is time to start integration over the cell, which we do by looping over all quadrature points, which we will number by q\\\\_index.\\n\\n```\\n         for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n           {\\n```\\n\\nFirst assemble the matrix: For the Laplace problem, the matrix on each cell is the integral over the gradients of shape function i and j. Since we do not integrate, but rather use quadrature, this is the sum over all quadrature points of the integrands times the determinant of the Jacobian matrix at the quadrature point times the weight of this quadrature point. You can get the gradient of shape function \\\\(i\\\\) at quadrature point with number q\\\\_index by using `fe_values.shape_grad(i,q_index)`; this gradient is a 2-dimensional vector (in fact it is of type [Tensor](classTensor.html)<1,dim>, with here dim=2) and the product of two such vectors is the scalar product, i.e. the product of the two shape\\\\_grad function calls is the dot product. This is in turn multiplied by the Jacobian determinant and the quadrature point weight (that one gets together by the call to [FEValues::JxW()](classFEValuesBase.html#aeb33b877f81e2143752dda2c14a0029d) ). Finally, this is repeated for all shape functions \\\\(i\\\\) and \\\\(j\\\\):\\n\\n```\\n             for (const unsigned int i : fe_values.dof_indices())\\n               for (const unsigned int j : fe_values.dof_indices())\\n                 cell_matrix(i, j) +=\\n                   (fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                    fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                    fe_values.JxW(q_index));           // dx\\n```\\n\\nWe then do the same thing for the right hand side. Here, the integral is over the shape function i times the right hand side function, which we choose to be the function with constant value one (more interesting examples will be considered in the following programs).\\n\\n```\\n             for (const unsigned int i : fe_values.dof_indices())\\n               cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                               1. *                                // f(x_q)\\n                               fe_values.JxW(q_index));            // dx\\n           }\\n```\\n\\nNow that we have the contribution of this cell, we have to transfer it to the global matrix and right hand side. To this end, we first have to find out which global numbers the degrees of freedom on this cell have. Let's simply ask the cell for that information:\\n\\n```\\n         cell->get_dof_indices(local_dof_indices);\\n```\\n\\nThen again loop over all shape functions i and j and transfer the local elements to the global matrix. The global numbers can be obtained using local\\\\_dof\\\\_indices[i]:\\n\\n```\\n         for (const unsigned int i : fe_values.dof_indices())\\n           for (const unsigned int j : fe_values.dof_indices())\\n             system_matrix.add(local_dof_indices[i],\\n                               local_dof_indices[j],\\n                               cell_matrix(i, j));\\n```\\n\\nAnd again, we do the same thing for the right hand side vector.\\n\\n```\\n         for (const unsigned int i : fe_values.dof_indices())\\n           system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n       }\\n```\\n\\nNow almost everything is set up for the solution of the discrete system. However, we have not yet taken care of boundary values (in fact, Laplace's equation without Dirichlet boundary values is not even uniquely solvable, since you can add an arbitrary constant to the discrete solution). We therefore have to do something about the situation.\\n\\nFor this, we first obtain a list of the degrees of freedom on the boundary and the value the shape function shall have there. For simplicity, we only interpolate the boundary value function, rather than projecting it onto the boundary. There is a function in the library which does exactly this: [VectorTools::interpolate\\\\_boundary\\\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a). Its parameters are (omitting parameters for which default values exist and that we don't care about): the [DoFHandler](classDoFHandler.html) object to get the global numbers of the degrees of freedom on the boundary; the component of the boundary where the boundary values shall be interpolated; the boundary value function itself; and the output object.\\n\\nThe component of the boundary is meant as follows: in many cases, you may want to impose certain boundary values only on parts of the boundary. For example, you may have inflow and outflow boundaries in fluid dynamics, or clamped and free parts of bodies in deformation computations of bodies. Then you will want to denote these different parts of the boundary by indicators, and tell the interpolate\\\\_boundary\\\\_values function to only compute the boundary values on a certain part of the boundary (e.g. the clamped part, or the inflow boundary). By default, all boundaries have a 0 boundary indicator, unless otherwise specified. (For example, many functions in namespace [GridGenerator](namespaceGridGenerator.html) specify otherwise.) If sections of the boundary have different boundary conditions, you have to number those parts with different boundary indicators. The function call below will then only determine boundary values for those parts of the boundary for which the boundary indicator is in fact the zero specified as the second argument.\\n\\nThe function describing the boundary values is an object of type [Function](classFunction.html) or of a derived class. One of the derived classes is [Functions::ZeroFunction](classFunctions_1_1ZeroFunction.html), which describes (not unexpectedly) a function which is zero everywhere. We create such an object in-place and pass it to the [VectorTools::interpolate\\\\_boundary\\\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) function.\\n\\nFinally, the output object is a list of pairs of global degree of freedom numbers (i.e. the number of the degrees of freedom on the boundary) and their boundary values (which are zero here for all entries). This mapping of DoF numbers to boundary values is done by the `std::map` class.\\n\\n```\\n     std::map<types::global_dof_index, double> boundary_values;\\n     VectorTools::interpolate_boundary_values(dof_handler,\\n                                              types::boundary_id(0),\\n                                              Functions::ZeroFunction<2>(),\\n                                              boundary_values);\\n```\\n\\nNow that we got the list of boundary DoFs and their respective boundary values, let's use them to modify the system of equations accordingly. This is done by the following function call:\\n\\n```\\n     MatrixTools::apply_boundary_values(boundary_values,\\n                                        system_matrix,\\n                                        solution,\\n                                        system_rhs);\\n   }\\n```\\n\\n#### Step3::solve\\n\\nThe following function solves the discretized equation. As discussed in the introduction, we want to use an iterative solver to do this, specifically the Conjugate Gradient (CG) method.\\n\\nThe way to do this in deal.II is a three-step process:\\n\\n* First, we need to have an object that knows how to tell the CG algorithm when to stop. This is done by using a [SolverControl](classSolverControl.html) object, and as stopping criterion we say: stop after a maximum of 1000 iterations (which is far more than is needed for 1089 variables; see the results section to find out how many were really used), and stop if the norm of the residual is below \\\\(\\\\tau=10^{-6}\\\\|\\\\mathbf b\\\\|\\\\) where \\\\(\\\\mathbf b\\\\) is the right hand side vector. In practice, this latter criterion will be the one which stops the iteration.\\n* Then we need the solver itself. The template parameter to the [SolverCG](classSolverCG.html) class is the type of the vectors we are using.\\n* The last step is to actually solve the system of equations. The CG solver takes as arguments the components of the linear system \\\\(Ax=b\\\\) (in the order in which they appear in this equation), and a preconditioner as the fourth argument. We don't feel ready to delve into preconditioners yet, so we tell it to use the identity operation as preconditioner. Later tutorial programs will spend significant amount of time and space on constructing better preconditioners.\\n\\nAt the end of this process, the `solution` variable contains the nodal values of the solution function. At the end of the function, we output how many Conjugate Gradients iterations it took to solve the linear system.\\n\\n```\\n   void Step3::solve()\\n   {\\n     SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n     SolverCG<Vector<double>> solver(solver_control);\\n     solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n   \\n     std::cout << solver_control.last_step()\\n               << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n   }\\n```\\n\\n#### Step3::output\\\\_results\\n\\nThe last part of a typical finite element program is to output the results and maybe do some postprocessing (for example compute the maximal stress values at the boundary, or the average flux across the outflow, etc). We have no such postprocessing here, but we would like to write the solution to a file.\\n\\n```\\n   void Step3::output_results() const\\n   {\\n```\\n\\nTo write the output to a file, we need an object which knows about output formats and the like. This is the [DataOut](classDataOut.html) class, and we need an object of that type:\\n\\n```\\n     DataOut<2> data_out;\\n```\\n\\nNow we have to tell it where to take the values from which it shall write. We tell it which [DoFHandler](classDoFHandler.html) object to use, and the solution vector (and the name by which the solution variable shall appear in the output file). If we had more than one vector which we would like to look at in the output (for example right hand sides, errors per cell, etc) we would add them as well:\\n\\n```\\n     data_out.attach_dof_handler(dof_handler);\\n     data_out.add_data_vector(solution, \\\"solution\\\");\\n```\\n\\nAfter the [DataOut](classDataOut.html) object knows which data it is to work on, we have to tell it to process them into something the back ends can handle. The reason is that we have separated the frontend (which knows about how to treat [DoFHandler](classDoFHandler.html) objects and data vectors) from the back end (which knows many different output formats) and use an intermediate data format to transfer data from the front- to the backend. The data is transformed into this intermediate format by the following function:\\n\\n```\\n     data_out.build_patches();\\n```\\n\\nNow we have everything in place for the actual output. Just open a file and write the data into it, using VTK format (there are many other functions in the [DataOut](classDataOut.html) class we are using here that can write the data in postscript, AVS, GMV, Gnuplot, or some other file formats):\\n\\n```\\n     const std::string filename = \\\"solution.vtk\\\";\\n     std::ofstream     output(filename);\\n     data_out.write_vtk(output);\\n     std::cout << \\\"Output written to \\\" << filename << std::endl;\\n   }\\n```\\n\\n#### Step3::run\\n\\nFinally, the last function of this class is the main function which calls all the other functions of the `Step3` class. The order in which this is done resembles the order in which most finite element programs work. Since the names are mostly self-explanatory, there is not much to comment about:\\n\\n```\\n   void Step3::run()\\n   {\\n     make_grid();\\n     setup_system();\\n     assemble_system();\\n     solve();\\n     output_results();\\n   }\\n```\\n\\n### The `main` function\\n\\nThis is the main function of the program. Since the concept of a main function is mostly a remnant from the pre-object oriented era before C++ programming, it often does not do much more than creating an object of the top-level class and calling its principle function.\\n\\n```\\n   int main()\\n   {\\n     Step3 laplace_problem;\\n     laplace_problem.run();\\n   \\n     return 0;\\n   }\\n```\\n\\nResults\\n=======\\n\\nThe output of the program looks as follows:\\n\\n```\\nNumber of active cells: 1024\\nNumber of degrees of freedom: 1089\\n36 CG iterations needed to obtain convergence.\\nOutput written to solution.vtk\\n```\\n\\nThe last line is the output we generated at the bottom of the `output_results()` function: The program generated the file `solution.vtk`, which is in the VTK format that is widely used by many visualization programs today – including the two heavy-weights [VisIt](https://www.llnl.gov/visit) and [Paraview](https://www.paraview.org) that are the most commonly used programs for this purpose today.\\n\\nUsing VisIt, it is not very difficult to generate a picture of the solution like this:\\n\\n|  |\\n| --- |\\n| Visualization of the solution of step-3 |\\n\\nIt shows both the solution and the mesh, elevated above the \\\\(x\\\\)- \\\\(y\\\\) plane based on the value of the solution at each point. Of course the solution here is not particularly exciting, but that is a result of both what the Laplace equation represents and the right hand side \\\\(f(\\\\mathbf x)=1\\\\) we have chosen for this program: The Laplace equation describes (among many other uses) the vertical deformation of a membrane subject to an external (also vertical) force. In the current example, the membrane's borders are clamped to a square frame with no vertical variation; a constant force density will therefore intuitively lead to a membrane that simply bulges upward – like the one shown above.\\n\\nVisIt and Paraview both allow playing with various kinds of visualizations of the solution. Several video lectures show how to use these programs. See also [video lecture 11](https://www.math.colostate.edu/~bangerth/videos.676.11.html), [video lecture 32](https://www.math.colostate.edu/~bangerth/videos.676.32.html).\\n\\n### Possibilities for extensions\\n\\nIf you want to play around a little bit with this program, here are a few suggestions:\\n\\n* Change the geometry and mesh: In the program, we have generated a square domain and mesh by using the [GridGenerator::hyper\\\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403) function. However, the `GridGenerator` has a good number of other functions as well. Try an L-shaped domain, a ring, or other domains you find there.\\n* Change the boundary condition: The code uses the [Functions::ZeroFunction](classFunctions_1_1ZeroFunction.html) function to generate zero boundary conditions. However, you may want to try non-zero constant boundary values using `Functions::ConstantFunction<2>(1)` instead of `Functions::ZeroFunction<2>()` to have unit Dirichlet boundary values. More exotic functions are described in the documentation of the [Functions](namespaceFunctions.html) namespace, and you may pick one to describe your particular boundary values.\\n* Modify the type of boundary condition: Presently, what happens is that we use Dirichlet boundary values all around, since the default is that all boundary parts have boundary indicator zero, and then we tell the [VectorTools::interpolate\\\\_boundary\\\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) function to interpolate boundary values to zero on all boundary components with indicator zero.\\n\\n  We can change this behavior if we assign parts of the boundary different indicators. For example, try this immediately after calling [GridGenerator::hyper\\\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403):\\n\\n  ```\\n  triangulation.begin_active()->face(0)->set_boundary_id(1);\\n  ```\\n\\n  What this does is it first asks the triangulation to return an iterator that points to the first active cell. Of course, this being the coarse mesh for the triangulation of a square, the triangulation has only a single cell at this moment, and it is active. Next, we ask the cell to return an iterator to its first face, and then we ask the face to reset the boundary indicator of that face to 1. What then follows is this: When the mesh is refined, faces of child cells inherit the boundary indicator of their parents, i.e. even on the finest mesh, the faces on one side of the square have boundary indicator 1. Later, when we get to interpolating boundary conditions, the [VectorTools::interpolate\\\\_boundary\\\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) call will only produce boundary values for those faces that have zero boundary indicator, and leave those faces alone that have a different boundary indicator. What this then does is to impose Dirichlet boundary conditions on the former, and homogeneous Neumann conditions on the latter (i.e. zero normal derivative of the solution, unless one adds additional terms to the right hand side of the variational equality that deal with potentially non-zero Neumann conditions). You will see this if you run the program.\\n\\n  An alternative way to change the boundary indicator is to label the boundaries based on the Cartesian coordinates of the face centers. For example, we can label all of the cells along the top and bottom boundaries with a boundary indicator 1 by checking to see if the cell centers' y-coordinates are within a tolerance (here `1e-12`) of -1 and 1. Try this immediately after calling [GridGenerator::hyper\\\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403), as before:\\n\\n  ```\\n  for (auto &face : triangulation.active_face_iterators())\\n    if (face->at_boundary())\\n      if (std::fabs(face->center()(1) - (-1.0)) < 1e-12 ||\\n   std::fabs(face->center()(1) - (1.0)) < 1e-12)\\n        face->set_boundary_id(1);\\n  ```\\n\\n  Although this code is a bit longer than before, it is useful for complex geometries, as it does not require knowledge of face labels.\\n* A slight variation of the last point would be to set different boundary values as above, but then use a different boundary value function for boundary indicator one. In practice, what you have to do is to add a second call to `interpolate_boundary_values` for boundary indicator one:\\n\\n  ```\\n  VectorTools::interpolate_boundary_values(dof_handler,\\n   types::boundary_id(1),\\n   Functions::ConstantFunction<2>(1.),\\n                                           boundary_values);\\n  ```\\n\\n  If you have this call immediately after the first one to this function, then it will interpolate boundary values on faces with boundary indicator 1 to the unit value, and merge these interpolated values with those previously computed for boundary indicator 0. The result will be that we will get discontinuous boundary values, zero on three sides of the square, and one on the fourth.\\n* Use triangles: As mentioned in the results section of [step-1](step_1.html), for historical reasons, almost all tutorial programs for deal.II are written using quadrilateral or hexahedral meshes. But deal.II also supports triangular and tetrahedral meshes. So a good experiment would be to replace the mesh used here by a triangular mesh.\\n\\n  This is *almost* trivial. First, as discussed in [step-1](step_1.html), we may want to start with the quadrilateral mesh we are already creating, and then convert it into a triangular one. You can do that by replacing the first line of `Step3::make_grid()` by the following code:\\n\\n  ```\\n  Triangulation<2> triangulation_quad;\\n  GridGenerator::hyper_cube(triangulation_quad, -1, 1);\\n  GridGenerator::convert_hypercube_to_simplex_mesh (triangulation_quad,\\n   triangulation);\\n  ```\\n\\n  The [GridGenerator::convert\\\\_hypercube\\\\_to\\\\_simplex\\\\_mesh()](namespaceGridGenerator.html#ac7515d2b17c025dddc0e37286fb8d216) replaces each quadrilateral by eight triangles with half the diameter of the original quadrilateral; as a consequence, the resulting mesh is substantially finer and one might expect that the solution is consequently more accurate (but also has many more degrees of freedom). That is a question you can explore with the techniques discussed in the \\\"Results\\\" section of [step-4](step_4.html), but that goes beyond what we want to demonstrate here.\\n\\n  If you run this program, you will run into an error message that will look something like this:\\n\\n  ```\\n  --------------------------------------------------------\\n  An error occurred in line <2633> of file </home/bangerth/p/deal.II/1/dealii/include/deal.II/dofs/dof_accessor.templates.h> in function\\n      const ::FiniteElement<dimension_, space_dimension_>& ::DoFCellAccessor<dim, spacedim, lda>::get_fe() const [with int dimension_ = 2; int space_dimension_ = 2; bool level_dof_access = false]\\n  The violated condition was:\\n      this->reference_cell() == fe.reference_cell()\\n  Additional information:\\n      The reference-cell type used on this cell (Tri) does not match the\\n      reference-cell type of the finite element associated with this cell\\n      (Quad). Did you accidentally use simplex elements on hypercube meshes\\n      (or the other way around), or are you using a mixed mesh and assigned\\n      a simplex element to a hypercube cell (or the other way around) via\\n      the active_fe_index?\\n  ```\\n\\n  It is worth carefully reading the error message. It doesn't just state that there is an error, but also how it may have arisen. Specifically, it asks whether we are using a finite element for simplex meshes (in 2d simplices are triangles) with a hypercube mesh (in 2d hypercubes are quadrilaterals) or the other way around?\\n\\n  Of course, this is exactly what we are doing, though this may perhaps not be clear to you. But if you look up the documentation, you will find that the [FE\\\\_Q](classFE__Q.html) element we use in the main class can only be used on hypercube meshes; what we *want* to use instead now that we are using a simplex mesh is the [FE\\\\_SimplexP](classFE__SimplexP.html) class that is the equivalent to [FE\\\\_Q](classFE__Q.html) for simplex cells. (To do this, you will also have to add `#include <deal.II/fe/fe_simplex_p.h>` at the top of the file.)\\n\\n  The last thing you need to change (which at the time of writing is unfortunately not prompted by getting an error message) is that when we integrate, we need to use a quadrature formula that is appropriate for triangles. This is done by changing [QGauss](classQGauss.html) by [QGaussSimplex](classQGaussSimplex.html) in the code.\\n\\n  With all of these steps, you then get the following solution: ![Visualization of the solution of step-3 using triangles](images/steps/developer/step-3.solution-triangles.png)\\n* Observe convergence: We will only discuss computing errors in norms in [step-7](step_7.html), but it is easy to check that computations converge already here. For example, we could evaluate the value of the solution in a single point and compare the value for different numbers of global refinement (the number of global refinement steps is set in `LaplaceProblem::make_grid` above). To evaluate the solution at a point, say at \\\\((\\\\frac 13, \\\\frac 13)\\\\), we could add the following code to the `LaplaceProblem::output_results` function:\\n\\n  ```\\n  std::cout << \\\"Solution at (1/3,1/3): \\\"\\n            << VectorTools::point_value(dof_handler, solution,\\n   Point<2>(1./3, 1./3))\\n            << std::endl;\\n  ```\\n\\n  For 1 through 9 global refinement steps, we then get the following sequence of point values:\\n\\n  | # of refinements | \\\\(u\\\\_h(\\\\frac 13,\\\\frac13)\\\\) |\\n  | --- | --- |\\n  | 1 | 0.166667 |\\n  | 2 | 0.227381 |\\n  | 3 | 0.237375 |\\n  | 4 | 0.240435 |\\n  | 5 | 0.241140 |\\n  | 6 | 0.241324 |\\n  | 7 | 0.241369 |\\n  | 8 | 0.241380 |\\n  | 9 | 0.241383 |\\n\\n  By noticing that the difference between each two consecutive values reduces by about a factor of 4, we can conjecture that the \\\"correct\\\" value may be \\\\(u(\\\\frac 13, \\\\frac 13)\\\\approx 0.241384\\\\). In fact, if we assumed this to be the correct value, we could show that the sequence above indeed shows \\\\({\\\\cal\\n  O}(h^2)\\\\) convergence — theoretically, the convergence order should be \\\\({\\\\cal O}(h^2 |\\\\log h|)\\\\) but the symmetry of the domain and the mesh may lead to the better convergence order observed.\\n\\n  A slight variant of this would be to repeat the test with quadratic elements. All you need to do is to set the polynomial degree of the finite element to two in the constructor `LaplaceProblem::LaplaceProblem`.\\n* Convergence of the mean: A different way to see that the solution actually converges (to something — we can't tell whether it's really the correct value!) is to compute the mean of the solution. To this end, add the following code to `LaplaceProblem::output_results`:\\n\\n  ```\\n  std::cout << \\\"Mean value: \\\"\\n            << VectorTools::compute_mean_value (dof_handler,\\n   QGauss<2>(fe.degree + 1),\\n                                                solution,\\n                                                0)\\n            << std::endl;\\n  ```\\n\\n   The documentation of the function explains what the second and fourth parameters mean, while the first and third should be obvious. Doing the same study again where we change the number of global refinement steps, we get the following result:\\n\\n  | # of refinements | \\\\(\\\\int\\\\_\\\\Omega u\\\\_h(x)\\\\; dx\\\\) |\\n  | --- | --- |\\n  | 0 | 0.09375000 |\\n  | 1 | 0.12790179 |\\n  | 2 | 0.13733440 |\\n  | 3 | 0.13976069 |\\n  | 4 | 0.14037251 |\\n  | 5 | 0.14052586 |\\n  | 6 | 0.14056422 |\\n  | 7 | 0.14057382 |\\n  | 8 | 0.14057622 |\\n\\n  Again, the difference between two adjacent values goes down by about a factor of four, indicating convergence as \\\\({\\\\cal O}(h^2)\\\\).\\n\\n### Using HDF5 to output the solution and additional data\\n\\nHDF5 is a commonly used format that can be read by many scripting languages (e.g. R or Python). It is not difficult to get deal.II to produce some HDF5 files that can then be used in external scripts to postprocess some of the data generated by this program. Here are some ideas on what is possible.\\n\\n#### Changing the output to .h5\\n\\nTo fully make use of the automation we first need to introduce a private variable for the number of global refinement steps `unsigned int n_refinement_steps` , which will be used for the output filename. In `make_grid()` we then replace `triangulation.refine_global(5);` with\\n\\n```\\nn_refinement_steps = 5;\\ntriangulation.refine_global(n_refinement_steps);\\n```\\n\\nThe deal.II library has two different HDF5 bindings, one in the [HDF5](namespaceHDF5.html) namespace (for interfacing to general-purpose data files) and another one in [DataOut](classDataOut.html) (specifically for writing files for the visualization of solutions). Although the [HDF5](namespaceHDF5.html) deal.II binding supports both serial and MPI, the HDF5 [DataOut](classDataOut.html) binding only supports parallel output. For this reason we need to initialize an MPI communicator with only one processor. This is done by adding the following code.\\n\\n```\\nint main(int argc, char* argv[])\\n{\\n Utilities::MPI::MPI_InitFinalize mpi_initialization(argc, argv, 1);\\n  ...\\n}\\n```\\n\\nNext we change the `Step3::output_results()` output routine as described in the [DataOutBase](namespaceDataOutBase.html) namespace documentation:\\n\\n```\\nconst std::string filename_h5 = \\\"solution_\\\" + std::to_string(n_refinement_steps) + \\\".h5\\\";\\nDataOutBase::DataOutFilterFlags flags(true, true);\\nDataOutBase::DataOutFilter data_filter(flags);\\ndata_out.write_filtered_data(data_filter);\\ndata_out.write_hdf5_parallel(data_filter, filename_h5, MPI_COMM_WORLD);\\n```\\n\\nThe resulting file can then be visualized just like the VTK file that the original version of the tutorial produces; but, since HDF5 is a more general file format, it can also easily be processed in scripting languages for other purposes.\\n\\n#### Adding the point value and the mean (see extension above) into the .h5 file\\n\\nAfter outputting the solution, the file can be opened again to include more datasets. This allows us to keep all the necessary information of our experiment in a single result file, which can then be read and processed by some postprocessing script. (Have a look at [HDF5::Group::write\\\\_dataset()](classHDF5_1_1Group.html#af90cb30dc6f27aae41dd47008f7437f6) for further information on the possible output options.)\\n\\nTo make this happen, we first include the necessary header into our file :\\n\\n```\\n#include <deal.II/base/hdf5.h>\\n```\\n\\nAdding the following lines to the end of our output routine adds the information about the value of the solution at a particular point, as well as the mean value of the solution, to our HDF5 file :\\n\\n```\\nHDF5::File data_file(filename_h5, HDF5::File::FileAccessMode::open, MPI_COMM_WORLD);\\nVector<double> point_value(1);\\npoint_value[0] = VectorTools::point_value(dof_handler, solution,\\n Point<2>(1./3, 1./3));\\ndata_file.write_dataset(\\\"point_value\\\", point_value);\\nVector<double> mean_value(1);\\nmean_value[0] = VectorTools::compute_mean_value(dof_handler,\\n QGauss<2>(fe.degree + 1),\\n                                                solution, 0);\\ndata_file.write_dataset(\\\"mean_value\\\",mean_value);\\n```\\n\\n### Using R and ggplot2 to generate plots\\n\\nNote\\n:   Alternatively, one could use the python code in the next subsection.\\n\\nThe data put into HDF5 files above can then be used from scripting languages for further postprocessing. In the following, let us show how this can, in particular, be done with the [R programming language](https://en.wikipedia.org/wiki/R_(programming_language)), a widely used language in statistical data analysis. (Similar things can also be done in Python, for example.) If you are unfamiliar with R and ggplot2 you could check out the data carpentry course on R [here](https://datacarpentry.org/R-ecology-lesson/index.html). Furthermore, since most search engines struggle with searches of the form \\\"R + topic\\\", we recommend using the specializes service [RSeek](http://rseek.org)  instead.\\n\\nThe most prominent difference between R and other languages is that the assignment operator (`a = 5`) is typically written as `a <- 5`. As the latter is considered standard we will use it in our examples as well. To open the `.h5` file in R you have to install the [rhdf5](https://bioconductor.org/packages/release/bioc/html/rhdf5.html) package, which is a part of the Bioconductor package.\\n\\nFirst we will include all necessary packages and have a look at how the data is structured in our file.\\n\\n```\\nlibrary(rhdf5)     # library for handling HDF5 files\\nlibrary(ggplot2)   # main plotting library\\nlibrary(grDevices) # needed for output to PDF\\nlibrary(viridis)   # contains good colormaps for sequential data\\n \\nrefinement <- 5\\nh5f <- H5Fopen(paste(\\\"solution_\\\",refinement,\\\".h5\\\",sep=\\\"\\\"))\\nprint(h5f)\\n```\\n\\nThis gives the following output\\n\\n```\\nHDF5 FILE\\n   name /\\nfilename\\n \\n    name       otype  dclass     dim\\n0 cells       H5I_DATASET INTEGER  x 1024\\n1 mean_value  H5I_DATASET FLOAT   1\\n2 nodes       H5I_DATASET FLOAT    x 1089\\n3 point_value H5I_DATASET FLOAT   1\\n4 solution    H5I_DATASET FLOAT    x 1089\\n```\\n\\nThe datasets can be accessed by `h5f$name`. The function `dim(h5f$cells)` gives us the dimensions of the matrix that is used to store our cells. We can see the following three matrices, as well as the two additional data points we added.\\n\\n* `cells`: a 4x1024 matrix that stores the (C++) vertex indices for each cell\\n* `nodes`: a 2x1089 matrix storing the position values (x,y) for our cell vertices\\n* `solution`: a 1x1089 matrix storing the values of our solution at each vertex\\n\\nNow we can use this data to generate various plots. Plotting with ggplot2 usually splits into two steps. At first the data needs to be manipulated and added to a `data.frame`. After that, a `ggplot` object is constructed and manipulated by adding plot elements to it.\\n\\n`nodes` and `cells` contain all the information we need to plot our grid. The following code wraps all the data into one dataframe for plotting our grid:\\n\\n```\\n# Counting in R starts at 1 instead of 0, so we need to increment all\\n# vertex indices by one:\\ncell_ids <- h5f@f$cells+1\\n \\n# Store the x and y positions of each vertex in one big vector in a\\n# cell by cell fashion (every 4 entries belong to one cell):\\ncells_x <- h5f@f$nodes[1,][cell_ids]\\ncells_y <- h5f@f$nodes[2,][cell_ids]\\n \\n# Construct a vector that stores the matching cell by cell grouping\\n# (1,1,1,1,2,2,2,2,...):\\ngroups <- rep(1:ncol(cell_ids),each=4)\\n \\n# Finally put everything into one dataframe:\\nmeshdata <- data.frame(x = cells_x, y = cells_y, id = groups)\\n```\\n\\nWith the finished dataframe we have everything we need to plot our grid:\\n\\n```\\npdf (paste(\\\"grid_\\\",refinement,\\\".pdf\\\",sep=\\\"\\\"),width = 5,height = 5) # Open new PDF file\\nplt <- ggplot(meshdata,aes(x=x,y=y,group=id))                      # Construction of our plot\\n                                                                   # object, at first only data\\n \\nplt <- plt + geom_polygon(fill=\\\"white\\\",colour=\\\"black\\\")             # Actual plotting of the grid as polygons\\nplt <- plt + ggtitle(paste(\\\"grid at refinement level #\\\",refinement))\\n \\nprint(plt)                                                         # Show the current state of the plot/add it to the pdf\\ndev.off()                                                          # Close PDF file\\n```\\n\\nThe contents of this file then look as follows (not very exciting, but you get the idea):\\n\\n|  |\\n| --- |\\n| Grid after 5 refinement steps of step-3 |\\n\\nWe can also visualize the solution itself, and this is going to look more interesting. To make a 2D pseudocolor plot of our solution we will use `geom_raster`. This function needs a structured grid, i.e. uniform in x and y directions. Luckily our data at this point is structured in the right way. The following code plots a pseudocolor representation of our surface into a new PDF:\\n\\n```\\npdf (paste(\\\"pseudocolor_\\\",refinement,\\\".pdf\\\",sep=\\\"\\\"),width = 5,height = 4.2) # Open new PDF file\\ncolordata <- data.frame(x = h5f@f$nodes[1,],y = h5f@f$nodes[2,] , solution = h5f@f$solution[1,])\\nplt <- ggplot(colordata,aes(x=x,y=y,fill=solution))\\nplt <- plt + geom_raster(interpolate=TRUE)\\nplt <- plt + scale_fill_viridis()\\nplt <- plt + ggtitle(paste(\\\"solution at refinement level #\\\",refinement))\\n \\nprint(plt)\\ndev.off()\\nH5Fclose(h5f) # Close the HDF5 file\\n```\\n\\nThis is now going to look as follows:\\n\\n|  |\\n| --- |\\n| Solution after 5 refinement steps of step-3 |\\n\\nFor plotting the convergence curves we need to re-run the C++ code multiple times with different values for `n_refinement_steps` starting from 1. Since every file only contains a single data point we need to loop over them and concatenate the results into a single vector.\\n\\n```\\nn_ref <- 8   # Maximum refinement level for which results are existing\\n \\n# First we initiate all vectors with the results of the first level\\nh5f   <- H5Fopen(\\\"solution_1.h5\\\")\\ndofs  <- dim(h5f@f$solution)[2]\\nmean  <- h5f@f$mean_value\\npoint <- h5f@f$point_value\\nH5Fclose(h5f)\\n \\nfor (reflevel in 2:n_ref)\\n{\\n   h5f   <- H5Fopen(paste(\\\"solution_\\\",reflevel,\\\".h5\\\",sep=\\\"\\\"))\\n   dofs  <- c(dofs,dim(h5f\\\\$solution)[2])\\n   mean  <- c(mean,h5f\\\\$mean_value)\\n   point <- c(point,h5f\\\\$point_value)\\n   H5Fclose(h5f)\\n}\\n```\\n\\nAs we are not interested in the values themselves but rather in the error compared to a \\\"exact\\\" solution we will assume our highest refinement level to be that solution and omit it from the data.\\n\\n```\\n# Calculate the error w.r.t. our maximum refinement step\\nmean_error  <- abs(mean[1:n_ref-1]-mean[n_ref])\\npoint_error <- abs(point[1:n_ref-1]-point[n_ref])\\n \\n# Remove the highest value from our DoF data\\ndofs     <- dofs[1:n_ref-1]\\nconvdata <- data.frame(dofs = dofs, mean_value= mean_error, point_value = point_error)\\n```\\n\\nNow we have all the data available to generate our plots. It is often useful to plot errors on a log-log scale, which is accomplished in the following code:\\n\\n```\\npdf (paste(\\\"convergence.pdf\\\",sep=\\\"\\\"),width = 5,height = 4.2)\\nplt <- ggplot(convdata,mapping=aes(x = dofs, y = mean_value))\\nplt <- plt+geom_line()\\nplt <- plt+labs(x=\\\"#DoFs\\\",y = \\\"mean value error\\\")\\nplt <- plt+scale_x_log10()+scale_y_log10()\\nprint(plt)\\n \\nplt <- ggplot(convdata,mapping=aes(x = dofs, y = point_value))\\nplt <- plt+geom_line()\\nplt <- plt+labs(x=\\\"#DoFs\\\",y = \\\"point value error\\\")\\nplt <- plt+scale_x_log10()+scale_y_log10()\\nprint(plt)\\n \\ndev.off()\\n```\\n\\nThis results in the following plot that shows how the errors in the mean value and the solution value at the chosen point nicely converge to zero:\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\n### Using python to generate plots\\n\\nIn this section we discuss the postprocessing of the data stored in HDF5 files using the \\\"python\\\" programming language. The necessary packages to import are\\n\\n```\\nimport numpy as np                        # to work with multidimensional arrays\\nimport h5py                               # to work with %HDF5 files\\n \\nimport pandas as pd                       # for data frames\\nimport matplotlib.pyplot as plt           # plotting\\nfrom matplotlib.patches import Polygon\\n \\nfrom scipy.interpolate import griddata    # interpolation function\\nfrom matplotlib import cm                 # for colormaps\\n```\\n\\nThe HDF5 solution file corresponding to `refinement = 5` can be opened as\\n\\n```\\nrefinement = 5\\nfilename = \\\"solution_%d.h5\\\" % refinement\\nfile = h5py.File(filename, \\\"r\\\")\\n```\\n\\nThe following prints out the tables in the HDF5 file\\n\\n```\\nfor key, value in file.items():\\n    print(key, \\\" : \\\", value)\\n```\\n\\nwhich prints out\\n\\n```\\ncells  :  <HDF5 dataset \\\"cells\\\": shape (1024, 4), type \\\"<u4\\\">\\nmean_value  :  <HDF5 dataset \\\"mean_value\\\": shape (1,), type \\\"<f8\\\">\\nnodes  :  <HDF5 dataset \\\"nodes\\\": shape (1089, 2), type \\\"<f8\\\">\\npoint_value  :  <HDF5 dataset \\\"point_value\\\": shape (1,), type \\\"<f8\\\">\\nsolution  :  <HDF5 dataset \\\"solution\\\": shape (1089, 1), type \\\"<f8\\\">\\n```\\n\\nThere are \\\\((32+1)\\\\times(32+1) = 1089\\\\) nodes. The coordinates of these nodes \\\\((x,y)\\\\) are stored in the table `nodes` in the HDF5 file. There are a total of \\\\(32\\\\times 32 = 1024\\\\) cells. The nodes which make up each cell are marked in the table `cells` in the HDF5 file.\\n\\nNext, we extract the data into multidimensional arrays\\n\\n```\\nnodes = np.array(file[\\\"/nodes\\\"])\\ncells = np.array(file[\\\"/cells\\\"])\\nsolution = np.array(file[\\\"/solution\\\"])\\n \\nx, y = nodes.T\\n```\\n\\nThe following stores the \\\\(x\\\\) and \\\\(y\\\\) coordinates of each node of each cell in one flat array.\\n\\n```\\ncell_x = x[cells.flatten()]\\ncell_y = y[cells.flatten()]\\n```\\n\\nThe following tags the cell ids. Each four entries correspond to one cell. Then we collect the coordinates and ids into a data frame\\n\\n```\\nn_cells = cells.shape[0]\\ncell_ids = np.repeat(np.arange(n_cells), 4)\\nmeshdata = pd.DataFrame({\\\"x\\\": cell_x, \\\"y\\\": cell_y, \\\"ids\\\": cell_ids})\\n```\\n\\nThe data frame looks\\n\\n```\\nprint(meshdata)\\n \\n      x       y       ids\\n0       0.00000 0.00000 0\\n1       0.03125 0.00000 0\\n2       0.03125 0.03125 0\\n3       0.00000 0.03125 0\\n4       0.03125 0.00000 1\\n...     ...     ...     ...\\n4091    0.93750 1.00000 1022\\n4092    0.96875 0.96875 1023\\n4093    1.00000 0.96875 1023\\n4094    1.00000 1.00000 1023\\n4095    0.96875 1.00000 1023\\n \\n4096 rows Ã 3 columns\\n```\\n\\nTo plot the mesh, we loop over all cells and connect the first and last node to complete the polygon\\n\\n```\\nfig, ax = plt.subplots()\\nax.set_aspect(\\\"equal\\\", \\\"box\\\")\\nax.set_title(\\\"grid at refinement level #%d\\\" % refinement)\\n \\nfor cell_id, cell in meshdata.groupby([\\\"ids\\\"]):\\n    cell = pd.concat([cell, cell.head(1)])\\n    plt.plot(cell[\\\"x\\\"], cell[\\\"y\\\"], c=\\\"k\\\")\\n```\\n\\nAlternatively one could use the matplotlib built-in Polygon class\\n\\n```\\nfig, ax = plt.subplots()\\nax.set_aspect(\\\"equal\\\", \\\"box\\\")\\nax.set_title(\\\"grid at refinement level #%d\\\" % refinement)\\nfor cell_id, cell in meshdata.groupby([\\\"ids\\\"]):\\n    patch = Polygon(cell[[\\\"x\\\", \\\"y\\\"]], facecolor=\\\"w\\\", edgecolor=\\\"k\\\")\\n    ax.add_patch(patch)\\n```\\n\\nTo plot the solution, we first create a finer grid and then interpolate the solution values into the grid and then plot it.\\n\\n```\\nnx = int(np.sqrt(n_cells)) + 1\\nnx *= 10\\nxg = np.linspace(x.min(), x.max(), nx)\\nyg = np.linspace(y.min(), y.max(), nx)\\n \\nxgrid, ygrid = np.meshgrid(xg, yg)\\nsolution_grid = griddata((x, y), solution.flatten(), (xgrid, ygrid), method=\\\"linear\\\")\\n \\nfig = plt.figure()\\nax = fig.add_subplot(1, 1, 1)\\nax.set_title(\\\"solution at refinement level #%d\\\" % refinement)\\nc = ax.pcolor(xgrid, ygrid, solution_grid, cmap=cm.viridis)\\nfig.colorbar(c, ax=ax)\\n \\nplt.show()\\n```\\n\\nTo check the convergence of `mean_value` and `point_value` we loop over data of all refinements and store into vectors `mean_values` and `mean_values`\\n\\n```\\nmean_values = np.zeros((8,))\\npoint_values = np.zeros((8,))\\ndofs = np.zeros((8,))\\n \\nfor refinement in range(1, 9):\\n    filename = \\\"solution_%d.h5\\\" % refinement\\n    file = h5py.File(filename, \\\"r\\\")\\n    mean_values[refinement - 1] = np.array(file[\\\"/mean_value\\\"])[0]\\n    point_values[refinement - 1] = np.array(file[\\\"/point_value\\\"])[0]\\n    dofs[refinement - 1] = np.array(file[\\\"/solution\\\"]).shape[0]\\n```\\n\\nFollowing is the plot of `mean_values` on `log-log` scale\\n\\n```\\nmean_error = np.abs(mean_values[1:] - mean_values[:-1])\\nplt.loglog(dofs[:-1], mean_error)\\nplt.grid()\\nplt.xlabel(\\\"#DoFs\\\")\\nplt.ylabel(\\\"mean value error\\\")\\nplt.show()\\n```\\n\\nFollowing is the plot of `point_values` on `log-log` scale\\n\\n```\\npoint_error = np.abs(point_values[1:] - point_values[:-1])\\nplt.loglog(dofs[:-1], point_error)\\nplt.grid()\\nplt.xlabel(\\\"#DoFs\\\")\\nplt.ylabel(\\\"point value error\\\")\\nplt.show()\\n```\\n\\nA python package which mimics the `R` ggplot2 (which is based on specifying the grammar of the graphics) is [plotnine](https://plotnine.org/).\\n\\n```\\nWe need to import the following from the <code>plotnine</code> package\\nfrom plotnine import (\\n    ggplot,\\n    aes,\\n    geom_raster,\\n    geom_polygon,\\n    geom_line,\\n    labs,\\n    scale_x_log10,\\n    scale_y_log10,\\n    ggtitle,\\n)\\n```\\n\\nThen plot the mesh `meshdata` dataframe\\n\\n```\\nplot = (\\n    ggplot(meshdata, aes(x=\\\"x\\\", y=\\\"y\\\", group=\\\"ids\\\"))\\n    + geom_polygon(fill=\\\"white\\\", colour=\\\"black\\\")\\n    + ggtitle(\\\"grid at refinement level #%d\\\" % refinement)\\n)\\n \\nprint(plot)\\n```\\n\\nCollect the solution into a dataframe\\n\\n```\\ncolordata = pd.DataFrame({\\\"x\\\": x, \\\"y\\\": y, \\\"solution\\\": solution.flatten()})\\n```\\n\\nPlot of the solution\\n\\n```\\nplot = (\\n    ggplot(colordata, aes(x=\\\"x\\\", y=\\\"y\\\", fill=\\\"solution\\\"))\\n    + geom_raster(interpolate=True)\\n    + ggtitle(\\\"solution at refinement level #%d\\\" % refinement)\\n)\\n \\nprint(plot)\\n```\\n\\nCollect the convergence data into a dataframe\\n\\n```\\nconvdata = pd.DataFrame(\\n    {\\\"dofs\\\": dofs[:-1], \\\"mean_value\\\": mean_error, \\\"point_value\\\": point_error}\\n)\\n```\\n\\nFollowing is the plot of `mean_values` on `log-log` scale\\n\\n```\\nplot = (\\n    ggplot(convdata, mapping=aes(x=\\\"dofs\\\", y=\\\"mean_value\\\"))\\n    + geom_line()\\n    + labs(x=\\\"#DoFs\\\", y=\\\"mean value error\\\")\\n    + scale_x_log10()\\n    + scale_y_log10()\\n)\\n \\nplot.save(\\\"mean_error.pdf\\\", dpi=60)\\nprint(plot)\\n```\\n\\nFollowing is the plot of `point_values` on `log-log` scale\\n\\n```\\nplot = (\\n    ggplot(convdata, mapping=aes(x=\\\"dofs\\\", y=\\\"point_value\\\"))\\n    + geom_line()\\n    + labs(x=\\\"#DoFs\\\", y=\\\"point value error\\\")\\n    + scale_x_log10()\\n    + scale_y_log10()\\n)\\n \\nplot.save(\\\"point_error.pdf\\\", dpi=60)\\nprint(plot)\\n```\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 1999 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n */\\n \\n \\n \\n#include <deal.II/grid/tria.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/grid/grid_generator.h>\\n \\n#include <deal.II/fe/fe_q.h>\\n \\n#include <deal.II/dofs/dof_tools.h>\\n \\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/base/quadrature_lib.h>\\n \\n#include <deal.II/base/function.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/matrix_tools.h>\\n \\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_cg.h>\\n#include <deal.II/lac/precondition.h>\\n \\n#include <deal.II/numerics/data_out.h>\\n#include <fstream>\\n#include <iostream>\\n \\nusing namespace dealii;\\n \\n \\n \\nclass Step3\\n{\\npublic:\\n  Step3();\\n \\n void run();\\n \\n \\nprivate:\\n void make_grid();\\n void setup_system();\\n void assemble_system();\\n void solve();\\n void output_results() const;\\n \\n Triangulation<2> triangulation;\\n const FE_Q<2>    fe;\\n DoFHandler<2>    dof_handler;\\n \\n SparsityPattern      sparsity_pattern;\\n SparseMatrix<double> system_matrix;\\n \\n Vector<double> solution;\\n Vector<double> system_rhs;\\n};\\n \\n \\nStep3::Step3()\\n  : fe(/* polynomial degree = */ 1)\\n  , dof_handler(triangulation)\\n{}\\n \\n \\n \\nvoid Step3::make_grid()\\n{\\n GridGenerator::hyper_cube(triangulation, -1, 1);\\n triangulation.refine_global(5);\\n \\n  std::cout << \\\"Number of active cells: \\\" << triangulation.n_active_cells()\\n            << std::endl;\\n}\\n \\n \\n \\n \\nvoid Step3::setup_system()\\n{\\n  dof_handler.distribute_dofs(fe);\\n  std::cout << \\\"Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n            << std::endl;\\n \\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n  sparsity_pattern.copy_from(dsp);\\n \\n  system_matrix.reinit(sparsity_pattern);\\n \\n  solution.reinit(dof_handler.n_dofs());\\n  system_rhs.reinit(dof_handler.n_dofs());\\n}\\n \\n \\n \\nvoid Step3::assemble_system()\\n{\\n const QGauss<2> quadrature_formula(fe.degree + 1);\\n FEValues<2> fe_values(fe,\\n                        quadrature_formula,\\n update_values | update_gradients | update_JxW_values);\\n \\n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n \\n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n Vector<double>     cell_rhs(dofs_per_cell);\\n \\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n \\n for (const auto &cell : dof_handler.active_cell_iterators())\\n    {\\n      fe_values.reinit(cell);\\n \\n cell_matrix = 0;\\n      cell_rhs    = 0;\\n \\n for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n        {\\n for (const unsigned int i : fe_values.dof_indices())\\n            for (const unsigned int j : fe_values.dof_indices())\\n cell_matrix(i, j) +=\\n                (fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                 fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                 fe_values.JxW(q_index));           // dx\\n \\n for (const unsigned int i : fe_values.dof_indices())\\n            cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                            1. *                                // f(x_q)\\n                            fe_values.JxW(q_index));            // dx\\n        }\\n      cell->get_dof_indices(local_dof_indices);\\n \\n for (const unsigned int i : fe_values.dof_indices())\\n        for (const unsigned int j : fe_values.dof_indices())\\n          system_matrix.add(local_dof_indices[i],\\n                            local_dof_indices[j],\\n cell_matrix(i, j));\\n \\n for (const unsigned int i : fe_values.dof_indices())\\n        system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n    }\\n \\n \\n  std::map<types::global_dof_index, double> boundary_values;\\n VectorTools::interpolate_boundary_values(dof_handler,\\n types::boundary_id(0),\\n Functions::ZeroFunction<2>(),\\n                                           boundary_values);\\n MatrixTools::apply_boundary_values(boundary_values,\\n                                     system_matrix,\\n                                     solution,\\n                                     system_rhs);\\n}\\n \\n \\n \\nvoid Step3::solve()\\n{\\n SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n SolverCG<Vector<double>> solver(solver_control);\\n  solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n \\n  std::cout << solver_control.last_step()\\n            << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n}\\n \\n \\n \\nvoid Step3::output_results() const\\n{\\n DataOut<2> data_out;\\n  data_out.attach_dof_handler(dof_handler);\\n  data_out.add_data_vector(solution, \\\"solution\\\");\\n  data_out.build_patches();\\n \\n const std::string filename = \\\"solution.vtk\\\";\\n  std::ofstream     output(filename);\\n  data_out.write_vtk(output);\\n  std::cout << \\\"Output written to \\\" << filename << std::endl;\\n}\\n \\n \\n \\nvoid Step3::run()\\n{\\n  make_grid();\\n  setup_system();\\n  assemble_system();\\n  solve();\\n  output_results();\\n}\\n \\n \\n \\nint main()\\n{\\n  Step3 laplace_problem;\\n  laplace_problem.run();\\n \\n return 0;\\n}\\n```\\n\"}],\"temperature\":0.2,\"response_format\":{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"finetune_prompt-completion_pair\",\"strict\":true,\"description\":\"A pair of prompt and completion for finetuning a code LLM\",\"schema\":{\"type\":\"object\",\"properties\":{\"prompt\":{\"type\":\"string\",\"description\":\"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\"},\"completion\":{\"type\":\"string\",\"description\":\"The final code completion\"}},\"additionalProperties\":false,\"required\":[\"prompt\",\"completion\"]}}}}}\n",
      "{\"custom_id\":\"https://dealii.org/current/doxygen/deal.II//step_4.html\",\"method\":\"POST\",\"url\":\"/v1/chat/completions\",\"body\":{\"model\":\"gpt-4.1-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nThis example is programmed in a way that it is independent of the dimension for which we want to solve Laplace's equation; we will solve the equation in 2D and 3D, although the program is exactly the same. Non-constant right hand side function. Non-homogeneous boundary values.\\nTutorial content :\\nThis tutorial depends on [step-3](step_3.html).\\n\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_4-Intro)    - [The commented program](#step_4-CommProg)      * [Include files](#step_4-Includefiles)* [The `Step4` class template](#step_4-ThecodeStep4codeclasstemplate)* [Right hand side and boundary values](#step_4-Righthandsideandboundaryvalues)* [Implementation of the `Step4` class](#step_4-ImplementationofthecodeStep4codeclass)              + [Step4::Step4](#step_4-Step4Step4)+ [Step4::make\\\\_grid](#step_4-Step4make_grid)+ [Step4::setup\\\\_system](#step_4-Step4setup_system)+ [Step4::assemble\\\\_system](#step_4-Step4assemble_system)+ [Step4::solve](#step_4-Step4solve)+ [Step4::output\\\\_results](#step_4-Step4output_results)+ [Step4::run](#step_4-Step4run)* [The `main` function](#step_4-Thecodemaincodefunction) | 1. [Results](#step_4-Results)    * [Postprocessing: What to do with the solution?](#step_4-PostprocessingWhattodowiththesolution) * [Possibilities for extensions](#step_4-Possibilitiesforextensions)- [The plain program](#step_4-PlainProg) |\\n\\nIntroduction\\n============\\n\\nNote\\n:   The material presented here is also discussed in [video lecture 12](https://www.math.colostate.edu/~bangerth/videos.676.12.html), [video lecture 13](https://www.math.colostate.edu/~bangerth/videos.676.13.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\\n\\ndeal.II has a unique feature which we call `‘dimension independent programming’'. You may have noticed in the previous examples that many classes had a number in angle brackets suffixed to them. This is to indicate that for example the triangulation in two and three space dimensions are different, but related data types. We could as well have called them `Triangulation2d` and `Triangulation3d` instead of `Triangulation<2>` and `Triangulation<3>` to name the two classes, but this has an important drawback: assume you have a function which does exactly the same functionality, but on 2d or 3d triangulations, depending on which dimension we would like to solve the equation in presently (if you don't believe that it is the common case that a function does something that is the same in all dimensions, just take a look at the code below - there are almost no distinctions between 2d and 3d!). We would have to write the same function twice, once working on `Triangulation2d` and once working with a `Triangulation3d`. This is an unnecessary obstacle in programming and leads to a nuisance to keep the two function in sync (at best) or difficult to find errors if the two versions get out of sync (at worst; this would probably the more common case).\\n\\nSuch obstacles can be circumvented by using some template magic as provided by the C++ language: templatized classes and functions are not really classes or functions but only a pattern depending on an as-yet undefined data type parameter or on a numerical value which is also unknown at the point of definition. However, the compiler can build proper classes or functions from these templates if you provide it with the information that is needed for that. Of course, parts of the template can depend on the template parameters, and they will be resolved at the time of compilation for a specific template parameter. For example, consider the following piece of code:\\n\\n```\\ntemplate <int dim>\\nvoid make_grid (Triangulation<dim> &triangulation)\\n{\\n GridGenerator::hyper_cube (triangulation, -1, 1);\\n};\\n```\\n\\nAt the point where the compiler sees this function, it does not know anything about the actual value of `dim`. The only thing the compiler has is a template, i.e. a blueprint, to generate functions `make_grid` if given a particular value of `dim`. Since `dim` has an unknown value, there is no code the compiler can generate for the moment.\\n\\nHowever, if later down the compiler would encounter code that looks, for example, like this,\\n\\n```\\nTriangulation<2> triangulation;\\nmake_grid (triangulation);\\n```\\n\\nthen the compiler will deduce that the function `make_grid` for `dim==2` was requested and will compile the template above into a function with dim replaced by 2 everywhere, i.e. it will compile the function as if it were defined as\\n\\n```\\nvoid make_grid (Triangulation<2> &triangulation)\\n{\\n GridGenerator::hyper_cube (triangulation, -1, 1);\\n};\\n```\\n\\nHowever, it is worth to note that the function `GridGenerator::hyper_cube` depends on the dimension as well, so in this case, the compiler will call the function `GridGenerator::hyper_cube<2>` while if dim were 3, it would call `GridGenerator::hyper_cube<3>` which might be (and actually is) a totally unrelated function.\\n\\nThe same can be done with member variables. Consider the following function, which might in turn call the above one:\\n\\n```\\ntemplate <int dim>\\nvoid make_grid_and_dofs (Triangulation<dim> &triangulation)\\n{\\n  make_grid (triangulation);\\n \\n DoFHandler<dim> dof_handler(triangulation);\\n  ...\\n};\\n```\\n\\nThis function has a member variable of type `DoFHandler<dim>`. Again, the compiler can't compile this function until it knows for which dimension. If you call this function for a specific dimension as above, the compiler will take the template, replace all occurrences of dim by the dimension for which it was called, and compile it. If you call the function several times for different dimensions, it will compile it several times, each time calling the right `make_grid` function and reserving the right amount of memory for the member variable; note that the size of a `DoFHandler` might, and indeed does, depend on the space dimension.\\n\\nThe deal.II library is built around this concept of dimension-independent programming, and therefore allows you to program in a way that will not need to distinguish between the space dimensions. It should be noted that in only a very few places is it necessary to actually compare the dimension using `if`s or `switch`es. However, since the compiler has to compile each function for each dimension separately, even there it knows the value of `dim` at the time of compilation and will therefore be able to optimize away the `if` statement along with the unused branch.\\n\\nIn this example program, we will show how to program dimension independently (which in fact is even simpler than if you had to take care about the dimension) and we will extend the Laplace problem of the last example to a program that runs in two and three space dimensions at the same time. Other extensions are the use of a non-constant right hand side function and of non-zero boundary values.\\n\\nNote\\n:   When using templates, C++ imposes all sorts of syntax constraints that make it sometimes a bit difficult to understand why exactly something has to be written this way. A typical example is the need to use the keyword `typename` in so many places. If you are not entirely familiar with this already, then several of these difficulties are explained in the deal.II Frequently Asked Questions (FAQ) linked to from the [deal.II homepage](http://www.dealii.org/).\\n\\nThe commented program\\n=====================\\n\\n### Include files\\n\\nThe first few (many?) include files have already been used in the previous example, so we will not explain their meaning here again.\\n\\n```\\n   #include <deal.II/grid/tria.h>\\n   #include <deal.II/dofs/dof_handler.h>\\n   #include <deal.II/grid/grid_generator.h>\\n   #include <deal.II/fe/fe_q.h>\\n   #include <deal.II/dofs/dof_tools.h>\\n   #include <deal.II/fe/fe_values.h>\\n   #include <deal.II/base/quadrature_lib.h>\\n   #include <deal.II/base/function.h>\\n   #include <deal.II/numerics/vector_tools.h>\\n   #include <deal.II/numerics/matrix_tools.h>\\n   #include <deal.II/lac/vector.h>\\n   #include <deal.II/lac/full_matrix.h>\\n   #include <deal.II/lac/sparse_matrix.h>\\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n   #include <deal.II/lac/solver_cg.h>\\n   #include <deal.II/lac/precondition.h>\\n   \\n   #include <deal.II/numerics/data_out.h>\\n   #include <fstream>\\n   #include <iostream>\\n```\\n\\nThe final step, as in previous programs, is to import all the deal.II class and function names into the global namespace:\\n\\n```\\n   using namespace dealii;\\n```\\n\\n### The `Step4` class template\\n\\nThis is again the same `Step4` class as in the previous example. The only difference is that we have now declared it as a class with a template parameter, and the template parameter is of course the spatial dimension in which we would like to solve the Laplace equation. Of course, several of the member variables depend on this dimension as well, in particular the [Triangulation](classTriangulation.html) class, which has to represent quadrilaterals or hexahedra, respectively. Apart from this, everything is as before.\\n\\n```\\n   template <int dim>\\n   class Step4\\n   {\\n   public:\\n     Step4();\\n     void run();\\n   \\n   private:\\n     void make_grid();\\n     void setup_system();\\n     void assemble_system();\\n     void solve();\\n     void output_results() const;\\n   \\n     Triangulation<dim> triangulation;\\n     const FE_Q<dim>    fe;\\n     DoFHandler<dim>    dof_handler;\\n   \\n     SparsityPattern      sparsity_pattern;\\n     SparseMatrix<double> system_matrix;\\n   \\n     Vector<double> solution;\\n     Vector<double> system_rhs;\\n   };\\n```\\n\\n### Right hand side and boundary values\\n\\nIn the following, we declare two more classes denoting the right hand side and the non-homogeneous Dirichlet boundary values. Both are functions of a dim-dimensional space variable, so we declare them as templates as well.\\n\\nEach of these classes is derived from a common, abstract base class [Function](classFunction.html), which declares the common interface which all functions have to follow. In particular, concrete classes have to overload the `value` function, which takes a point in dim-dimensional space as parameters and returns the value at that point as a `double` variable.\\n\\nThe `value` function takes a second argument, which we have here named `component`: This is only meant for vector-valued functions, where you may want to access a certain component of the vector at the point `p`. However, our functions are scalar, so we need not worry about this parameter and we will not use it in the implementation of the functions. Inside the library's header files, the [Function](classFunction.html) base class's declaration of the `value` function has a default value of zero for the component, so we will access the `value` function of the right hand side with only one parameter, namely the point where we want to evaluate the function. A value for the component can then simply be omitted for scalar functions.\\n\\n[Function](classFunction.html) objects are used in lots of places in the library (for example, in [step-3](step_3.html) we used a [Functions::ZeroFunction](classFunctions_1_1ZeroFunction.html) instance as an argument to [VectorTools::interpolate\\\\_boundary\\\\_values](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a)) and this is the first tutorial where we define a new class that inherits from [Function](classFunction.html). Since we only ever call [Function::value()](classFunction.html#acbfcab66b2fc63bfea59268f40772bb4), we could get away with just a plain function (and this is what is done in [step-5](step_5.html)), but since this is a tutorial we inherit from [Function](classFunction.html) for the sake of example.\\n\\n```\\n   template <int dim>\\n   class RightHandSide : public Function<dim>\\n   {\\n   public:\\n     virtual double value(const Point<dim>  &p,\\n                          const unsigned int component = 0) const override;\\n   };\\n   \\n   \\n   \\n   template <int dim>\\n   class BoundaryValues : public Function<dim>\\n   {\\n   public:\\n     virtual double value(const Point<dim>  &p,\\n                          const unsigned int component = 0) const override;\\n   };\\n```\\n\\nIf you are not familiar with what the keywords `virtual` and `override` in the function declarations above mean, you will probably want to take a look at your favorite C++ book or an online tutorial such as <http://www.cplusplus.com/doc/tutorial/polymorphism/> . In essence, what is happening here is that Function<dim> is an \\\"abstract\\\" base class that declares a certain \\\"interface\\\" – a set of functions one can call on objects of this kind. But it does not actually *implement* these functions: it just says \\\"this is how Function objects look like\\\", but what kind of function it actually is, is left to derived classes that implement the `value()` function.\\n\\nDeriving one class from another is often called an \\\"is-a\\\" relationship function. Here, the `RightHandSide` class \\\"is a\\\" [Function](classFunction.html) class because it implements the interface described by the [Function](classFunction.html) base class. (The actual implementation of the `value()` function is in the code block below.) The `virtual` keyword then means \\\"Yes, the\\nfunction here is one that can be overridden by derived classes\\\", and the `override` keyword means \\\"Yes, this is in fact a function we know\\nhas been declared as part of the base class\\\". The `override` keyword is not strictly necessary, but is an insurance against typos: If we get the name of the function or the type of one argument wrong, the compiler will warn us by stating \\\"You say that this function overrides one in a base class,\\nbut I don't actually know any such function with this name and these\\narguments.\\\"\\n\\nBut back to the concrete case here: For this tutorial, we choose as right hand side the function \\\\(4(x^4+y^4)\\\\) in 2d, or \\\\(4(x^4+y^4+z^4)\\\\) in 3d. We could write this distinction using an if-statement on the space dimension, but here is a simple way that also allows us to use the same function in 1d (or in 4D, if you should desire to do so), by using a short loop. Fortunately, the compiler knows the size of the loop at compile time (remember that at the time when you define the template, the compiler doesn't know the value of `dim`, but when it later encounters a statement or declaration `RightHandSide<2>`, it will take the template, replace all occurrences of dim by 2 and compile the resulting function). In other words, at the time of compiling this function, the number of times the body will be executed is known, and the compiler can minimize the overhead needed for the loop; the result will be as fast as if we had used the formulas above right away.\\n\\nThe last thing to note is that a `Point<dim>` denotes a point in dim-dimensional space, and its individual components (i.e. \\\\(x\\\\), \\\\(y\\\\), ... coordinates) can be accessed using the () operator (in fact, the [] operator will work just as well) with indices starting at zero as usual in C and C++.\\n\\n```\\n   template <int dim>\\n   double RightHandSide<dim>::value(const Point<dim> &p,\\n                                    const unsigned int /*component*/) const\\n   {\\n     double return_value = 0.0;\\n     for (unsigned int i = 0; i < dim; ++i)\\n       return_value += 4.0 * std::pow(p[i], 4.0);\\n   \\n     return return_value;\\n   }\\n```\\n\\nAs boundary values, we choose \\\\(x^2+y^2\\\\) in 2d, and \\\\(x^2+y^2+z^2\\\\) in 3d. This happens to be equal to the square of the vector from the origin to the point at which we would like to evaluate the function, irrespective of the dimension. So that is what we return:\\n\\n```\\n   template <int dim>\\n   double BoundaryValues<dim>::value(const Point<dim> &p,\\n                                     const unsigned int /*component*/) const\\n   {\\n     return p.square();\\n   }\\n```\\n\\n### Implementation of the `Step4` class\\n\\nNext for the implementation of the class template that makes use of the functions above. As before, we will write everything as templates that have a formal parameter `dim` that we assume unknown at the time we define the template functions. Only later, the compiler will find a declaration of `Step4<2>` (in the `main` function, actually) and compile the entire class with `dim` replaced by 2, a process referred to as ‘instantiation of a template’. When doing so, it will also replace instances of `RightHandSide<dim>` by `RightHandSide<2>` and instantiate the latter class from the class template.\\n\\nIn fact, the compiler will also find a declaration `Step4<3>` in `main()`. This will cause it to again go back to the general `Step4<dim>` template, replace all occurrences of `dim`, this time by 3, and compile the class a second time. Note that the two instantiations `Step4<2>` and `Step4<3>` are completely independent classes; their only common feature is that they are both instantiated from the same general template, but they are not convertible into each other, for example, and share no code (both instantiations are compiled completely independently).\\n\\n#### Step4::Step4\\n\\nAfter this introduction, here is the constructor of the `Step4` class. It specifies the desired polynomial degree of the finite elements and associates the [DoFHandler](classDoFHandler.html) to the triangulation just as in the previous example program, [step-3](step_3.html):\\n\\n```\\n   template <int dim>\\n   Step4<dim>::Step4()\\n     : fe(/* polynomial degree = */ 1)\\n     , dof_handler(triangulation)\\n   {}\\n```\\n\\n#### Step4::make\\\\_grid\\n\\nGrid creation is something inherently dimension dependent. However, as long as the domains are sufficiently similar in 2d or 3d, the library can abstract for you. In our case, we would like to again solve on the square \\\\([-1,1]\\\\times [-1,1]\\\\) in 2d, or on the cube \\\\([-1,1] \\\\times [-1,1] \\\\times\\n[-1,1]\\\\) in 3d; both can be termed [GridGenerator::hyper\\\\_cube()](namespaceGridGenerator.html#acea0cbcd68e52ce8113d1134b87de403), so we may use the same function in whatever dimension we are. Of course, the functions that create a hypercube in two and three dimensions are very much different, but that is something you need not care about. Let the library handle the difficult things.\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::make_grid()\\n   {\\n     GridGenerator::hyper_cube(triangulation, -1, 1);\\n     triangulation.refine_global(4);\\n   \\n     std::cout << \\\"   Number of active cells: \\\" << triangulation.n_active_cells()\\n               << std::endl\\n               << \\\"   Total number of cells: \\\" << triangulation.n_cells()\\n               << std::endl;\\n   }\\n```\\n\\n#### Step4::setup\\\\_system\\n\\nThis function looks exactly like in the previous example, although it performs actions that in their details are quite different if `dim` happens to be 3. The only significant difference from a user's perspective is the number of cells resulting, which is much higher in three than in two space dimensions!\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::setup_system()\\n   {\\n     dof_handler.distribute_dofs(fe);\\n   \\n     std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n               << std::endl;\\n   \\n     DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n     DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n     sparsity_pattern.copy_from(dsp);\\n   \\n     system_matrix.reinit(sparsity_pattern);\\n   \\n     solution.reinit(dof_handler.n_dofs());\\n     system_rhs.reinit(dof_handler.n_dofs());\\n   }\\n```\\n\\n#### Step4::assemble\\\\_system\\n\\nUnlike in the previous example, we would now like to use a non-constant right hand side function and non-zero boundary values. Both are tasks that are readily achieved with only a few new lines of code in the assemblage of the matrix and right hand side.\\n\\nMore interesting, though, is the way we assemble matrix and right hand side vector dimension independently: there is simply no difference to the two-dimensional case. Since the important objects used in this function (quadrature formula, [FEValues](classFEValues.html)) depend on the dimension by way of a template parameter as well, they can take care of setting up properly everything for the dimension for which this function is compiled. By declaring all classes which might depend on the dimension using a template parameter, the library can make nearly all work for you and you don't have to care about most things.\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::assemble_system()\\n   {\\n     const QGauss<dim> quadrature_formula(fe.degree + 1);\\n```\\n\\nWe wanted to have a non-constant right hand side, so we use an object of the class declared above to generate the necessary data. Since this right hand side object is only used locally in the present function, we declare it here as a local variable:\\n\\n```\\n     RightHandSide<dim> right_hand_side;\\n```\\n\\nCompared to the previous example, in order to evaluate the non-constant right hand side function we now also need the quadrature points on the cell we are presently on (previously, we only required values and gradients of the shape function from the [FEValues](classFEValues.html) object, as well as the quadrature weights, [FEValues::JxW()](classFEValuesBase.html#aeb33b877f81e2143752dda2c14a0029d) ). We can tell the [FEValues](classFEValues.html) object to do for us by also giving it the [update\\\\_quadrature\\\\_points](group__feaccess.html#ggaa94b67d2fdcc390690c523f28019e52fad5c9ff886b9615349a5d04a6c782df4a \\\"Transformed quadrature points.\\\") flag:\\n\\n```\\n     FEValues<dim> fe_values(fe,\\n                             quadrature_formula,\\n                             update_values | update_gradients |\\n                               update_quadrature_points | update_JxW_values);\\n```\\n\\nWe then again define the same abbreviation as in the previous program. The value of this variable of course depends on the dimension which we are presently using, but the [FiniteElement](classFiniteElement.html) class does all the necessary work for you and you don't have to care about the dimension dependent parts:\\n\\n```\\n     const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n   \\n     FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n     Vector<double>     cell_rhs(dofs_per_cell);\\n   \\n     std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n```\\n\\nNext, we again have to loop over all cells and assemble local contributions. Note, that a cell is a quadrilateral in two space dimensions, but a hexahedron in 3d. In fact, the `active_cell_iterator` data type is something different, depending on the dimension we are in, but to the outside world they look alike and you will probably never see a difference. In any case, the real type is hidden by using `auto`:\\n\\n```\\n     for (const auto &cell : dof_handler.active_cell_iterators())\\n       {\\n         fe_values.reinit(cell);\\n   \\n         cell_matrix = 0;\\n         cell_rhs    = 0;\\n```\\n\\nNow we have to assemble the local matrix and right hand side. This is done exactly like in the previous example, but now we revert the order of the loops (which we can safely do since they are independent of each other) and merge the loops for the local matrix and the local vector as far as possible to make things a bit faster.\\n\\nAssembling the right hand side presents the only significant difference to how we did things in [step-3](step_3.html): Instead of using a constant right hand side with value 1, we use the object representing the right hand side and evaluate it at the quadrature points:\\n\\n```\\n         for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n           for (const unsigned int i : fe_values.dof_indices())\\n             {\\n               for (const unsigned int j : fe_values.dof_indices())\\n                 cell_matrix(i, j) +=\\n                   (fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                    fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                    fe_values.JxW(q_index));           // dx\\n   \\n               const auto &x_q = fe_values.quadrature_point(q_index);\\n               cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                               right_hand_side.value(x_q) *        // f(x_q)\\n                               fe_values.JxW(q_index));            // dx\\n             }\\n```\\n\\nAs a final remark to these loops: when we assemble the local contributions into `cell_matrix(i,j)`, we have to multiply the gradients of shape functions \\\\(i\\\\) and \\\\(j\\\\) at point number q\\\\_index and multiply it with the scalar weights JxW. This is what actually happens: `fe_values.shape_grad(i,q_index)` returns a `dim` dimensional vector, represented by a `Tensor<1,dim>` object, and the operator\\\\* that multiplies it with the result of `fe_values.shape_grad(j,q_index)` makes sure that the `dim` components of the two vectors are properly contracted, and the result is a scalar floating point number that then is multiplied with the weights. Internally, this operator\\\\* makes sure that this happens correctly for all `dim` components of the vectors, whether `dim` be 2, 3, or any other space dimension; from a user's perspective, this is not something worth bothering with, however, making things a lot simpler if one wants to write code dimension independently.\\n\\nWith the local systems assembled, the transfer into the global matrix and right hand side is done exactly as before, but here we have again merged some loops for efficiency:\\n\\n```\\n         cell->get_dof_indices(local_dof_indices);\\n         for (const unsigned int i : fe_values.dof_indices())\\n           {\\n             for (const unsigned int j : fe_values.dof_indices())\\n               system_matrix.add(local_dof_indices[i],\\n                                 local_dof_indices[j],\\n                                 cell_matrix(i, j));\\n   \\n             system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n           }\\n       }\\n```\\n\\nAs the final step in this function, we wanted to have non-homogeneous boundary values in this example, unlike the one before. This is a simple task, we only have to replace the [Functions::ZeroFunction](classFunctions_1_1ZeroFunction.html) used there by an object of the class which describes the boundary values we would like to use (i.e. the `BoundaryValues` class declared above):\\n\\nThe function [VectorTools::interpolate\\\\_boundary\\\\_values()](namespaceVectorTools.html#a41e94ecf8f78d1fbefe6678f2350530a) will only work on faces that have been marked with boundary indicator 0 (because that's what we say the function should work on with the second argument below). If there are faces with boundary id other than 0, then the function interpolate\\\\_boundary\\\\_values() will do nothing on these faces. For the Laplace equation doing nothing is equivalent to assuming that on those parts of the boundary a zero Neumann boundary condition holds.\\n\\n```\\n     std::map<types::global_dof_index, double> boundary_values;\\n     VectorTools::interpolate_boundary_values(dof_handler,\\n                                              types::boundary_id(0),\\n                                              BoundaryValues<dim>(),\\n                                              boundary_values);\\n     MatrixTools::apply_boundary_values(boundary_values,\\n                                        system_matrix,\\n                                        solution,\\n                                        system_rhs);\\n   }\\n```\\n\\n#### Step4::solve\\n\\nSolving the linear system of equations is something that looks almost identical in most programs. In particular, it is dimension independent, so this function is copied verbatim from the previous example.\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::solve()\\n   {\\n     SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n     SolverCG<Vector<double>> solver(solver_control);\\n     solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n   \\n     std::cout << \\\"   \\\" << solver_control.last_step()\\n               << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n   }\\n```\\n\\n#### Step4::output\\\\_results\\n\\nThis function also does what the respective one did in [step-3](step_3.html). No changes here for dimension independence either.\\n\\nSince the program will run both 2d and 3d versions of the Laplace solver, we use the dimension in the filename to generate distinct filenames for each run (in a better program, one would check whether `dim` can have other values than 2 or 3, but we neglect this here for the sake of brevity).\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::output_results() const\\n   {\\n     DataOut<dim> data_out;\\n   \\n     data_out.attach_dof_handler(dof_handler);\\n     data_out.add_data_vector(solution, \\\"solution\\\");\\n   \\n     data_out.build_patches();\\n   \\n     std::ofstream output(dim == 2 ? \\\"solution-2d.vtk\\\" : \\\"solution-3d.vtk\\\");\\n     data_out.write_vtk(output);\\n   }\\n```\\n\\n#### Step4::run\\n\\nThis is the function which has the top-level control over everything. Apart from one line of additional output, it is the same as for the previous example.\\n\\n```\\n   template <int dim>\\n   void Step4<dim>::run()\\n   {\\n     std::cout << \\\"Solving problem in \\\" << dim << \\\" space dimensions.\\\"\\n               << std::endl;\\n   \\n     make_grid();\\n     setup_system();\\n     assemble_system();\\n     solve();\\n     output_results();\\n   }\\n```\\n\\n### The `main` function\\n\\nAnd this is the main function. It also looks mostly like in [step-3](step_3.html), but if you look at the code below, note how we first create a variable of type `Step4<2>` (forcing the compiler to compile the class template with `dim` replaced by `2`) and run a 2d simulation, and then we do the whole thing over in 3d.\\n\\nIn practice, this is probably not what you would do very frequently (you probably either want to solve a 2d problem, or one in 3d, but not both at the same time). However, it demonstrates the mechanism by which we can simply change which dimension we want in a single place, and thereby force the compiler to recompile the dimension independent class templates for the dimension we request. The emphasis here lies on the fact that we only need to change a single place. This makes it rather trivial to debug the program in 2d where computations are fast, and then switch a single place to a 3 to run the much more computing intensive program in 3d for ‘real’ computations.\\n\\nEach of the two blocks is enclosed in braces to make sure that the `laplace_problem_2d` variable goes out of scope (and releases the memory it holds) before we move on to allocate memory for the 3d case. Without the additional braces, the `laplace_problem_2d` variable would only be destroyed at the end of the function, i.e. after running the 3d problem, and would needlessly hog memory while the 3d run could actually use it.\\n\\n```\\n   int main()\\n   {\\n     {\\n       Step4<2> laplace_problem_2d;\\n       laplace_problem_2d.run();\\n     }\\n   \\n     {\\n       Step4<3> laplace_problem_3d;\\n       laplace_problem_3d.run();\\n     }\\n   \\n     return 0;\\n   }\\n```\\n\\nResults\\n=======\\n\\nThe output of the program looks as follows (the number of iterations may vary by one or two, depending on your computer, since this is often dependent on the round-off accuracy of floating point operations, which differs between processors):\\n\\n```\\nSolving problem in 2 space dimensions.\\n   Number of active cells: 256\\n   Total number of cells: 341\\n   Number of degrees of freedom: 289\\n   19 CG iterations needed to obtain convergence.\\nSolving problem in 3 space dimensions.\\n   Number of active cells: 4096\\n   Total number of cells: 4681\\n   Number of degrees of freedom: 4913\\n   20 CG iterations needed to obtain convergence.\\n```\\n\\nIt is obvious that in three spatial dimensions the number of cells and therefore also the number of degrees of freedom is much higher. What cannot be seen here, is that besides this higher number of rows and columns in the matrix, there are also significantly more entries per row of the matrix in three space dimensions. Together, this leads to a much higher numerical effort for solving the system of equation, which you can feel in the run time of the two solution steps when you actually run the program.\\n\\nThe program produces two files: `solution-2d.vtk` and `solution-3d.vtk`, which can be viewed using the programs VisIt or Paraview (in case you do not have these programs, you can easily change the output format in the program to something which you can view more easily). Visualizing solutions is a bit of an art, but it can also be fun, so you should play around with your favorite visualization tool to get familiar with its functionality. Here's what I have come up with for the 2d solution:\\n\\n![](images/steps/developer/step-4.solution-2d.png)\\n\\n(See also [video lecture 11](https://www.math.colostate.edu/~bangerth/videos.676.11.html), [video lecture 32](https://www.math.colostate.edu/~bangerth/videos.676.32.html).) The picture shows the solution of the problem under consideration as a 3D plot. As can be seen, the solution is almost flat in the interior of the domain and has a higher curvature near the boundary. This, of course, is due to the fact that for Laplace's equation the curvature of the solution is equal to the right hand side and that was chosen as a quartic polynomial which is nearly zero in the interior and is only rising sharply when approaching the boundaries of the domain; the maximal values of the right hand side function are at the corners of the domain, where also the solution is moving most rapidly. It is also nice to see that the solution follows the desired quadratic boundary values along the boundaries of the domain. It can also be useful to verify a computed solution against an analytical solution. For an explanation of this technique, see [step-7](step_7.html).\\n\\nOn the other hand, even though the picture does not show the mesh lines explicitly, you can see them as little kinks in the solution. This clearly indicates that the solution hasn't been computed to very high accuracy and that to get a better solution, we may have to compute on a finer mesh.\\n\\nIn three spatial dimensions, visualization is a bit more difficult. The left picture shows the solution and the mesh it was computed on on the surface of the domain. This is nice, but it has the drawback that it completely hides what is happening on the inside. The picture on the right is an attempt at visualizing the interior as well, by showing surfaces where the solution has constant values (as indicated by the legend at the top left). Isosurface pictures look best if one makes the individual surfaces slightly transparent so that it is possible to see through them and see what's behind.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nNote\\n:   A final remark on visualization: the idea of visualization is to give insight, which is not the same as displaying information. In particular, it is easy to overload a picture with information, but while it shows more information it makes it also more difficult to glean insight. As an example, the program I used to generate these pictures, VisIt, by default puts tick marks on every axis, puts a big fat label \\\"X Axis\\\" on the \\\\(x\\\\) axis and similar for the other axes, shows the file name from which the data was taken in the top left and the name of the user doing so and the time and date on the bottom right. None of this is important here: the axes are equally easy to make out because the tripod at the bottom left is still visible, and we know from the program that the domain is \\\\([-1,1]^3\\\\), so there is no need for tick marks. As a consequence, I have switched off all the extraneous stuff in the picture: the art of visualization is to reduce the picture to those parts that are important to see what one wants to see, but no more.\\n\\n### Postprocessing: What to do with the solution?\\n\\nThis tutorial – like most of the other programs – principally only shows how to numerically approximate the solution of a partial differential equation, and then how to visualize this solution graphically. But solving a PDE is of course not the goal in most practical applications (unless you are a numerical methods developer and the *method* is the goal): We generally want to solve a PDE because we want to *extract information* from it. Examples for what people are interested in from solutions include the following:\\n\\n* Let's say you solve the equations of elasticity (which we will do in [step-8](step_8.html)), then that's presumably because you want to know about the deformation of an elastic object under a given load. From an engineering perspective, what you then presumably want to learn is the degree of deformation of the object, say at a specific point; or you may want to know the maximum [stress](https://en.wikipedia.org/wiki/Stress_(mechanics)) in order to determine whether the applied load exceeds the safe maximal stress the material can withstand.\\n* If you are solving fluid flow problems (such as in [step-22](step_22.html), [step-57](step_57.html), [step-67](step_67.html), and [step-69](step_69.html)), then you might be interested in the fluid velocity at specific points, and oftentimes the forces the fluid exerts on the boundary of the fluid domain. The latter is important in many applications: If the fluid in question is the air flowing around an airplane, then we are typically interested in the drag and lift forces on the fuselage and wings. If the fluid is water flowing around a ship, then we typically care about the drag force on the ship.\\n* If you are solving the Maxwell equations of electromagnetics, you are typically interested in how much energy is radiated in certain directions (say, in order to know the range of information transmission via an antenna, or to determine the [radar cross section](https://en.wikipedia.org/wiki/Radar_cross_section) of planes or ships).\\n\\nThe point here is that from an engineering perspective, *solving* the PDE is only the first step. The second step is to *evaluate* the computed solution in order to extract relevant numbers that allow us to either *optimize a design*, or to *make decisions*. This second step is often called \\\"postprocessing the solution\\\".\\n\\nThis program does not solve a solid or fluid mechanics problem, so we should try to illustrate postprocessing with something that makes sense in the context of the equation we solve here. The Poisson equation in two space dimensions is a model for the vertical deformation of a membrane that is clamped at the boundary and is subject to a vertical force. For this kind of situation, it makes sense to evaluate the *average vertical displacement*,\\n\\n\\\\[\\n\\\\bar u\\\\_h = \\\\frac{\\\\int\\\\_\\\\Omega u\\\\_h(\\\\mathbf x) \\\\, dx}{|\\\\Omega|},\\n\\\\]\\n\\nwhere \\\\(|\\\\Omega| = \\\\int\\\\_\\\\Omega 1 \\\\, dx\\\\) is the area of the domain. To compute \\\\(\\\\bar u\\\\_h\\\\), as usual we replace integrals over the domain by a sum of integrals over cells,\\n\\n\\\\[\\n\\\\int\\\\_\\\\Omega u\\\\_h(\\\\mathbf x) \\\\, dx\\n=\\n\\\\sum\\\\_K \\\\int\\\\_K u\\\\_h(\\\\mathbf x) \\\\, dx,\\n\\\\]\\n\\nand then integrals over cells are approximated by quadrature:\\n\\n\\\\begin{align\\\\*}\\n\\\\int\\\\_\\\\Omega u\\\\_h(\\\\mathbf x) \\\\, dx\\n&=\\n\\\\sum\\\\_K \\\\int\\\\_K u\\\\_h(\\\\mathbf x) \\\\, dx,\\n\\\\\\\\\\n&=\\n\\\\sum\\\\_K \\\\sum\\\\_q u\\\\_h(\\\\mathbf x\\\\_q^K) w\\\\_q^K,\\n\\\\end{align\\\\*}\\n\\nwhere \\\\(w\\\\_q^K\\\\) is the weight of the \\\\(q\\\\)th quadrature point evaluated on cell \\\\(K\\\\). All of this is as always provided by the [FEValues](classFEValues.html) class – the entry point for all integrals in deal.II.\\n\\nThe actual implementation of this is straightforward once you know how to get the values of the solution \\\\(u\\\\) at the quadrature points of a cell. This functionality is provided by [FEValues::get\\\\_function\\\\_values()](classFEValuesBase.html#a33e437195106aee8e3ad88b2dd40d223), a function that takes a global vector of nodal values as input and returns a vector of function values at the quadrature points of the current cell. Using this function, to see how it all works together you can place the following code snippet anywhere in the program after the solution has been computed (the `output_results()` function seems like a good place to also do postprocessing, for example):\\n\\n```\\nQGauss<dim>   quadrature_formula(fe.degree + 1);\\nFEValues<dim> fe_values(fe,\\n                        quadrature_formula,\\n update_values | update_JxW_values);\\n \\nstd::vector<double> solution_values(quadrature_formula.size());\\ndouble              integral_of_u   = 0;\\ndouble              volume_of_omega = 0;\\n \\nfor (const auto &cell : dof_handler.active_cell_iterators())\\n  {\\n    fe_values.reinit(cell);\\n    fe_values.get_function_values(solution, solution_values);\\n \\n for (const unsigned int q_point : fe_values.quadrature_point_indices())\\n      {\\n        integral_of_u += solution_values[q_point] * fe_values.JxW(q_point);\\n        volume_of_omega += 1 * fe_values.JxW(q_point);\\n      }\\n  }\\nstd::cout << \\\"   Mean value of u=\\\" << integral_of_u / volume_of_omega\\n          << std::endl;\\n```\\n\\nIn this code snippet, we also compute the volume (or, since we are currently thinking about a two-dimensional situation: the area) \\\\(|\\\\Omega|\\\\) by computing the integral \\\\(|\\\\Omega| = \\\\int\\\\_\\\\Omega 1 \\\\, dx\\\\) in exactly the same way, via quadrature. (We could avoid having to compute \\\\(|\\\\Omega|\\\\) by hand here, using the fact that deal.II has a function for this: [GridTools::volume()](namespaceGridTools.html#abde377a9a6f142b42aecf41cd56043ae). That said, it is efficient to compute the two integrals concurrently in the same loop, and so that's what we do.)\\n\\nThis program of course also solves the same Poisson equation in three space dimensions. In this situation, the Poisson equation is often used as a model for diffusion of either a physical species (say, of ink in a tank of water, or a pollutant in the air) or of energy (specifically, of thermal energy in a solid body). In that context, the quantity\\n\\n\\\\[\\n\\\\Phi\\\\_h = \\\\int\\\\_{\\\\partial\\\\Omega} \\\\nabla u\\\\_h(\\\\mathbf x) \\\\cdot \\\\mathbf n(\\\\mathbf x) \\\\; dx\\n\\\\]\\n\\nis the *flux* of this species or energy across the boundary. (In actual physical models, one would also have to multiply the right hand side by a diffusivity or conductivity constant, but let us ignore this here.) In much the same way as before, we compute such integrals by splitting it over integrals of *faces* of cells, and then applying quadrature:\\n\\n\\\\begin{align\\\\*}\\n\\\\Phi\\\\_h\\n&=\\n\\\\int\\\\_{\\\\partial\\\\Omega} \\\\nabla u\\\\_h(\\\\mathbf x) \\\\cdot \\\\mathbf n(\\\\mathbf x) \\\\; dx\\n\\\\\\\\\\n&=\\n\\\\sum\\\\_K\\n\\\\sum\\\\_{f \\\\in \\\\text{faces of @f$K@f$}, f\\\\subset\\\\partial\\\\Omega}\\n\\\\int\\\\_f \\\\nabla u\\\\_h(\\\\mathbf x) \\\\cdot \\\\mathbf n(\\\\mathbf x) \\\\; dx\\n\\\\\\\\\\n&=\\n\\\\sum\\\\_K\\n\\\\sum\\\\_{f \\\\in \\\\text{faces of @f$K@f$}, f\\\\subset\\\\partial\\\\Omega}\\n\\\\sum\\\\_q \\\\nabla u\\\\_h(\\\\mathbf x\\\\_q^f) \\\\cdot \\\\mathbf n(\\\\mathbf x\\\\_q^f) w\\\\_q^f,\\n\\\\end{align\\\\*}\\n\\nwhere now \\\\(\\\\mathbf x\\\\_q^f\\\\) are the quadrature points located on face \\\\(f\\\\), and \\\\(w\\\\_q^f\\\\) are the weights associated with these faces. The second of the sum symbols loops over all faces of cell \\\\(K\\\\), but restricted to those that are actually at the boundary.\\n\\nThis all is easily implemented by the following code that replaces the use of the [FEValues](classFEValues.html) class (which is used for integrating over cells – i.e., domain integrals) by the [FEFaceValues](classFEFaceValues.html) class (which is used for integrating over faces – i.e., boundary integrals):\\n\\n```\\nQGauss<dim - 1>   face_quadrature_formula(fe.degree + 1);\\nFEFaceValues<dim> fe_face_values(fe,\\n                                 face_quadrature_formula,\\n update_gradients | update_normal_vectors |\\n update_JxW_values);\\n \\nstd::vector<Tensor<1, dim>> solution_gradients(face_quadrature_formula.size());\\ndouble                      flux = 0;\\n \\nfor (const auto &cell : dof_handler.active_cell_iterators())\\n  for (const auto &face : cell->face_iterators())\\n    if (face->at_boundary())\\n      {\\n        fe_face_values.reinit(cell, face);\\n        fe_face_values.get_function_gradients(solution, solution_gradients);\\n \\n for (const unsigned int q_point :\\n             fe_face_values.quadrature_point_indices())\\n          {\\n            flux += solution_gradients[q_point] *\\n                    fe_face_values.normal_vector(q_point) *\\n                    fe_face_values.JxW(q_point);\\n          }\\n      }\\nstd::cout << \\\"   Flux=\\\" << flux << std::endl;\\n```\\n\\nIf you add these two code snippets to the code, you will get output like the following when you run the program:\\n\\n```\\nSolving problem in 2 space dimensions.\\n   Number of active cells: 256\\n   Total number of cells: 341\\n   Number of degrees of freedom: 289\\n   26 CG iterations needed to obtain convergence.\\n   Mean value of u=1.33303\\n   Flux=-3.68956\\nSolving problem in 3 space dimensions.\\n   Number of active cells: 4096\\n   Total number of cells: 4681\\n   Number of degrees of freedom: 4913\\n   30 CG iterations needed to obtain convergence.\\n   Mean value of u=1.58058\\n   Flux=-8.29435\\n```\\n\\nThis makes some sense: If you look, for example, at the 2d output above, the solution varies between values of 1 and 2, but with a larger part of the solution closer to one than two; so an average value of 1.33 for the mean value is reasonable. For the flux, recall that \\\\(\\\\nabla u \\\\cdot \\\\mathbf n\\\\) is the directional derivative in the normal direction – in other words, how the solution changes as we move from the interior of the domain towards the boundary. If you look at the 2d solution, you will realize that for most parts of the boundary, the solution *decreases* as we approach the boundary, so the normal derivative is negative – so if we integrate along the boundary, we should expect (and obtain!) a negative value.\\n\\n### Possibilities for extensions\\n\\nThere are many ways with which one can play with this program. The simpler ones include essentially all the possibilities already discussed in the [Possibilities for extensions in the documentation of step 3](step_3.html#extensions), except that you will have to think about whether something now also applies to the 3d case discussed in the current program.\\n\\nIt is also worthwhile considering the postprocessing options discussed above. The documentation states two numbers (the mean value and the normal flux) for both the 2d and 3d cases. Can we trust these numbers? We have convinced ourselves that at least the mean value is reasonable, and that the sign of the flux is probably correct. But are these numbers accurate?\\n\\nA general rule is that we should never trust a number unless we have verified it in some way. From the theory of finite element methods, we know that as we make the mesh finer and finer, the numerical solution \\\\(u\\\\_h\\\\) we compute here must converge to the exact solution \\\\(u\\\\). As a consequence, we also expect that \\\\(\\\\bar u\\\\_h \\\\rightarrow \\\\bar u\\\\) and \\\\(\\\\Phi\\\\_h \\\\rightarrow \\\\Phi\\\\), but that does not mean that for any given mesh \\\\(\\\\bar u\\\\_h\\\\) or \\\\(\\\\Phi\\\\_h\\\\) are particularly accurate approximations.\\n\\nTo test this kind of thing, we have already considered the convergence of a point value in [step-3](step_3.html). We can do the same here by selecting how many times the mesh is globally refined in the `make_grid()` function of this program. For the mean value of the solution, we then get the following numbers:\\n\\n| # of refinements | \\\\(\\\\bar u\\\\_h\\\\) in 2d | \\\\(\\\\bar u\\\\_h\\\\) in 3d |\\n| --- | --- | --- |\\n| 4 | 1.33303 | 1.58058 |\\n| 5 | 1.33276 | 1.57947 |\\n| 6 | 1.3327 | 1.5792 |\\n| 7 | 1.33269 | 1.57914 |\\n| 8 | 1.33268 |  |\\n| 9 | 1.33268 |  |\\n\\nI did not have the patience to run the last two values for the 3d case – one needs quite a fine mesh for this, with correspondingly long run times. But we can be reasonably assured that values around 1.33 (for the 2d case) and 1.58 (for the 3d case) are about right – and at least for engineering applications, three digits of accuracy are good enough.\\n\\nThe situation looks very different for the flux. Here, we get results such as the following:\\n\\n| # of refinements | \\\\(\\\\Phi\\\\_h\\\\) in 2d | \\\\(\\\\Phi\\\\_h\\\\) in 3d |\\n| --- | --- | --- |\\n| 4 | -3.68956 | -8.29435 |\\n| 5 | -4.90147 | -13.0691 |\\n| 6 | -5.60745 | -15.9171 |\\n| 7 | -5.99111 | -17.4918 |\\n| 8 | -6.19196 |  |\\n| 9 | -6.29497 |  |\\n| 10 | -6.34721 |  |\\n| 11 | -6.37353 |  |\\n\\nSo this is not great. For the 2d case, we might infer that perhaps a value around -6.4 might be right if we just refine the mesh enough – though 11 refinements already leads to some 4,194,304 cells. In any case, the first number (the one shown in the beginning where we discussed postprocessing) was off by almost a factor of 2!\\n\\nFor the 3d case, the last number shown was on a mesh with 2,097,152 cells; the next one would have had 8 times as many cells. In any case, the numbers mean that we can't even be sure that the first digit of that last number is correct! In other words, it was worth checking, or we would have just believed all of these numbers. In fact, that last column isn't even doing a particularly good job convincing us that the code might be correctly implemented.\\n\\nIf you keep reading through the other tutorial programs, you will find many ways to make these sorts of computations more accurate and to come to believe that the flux actually does converge to its correct value. For example, we can dramatically increase the accuracy of the computation by using adaptive mesh refinement ([step-6](step_6.html)) near the boundary, and in particular by using higher polynomial degree finite elements (also [step-6](step_6.html), but also [step-7](step_7.html)). Using the latter, using cubic elements (polynomial degree 3), we can actually compute the flux pretty accurately even in 3d: \\\\(\\\\Phi\\\\_h=-19.0148\\\\) with 4 global refinement steps, and \\\\(\\\\Phi\\\\_h=-19.1533\\\\) with 5 refinement steps. These numbers are already pretty close together and give us a reasonable idea of the first two correct digits of the \\\"true\\\" answer.\\n\\nNote\\n:   We would be remiss to not also comment on the fact that there are good theoretical reasons why computing the flux accurately appears to be so much more difficult than the average value. This has to do with the fact that finite element theory provides us with the estimate \\\\(\\\\|u-u\\\\_h\\\\|\\\\_{L\\\\_2(\\\\Omega)} \\\\le C h^2 \\\\|\\\\nabla^2u\\\\|\\\\_{L\\\\_2(\\\\Omega)}\\\\) when using the linear elements this program uses – that is, for every global mesh refinement, \\\\(h\\\\) is reduced by a factor of two and the error goes down by a factor of 4. Now, the \\\\(L\\\\_2\\\\) error is not equivalent to the error in the mean value, but the two are related: They are both integrals over the domain, using the *value* of the solution. We expect the mean value to converge no worse than the \\\\(L\\\\_2\\\\) norm of the error. At the same time, theory also provides us with this estimate: \\\\(\\\\|\\\\nabla (u-u\\\\_h)\\\\|\\\\_{L\\\\_2(\\\\partial\\\\Omega)} \\\\le\\n    C h^{1/2} \\\\|\\\\nabla^2u\\\\|\\\\_{L\\\\_2(\\\\Omega)}\\\\). The move from values to gradients reduces the convergence rates by one order, and the move from domain to boundary by another half order. Here, then, each refinement step reduces the error not by a factor of 4 any more, by only by a factor of \\\\(\\\\sqrt{2} \\\\approx 1.4\\\\). It takes a lot of global refinement steps to reduce the error by, say, a factor ten or hundred, and this is reflected in the very slow convergence evidenced by the table. On the other hand, for cubic elements (i.e., polynomial degree 3), we would get \\\\(\\\\|u-u\\\\_h\\\\|\\\\_{L\\\\_2(\\\\Omega)} \\\\le C h^4 \\\\|\\\\nabla^4u\\\\|\\\\_{L\\\\_2(\\\\Omega)}\\\\) and after reduction by 1.5 orders, we would still have \\\\(\\\\|\\\\nabla (u-u\\\\_h)\\\\|\\\\_{L\\\\_2(\\\\partial\\\\Omega)} \\\\le\\n    C h^{2+1/2} \\\\|\\\\nabla^4u\\\\|\\\\_{L\\\\_2(\\\\Omega)}\\\\). This rate, \\\\({\\\\cal O}(h^{2.5})\\\\) is still quite rapid, and it is perhaps not surprising that we get much better answers with these higher order elements. This also illustrates that when trying to approximate anything that relates to a gradient of the solution, using linear elements (polynomial degree one) is really not a good choice at all.\\n:   In this very specific case, it turns out that we can actually compute the exact value of \\\\(\\\\Phi\\\\). This is because for the Poisson equation we compute the solution of here, \\\\(-\\\\Delta u = f\\\\), we can integrate over the domain, \\\\(-\\\\int\\\\_\\\\Omega \\\\Delta u = \\\\int\\\\_\\\\Omega f\\\\), and then use that \\\\(\\\\Delta = \\\\text{div}\\\\;\\\\text{grad}\\\\); this allows us to use the divergence theorem followed by multiplying by minus one to find \\\\(\\\\int\\\\_{\\\\partial\\\\Omega} \\\\nabla u \\\\cdot n = -\\\\int\\\\_\\\\Omega f\\\\). The left hand side happens to be \\\\(\\\\Phi\\\\). For the specific right hand side \\\\(f(x\\\\_1,x\\\\_2)=4(x\\\\_1^4+x\\\\_2^4)\\\\) we use in 2d, we then get \\\\(-\\\\int\\\\_\\\\Omega f = -\\\\int\\\\_{-1}^{1} \\\\int\\\\_{-1}^{1} 4(x\\\\_1^4+x\\\\_2^4) \\\\; dx\\\\_2\\\\; dx\\\\_1\\n    = -16 \\\\left[\\\\int\\\\_{-1}^{1} x^4 \\\\; dx\\\\right] = -16\\\\times\\\\frac 25\\\\), which has a numerical value of exactly -6.4 – right on with our guess above. In 3d, we can do the same and get that the exact value is \\\\(-\\\\int\\\\_\\\\Omega f =\\n    -\\\\int\\\\_{-1}^{1} \\\\int\\\\_{-1}^{1} \\\\int\\\\_{-1}^{1} 4(x\\\\_1^4+x\\\\_2^4+x\\\\_3^4) \\\\; dx\\\\_3 \\\\; dx\\\\_2\\\\; dx\\\\_1\\n    = -48\\\\times\\\\frac 25=-19.2\\\\). What we found with cubic elements is then quite close to this exact value. Of course, in practice we almost never have exact values to compare with: If we could compute something on a piece of paper, we wouldn't have to solve the PDE numerically. But these sorts of situations make for excellent test cases that help us verify that our numerical solver works correctly. In many other cases, the literature contains numbers where others have already computed an answer accurately using their own software, and these are also often useful to compare against in verifying the correctness of our codes.\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 1999 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n */\\n \\n \\n \\n#include <deal.II/grid/tria.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/matrix_tools.h>\\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_cg.h>\\n#include <deal.II/lac/precondition.h>\\n \\n#include <deal.II/numerics/data_out.h>\\n#include <fstream>\\n#include <iostream>\\n \\nusing namespace dealii;\\n \\n \\ntemplate <int dim>\\nclass Step4\\n{\\npublic:\\n  Step4();\\n void run();\\n \\nprivate:\\n void make_grid();\\n void setup_system();\\n void assemble_system();\\n void solve();\\n void output_results() const;\\n \\n Triangulation<dim> triangulation;\\n const FE_Q<dim>    fe;\\n DoFHandler<dim>    dof_handler;\\n \\n SparsityPattern      sparsity_pattern;\\n SparseMatrix<double> system_matrix;\\n \\n Vector<double> solution;\\n Vector<double> system_rhs;\\n};\\n \\n \\n \\ntemplate <int dim>\\nclass RightHandSide : public Function<dim>\\n{\\npublic:\\n virtual double value(const Point<dim>  &p,\\n const unsigned int component = 0) const override;\\n};\\n \\n \\n \\ntemplate <int dim>\\nclass BoundaryValues : public Function<dim>\\n{\\npublic:\\n virtual double value(const Point<dim>  &p,\\n const unsigned int component = 0) const override;\\n};\\n \\ntemplate <int dim>\\ndouble RightHandSide<dim>::value(const Point<dim> &p,\\n const unsigned int /*component*/) const\\n{\\n double return_value = 0.0;\\n for (unsigned int i = 0; i < dim; ++i)\\n    return_value += 4.0 * std::pow(p[i], 4.0);\\n \\n return return_value;\\n}\\n \\n \\ntemplate <int dim>\\ndouble BoundaryValues<dim>::value(const Point<dim> &p,\\n const unsigned int /*component*/) const\\n{\\n return p.square();\\n}\\n \\n \\n \\n \\n \\n \\n \\ntemplate <int dim>\\nStep4<dim>::Step4()\\n  : fe(/* polynomial degree = */ 1)\\n  , dof_handler(triangulation)\\n{}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::make_grid()\\n{\\n GridGenerator::hyper_cube(triangulation, -1, 1);\\n triangulation.refine_global(4);\\n \\n  std::cout << \\\"   Number of active cells: \\\" << triangulation.n_active_cells()\\n            << std::endl\\n            << \\\"   Total number of cells: \\\" << triangulation.n_cells()\\n            << std::endl;\\n}\\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::setup_system()\\n{\\n  dof_handler.distribute_dofs(fe);\\n \\n  std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n            << std::endl;\\n \\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n  sparsity_pattern.copy_from(dsp);\\n \\n  system_matrix.reinit(sparsity_pattern);\\n \\n  solution.reinit(dof_handler.n_dofs());\\n  system_rhs.reinit(dof_handler.n_dofs());\\n}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::assemble_system()\\n{\\n const QGauss<dim> quadrature_formula(fe.degree + 1);\\n \\n  RightHandSide<dim> right_hand_side;\\n \\n FEValues<dim> fe_values(fe,\\n                          quadrature_formula,\\n update_values | update_gradients |\\n update_quadrature_points | update_JxW_values);\\n \\n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n \\n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n Vector<double>     cell_rhs(dofs_per_cell);\\n \\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n \\n for (const auto &cell : dof_handler.active_cell_iterators())\\n    {\\n      fe_values.reinit(cell);\\n \\n cell_matrix = 0;\\n      cell_rhs    = 0;\\n \\n for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n        for (const unsigned int i : fe_values.dof_indices())\\n          {\\n for (const unsigned int j : fe_values.dof_indices())\\n cell_matrix(i, j) +=\\n                (fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                 fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                 fe_values.JxW(q_index));           // dx\\n \\n const auto &x_q = fe_values.quadrature_point(q_index);\\n            cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                            right_hand_side.value(x_q) *        // f(x_q)\\n                            fe_values.JxW(q_index));            // dx\\n          }\\n \\n      cell->get_dof_indices(local_dof_indices);\\n for (const unsigned int i : fe_values.dof_indices())\\n        {\\n for (const unsigned int j : fe_values.dof_indices())\\n            system_matrix.add(local_dof_indices[i],\\n                              local_dof_indices[j],\\n cell_matrix(i, j));\\n \\n          system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n        }\\n    }\\n \\n  std::map<types::global_dof_index, double> boundary_values;\\n VectorTools::interpolate_boundary_values(dof_handler,\\n types::boundary_id(0),\\n                                           BoundaryValues<dim>(),\\n                                           boundary_values);\\n MatrixTools::apply_boundary_values(boundary_values,\\n                                     system_matrix,\\n                                     solution,\\n                                     system_rhs);\\n}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::solve()\\n{\\n SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n SolverCG<Vector<double>> solver(solver_control);\\n  solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n \\n  std::cout << \\\"   \\\" << solver_control.last_step()\\n            << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::output_results() const\\n{\\n DataOut<dim> data_out;\\n \\n  data_out.attach_dof_handler(dof_handler);\\n  data_out.add_data_vector(solution, \\\"solution\\\");\\n \\n  data_out.build_patches();\\n \\n  std::ofstream output(dim == 2 ? \\\"solution-2d.vtk\\\" : \\\"solution-3d.vtk\\\");\\n  data_out.write_vtk(output);\\n}\\n \\n \\n \\n \\ntemplate <int dim>\\nvoid Step4<dim>::run()\\n{\\n  std::cout << \\\"Solving problem in \\\" << dim << \\\" space dimensions.\\\"\\n            << std::endl;\\n \\n  make_grid();\\n  setup_system();\\n  assemble_system();\\n  solve();\\n  output_results();\\n}\\n \\n \\n \\nint main()\\n{\\n  {\\n    Step4<2> laplace_problem_2d;\\n    laplace_problem_2d.run();\\n  }\\n \\n  {\\n    Step4<3> laplace_problem_3d;\\n    laplace_problem_3d.run();\\n  }\\n \\n return 0;\\n}\\n```\\n\"}],\"temperature\":0.2,\"response_format\":{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"finetune_prompt-completion_pair\",\"strict\":true,\"description\":\"A pair of prompt and completion for finetuning a code LLM\",\"schema\":{\"type\":\"object\",\"properties\":{\"prompt\":{\"type\":\"string\",\"description\":\"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\"},\"completion\":{\"type\":\"string\",\"description\":\"The final code completion\"}},\"additionalProperties\":false,\"required\":[\"prompt\",\"completion\"]}}}}}\n",
      "{\"custom_id\":\"https://dealii.org/current/doxygen/deal.II//step_5.html\",\"method\":\"POST\",\"url\":\"/v1/chat/completions\",\"body\":{\"model\":\"gpt-4.1-mini\",\"messages\":[{\"role\":\"user\",\"content\":\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nComputations on successively refined grids. Reading a grid from disk. Some optimizations. Using assertions. Non-constant coefficient in the elliptic operator (yielding the extended Poisson equation). Preconditioning the CG solver for the linear system of equations.\\nTutorial content :\\nThis tutorial depends on [step-4](step_4.html).\\n\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_5-Intro)    * [Successively refined grids](#step_5-Successivelyrefinedgrids) * [Reading in an externally generated mesh](#step_5-Readinginanexternallygeneratedmesh) * [Solving a generalized Laplace (Poisson) equation](#step_5-SolvingageneralizedLaplacePoissonequation) * [Support for debugging: Assertions](#step_5-SupportfordebuggingAssertions)- [The commented program](#step_5-CommProg)      * [Include files](#step_5-Includefiles)* [The `Step5` class template](#step_5-ThecodeStep5codeclasstemplate)* [Working with nonconstant coefficients](#step_5-Workingwithnonconstantcoefficients)* [The `Step5` class implementation](#step_5-ThecodeStep5codeclassimplementation)              + [Step5::Step5](#step_5-Step5Step5)+ [Step5::setup\\\\_system](#step_5-Step5setup_system)+ [Step5::assemble\\\\_system](#step_5-Step5assemble_system)+ [Step5::solve](#step_5-Step5solve)+ [Step5::output\\\\_results and setting output flags](#step_5-Step5output_resultsandsettingoutputflags)+ [Step5::run](#step_5-Step5run)* [The `main` function](#step_5-Thecodemaincodefunction) | 1. [Results](#step_5-Results)    - [The plain program](#step_5-PlainProg) |\\n\\nIntroduction\\n============\\n\\nNote\\n:   The material presented here is also discussed in [video lecture 14](https://www.math.colostate.edu/~bangerth/videos.676.14.html). (All video lectures are also available [here](https://www.math.colostate.edu/~bangerth/videos.html).)\\n\\nThis example shows a number of improvements over the previous examples, along with some of the things that can usually be found in finite element programs. Let us outline these in the following.\\n\\n### Successively refined grids\\n\\nYou know from theory that the solution of a partial differential equation computed by the finite element method is an approximation of the exact solution, and that the approximation *converges* to the exact solution. But if you only compute on a single mesh (as we have done in [step-3](step_3.html) and [step-4](step_4.html)), how do you know that the approximation is good enough (however you want to define that)? In practice, there are two ways you can assess this: First, you can compute the solution on a whole sequence of meshes and observe how the solution changes (or doesn't) from one mesh to another. Second, you can just compare the solution on one mesh against the solution computed on a once-refined meshes. Both [step-3](step_3.html) and [step-4](step_4.html) discuss these sorts of things in their respective \\\"Results\\\" sections, doing the mesh refinement mostly by hand: You had to make a change in the program, re-compile everything, and then run the program again.\\n\\nThis program automates this process via a loop over a sequence of more-and-more refined meshes, doing the mesh refinement as part of the loop. In this program, the mesh is refined by simply replacing every (quadrilateral) cell of the mesh by its four children. In reality, this is often not necessary, because the solution is already sufficiently good in some parts of the domain whereas the mesh is still too coarse in other parts, and in those cases one can get away with refining only *some* of the cells – but this is the topic of [step-6](step_6.html), and we leave it for there.\\n\\n### Reading in an externally generated mesh\\n\\nIn practical applications, the domain on which you want to solve a partial differential equation is often subdivided into a triangulations by automatic *mesh generators*, i.e., specialized tools external to deal.II. (deal.II can generate some *simple* meshes using the functions in namespace [GridGenerator](namespaceGridGenerator.html), and it also has interfaces to the Gmsh mesh generator in namespace [Gmsh](namespaceGmsh.html), but for most complex geometries, you will want to use an external mesh generator.) These mesh generators will typically write the mesh they create into a file. In order to use such meshes, it is important to read these files into the coarse grid triangulation from which we can then continue by refining the mesh appropriately. For reading meshes, we will use the [GridIn](classGridIn.html) class that can read meshes in a substantial number of formats produced by most of the widely used mesh generators. In this tutorial, we will read a coarse grid in UCD (short for \\\"unstructured\\ncell data\\\") format: When this program was first written around 2000, the UCD format was what the AVS Explorer used – a program reasonably widely used at the time though today no longer of importance. The file format itself has survived and is still widely understood, but because [GridIn](classGridIn.html) reads so many different formats, the specific choice used in this tutorial program is perhaps not all that important.\\n\\n### Solving a generalized Laplace (Poisson) equation\\n\\nThe equation to solve here is as follows:\\n\\n\\\\begin{align\\\\*}\\n-\\\\nabla \\\\cdot a(\\\\mathbf x) \\\\nabla u(\\\\mathbf x) &= 1 \\\\qquad\\\\qquad & \\\\text{in}\\\\ \\\\Omega,\\n\\\\\\\\\\nu &= 0 \\\\qquad\\\\qquad & \\\\text{on}\\\\ \\\\partial\\\\Omega.\\n\\\\end{align\\\\*}\\n\\nIf \\\\(a(\\\\mathbf x)\\\\) was a constant coefficient, this would simply be the Poisson equation that we have already solved in [step-3](step_3.html) and [step-4](step_4.html). However, if it is indeed spatially variable, it is a more complex equation (sometimes referred to as the \\\"Poisson equation with a coefficient\\\"). Specifically, we will here choose it as follows:\\n\\n\\\\begin{align\\\\*}\\na(\\\\mathbf x) =\\n\\\\begin{cases}\\n20 & \\\\text{if}\\\\ |\\\\mathbf x|<0.5, \\\\\\\\\\n1 & \\\\text{otherwise.}\\n\\\\end{cases}\\n\\\\end{align\\\\*}\\n\\nDepending on what the variable \\\\(u\\\\) refers to, it models a variety of situations with wide applicability:\\n\\n* If \\\\(u\\\\) is the electric potential, then \\\\(-a\\\\nabla u\\\\) is the electric current in a medium and the coefficient \\\\(a\\\\) is the conductivity of the medium at any given point. (In this situation, the right hand side of the equation would be the electric source density and would usually be zero or consist of localized, Delta-like, functions if specific points of the domain are connected to current sources that send electrons into or out of the domain.) In many media, \\\\(a=a(\\\\mathbf x)\\\\) is indeed spatially variable because the medium is not homogeneous. For example, in [electrical impedance tomography](https://en.wikipedia.org/wiki/Electrical_impedance_tomography), a biomedical imaging technique, one wants to image the body's interior by sending electric currents through the body between electrodes attached to the skin; in this case, \\\\(a(\\\\mathbf x)\\\\) describes the electrical conductivity of the different parts of the human body – so \\\\(a(\\\\mathbf x)\\\\) would be large for points \\\\(\\\\mathbf x\\\\) that lie in organs well supplied by blood (such as the heart), whereas it would be small for organs such as the lung that do not conduct electricity well (because air is a poor conductor). Similarly, if you are simulating an electronic device, \\\\(a(\\\\mathbf x)\\\\) would be large in parts of the volume occupied by conductors such as copper, gold, or aluminum; it would have intermediate values for parts of the volume occupied by semiconductors such as silicon; and it would be small in non-conducting and insulating parts of the volume (e.g., those occupied by air, or the circuit board on which the electronics are mounted).\\n* If we are describing the vertical deflection \\\\(u\\\\) of a thin membrane under a vertical force \\\\(f\\\\), then \\\\(a\\\\) would be a measure of the local stiffness of the membrane, which can be spatially variable if the membrane is made from different materials, or if the thickness of the membrane varies spatially. This is the interpretation of the equation that will allow us to interpret the images shown in the results section below.\\n\\nSince the Laplace/Poisson equation appears in so many contexts, there are of course many more uses than just the two listed above, each providing a different interpretation what a spatially variable coefficient would mean in that context.\\n\\nWhat you should have taken away from this is that equations with spatially variable coefficients in the differential operator are quite common, and indeed quite useful in describing the world around us. As a consequence, we should be able to reflect such cases in the numerical methods we use. It turns out that it is not entirely obvious how to deal with such spatially variable coefficients in finite difference methods (though it is also not too complicated to come with ways to do that systematically). But we are using finite element methods, and for these it is entirely trivial to incorporate such coefficients: You just do what you always do, namely multiply by a test function, then integrate by parts. This yields the weak form, which here reads as follows:\\n\\n\\\\begin{align\\\\*}\\n\\\\int\\\\_\\\\Omega a(\\\\mathbf x) \\\\nabla \\\\varphi(\\\\mathbf x) \\\\cdot\\n\\\\nabla u(\\\\mathbf x) \\\\; dx\\n&=\\n\\\\int\\\\_\\\\Omega \\\\varphi(\\\\mathbf x) f(\\\\mathbf x) \\\\; dx \\\\qquad \\\\qquad \\\\forall \\\\varphi.\\n\\\\end{align\\\\*}\\n\\nFor this program here, we will specifically use \\\\(f(\\\\mathbf x)=1\\\\). In our usual short-hand notation, the equation's weak form can then be written as\\n\\n\\\\begin{align\\\\*}\\n(a \\\\nabla \\\\varphi, \\\\nabla u) &= (\\\\varphi, 1) \\\\qquad \\\\qquad \\\\forall \\\\varphi.\\n\\\\end{align\\\\*}\\n\\nAs you will recall from [step-3](step_3.html) and [step-4](step_4.html), the weak formulation is implemented in the `assemble_system` function, substituting integrals by quadrature. Indeed, what you will find in this program is that as before, the implementation follows immediately from the statement of the weak form above.\\n\\n### Support for debugging: Assertions\\n\\nFinite element programs tend to be complex pieces of software, so debugging is an important aspect of developing finite element codes. deal.II supports safe programming by using assertions that check the validity of parameters and internal states in a \\\"debug\\\" mode, but are removed in \\\"optimized\\\" (or \\\"release\\\") mode. (See also [video lecture 18](https://www.math.colostate.edu/~bangerth/videos.676.18.html).) This program will show you how to write such [assertions](https://en.wikipedia.org/wiki/Assertion_(software_development)).\\n\\nThe usefulness of assertions is that they allow you to put whatever you *think* must be true into actual code, and let the computer check that you are right. To give an example, here is the function that adds one vector to another:\\n\\n```\\ntemplate <typename Number>\\nVector<Number> &\\nVector<Number>::operator+=(const Vector<Number> &v)\\n{\\n Assert(size() != 0, ExcEmptyObject());\\n Assert(size() == v.size(), ExcDimensionMismatch(size(), v.size()));\\n \\n  ... do the actual addition of elements ...\\n \\n return *this;\\n}\\n```\\n\\nThe point here is that it only makes sense to add two vectors together if (i) the vectors have nonzero size, and (ii) have the same size. It does not make sense to add a vector of size 10 to a vector of size 20. That is an obvious statement, and one could argue that if anyone tried to do so anyway, they get what they deserve – most often this may be wrong results, overwritten memory, or other terrible things that are difficult to debug. It is much better to *check* such conditions – i.e., to check the *assumptions* a function such as the one above makes on function arguments or the internal state of the program it is working on – because if you check, you can do two things: (i) If an assumption is violated, you can abort the program at the first moment where you know that something is going wrong, rather than letting the program later spend quality hours with a debugger trying to figure out why the program is producing wrong results; (ii) if an assumption is violated, you can print information that explicitly shows what the violated assumption is, where in the program this happened, and how you got to this place (i.e., it can show you the [stack trace](https://en.wikipedia.org/wiki/Stack_trace)).\\n\\nThe two `Assert` statements above do exactly this: The first argument to `Assert` is the condition whose truth we want to ensure. The second argument is an object that contains information (and can print this information) used if the condition is not true. The program will show a real-world case where assertions are useful in user code.\\n\\nThe commented program\\n=====================\\n\\n### Include files\\n\\nAgain, the first few include files are already known, so we won't comment on them:\\n\\n```\\n   #include <deal.II/base/quadrature_lib.h>\\n   #include <deal.II/base/function.h>\\n   #include <deal.II/lac/vector.h>\\n   #include <deal.II/lac/full_matrix.h>\\n   #include <deal.II/lac/sparse_matrix.h>\\n   #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n   #include <deal.II/lac/solver_cg.h>\\n   #include <deal.II/lac/precondition.h>\\n   #include <deal.II/grid/tria.h>\\n   #include <deal.II/dofs/dof_handler.h>\\n   #include <deal.II/dofs/dof_tools.h>\\n   #include <deal.II/fe/fe_q.h>\\n   #include <deal.II/fe/fe_values.h>\\n   #include <deal.II/numerics/vector_tools.h>\\n   #include <deal.II/numerics/matrix_tools.h>\\n   #include <deal.II/numerics/data_out.h>\\n```\\n\\nThis one is new. We want to read a triangulation from disk, and the class which does this is declared in the following file :\\n\\n```\\n   #include <deal.II/grid/grid_in.h>\\n```\\n\\nWe will use a circular domain, and the object describing the boundary of it comes from this file :\\n\\n```\\n   #include <deal.II/grid/manifold_lib.h>\\n```\\n\\nThis is C++ ...\\n\\n```\\n   #include <fstream>\\n   #include <iostream>\\n```\\n\\nFinally, this has been discussed in previous tutorial programs before:\\n\\n```\\n   using namespace dealii;\\n```\\n\\n### The `Step5` class template\\n\\nThe main class is mostly as in the previous example. The most visible change is that the function `make_grid` has been removed, since creating the grid is now done in the `run` function and the rest of its functionality is now in `setup_system`. Apart from this, everything is as before.\\n\\n```\\n   template <int dim>\\n   class Step5\\n   {\\n   public:\\n     Step5();\\n     void run();\\n   \\n   private:\\n     void setup_system();\\n     void assemble_system();\\n     void solve();\\n     void output_results(const unsigned int cycle) const;\\n   \\n     Triangulation<dim> triangulation;\\n     const FE_Q<dim>    fe;\\n     DoFHandler<dim>    dof_handler;\\n   \\n     SparsityPattern      sparsity_pattern;\\n     SparseMatrix<double> system_matrix;\\n   \\n     Vector<double> solution;\\n     Vector<double> system_rhs;\\n   };\\n```\\n\\n### Working with nonconstant coefficients\\n\\nIn [step-4](step_4.html), we showed how to use non-constant boundary values and right hand side. In this example, we want to use a variable coefficient in the elliptic operator instead. Since we have a function which just depends on the point in space we can do things a bit more simply and use a plain function instead of inheriting from [Function](classFunction.html).\\n\\nThis is the implementation of the coefficient function for a single point. We let it return 20 if the distance to the origin is less than 0.5, and 1 otherwise.\\n\\n```\\n   template <int dim>\\n   double coefficient(const Point<dim> &p)\\n   {\\n     if (p.square() < 0.5 * 0.5)\\n       return 20;\\n     else\\n       return 1;\\n   }\\n```\\n\\n### The `Step5` class implementation\\n\\n#### Step5::Step5\\n\\nThis function is as before.\\n\\n```\\n   template <int dim>\\n   Step5<dim>::Step5()\\n     : fe(/* polynomial degree = */ 1)\\n     , dof_handler(triangulation)\\n   {}\\n```\\n\\n#### Step5::setup\\\\_system\\n\\nThis is the function `make_grid` from the previous example, minus the generation of the grid. Everything else is unchanged:\\n\\n```\\n   template <int dim>\\n   void Step5<dim>::setup_system()\\n   {\\n     dof_handler.distribute_dofs(fe);\\n   \\n     std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n               << std::endl;\\n   \\n     DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n     DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n     sparsity_pattern.copy_from(dsp);\\n   \\n     system_matrix.reinit(sparsity_pattern);\\n   \\n     solution.reinit(dof_handler.n_dofs());\\n     system_rhs.reinit(dof_handler.n_dofs());\\n   }\\n```\\n\\n#### Step5::assemble\\\\_system\\n\\nAs in the previous examples, this function is not changed much with regard to its functionality, but there are still some optimizations which we will show. For this, it is important to note that if efficient solvers are used (such as the preconditioned CG method), assembling the matrix and right hand side can take a comparable time, and you should think about using one or two optimizations at some places.\\n\\nThe first parts of the function are completely unchanged from before:\\n\\n```\\n   template <int dim>\\n   void Step5<dim>::assemble_system()\\n   {\\n     const QGauss<dim> quadrature_formula(fe.degree + 1);\\n   \\n     FEValues<dim> fe_values(fe,\\n                             quadrature_formula,\\n                             update_values | update_gradients |\\n                               update_quadrature_points | update_JxW_values);\\n   \\n     const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n   \\n     FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n     Vector<double>     cell_rhs(dofs_per_cell);\\n   \\n     std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n```\\n\\nNext is the typical loop over all cells to compute local contributions and then to transfer them into the global matrix and vector. The only change in this part, compared to [step-4](step_4.html), is that we will use the `coefficient()` function defined above to compute the coefficient value at each quadrature point.\\n\\n```\\n     for (const auto &cell : dof_handler.active_cell_iterators())\\n       {\\n         fe_values.reinit(cell);\\n   \\n         cell_matrix = 0.;\\n         cell_rhs    = 0.;\\n   \\n         for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n           {\\n             const double current_coefficient =\\n               coefficient(fe_values.quadrature_point(q_index));\\n             for (const unsigned int i : fe_values.dof_indices())\\n               {\\n                 for (const unsigned int j : fe_values.dof_indices())\\n                   cell_matrix(i, j) +=\\n                     (current_coefficient *              // a(x_q)\\n                      fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                      fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                      fe_values.JxW(q_index));           // dx\\n   \\n                 cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                                 1.0 *                               // f(x_q)\\n                                 fe_values.JxW(q_index));            // dx\\n               }\\n           }\\n   \\n   \\n         cell->get_dof_indices(local_dof_indices);\\n         for (const unsigned int i : fe_values.dof_indices())\\n           {\\n             for (const unsigned int j : fe_values.dof_indices())\\n               system_matrix.add(local_dof_indices[i],\\n                                 local_dof_indices[j],\\n                                 cell_matrix(i, j));\\n   \\n             system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n           }\\n       }\\n```\\n\\nWith the matrix so built, we use zero boundary values again:\\n\\n```\\n     std::map<types::global_dof_index, double> boundary_values;\\n     VectorTools::interpolate_boundary_values(dof_handler,\\n                                              types::boundary_id(0),\\n                                              Functions::ZeroFunction<dim>(),\\n                                              boundary_values);\\n     MatrixTools::apply_boundary_values(boundary_values,\\n                                        system_matrix,\\n                                        solution,\\n                                        system_rhs);\\n   }\\n```\\n\\n#### Step5::solve\\n\\nThe solution process again looks mostly like in the previous examples. However, we will now use a preconditioned conjugate gradient algorithm. It is not very difficult to make this change. In fact, the only thing we have to alter is that we need an object which will act as a preconditioner. We will use SSOR (symmetric successive overrelaxation), with a relaxation factor of 1.2. For this purpose, the `SparseMatrix` class has a function which does one SSOR step, and we need to package the address of this function together with the matrix on which it should act (which is the matrix to be inverted) and the relaxation factor into one object. The `PreconditionSSOR` class does this for us. (`PreconditionSSOR` class takes a template argument denoting the matrix type it is supposed to work on. The default value is `SparseMatrix<double>`, which is exactly what we need here, so we simply stick with the default and do not specify anything in the angle brackets.)\\n\\nNote that for the present case, SSOR doesn't really perform much better than most other preconditioners (though better than no preconditioning at all). A brief comparison of different preconditioners is presented in the Results section of the next tutorial program, [step-6](step_6.html).\\n\\nWith this, the rest of the function is trivial: instead of the `PreconditionIdentity` object we have created before, we now use the preconditioner we have declared, and the CG solver will do the rest for us:\\n\\n```\\n   template <int dim>\\n   void Step5<dim>::solve()\\n   {\\n     SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n     SolverCG<Vector<double>> solver(solver_control);\\n   \\n     PreconditionSSOR<SparseMatrix<double>> preconditioner;\\n     preconditioner.initialize(system_matrix, 1.2);\\n   \\n     solver.solve(system_matrix, solution, system_rhs, preconditioner);\\n   \\n     std::cout << \\\"   \\\" << solver_control.last_step()\\n               << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n   }\\n```\\n\\n#### Step5::output\\\\_results and setting output flags\\n\\nWriting output to a file is mostly the same as for the previous tutorial. The only difference is that we now need to construct a different filename for each refinement cycle.\\n\\nThe function writes the output in VTU format, a variation of the VTK format that requires less disk space because it compresses the data. Of course, there are many other formats supported by the [DataOut](classDataOut.html) class if you desire to use a program for visualization that doesn't understand VTK or VTU.\\n\\n```\\n   template <int dim>\\n   void Step5<dim>::output_results(const unsigned int cycle) const\\n   {\\n     DataOut<dim> data_out;\\n   \\n     data_out.attach_dof_handler(dof_handler);\\n     data_out.add_data_vector(solution, \\\"solution\\\");\\n   \\n     data_out.build_patches();\\n   \\n     std::ofstream output(\\\"solution-\\\" + std::to_string(cycle) + \\\".vtu\\\");\\n     data_out.write_vtu(output);\\n   }\\n```\\n\\n#### Step5::run\\n\\nThe second to last thing in this program is the definition of the `run()` function. In contrast to the previous programs, we will compute on a sequence of meshes that after each iteration is globally refined. The function therefore consists of a loop over 6 cycles. In each cycle, we first print the cycle number, and then have to decide what to do with the mesh. If this is not the first cycle, we simply refine the existing mesh once globally. Before running through these cycles, however, we have to generate a mesh:\\n\\nIn previous examples, we have already used some of the functions from the `GridGenerator` class. Here we would like to read a grid from a file where the cells are stored and which may originate from someone else, or may be the product of a mesh generator tool.\\n\\nIn order to read a grid from a file, we generate an object of data type [GridIn](classGridIn.html) and associate the triangulation to it (i.e. we tell it to fill our triangulation object when we ask it to read the file). Then we open the respective file and initialize the triangulation with the data in the file :\\n\\n```\\n   template <int dim>\\n   void Step5<dim>::run()\\n   {\\n     GridIn<dim> grid_in;\\n     grid_in.attach_triangulation(triangulation);\\n     std::ifstream input_file(\\\"circle-grid.inp\\\");\\n```\\n\\nWe would now like to read the file. However, the input file is only for a two-dimensional triangulation, while this function is a template for arbitrary dimension. Since this is only a demonstration program, we will not use different input files for the different dimensions, but rather quickly kill the whole program if we are not in 2d. Of course, since the main function below assumes that we are working in two dimensions we could skip this check, in this version of the program, without any ill effects.\\n\\nIt turns out that perhaps 90 per cent of programming errors are invalid function parameters such as invalid array sizes, etc., so we use assertions heavily throughout deal.II to catch such mistakes. For this, the `Assert` macro is a good choice, since it makes sure that the condition which is given as first argument is valid, and if not throws an exception (its second argument) which will usually terminate the program giving information where the error occurred and what the reason was. (A longer discussion of what exactly the `Assert` macro does can be found in the [exception documentation topic](group__Exceptions.html).) This generally reduces the time to find programming errors dramatically and we have found assertions an invaluable means to program fast.\\n\\nOn the other hand, all these checks (there are over 10,000 of them in the library at present) should not slow down the program too much if you want to do large computations. To this end, the `Assert` macro is only used in debug mode and expands to nothing if in optimized mode. Therefore, while you test your program on small problems and debug it, the assertions will tell you where the problems are. Once your program is stable, you can switch off debugging and the program will run your real computations without the assertions and at maximum speed. More precisely: turning off all the checks in the library (which prevent you from calling functions with wrong arguments, walking off of arrays, etc.) by compiling your program in optimized mode usually makes things run about four times faster. Even though optimized programs are more performant, you should always develop in debug mode since it allows the library to find lots of common programming errors automatically. For those who want to try: The way to switch from debug mode to optimized mode is to recompile your program with the command `make release`. The output of the `make` program should now indicate to you that the program is now compiled in optimized mode, and it will later also be linked to libraries that have been compiled for optimized mode. In order to switch back to debug mode, simply recompile with the command `make debug`.\\n\\n```\\n     Assert(dim == 2, ExcNotImplemented());\\n```\\n\\nExcNotImplemented is a globally defined exception, which may be thrown whenever a piece of code has simply not been implemented for a case other than the condition checked in the assertion. Here, it would not be difficult to simply implement reading a *different* mesh file that contains a description of a 1d or 3d geometry, but this has not (yet) been implemented and so the exception is appropriate.\\n\\nUsually, one would like to use more specific exception classes, and particular in this case one would of course try to do something else if `dim` is not equal to two, e.g. create a grid using library functions. Aborting a program is usually not a good idea and assertions should really only be used for exceptional cases which should not occur, but might due to stupidity of the programmer, user, or someone else.\\n\\nSo if we got past the assertion, we know that dim==2, and we can now actually read the grid. It is in UCD (unstructured cell data) format (though the convention is to use the suffix `inp` for UCD files):\\n\\n```\\n     grid_in.read_ucd(input_file);\\n```\\n\\nIf you like to use another input format, you have to use one of the other `grid_in.read_xxx` function. (See the documentation of the `GridIn` class to find out what input formats are presently supported.)\\n\\nThe grid in the file describes a circle. Therefore we have to use a manifold object which tells the triangulation where to put new points on the boundary when the grid is refined. Unlike [step-1](step_1.html), since [GridIn](classGridIn.html) does not know that the domain has a circular boundary (unlike [GridGenerator::hyper\\\\_shell](namespaceGridGenerator.html#a36a5f3b1be1d673f50d01a51a6aba6c3)) we have to explicitly attach a manifold to the boundary after creating the triangulation to get the correct result when we refine the mesh.\\n\\n```\\n     const SphericalManifold<dim> boundary;\\n     triangulation.set_all_manifold_ids_on_boundary(0);\\n     triangulation.set_manifold(0, boundary);\\n   \\n     for (unsigned int cycle = 0; cycle < 6; ++cycle)\\n       {\\n         std::cout << \\\"Cycle \\\" << cycle << ':' << std::endl;\\n   \\n         if (cycle != 0)\\n           triangulation.refine_global(1);\\n```\\n\\nNow that we have a mesh for sure, we write some output and do all the things that we have already seen in the previous examples.\\n\\n```\\n         std::cout << \\\"   Number of active cells: \\\" \\n                   << triangulation.n_active_cells() \\n                   << std::endl                      \\n                   << \\\"   Total number of cells: \\\" \\n                   << triangulation.n_cells()        \\n                   << std::endl;\\n   \\n         setup_system();\\n         assemble_system();\\n         solve();\\n         output_results(cycle);\\n       }\\n   }\\n```\\n\\n### The `main` function\\n\\nThe main function looks mostly like the one in the previous example, so we won't comment on it further:\\n\\n```\\n   int main()\\n   {\\n     Step5<2> laplace_problem_2d;\\n     laplace_problem_2d.run();\\n     return 0;\\n   }\\n```\\n\\nResults\\n=======\\n\\nHere is the console output:\\n\\n```\\nCycle 0:\\n   Number of active cells: 20\\n   Total number of cells: 20\\n   Number of degrees of freedom: 25\\n   8 CG iterations needed to obtain convergence.\\nCycle 1:\\n   Number of active cells: 80\\n   Total number of cells: 100\\n   Number of degrees of freedom: 89\\n   12 CG iterations needed to obtain convergence.\\nCycle 2:\\n   Number of active cells: 320\\n   Total number of cells: 420\\n   Number of degrees of freedom: 337\\n   21 CG iterations needed to obtain convergence.\\nCycle 3:\\n   Number of active cells: 1280\\n   Total number of cells: 1700\\n   Number of degrees of freedom: 1313\\n   38 CG iterations needed to obtain convergence.\\nCycle 4:\\n   Number of active cells: 5120\\n   Total number of cells: 6820\\n   Number of degrees of freedom: 5185\\n   70 CG iterations needed to obtain convergence.\\nCycle 5:\\n   Number of active cells: 20480\\n   Total number of cells: 27300\\n   Number of degrees of freedom: 20609\\n   136 CG iterations needed to obtain convergence.\\n```\\n\\nIn each cycle, the number of cells quadruples and the number of CG iterations roughly doubles. Also, in each cycle, the program writes one output graphic file in VTU format. They are depicted in the following:\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n|  |  |\\n|  |  |\\n\\nDue to the variable coefficient (the curvature there is reduced by the same factor by which the coefficient is increased), the top region of the solution is flattened. The gradient of the solution is discontinuous along the interface, although this is not very clearly visible in the pictures above. We will look at this in more detail in the next example.\\n\\nThe pictures also show that the solution computed by this program is actually pretty wrong on a very coarse mesh (its magnitude is wrong). That's because no numerical method guarantees that the solution on a coarse mesh is particularly accurate – but we know that the solution *converges* to the exact solution, and indeed you can see how the solutions from one mesh to the next seem to not change very much any more at the end.\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 1999 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n */\\n \\n \\n \\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/sparse_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_cg.h>\\n#include <deal.II/lac/precondition.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_q.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/matrix_tools.h>\\n#include <deal.II/numerics/data_out.h>\\n \\n#include <deal.II/grid/grid_in.h>\\n \\n#include <deal.II/grid/manifold_lib.h>\\n \\n#include <fstream>\\n#include <iostream>\\n \\n \\nusing namespace dealii;\\n \\n \\n \\ntemplate <int dim>\\nclass Step5\\n{\\npublic:\\n  Step5();\\n void run();\\n \\nprivate:\\n void setup_system();\\n void assemble_system();\\n void solve();\\n void output_results(const unsigned int cycle) const;\\n \\n Triangulation<dim> triangulation;\\n const FE_Q<dim>    fe;\\n DoFHandler<dim>    dof_handler;\\n \\n SparsityPattern      sparsity_pattern;\\n SparseMatrix<double> system_matrix;\\n \\n Vector<double> solution;\\n Vector<double> system_rhs;\\n};\\n \\n \\n \\n \\ntemplate <int dim>\\ndouble coefficient(const Point<dim> &p)\\n{\\n if (p.square() < 0.5 * 0.5)\\n return 20;\\n else\\n return 1;\\n}\\n \\n \\n \\ntemplate <int dim>\\nStep5<dim>::Step5()\\n  : fe(/* polynomial degree = */ 1)\\n  , dof_handler(triangulation)\\n{}\\n \\n \\n \\n \\ntemplate <int dim>\\nvoid Step5<dim>::setup_system()\\n{\\n  dof_handler.distribute_dofs(fe);\\n \\n  std::cout << \\\"   Number of degrees of freedom: \\\" << dof_handler.n_dofs()\\n            << std::endl;\\n \\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dsp);\\n  sparsity_pattern.copy_from(dsp);\\n \\n  system_matrix.reinit(sparsity_pattern);\\n \\n  solution.reinit(dof_handler.n_dofs());\\n  system_rhs.reinit(dof_handler.n_dofs());\\n}\\n \\n \\n \\n \\ntemplate <int dim>\\nvoid Step5<dim>::assemble_system()\\n{\\n const QGauss<dim> quadrature_formula(fe.degree + 1);\\n \\n FEValues<dim> fe_values(fe,\\n                          quadrature_formula,\\n update_values | update_gradients |\\n update_quadrature_points | update_JxW_values);\\n \\n const unsigned int dofs_per_cell = fe.n_dofs_per_cell();\\n \\n FullMatrix<double> cell_matrix(dofs_per_cell, dofs_per_cell);\\n Vector<double>     cell_rhs(dofs_per_cell);\\n \\n  std::vector<types::global_dof_index> local_dof_indices(dofs_per_cell);\\n \\n for (const auto &cell : dof_handler.active_cell_iterators())\\n    {\\n      fe_values.reinit(cell);\\n \\n cell_matrix = 0.;\\n      cell_rhs    = 0.;\\n \\n for (const unsigned int q_index : fe_values.quadrature_point_indices())\\n        {\\n const double current_coefficient =\\n            coefficient(fe_values.quadrature_point(q_index));\\n for (const unsigned int i : fe_values.dof_indices())\\n            {\\n for (const unsigned int j : fe_values.dof_indices())\\n cell_matrix(i, j) +=\\n                  (current_coefficient *              // a(x_q)\\n                   fe_values.shape_grad(i, q_index) * // grad phi_i(x_q)\\n                   fe_values.shape_grad(j, q_index) * // grad phi_j(x_q)\\n                   fe_values.JxW(q_index));           // dx\\n \\n              cell_rhs(i) += (fe_values.shape_value(i, q_index) * // phi_i(x_q)\\n                              1.0 *                               // f(x_q)\\n                              fe_values.JxW(q_index));            // dx\\n            }\\n        }\\n \\n \\n      cell->get_dof_indices(local_dof_indices);\\n for (const unsigned int i : fe_values.dof_indices())\\n        {\\n for (const unsigned int j : fe_values.dof_indices())\\n            system_matrix.add(local_dof_indices[i],\\n                              local_dof_indices[j],\\n cell_matrix(i, j));\\n \\n          system_rhs(local_dof_indices[i]) += cell_rhs(i);\\n        }\\n    }\\n \\n  std::map<types::global_dof_index, double> boundary_values;\\n VectorTools::interpolate_boundary_values(dof_handler,\\n types::boundary_id(0),\\n Functions::ZeroFunction<dim>(),\\n                                           boundary_values);\\n MatrixTools::apply_boundary_values(boundary_values,\\n                                     system_matrix,\\n                                     solution,\\n                                     system_rhs);\\n}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step5<dim>::solve()\\n{\\n SolverControl            solver_control(1000, 1e-6 * system_rhs.l2_norm());\\n SolverCG<Vector<double>> solver(solver_control);\\n \\n PreconditionSSOR<SparseMatrix<double>> preconditioner;\\n  preconditioner.initialize(system_matrix, 1.2);\\n \\n  solver.solve(system_matrix, solution, system_rhs, preconditioner);\\n \\n  std::cout << \\\"   \\\" << solver_control.last_step()\\n            << \\\" CG iterations needed to obtain convergence.\\\" << std::endl;\\n}\\n \\n \\n \\ntemplate <int dim>\\nvoid Step5<dim>::output_results(const unsigned int cycle) const\\n{\\n DataOut<dim> data_out;\\n \\n  data_out.attach_dof_handler(dof_handler);\\n  data_out.add_data_vector(solution, \\\"solution\\\");\\n \\n  data_out.build_patches();\\n \\n  std::ofstream output(\\\"solution-\\\" + std::to_string(cycle) + \\\".vtu\\\");\\n  data_out.write_vtu(output);\\n}\\n \\n \\n \\n \\n \\ntemplate <int dim>\\nvoid Step5<dim>::run()\\n{\\n GridIn<dim> grid_in;\\n  grid_in.attach_triangulation(triangulation);\\n  std::ifstream input_file(\\\"circle-grid.inp\\\");\\n Assert(dim == 2, ExcNotImplemented());\\n \\n  grid_in.read_ucd(input_file);\\n \\n const SphericalManifold<dim> boundary;\\n triangulation.set_all_manifold_ids_on_boundary(0);\\n triangulation.set_manifold(0, boundary);\\n \\n for (unsigned int cycle = 0; cycle < 6; ++cycle)\\n    {\\n      std::cout << \\\"Cycle \\\" << cycle << ':' << std::endl;\\n \\n if (cycle != 0)\\n triangulation.refine_global(1);\\n \\n      std::cout << \\\"   Number of active cells: \\\" \\n                << triangulation.n_active_cells() \\n                << std::endl                      \\n                << \\\"   Total number of cells: \\\" \\n                << triangulation.n_cells()        \\n                << std::endl;\\n \\n      setup_system();\\n      assemble_system();\\n      solve();\\n      output_results(cycle);\\n    }\\n}\\n \\n \\n \\nint main()\\n{\\n  Step5<2> laplace_problem_2d;\\n  laplace_problem_2d.run();\\n return 0;\\n}\\n```\\n\"}],\"temperature\":0.2,\"response_format\":{\"type\":\"json_schema\",\"json_schema\":{\"name\":\"finetune_prompt-completion_pair\",\"strict\":true,\"description\":\"A pair of prompt and completion for finetuning a code LLM\",\"schema\":{\"type\":\"object\",\"properties\":{\"prompt\":{\"type\":\"string\",\"description\":\"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\"},\"completion\":{\"type\":\"string\",\"description\":\"The final code completion\"}},\"additionalProperties\":false,\"required\":[\"prompt\",\"completion\"]}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Literal\n",
    "import openai\n",
    "\n",
    "\n",
    "class Message(BaseModel):\n",
    "    role: Literal[\"user\"] | Literal[\"system\"] | Literal[\"assistant\"] = \"user\"\n",
    "    content: str\n",
    "\n",
    "\n",
    "class OpenAIChatBody(BaseModel):\n",
    "    model: str = \"gpt-4.1-mini\"\n",
    "    messages: list[Message] = Field(default_factory=list)\n",
    "    temperature: float = 0.2\n",
    "    response_format: Dict = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"finetune_prompt-completion_pair\",\n",
    "            \"strict\": True,\n",
    "            \"description\": \"A pair of prompt and completion for finetuning a code LLM\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)\",\n",
    "                    },\n",
    "                    \"completion\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The final code completion\",\n",
    "                    },\n",
    "                },\n",
    "                \"additionalProperties\": False,\n",
    "                \"required\": [\"prompt\", \"completion\"],\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "class OpenAIRequest(BaseModel):\n",
    "    custom_id: str\n",
    "    method: Literal[\"POST\"] = \"POST\"\n",
    "    url: str = \"/v1/chat/completions\"\n",
    "    body: OpenAIChatBody\n",
    "\n",
    "\n",
    "def get_batch_file_content(tutorials: pl.DataFrame, limit: int | None = None) -> str:\n",
    "    res = []\n",
    "    prompt_template = \"\"\"You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\n",
    "and provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\n",
    "The prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\n",
    "(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\n",
    "and the completion is the final code.\n",
    "Tutorial description : \n",
    "{descr}\n",
    "Tutorial content :\n",
    "{content}\n",
    "\"\"\"\n",
    "    for name, link, descr, content in tqdm(\n",
    "        tutorials.lazy()\n",
    "        .limit(limit)\n",
    "        .select(\"name\", \"link\", \"description\", \"content\")\n",
    "        .collect()\n",
    "        .iter_rows(),\n",
    "        total=limit if limit else len(tutorials),\n",
    "    ):\n",
    "        req = OpenAIRequest(\n",
    "            custom_id=link,\n",
    "            body=OpenAIChatBody(\n",
    "                messages=[\n",
    "                    Message(\n",
    "                        content=prompt_template.format(descr=descr, content=content)\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        json = req.model_dump_json()\n",
    "        res.append(json)\n",
    "\n",
    "    return \"\\n\".join(res)\n",
    "\n",
    "\n",
    "def create_batch_file(tutorials: pl.DataFrame, limit: int | None = None):\n",
    "    with open(\"batch_tutorials_prompt_completion.jsonl\", \"w\") as f:\n",
    "        f.write(get_batch_file_content(tutorials, limit))\n",
    "\n",
    "\n",
    "tutorials = pl.read_parquet(\"tutorials.parquet\")\n",
    "batch_file_content = get_batch_file_content(tutorials, limit=5)\n",
    "print(batch_file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4760403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 50, end: 70, reached end: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1022.33it/s]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=oai_key)\n",
    "batch_file = \"batch_tutorials_prompt_completion.jsonl\"\n",
    "step = 20\n",
    "k = 2.5\n",
    "start = int(k * step)\n",
    "end = min(len(tutorials), int((k + 1) * step))\n",
    "reached_end = end == len(tutorials)\n",
    "print(f\"start: {start}, end: {end}, reached end: {reached_end}\")\n",
    "create_batch_file(tutorials[start: end])\n",
    "\n",
    "# with open(batch_file, \"rb\") as f:\n",
    "#     batch_file_id = client.files.create(\n",
    "#         file=f,\n",
    "#         purpose=\"batch\"\n",
    "#     ).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4de7209c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_680bb564943c819099243916122c52bb', completion_window='24h', created_at=1745597796, endpoint='/v1/chat/completions', input_file_id='file-XpxfGR2iF7R6TYBCz61VYM', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1745684196, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = client.batches.create(\n",
    "    input_file_id=batch_file_id,\n",
    "    completion_window=\"24h\",\n",
    "    endpoint=\"/v1/chat/completions\"\n",
    ")\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c1e002ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'batch_680bb564943c819099243916122c52bb',\n",
       " 'completion_window': '24h',\n",
       " 'created_at': 1745597796,\n",
       " 'endpoint': '/v1/chat/completions',\n",
       " 'input_file_id': 'file-XpxfGR2iF7R6TYBCz61VYM',\n",
       " 'object': 'batch',\n",
       " 'status': 'validating',\n",
       " 'cancelled_at': None,\n",
       " 'cancelling_at': None,\n",
       " 'completed_at': None,\n",
       " 'error_file_id': None,\n",
       " 'errors': None,\n",
       " 'expired_at': None,\n",
       " 'expires_at': 1745684196,\n",
       " 'failed_at': None,\n",
       " 'finalizing_at': None,\n",
       " 'in_progress_at': None,\n",
       " 'metadata': None,\n",
       " 'output_file_id': None,\n",
       " 'request_counts': {'completed': 0, 'failed': 0, 'total': 0}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_id = batch.id if True else \"batch_680ba4a753188190af3ddd234ac386a5\"\n",
    "client.batches.retrieve(batch_id).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567df0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d29efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_file = \"batch_tutorials_prompt_completion.jsonl\"\n",
    "with open(batch_file, \"r\") as f:\n",
    "    line = f.readline()\n",
    "openai_api_url = \"https://api.openai.com\"\n",
    "r = JSON.loads(line)\n",
    "response = requests.post(\n",
    "    openai_api_url + r[\"url\"],\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {oai_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    },\n",
    "    json=r[\"body\"]\n",
    "    \n",
    ").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24aec843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': 'https://dealii.org/current/doxygen/deal.II//step_51.html',\n",
       " 'method': 'POST',\n",
       " 'url': '/v1/chat/completions',\n",
       " 'body': {'model': 'gpt-4.1-mini',\n",
       "  'messages': [{'role': 'user',\n",
       "    'content': 'You are an expert in AI finetuning and C++. Your task is to analyze the following Deal.II tutorial content,\\nand provide a pair prompt / completion that is ideally suited for fine tuning a code LLM. You will provide this pair in a JSON format.\\nThe prompt is what a scientific user would ask of the code LLM, focusing on theoritical aspect and not the technical one (so no reference to deal.II or C++).\\n(example: Solve the scalar wave equation in 2D with Dirichlet boundary conditions),\\nand the completion is the final code.\\nTutorial description : \\nSolving the convection-diffusion equation with a hybridizable discontinuous Galerkin method using face elements.\\nTutorial content :\\nThis tutorial depends on [step-7](step_7.html), [step-9](step_9.html).\\n\\n| **Table of contents** | |\\n| --- | --- |\\n| 1. [Introduction](#step_51-Intro)    * [Hybridizable discontinuous Galerkin methods](#step_51-HybridizablediscontinuousGalerkinmethods)       + [Reducing the size of the linear system](#step_51-Reducingthesizeofthelinearsystem) + [Relation with Static Condensation](#step_51-RelationwithStaticCondensation) + [Solution quality and rates of convergence](#step_51-Solutionqualityandratesofconvergence)+ [Alternative approaches](#step_51-Alternativeapproaches)* [HDG applied to the convection-diffusion problem](#step_51-HDGappliedtotheconvectiondiffusionproblem)         + [Post-processing and super-convergence](#step_51-Postprocessingandsuperconvergence)* [Problem specific data](#step_51-Problemspecificdata) * [Implementation](#step_51-Implementation)- [The commented program](#step_51-CommProg)      * [Include files](#step_51-Includefiles)* [Equation data](#step_51-Equationdata)* [The HDG solver class](#step_51-TheHDGsolverclass)* [The HDG class implementation](#step_51-TheHDGclassimplementation)              + [Constructor](#step_51-Constructor)+ [HDG::setup\\\\_system](#step_51-HDGsetup_system)+ [HDG::PerTaskData](#step_51-HDGPerTaskData)+ [HDG::ScratchData](#step_51-HDGScratchData)+ [HDG::PostProcessScratchData](#step_51-HDGPostProcessScratchData)+ [HDG::assemble\\\\_system](#step_51-HDGassemble_system)+ [HDG::assemble\\\\_system\\\\_one\\\\_cell](#step_51-HDGassemble_system_one_cell)+ [HDG::copy\\\\_local\\\\_to\\\\_global](#step_51-HDGcopy_local_to_global)+ [HDG::solve](#step_51-HDGsolve)+ [HDG::postprocess](#step_51-HDGpostprocess)+ [HDG::postprocess\\\\_one\\\\_cell](#step_51-HDGpostprocess_one_cell)+ [HDG::output\\\\_results](#step_51-HDGoutput_results)+ [HDG::refine\\\\_grid](#step_51-HDGrefine_grid)+ [HDG::run](#step_51-HDGrun) | 1. [Results](#step_51-Results)    * [Program output](#step_51-Programoutput)      + [Convergence tables](#step_51-Convergencetables)* [Comparison with continuous finite elements](#step_51-Comparisonwithcontinuousfiniteelements)        + [Results for 2D](#step_51-Resultsfor2D)+ [Results for 3D](#step_51-Resultsfor3D)* [Possibilities for improvements](#step_51-Possibilitiesforimprovements)- [The plain program](#step_51-PlainProg) |\\n\\n*This program was contributed by Martin Kronbichler and Scott Miller.*\\n\\nIntroduction\\n============\\n\\nThis tutorial program presents the implementation of a hybridizable discontinuous Galkerin method for the convection-diffusion equation.\\n\\n### Hybridizable discontinuous Galerkin methods\\n\\nOne common argument against the use of discontinuous Galerkin elements is the large number of globally coupled degrees of freedom that one must solve in an implicit system. This is because, unlike continuous finite elements, in typical discontinuous elements there is one degree of freedom at each vertex *for each of the adjacent elements*, rather than just one, and similarly for edges and faces. As an example of how fast the number of unknowns grows, consider the [FE\\\\_DGPMonomial](classFE__DGPMonomial.html) basis: each scalar solution component is represented by polynomials of degree \\\\(p\\\\) with \\\\((1/\\\\text{dim}!) \\\\prod\\\\_{i=1}^{\\\\text{dim}}(p+i)\\\\) degrees of freedom per element. Typically, all degrees of freedom in an element are coupled to all of the degrees of freedom in the adjacent elements. The resulting discrete equations yield very large linear systems very quickly, especially for systems of equations in 2 or 3 dimensions.\\n\\n#### Reducing the size of the linear system\\n\\nTo alleviate the computational cost of solving such large linear systems, the hybridizable discontinuous Galerkin (HDG) methodology was introduced by Cockburn and co-workers (see the references in the recent HDG overview article by Nguyen and Peraire [[162]](citelist.html#CITEREF_Ngu2012)).\\n\\nThe HDG method achieves this goal by formulating the mathematical problem using Dirichlet-to-Neumann mappings. The partial differential equations are first written as a first order system, and each field is then discretized via a DG method. At this point, the single-valued \"trace\" values on the skeleton of the mesh, i.e., element faces, are taken to be independent unknown quantities. This yields unknowns in the discrete formulation that fall into two categories:\\n\\n* Face unknowns that only couple with the cell unknowns from both sides of the face;\\n* Cell unknowns that only couple with the cell and face unknowns defined within the same cell. Crucially, no cell interior degree of freedom on one cell ever couples to any interior cell degree of freedom of a different cell.\\n\\nThe Dirichlet-to-Neumann map concept then permits the following solution procedure:\\n\\n1. Use local element interior data to enforce a Neumann condition on the skeleton of the triangulation. The global problem is then to solve for the trace values, which are the only globally coupled unknowns.\\n2. Use the known skeleton values as Dirichlet data for solving local element-level solutions. This is known as the \\'local solver\\', and is an *embarrassingly parallel* element-by-element solution process.\\n\\n#### Relation with Static Condensation\\n\\nThe above procedure also has a linear algebra interpretation—referred to as *static condensation*—that was exploited to reduce the size of the global linear system by Guyan in the context of continuous Finite Elements [[108]](citelist.html#CITEREF_G65), and by Fraeijs de Veubeke for mixed methods [[72]](citelist.html#CITEREF_F65). In the latter case (mixed formulation), the system reduction was achieved through the use of discontinuous fluxes combined with the introduction of an additional auxiliary *hybrid* variable that approximates the trace of the unknown at the boundary of every element. This procedure became known as hybridization and—by analogy—is the reason why the local discontinuous Galerkin method introduced by Cockburn, Gopalakrishnan, and Lazarov in 2009 [[62]](citelist.html#CITEREF_CGL2009), and subsequently developed by their collaborators, eventually came to be known as the *hybridizable discontinuous Galerkin* (HDG) method.\\n\\nLet us write the complete linear system associated to the HDG problem as a block system with the discrete DG (cell interior) variables \\\\(U\\\\) as first block and the skeleton (face) variables \\\\(\\\\Lambda\\\\) as the second block:\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\begin{pmatrix} A & B \\\\\\\\ C & D \\\\end{pmatrix}\\n\\\\begin{pmatrix} U \\\\\\\\ \\\\Lambda \\\\end{pmatrix}\\n=\\n\\\\begin{pmatrix} F \\\\\\\\ G \\\\end{pmatrix}.\\n\\\\end{eqnarray\\\\*}\\n\\nOur aim is now to eliminate the \\\\(U\\\\) block with a Schur complement approach similar to [step-20](step_20.html), which results in the following two steps:\\n\\n\\\\begin{eqnarray\\\\*}\\n(D - C A^{-1} B) \\\\Lambda &=& G - C A^{-1} F, \\\\\\\\\\nA U &=& F - B \\\\Lambda.\\n\\\\end{eqnarray\\\\*}\\n\\nThe point is that the presence of \\\\(A^{-1}\\\\) is not a problem because \\\\(A\\\\) is a block diagonal matrix where each block corresponds to one cell and is therefore easy enough to invert. The coupling to other cells is introduced by the matrices \\\\(B\\\\) and \\\\(C\\\\) over the skeleton variable. The block-diagonality of \\\\(A\\\\) and the structure in \\\\(B\\\\) and \\\\(C\\\\) allow us to invert the matrix \\\\(A\\\\) element by element (the local solution of the Dirichlet problem) and subtract \\\\(CA^{-1}B\\\\) from \\\\(D\\\\). The steps in the Dirichlet-to-Neumann map concept hence correspond to\\n\\n1. constructing the Schur complement matrix \\\\(D-C A^{-1} B\\\\) and right hand side \\\\(G - C A^{-1} F\\\\) *locally on each cell* and inserting the contribution into the global trace matrix in the usual way,\\n2. solving the Schur complement system for \\\\(\\\\Lambda\\\\), and\\n3. solving for \\\\(U\\\\) using the second equation, given \\\\(\\\\Lambda\\\\).\\n\\n#### Solution quality and rates of convergence\\n\\nAnother criticism of traditional DG methods is that the approximate fluxes converge suboptimally. The local HDG solutions can be shown to converge as \\\\(\\\\mathcal{O}(h^{p+1})\\\\), i.e., at optimal order. Additionally, a super-convergence property can be used to post-process a new approximate solution that converges at the rate \\\\(\\\\mathcal{O}(h^{p+2})\\\\).\\n\\n#### Alternative approaches\\n\\nThe hybridizable discontinuous Galerkin method is only one way in which the problems of the discontinuous Galerkin method can be addressed. Another idea is what is called the \"weak Galerkin\" method. It is explored in [step-61](step_61.html).\\n\\n### HDG applied to the convection-diffusion problem\\n\\nThe HDG formulation used for this example is taken from   \\n **N.C. Nguyen, J. Peraire, B. Cockburn: *An implicit high-order hybridizable discontinuous Galerkin method for linear convectionâ\\x80\\x93diffusion equations*, Journal of Computational [Physics](namespacePhysics.html), 2009, 228:9, 3232-3254. [[DOI]](http://dx.doi.org/10.1016/j.jcp.2009.01.030)**\\n\\nWe consider the convection-diffusion equation over the domain \\\\(\\\\Omega\\\\) with Dirichlet boundary \\\\(\\\\partial \\\\Omega\\\\_D\\\\) and Neumann boundary \\\\(\\\\partial \\\\Omega\\\\_N\\\\):\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\nabla \\\\cdot (\\\\mathbf{c} u) - \\\\nabla \\\\cdot (\\\\kappa \\\\nabla u) &=& f,\\n\\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\nu &=& g\\\\_D, \\\\quad \\\\text{ on } \\\\partial \\\\Omega\\\\_D, \\\\\\\\\\n(\\\\mathbf{c} u - \\\\kappa \\\\nabla u)\\\\cdot \\\\mathbf{n} &=& g\\\\_N,\\n\\\\quad \\\\text{ on } \\\\partial \\\\Omega\\\\_N.\\n\\\\end{eqnarray\\\\*}\\n\\nIntroduce the auxiliary variable \\\\(\\\\mathbf{q}=-\\\\kappa \\\\nabla u\\\\) and rewrite the above equation as the first order system:\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\mathbf{q} + \\\\kappa \\\\nabla u &=& 0, \\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\n\\\\nabla \\\\cdot (\\\\mathbf{c} u + \\\\mathbf{q}) &=& f, \\\\quad \\\\text{ in } \\\\Omega, \\\\\\\\\\nu &=& g\\\\_D, \\\\quad \\\\text{ on } \\\\partial \\\\Omega\\\\_D, \\\\\\\\\\n(\\\\mathbf{q} + \\\\mathbf{c}u)\\\\cdot\\\\mathbf{n} &=& g\\\\_N,\\n\\\\quad \\\\text{ on } \\\\partial \\\\Omega\\\\_N.\\n\\\\end{eqnarray\\\\*}\\n\\nWe multiply these equations by the weight functions \\\\(\\\\mathbf{v}, w\\\\) and integrate by parts over every element \\\\(K\\\\) to obtain:\\n\\n\\\\begin{eqnarray\\\\*}\\n(\\\\mathbf{v}, \\\\kappa^{-1} \\\\mathbf{q})\\\\_K - (\\\\nabla\\\\cdot\\\\mathbf{v}, u)\\\\_K\\n+ \\\\left<\\\\mathbf{v}\\\\cdot\\\\mathbf{n}, {\\\\hat{u}}\\\\right>\\\\_{\\\\partial K} &=& 0, \\\\\\\\\\n- (\\\\nabla w, \\\\mathbf{c} u + \\\\mathbf{q})\\\\_K\\n+ \\\\left<w, (\\\\widehat{\\\\mathbf{c} u}+{\\\\hat{\\\\mathbf{q}}})\\\\cdot\\\\mathbf{n}\\\\right>\\\\_{\\\\partial K}\\n&=& (w,f)\\\\_K.\\n\\\\end{eqnarray\\\\*}\\n\\nThe terms decorated with a hat denote the numerical traces (also commonly referred to as numerical fluxes). They are approximations to the interior values on the boundary of the element. To ensure conservation, these terms must be single-valued on any given element edge \\\\(\\\\partial K\\\\) even though, with discontinuous shape functions, there may of course be multiple values coming from the cells adjacent to an interface. We eliminate the numerical trace \\\\(\\\\hat{\\\\mathbf{q}}\\\\) by using traces of the form:\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\widehat{\\\\mathbf{c} u}+\\\\hat{\\\\mathbf{q}} = \\\\mathbf{c}\\\\hat{u} + \\\\mathbf{q}\\n+ \\\\tau(u - \\\\hat{u})\\\\mathbf{n} \\\\quad \\\\text{ on } \\\\partial K.\\n\\\\end{eqnarray\\\\*}\\n\\nThe variable \\\\(\\\\hat {u}\\\\) is introduced as an additional independent variable and is the one for which we finally set up a globally coupled linear system. As mentioned above, it is defined on the element faces and discontinuous from one face to another wherever faces meet (at vertices in 2d, and at edges and vertices in 3d). Values for \\\\(u\\\\) and \\\\(\\\\mathbf{q}\\\\) appearing in the numerical trace function are taken to be the cell\\'s interior solution restricted to the boundary \\\\(\\\\partial K\\\\).\\n\\nThe local stabilization parameter \\\\(\\\\tau\\\\) has effects on stability and accuracy of HDG solutions; see the literature for a further discussion. A stabilization parameter of unity is reported to be the choice which gives best results. A stabilization parameter \\\\(\\\\tau\\\\) that tends to infinity prohibits jumps in the solution over the element boundaries, making the HDG solution approach the approximation with continuous finite elements. In the program below, we choose the stabilization parameter as\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\tau = \\\\frac{\\\\kappa}{\\\\ell} + |\\\\mathbf{c} \\\\cdot \\\\mathbf{n}|\\n\\\\end{eqnarray\\\\*}\\n\\nwhere we set the diffusion \\\\(\\\\kappa=1\\\\) and the diffusion length scale to \\\\(\\\\ell = \\\\frac{1}{5}\\\\).\\n\\nThe trace/skeleton variables in HDG methods are single-valued on element faces. As such, they must strongly represent the Dirichlet data on \\\\(\\\\partial\\\\Omega\\\\_D\\\\). This means that\\n\\n\\\\begin{equation\\\\*}\\n\\\\hat{u}|\\\\_{\\\\partial \\\\Omega\\\\_D} = g\\\\_D,\\n\\\\end{equation\\\\*}\\n\\nwhere the equal sign actually means an \\\\(L\\\\_2\\\\) projection of the boundary function \\\\(g\\\\) onto the space of the face variables (e.g. linear functions on the faces). This constraint is then applied to the skeleton variable \\\\(\\\\hat{u}\\\\) using inhomogeneous constraints by the method [VectorTools::project\\\\_boundary\\\\_values](namespaceVectorTools.html#a747e71d426643718d52eda904d46bb20).\\n\\nSumming the elemental contributions across all elements in the triangulation, enforcing the normal component of the numerical flux, and integrating by parts on the equation weighted by \\\\(w\\\\), we arrive at the final form of the problem: Find \\\\((\\\\mathbf{q}\\\\_h, u\\\\_h, \\\\hat{u}\\\\_h) \\\\in\\n\\\\mathcal{V}\\\\_h^p \\\\times \\\\mathcal{W}\\\\_h^p \\\\times \\\\mathcal{M}\\\\_h^p\\\\) such that\\n\\n\\\\begin{align\\\\*}\\n(\\\\mathbf{v}, \\\\kappa^{-1} \\\\mathbf{q}\\\\_h)\\\\_{\\\\mathcal{T}}\\n- ( \\\\nabla\\\\cdot\\\\mathbf{v}, u\\\\_h)\\\\_{\\\\mathcal{T}}\\n+ \\\\left<\\\\mathbf{v}\\\\cdot\\\\mathbf{n}, \\\\hat{u}\\\\_h\\\\right>\\\\_{\\\\partial\\\\mathcal{T}}\\n&= 0,\\n\\\\quad &&\\\\forall \\\\mathbf{v} \\\\in \\\\mathcal{V}\\\\_h^p,\\n\\\\\\\\\\n- (\\\\nabla w, \\\\mathbf{c} u\\\\_h)\\\\_{\\\\mathcal{T}}\\n+ (w, \\\\nabla \\\\cdot \\\\mathbf{q}\\\\_h)\\\\_{\\\\mathcal{T}}\\n+ (w, (\\\\mathbf{c}\\\\cdot\\\\mathbf{n}) \\\\hat{u}\\\\_h)\\\\_{\\\\partial \\\\mathcal{T}}\\n+ \\\\left<w, \\\\tau (u\\\\_h - \\\\hat{u}\\\\_h)\\\\right>\\\\_{\\\\partial \\\\mathcal{T}}\\n&=\\n(w, f)\\\\_{\\\\mathcal{T}},\\n\\\\quad &&\\\\forall w \\\\in \\\\mathcal{W}\\\\_h^p,\\n\\\\\\\\\\n\\\\left< \\\\mu, \\\\hat{u}\\\\_h\\\\mathbf{c} \\\\cdot \\\\mathbf{n}\\n+ \\\\mathbf{q}\\\\_h\\\\cdot \\\\mathbf{n}\\n+ \\\\tau (u\\\\_h - \\\\hat{u}\\\\_h)\\\\right>\\\\_{\\\\partial \\\\mathcal{T}}\\n&=\\n\\\\left<\\\\mu, g\\\\_N\\\\right>\\\\_{\\\\partial\\\\Omega\\\\_N},\\n\\\\quad &&\\\\forall \\\\mu \\\\in \\\\mathcal{M}\\\\_h^p.\\n\\\\end{align\\\\*}\\n\\nThe unknowns \\\\((\\\\mathbf{q}\\\\_h, u\\\\_h)\\\\) are referred to as local variables; they are represented as standard DG variables. The unknown \\\\(\\\\hat{u}\\\\_h\\\\) is the skeleton variable which has support on the codimension-1 surfaces (faces) of the mesh.\\n\\nWe use the notation \\\\((\\\\cdot, \\\\cdot)\\\\_{\\\\mathcal{T}} = \\\\sum\\\\_K (\\\\cdot, \\\\cdot)\\\\_K\\\\) to denote the sum of integrals over all cells and \\\\(\\\\left<\\\\cdot,\\n\\\\cdot\\\\right>\\\\_{\\\\partial \\\\mathcal{T}} = \\\\sum\\\\_K \\\\left<\\\\cdot,\\n\\\\cdot\\\\right>\\\\_{\\\\partial K}\\\\) to denote integration over all faces of all cells, i.e., interior faces are visited twice, once from each side and with the corresponding normal vectors. When combining the contribution from both elements sharing a face, the above equation yields terms familiar from the DG method, with jumps of the solution over the cell boundaries.\\n\\nIn the equation above, the space \\\\(\\\\mathcal {W}\\\\_h^{p}\\\\) for the scalar variable \\\\(u\\\\_h\\\\) is defined as the space of functions that are tensor product polynomials of degree \\\\(p\\\\) on each cell and discontinuous over the element boundaries \\\\(\\\\mathcal Q\\\\_{-p}\\\\), i.e., the space described by `FE_DGQ<dim>(p)`. The space for the gradient or flux variable \\\\(\\\\mathbf{q}\\\\_i\\\\) is a vector element space where each component is a locally polynomial and discontinuous \\\\(\\\\mathcal Q\\\\_{-p}\\\\). In the code below, we collect these two local parts together in one [FESystem](classFESystem.html) where the first `dim` components denote the gradient part and the last scalar component corresponds to the scalar variable. For the skeleton component \\\\(\\\\hat{u}\\\\_h\\\\), we define a space that consists of discontinuous tensor product polynomials that live on the element faces, which in deal.II is implemented by the class [FE\\\\_FaceQ](classFE__FaceQ.html). This space is otherwise similar to [FE\\\\_DGQ](classFE__DGQ.html), i.e., the solution function is not continuous between two neighboring faces, see also the results section below for an illustration.\\n\\nIn the weak form given above, we can note the following coupling patterns:\\n\\n1. The matrix \\\\(A\\\\) consists of local-local coupling terms. These arise when the local weighting functions \\\\((\\\\mathbf{v}, w)\\\\) multiply the local solution terms \\\\((\\\\mathbf{q}\\\\_h, u\\\\_h)\\\\). Because the elements are discontinuous, \\\\(A\\\\) is block diagonal.\\n2. The matrix \\\\(B\\\\) represents the local-face coupling. These are the terms with weighting functions \\\\((\\\\mathbf{v}, w)\\\\) multiplying the skeleton variable \\\\(\\\\hat{u}\\\\_h\\\\).\\n3. The matrix \\\\(C\\\\) represents the face-local coupling, which involves the weighting function \\\\(\\\\mu\\\\) multiplying the local solutions \\\\((\\\\mathbf{q}\\\\_h, u\\\\_h)\\\\).\\n4. The matrix \\\\(D\\\\) is the face-face coupling; terms involve both \\\\(\\\\mu\\\\) and \\\\(\\\\hat{u}\\\\_h\\\\).\\n\\n#### Post-processing and super-convergence\\n\\nOne special feature of the HDG methods is that they typically allow for constructing an enriched solution that gains accuracy. This post-processing takes the HDG solution in an element-by-element fashion and combines it such that one can get \\\\(\\\\mathcal O(h^{p+2})\\\\) order of accuracy when using polynomials of degree \\\\(p\\\\). For this to happen, there are two necessary ingredients:\\n\\n1. The computed solution gradient \\\\(\\\\mathbf{q}\\\\_h\\\\) converges at optimal rate, i.e., \\\\(\\\\mathcal{O}(h^{p+1})\\\\).\\n2. The cell-wise average of the scalar part of the solution, \\\\(\\\\frac{(1,u\\\\_h)\\\\_K}{\\\\text{vol}(K)}\\\\), super-converges at rate \\\\(\\\\mathcal{O}(h^{p+2})\\\\).\\n\\nWe now introduce a new variable \\\\(u\\\\_h^\\\\* \\\\in \\\\mathcal{V}\\\\_h^{p+1}\\\\), which we find by minimizing the expression \\\\(|\\\\kappa \\\\nabla u\\\\_h^\\\\* + \\\\mathbf{q}\\\\_h|^2\\\\) over the cell \\\\(K\\\\) under the constraint \\\\(\\\\left(1, u\\\\_h^\\\\*\\\\right)\\\\_K = \\\\left(1,\\nu\\\\_h\\\\right)\\\\_K\\\\). The constraint is necessary because the minimization functional does not determine the constant part of \\\\(u\\\\_h^\\\\*\\\\). This translates to the following system of equations:\\n\\n\\\\begin{eqnarray\\\\*}\\n\\\\left(1, u\\\\_h^\\\\*\\\\right)\\\\_K &=& \\\\left(1, u\\\\_h\\\\right)\\\\_K\\\\\\\\\\n\\\\left(\\\\nabla w\\\\_h^\\\\*, \\\\kappa \\\\nabla u\\\\_h^\\\\*\\\\right)\\\\_K &=&\\n-\\\\left(\\\\nabla w\\\\_h^\\\\*, \\\\mathbf{q}\\\\_h\\\\right)\\\\_K\\n\\\\quad \\\\text{for all } w\\\\_h^\\\\* \\\\in \\\\mathcal Q^{p+1}.\\n\\\\end{eqnarray\\\\*}\\n\\nSince we test by the whole set of basis functions in the space of tensor product polynomials of degree \\\\(p+1\\\\) in the second set of equations, this is an overdetermined system with one more equation than unknowns. We fix this in the code below by omitting one of these equations (since the rows in the Laplacian are linearly dependent when representing a constant function). As we will see below, this form of the post-processing gives the desired super-convergence result with rate \\\\(\\\\mathcal {O}(h^{p+2})\\\\). It should be noted that there is some freedom in constructing \\\\(u\\\\_h^\\\\*\\\\) and this minimization approach to extract the information from the gradient is not the only one. In particular, the post-processed solution defined here does not satisfy the convection-diffusion equation in any sense. As an alternative, the paper by Nguyen, Peraire and Cockburn cited above suggests another somewhat more involved formula for convection-diffusion that can also post-process the flux variable into an \\\\(H(\\\\Omega,\\\\mathrm{div})\\\\)-conforming variant and better represents the local convection-diffusion operator when the diffusion is small. We leave the implementation of a more sophisticated post-processing as a possible extension to the interested reader.\\n\\nNote that for vector-valued problems, the post-processing works similarly. One simply sets the constraint for the mean value of each vector component separately and uses the gradient as the main source of information.\\n\\n### Problem specific data\\n\\nFor this tutorial program, we consider almost the same test case as in [step-7](step_7.html). The computational domain is \\\\(\\\\Omega \\\\dealcoloneq [-1,1]^d\\\\) and the exact solution corresponds to the one in [step-7](step_7.html), except for a scaling. We use the following source centers \\\\(x\\\\_i\\\\) for the exponentials\\n\\n* 1D: \\\\(\\\\{x\\\\_i\\\\}^1 = \\\\{ -\\\\frac{1}{3}, 0, \\\\frac{1}{3} \\\\}\\\\),\\n* 2D: \\\\(\\\\{\\\\mathbf{x}\\\\_i\\\\}^2 = \\\\{ (-\\\\frac{1}{2},\\\\frac{1}{2}),\\n  (-\\\\frac{1}{2},-\\\\frac{1}{2}),\\n  (\\\\frac{1}{2},-\\\\frac{1}{2})\\n  \\\\}\\\\),\\n* 3D: \\\\(\\\\{\\\\mathbf{x}\\\\_i\\\\}^3 = \\\\{ (-\\\\frac{1}{2},\\\\frac{1}{2}, \\\\frac{1}{4}),\\n  (-\\\\frac{3}{5},-\\\\frac{1}{2}, -\\\\frac{1}{8}),\\n  (\\\\frac{1}{2},-\\\\frac{1}{2}, \\\\frac{1}{2})\\n  \\\\}\\\\).\\n\\nWith the exact solution given, we then choose the forcing on the right hand side and the Neumann boundary condition such that we obtain this solution (manufactured solution technique). In this example, we choose the diffusion equal to one and the convection as\\n\\n\\\\[\\n\\\\mathbf{c} = \\\\begin{cases}\\n1, & \\\\textrm{dim}=1 \\\\\\\\\\n(y, -x), & \\\\textrm{dim}=2 \\\\\\\\\\n(y, -x, 1), & \\\\textrm{dim}=3\\n\\\\end{cases}\\n\\\\]\\n\\nNote that the convection is divergence-free, \\\\(\\\\nabla \\\\cdot c = 0\\\\).\\n\\n### Implementation\\n\\nBesides implementing the above equations, the implementation below provides the following features:\\n\\n* [WorkStream](namespaceWorkStream.html) to parallelize local solvers. Workstream has been presented in detail in [step-9](step_9.html).\\n* Reconstruct the local DG solution from the trace.\\n* Post-processing the solution for superconvergence.\\n* [DataOutFaces](classDataOutFaces.html) for direct output of the global skeleton solution.\\n\\nThe commented program\\n=====================\\n\\n### Include files\\n\\nMost of the deal.II include files have already been covered in previous examples and are not commented on.\\n\\n```\\n \\xa0 #include <deal.II/base/quadrature_lib.h>\\n \\xa0 #include <deal.II/base/function.h>\\n \\xa0 #include <deal.II/base/tensor_function.h>\\n \\xa0 #include <deal.II/base/exceptions.h>\\n \\xa0 #include <deal.II/base/work_stream.h>\\n \\xa0 #include <deal.II/base/convergence_table.h>\\n \\xa0 #include <deal.II/lac/vector.h>\\n \\xa0 #include <deal.II/lac/affine_constraints.h>\\n \\xa0 #include <deal.II/lac/full_matrix.h>\\n \\xa0 #include <deal.II/lac/dynamic_sparsity_pattern.h>\\n \\xa0 #include <deal.II/lac/solver_bicgstab.h>\\n \\xa0 #include <deal.II/lac/precondition.h>\\n \\xa0 #include <deal.II/grid/tria.h>\\n \\xa0 #include <deal.II/grid/grid_generator.h>\\n \\xa0 #include <deal.II/grid/grid_refinement.h>\\n \\xa0 #include <deal.II/dofs/dof_handler.h>\\n \\xa0 #include <deal.II/dofs/dof_renumbering.h>\\n \\xa0 #include <deal.II/dofs/dof_tools.h>\\n \\xa0 #include <deal.II/fe/fe_dgq.h>\\n \\xa0 #include <deal.II/fe/fe_system.h>\\n \\xa0 #include <deal.II/fe/fe_values.h>\\n \\xa0 #include <deal.II/numerics/vector_tools.h>\\n \\xa0 #include <deal.II/numerics/error_estimator.h>\\n \\xa0 #include <deal.II/numerics/data_out.h>\\n```\\n\\nHowever, we do have a few new includes for the example. The first one defines finite element spaces on the faces of the triangulation, which we refer to as the \\'skeleton\\'. These finite elements do not have any support on the element interior, and they represent polynomials that have a single value on each codimension-1 surface, but admit discontinuities on codimension-2 surfaces.\\n\\n```\\n \\xa0 #include <deal.II/fe/fe_face.h>\\n```\\n\\nThe second new file we include defines a new type of sparse matrix. The regular `SparseMatrix` type stores indices to all non-zero entries. The `ChunkSparseMatrix` takes advantage of the coupled nature of DG solutions. It stores an index to a matrix sub-block of a specified size. In the HDG context, this sub-block-size is actually the number of degrees of freedom per face defined by the skeleton solution field. This reduces the memory consumption of the matrix by up to one third and results in similar speedups when using the matrix in solvers.\\n\\n```\\n \\xa0 #include <deal.II/lac/chunk_sparse_matrix.h>\\n```\\n\\nThe final new include for this example deals with data output. Since we have a finite element field defined on the skeleton of the mesh, we would like to visualize what that solution actually is. [DataOutFaces](classDataOutFaces.html) does exactly this; the interface is the almost the same as the familiar [DataOut](classDataOut.html), but the output only has codimension-1 data for the simulation.\\n\\n```\\n \\xa0 #include <deal.II/numerics/data_out_faces.h>\\n \\xa0 \\n \\xa0 #include <iostream>\\n```\\n\\nWe start by putting all of our classes into their own namespace.\\n\\n```\\n \\xa0 namespace Step51\\n \\xa0 {\\n \\xa0   using namespace dealii;\\n```\\n\\n### Equation data\\n\\nThe structure of the analytic solution is the same as in [step-7](step_7.html). There are two exceptions. Firstly, we also create a solution for the 3d case, and secondly, we scale the solution so its norm is of order unity for all values of the solution width.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   class SolutionBase\\n \\xa0   {\\n \\xa0   protected:\\n \\xa0     static const unsigned int n_source_centers = 3;\\n \\xa0     static const Point<dim>   source_centers[n_source_centers];\\n \\xa0     static const double       width;\\n \\xa0   };\\n \\xa0 \\n \\xa0 \\n \\xa0   template <>\\n \\xa0   const Point<1>\\n \\xa0     SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\\n \\xa0       {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\\n \\xa0 \\n \\xa0 \\n \\xa0   template <>\\n \\xa0   const Point<2>\\n \\xa0     SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\\n \\xa0       {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\\n \\xa0 \\n \\xa0   template <>\\n \\xa0   const Point<3>\\n \\xa0     SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\\n \\xa0       Point<3>(-0.5, +0.5, 0.25),\\n \\xa0       Point<3>(-0.6, -0.5, -0.125),\\n \\xa0       Point<3>(+0.5, -0.5, 0.5)};\\n \\xa0 \\n \\xa0   template <int dim>\\n \\xa0   const double SolutionBase<dim>::width = 1. / 5.;\\n \\xa0 \\n \\xa0 \\n \\xa0   template <int dim>\\n \\xa0   class Solution : public Function<dim>, protected SolutionBase<dim>\\n \\xa0   {\\n \\xa0   public:\\n \\xa0     virtual double value(const Point<dim> &p,\\n \\xa0                          const unsigned int /*component*/ = 0) const override\\n \\xa0     {\\n \\xa0       double sum = 0;\\n \\xa0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n \\xa0         {\\n \\xa0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\xa0           sum +=\\n \\xa0             std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\\n \\xa0         }\\n \\xa0 \\n \\xa0       return sum /\\n \\xa0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n \\xa0     }\\n \\xa0 \\n \\xa0     virtual Tensor<1, dim>\\n \\xa0     gradient(const Point<dim> &p,\\n \\xa0              const unsigned int /*component*/ = 0) const override\\n \\xa0     {\\n \\xa0       Tensor<1, dim> sum;\\n \\xa0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n \\xa0         {\\n \\xa0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\xa0 \\n \\xa0           sum +=\\n \\xa0             (-2 / (this->width * this->width) *\\n \\xa0              std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\\n \\xa0              x_minus_xi);\\n \\xa0         }\\n \\xa0 \\n \\xa0       return sum /\\n \\xa0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n \\xa0     }\\n \\xa0   };\\n```\\n\\nThis class implements a function where the scalar solution and its negative gradient are collected together. This function is used when computing the error of the HDG approximation and its implementation is to simply call value and gradient function of the Solution class.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\\n \\xa0   {\\n \\xa0   public:\\n \\xa0     SolutionAndGradient()\\n \\xa0       : Function<dim>(dim + 1)\\n \\xa0     {}\\n \\xa0 \\n \\xa0     virtual void vector_value(const Point<dim> &p,\\n \\xa0                               Vector<double>   &v) const override\\n \\xa0     {\\n \\xa0       AssertDimension(v.size(), dim + 1);\\n \\xa0       Solution<dim>  solution;\\n \\xa0       Tensor<1, dim> grad = solution.gradient(p);\\n \\xa0       for (unsigned int d = 0; d < dim; ++d)\\n \\xa0         v[d] = -grad[d];\\n \\xa0       v[dim] = solution.value(p);\\n \\xa0     }\\n \\xa0   };\\n```\\n\\nNext comes the implementation of the convection velocity. As described in the introduction, we choose a velocity field that is \\\\((y, -x)\\\\) in 2d and \\\\((y, -x, 1)\\\\) in 3d. This gives a divergence-free velocity field.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   class ConvectionVelocity : public TensorFunction<1, dim>\\n \\xa0   {\\n \\xa0   public:\\n \\xa0     ConvectionVelocity()\\n \\xa0       : TensorFunction<1, dim>()\\n \\xa0     {}\\n \\xa0 \\n \\xa0     virtual Tensor<1, dim> value(const Point<dim> &p) const override\\n \\xa0     {\\n \\xa0       Tensor<1, dim> convection;\\n \\xa0       switch (dim)\\n \\xa0         {\\n \\xa0           case 1:\\n \\xa0             convection[0] = 1;\\n \\xa0             break;\\n \\xa0           case 2:\\n \\xa0             convection[0] = p[1];\\n \\xa0             convection[1] = -p[0];\\n \\xa0             break;\\n \\xa0           case 3:\\n \\xa0             convection[0] = p[1];\\n \\xa0             convection[1] = -p[0];\\n \\xa0             convection[2] = 1;\\n \\xa0             break;\\n \\xa0           default:\\n \\xa0             DEAL_II_NOT_IMPLEMENTED();\\n \\xa0         }\\n \\xa0       return convection;\\n \\xa0     }\\n \\xa0   };\\n```\\n\\nThe last function we implement is the right hand side for the manufactured solution. It is very similar to [step-7](step_7.html), with the exception that we now have a convection term instead of the reaction term. Since the velocity field is incompressible, i.e., \\\\(\\\\nabla \\\\cdot \\\\mathbf{c} =\\n0\\\\), the advection term simply reads \\\\(\\\\mathbf{c} \\\\nabla u\\\\).\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   class RightHandSide : public Function<dim>, protected SolutionBase<dim>\\n \\xa0   {\\n \\xa0   public:\\n \\xa0     virtual double value(const Point<dim> &p,\\n \\xa0                          const unsigned int /*component*/ = 0) const override\\n \\xa0     {\\n \\xa0       ConvectionVelocity<dim> convection_velocity;\\n \\xa0       Tensor<1, dim>          convection = convection_velocity.value(p);\\n \\xa0       double                  sum        = 0;\\n \\xa0       for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n \\xa0         {\\n \\xa0           const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\xa0 \\n \\xa0           sum +=\\n \\xa0             ((2 * dim - 2 * convection * x_minus_xi -\\n \\xa0               4 * x_minus_xi.norm_square() / (this->width * this->width)) /\\n \\xa0              (this->width * this->width) *\\n \\xa0              std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\\n \\xa0         }\\n \\xa0 \\n \\xa0       return sum /\\n \\xa0              std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n \\xa0     }\\n \\xa0   };\\n```\\n\\n### The HDG solver class\\n\\nThe HDG solution procedure follows closely that of [step-7](step_7.html). The major difference is the use of three different sets of [DoFHandler](classDoFHandler.html) and FE objects, along with the [ChunkSparseMatrix](classChunkSparseMatrix.html) and the corresponding solutions vectors. We also use [WorkStream](namespaceWorkStream.html) to enable a multithreaded local solution process which exploits the embarrassingly parallel nature of the local solver. For [WorkStream](namespaceWorkStream.html), we define the local operations on a cell and a copy function into the global matrix and vector. We do this both for the assembly (which is run twice, once when we generate the system matrix and once when we compute the element-interior solutions from the skeleton values) and for the postprocessing where we extract a solution that converges at higher order.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   class HDG\\n \\xa0   {\\n \\xa0   public:\\n \\xa0     enum RefinementMode\\n \\xa0     {\\n \\xa0       global_refinement,\\n \\xa0       adaptive_refinement\\n \\xa0     };\\n \\xa0 \\n \\xa0     HDG(const unsigned int degree, const RefinementMode refinement_mode);\\n \\xa0     void run();\\n \\xa0 \\n \\xa0   private:\\n \\xa0     void setup_system();\\n \\xa0     void assemble_system(const bool reconstruct_trace = false);\\n \\xa0     void solve();\\n \\xa0     void postprocess();\\n \\xa0     void refine_grid(const unsigned int cycle);\\n \\xa0     void output_results(const unsigned int cycle);\\n```\\n\\nData for the assembly and solution of the primal variables.\\n\\n```\\n \\xa0     struct PerTaskData;\\n \\xa0     struct ScratchData;\\n```\\n\\nPost-processing the solution to obtain \\\\(u^\\\\*\\\\) is an element-by-element procedure; as such, we do not need to assemble any global data and do not declare any \\'task data\\' for [WorkStream](namespaceWorkStream.html) to use.\\n\\n```\\n \\xa0     struct PostProcessScratchData;\\n```\\n\\nThe following three functions are used by [WorkStream](namespaceWorkStream.html) to do the actual work of the program.\\n\\n```\\n \\xa0     void assemble_system_one_cell(\\n \\xa0       const typename DoFHandler<dim>::active_cell_iterator &cell,\\n \\xa0       ScratchData                                          &scratch,\\n \\xa0       PerTaskData                                          &task_data);\\n \\xa0 \\n \\xa0     void copy_local_to_global(const PerTaskData &data);\\n \\xa0 \\n \\xa0     void postprocess_one_cell(\\n \\xa0       const typename DoFHandler<dim>::active_cell_iterator &cell,\\n \\xa0       PostProcessScratchData                               &scratch,\\n \\xa0       unsigned int                                         &empty_data);\\n \\xa0 \\n \\xa0 \\n \\xa0     Triangulation<dim> triangulation;\\n```\\n\\nThe \\'local\\' solutions are interior to each element. These represent the primal solution field \\\\(u\\\\) as well as the auxiliary field \\\\(\\\\mathbf{q}\\\\).\\n\\n```\\n \\xa0     const FESystem<dim> fe_local;\\n \\xa0     DoFHandler<dim>     dof_handler_local;\\n \\xa0     Vector<double>      solution_local;\\n```\\n\\nThe new finite element type and corresponding `DoFHandler` are used for the global skeleton solution that couples the element-level local solutions.\\n\\n```\\n \\xa0     const FE_FaceQ<dim> fe;\\n \\xa0     DoFHandler<dim>     dof_handler;\\n \\xa0     Vector<double>      solution;\\n \\xa0     Vector<double>      system_rhs;\\n```\\n\\nAs stated in the introduction, HDG solutions can be post-processed to attain superconvergence rates of \\\\(\\\\mathcal{O}(h^{p+2})\\\\). The post-processed solution is a discontinuous finite element solution representing the primal variable on the interior of each cell. We define a FE type of degree \\\\(p+1\\\\) to represent this post-processed solution, which we only use for output after constructing it.\\n\\n```\\n \\xa0     const FE_DGQ<dim> fe_u_post;\\n \\xa0     DoFHandler<dim>   dof_handler_u_post;\\n \\xa0     Vector<double>    solution_u_post;\\n```\\n\\nThe degrees of freedom corresponding to the skeleton strongly enforce Dirichlet boundary conditions, just as in a continuous Galerkin finite element method. We can enforce the boundary conditions in an analogous manner via an [AffineConstraints](classAffineConstraints.html) object. In addition, hanging nodes are handled in the same way as for continuous finite elements: For the face elements which only define degrees of freedom on the face, this process sets the solution on the refined side to coincide with the representation on the coarse side.\\n\\nNote that for HDG, the elimination of hanging nodes is not the only possibility — in terms of the HDG theory, one could also use the unknowns from the refined side and express the local solution on the coarse side through the trace values on the refined side. However, such a setup is not as easily implemented in terms of deal.II loops and not further analyzed.\\n\\n```\\n \\xa0     AffineConstraints<double> constraints;\\n```\\n\\nThe usage of the [ChunkSparseMatrix](classChunkSparseMatrix.html) class is similar to the usual sparse matrices: You need a sparsity pattern of type [ChunkSparsityPattern](classChunkSparsityPattern.html) and the actual matrix object. When creating the sparsity pattern, we just have to additionally pass the size of local blocks.\\n\\n```\\n \\xa0     ChunkSparsityPattern      sparsity_pattern;\\n \\xa0     ChunkSparseMatrix<double> system_matrix;\\n```\\n\\nSame as [step-7](step_7.html):\\n\\n```\\n \\xa0     const RefinementMode refinement_mode;\\n \\xa0     ConvergenceTable     convergence_table;\\n \\xa0   };\\n```\\n\\n### The HDG class implementation\\n\\n#### Constructor\\n\\nThe constructor is similar to those in other examples, with the exception of handling multiple [DoFHandler](classDoFHandler.html) and [FiniteElement](classFiniteElement.html) objects. Note that we create a system of finite elements for the local DG part, including the gradient/flux part and the scalar part.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\\n \\xa0     : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\\n \\xa0     , dof_handler_local(triangulation)\\n \\xa0     , fe(degree)\\n \\xa0     , dof_handler(triangulation)\\n \\xa0     , fe_u_post(degree + 1)\\n \\xa0     , dof_handler_u_post(triangulation)\\n \\xa0     , refinement_mode(refinement_mode)\\n \\xa0   {}\\n```\\n\\n#### HDG::setup\\\\_system\\n\\nThe system for an HDG solution is setup in an analogous manner to most of the other tutorial programs. We are careful to distribute dofs with all of our [DoFHandler](classDoFHandler.html) objects. The `solution` and `system_matrix` objects go with the global skeleton solution.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::setup_system()\\n \\xa0   {\\n \\xa0     dof_handler_local.distribute_dofs(fe_local);\\n \\xa0     dof_handler.distribute_dofs(fe);\\n \\xa0     dof_handler_u_post.distribute_dofs(fe_u_post);\\n \\xa0 \\n \\xa0     std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\\n \\xa0               << std::endl;\\n \\xa0 \\n \\xa0     solution.reinit(dof_handler.n_dofs());\\n \\xa0     system_rhs.reinit(dof_handler.n_dofs());\\n \\xa0 \\n \\xa0     solution_local.reinit(dof_handler_local.n_dofs());\\n \\xa0     solution_u_post.reinit(dof_handler_u_post.n_dofs());\\n \\xa0 \\n \\xa0     constraints.clear();\\n \\xa0     DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n \\xa0     std::map<types::boundary_id, const Function<dim> *> boundary_functions;\\n \\xa0     Solution<dim>                                       solution_function;\\n \\xa0     boundary_functions[0] = &solution_function;\\n \\xa0     VectorTools::project_boundary_values(dof_handler,\\n \\xa0                                          boundary_functions,\\n \\xa0                                          QGauss<dim - 1>(fe.degree + 1),\\n \\xa0                                          constraints);\\n \\xa0     constraints.close();\\n```\\n\\nWhen creating the chunk sparsity pattern, we first create the usual dynamic sparsity pattern and then set the chunk size, which is equal to the number of dofs on a face, when copying this into the final sparsity pattern.\\n\\n```\\n \\xa0     {\\n \\xa0       DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n \\xa0       DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\\n \\xa0       sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\\n \\xa0     }\\n \\xa0     system_matrix.reinit(sparsity_pattern);\\n \\xa0   }\\n```\\n\\n#### HDG::PerTaskData\\n\\nNext comes the definition of the local data structures for the parallel assembly. The first structure `PerTaskData` contains the local vector and matrix that are written into the global matrix, whereas the ScratchData contains all data that we need for the local assembly. There is one variable worth noting here, namely the boolean variable `trace_reconstruct`. As mentioned in the introduction, we solve the HDG system in two steps. First, we create a linear system for the skeleton system where we condense the local part into it via the Schur complement \\\\(D-CA^{-1}B\\\\). Then, we solve for the local part using the skeleton solution. For these two steps, we need the same matrices on the elements twice, which we want to compute by two assembly steps. Since most of the code is similar, we do this with the same function but only switch between the two based on a flag that we set when starting the assembly. Since we need to pass this information on to the local worker routines, we store it once in the task data.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   struct HDG<dim>::PerTaskData\\n \\xa0   {\\n \\xa0     FullMatrix<double>                   cell_matrix;\\n \\xa0     Vector<double>                       cell_vector;\\n \\xa0     std::vector<types::global_dof_index> dof_indices;\\n \\xa0 \\n \\xa0     bool trace_reconstruct;\\n \\xa0 \\n \\xa0     PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\\n \\xa0       : cell_matrix(n_dofs, n_dofs)\\n \\xa0       , cell_vector(n_dofs)\\n \\xa0       , dof_indices(n_dofs)\\n \\xa0       , trace_reconstruct(trace_reconstruct)\\n \\xa0     {}\\n \\xa0   };\\n```\\n\\n#### HDG::ScratchData\\n\\n`ScratchData` contains persistent data for each thread within [WorkStream](namespaceWorkStream.html). The [FEValues](classFEValues.html), matrix, and vector objects should be familiar by now. There are two objects that need to be discussed: `std::vector<std::vector<unsigned int> > fe_local_support_on_face` and `std::vector<std::vector<unsigned int> > fe_support_on_face`. These are used to indicate whether or not the finite elements chosen have support (non-zero values) on a given face of the reference cell for the local part associated to `fe_local` and the skeleton part `fe`. We extract this information in the constructor and store it once for all cells that we work on. Had we not stored this information, we would be forced to assemble a large number of zero terms on each cell, which would significantly slow the program.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   struct HDG<dim>::ScratchData\\n \\xa0   {\\n \\xa0     FEValues<dim>     fe_values_local;\\n \\xa0     FEFaceValues<dim> fe_face_values_local;\\n \\xa0     FEFaceValues<dim> fe_face_values;\\n \\xa0 \\n \\xa0     FullMatrix<double> ll_matrix;\\n \\xa0     FullMatrix<double> lf_matrix;\\n \\xa0     FullMatrix<double> fl_matrix;\\n \\xa0     FullMatrix<double> tmp_matrix;\\n \\xa0     Vector<double>     l_rhs;\\n \\xa0     Vector<double>     tmp_rhs;\\n \\xa0 \\n \\xa0     std::vector<Tensor<1, dim>> q_phi;\\n \\xa0     std::vector<double>         q_phi_div;\\n \\xa0     std::vector<double>         u_phi;\\n \\xa0     std::vector<Tensor<1, dim>> u_phi_grad;\\n \\xa0     std::vector<double>         tr_phi;\\n \\xa0     std::vector<double>         trace_values;\\n \\xa0 \\n \\xa0     std::vector<std::vector<unsigned int>> fe_local_support_on_face;\\n \\xa0     std::vector<std::vector<unsigned int>> fe_support_on_face;\\n \\xa0 \\n \\xa0     ConvectionVelocity<dim> convection_velocity;\\n \\xa0     RightHandSide<dim>      right_hand_side;\\n \\xa0     const Solution<dim>     exact_solution;\\n \\xa0 \\n \\xa0     ScratchData(const FiniteElement<dim> &fe,\\n \\xa0                 const FiniteElement<dim> &fe_local,\\n \\xa0                 const QGauss<dim>        &quadrature_formula,\\n \\xa0                 const QGauss<dim - 1>    &face_quadrature_formula,\\n \\xa0                 const UpdateFlags         local_flags,\\n \\xa0                 const UpdateFlags         local_face_flags,\\n \\xa0                 const UpdateFlags         flags)\\n \\xa0       : fe_values_local(fe_local, quadrature_formula, local_flags)\\n \\xa0       , fe_face_values_local(fe_local,\\n \\xa0                              face_quadrature_formula,\\n \\xa0                              local_face_flags)\\n \\xa0       , fe_face_values(fe, face_quadrature_formula, flags)\\n \\xa0       , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n \\xa0       , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n \\xa0       , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n \\xa0       , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n \\xa0       , l_rhs(fe_local.n_dofs_per_cell())\\n \\xa0       , tmp_rhs(fe_local.n_dofs_per_cell())\\n \\xa0       , q_phi(fe_local.n_dofs_per_cell())\\n \\xa0       , q_phi_div(fe_local.n_dofs_per_cell())\\n \\xa0       , u_phi(fe_local.n_dofs_per_cell())\\n \\xa0       , u_phi_grad(fe_local.n_dofs_per_cell())\\n \\xa0       , tr_phi(fe.n_dofs_per_cell())\\n \\xa0       , trace_values(face_quadrature_formula.size())\\n \\xa0       , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n \\xa0       , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n \\xa0       , exact_solution()\\n \\xa0     {\\n \\xa0       for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n \\xa0         for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\\n \\xa0           {\\n \\xa0             if (fe_local.has_support_on_face(i, face_no))\\n \\xa0               fe_local_support_on_face[face_no].push_back(i);\\n \\xa0           }\\n \\xa0 \\n \\xa0       for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n \\xa0         for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\\n \\xa0           {\\n \\xa0             if (fe.has_support_on_face(i, face_no))\\n \\xa0               fe_support_on_face[face_no].push_back(i);\\n \\xa0           }\\n \\xa0     }\\n \\xa0 \\n \\xa0     ScratchData(const ScratchData &sd)\\n \\xa0       : fe_values_local(sd.fe_values_local.get_fe(),\\n \\xa0                         sd.fe_values_local.get_quadrature(),\\n \\xa0                         sd.fe_values_local.get_update_flags())\\n \\xa0       , fe_face_values_local(sd.fe_face_values_local.get_fe(),\\n \\xa0                              sd.fe_face_values_local.get_quadrature(),\\n \\xa0                              sd.fe_face_values_local.get_update_flags())\\n \\xa0       , fe_face_values(sd.fe_face_values.get_fe(),\\n \\xa0                        sd.fe_face_values.get_quadrature(),\\n \\xa0                        sd.fe_face_values.get_update_flags())\\n \\xa0       , ll_matrix(sd.ll_matrix)\\n \\xa0       , lf_matrix(sd.lf_matrix)\\n \\xa0       , fl_matrix(sd.fl_matrix)\\n \\xa0       , tmp_matrix(sd.tmp_matrix)\\n \\xa0       , l_rhs(sd.l_rhs)\\n \\xa0       , tmp_rhs(sd.tmp_rhs)\\n \\xa0       , q_phi(sd.q_phi)\\n \\xa0       , q_phi_div(sd.q_phi_div)\\n \\xa0       , u_phi(sd.u_phi)\\n \\xa0       , u_phi_grad(sd.u_phi_grad)\\n \\xa0       , tr_phi(sd.tr_phi)\\n \\xa0       , trace_values(sd.trace_values)\\n \\xa0       , fe_local_support_on_face(sd.fe_local_support_on_face)\\n \\xa0       , fe_support_on_face(sd.fe_support_on_face)\\n \\xa0       , exact_solution()\\n \\xa0     {}\\n \\xa0   };\\n```\\n\\n#### HDG::PostProcessScratchData\\n\\n`PostProcessScratchData` contains the data used by [WorkStream](namespaceWorkStream.html) when post-processing the local solution \\\\(u^\\\\*\\\\). It is similar, but much simpler, than `ScratchData`.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   struct HDG<dim>::PostProcessScratchData\\n \\xa0   {\\n \\xa0     FEValues<dim> fe_values_local;\\n \\xa0     FEValues<dim> fe_values;\\n \\xa0 \\n \\xa0     std::vector<double>         u_values;\\n \\xa0     std::vector<Tensor<1, dim>> u_gradients;\\n \\xa0     FullMatrix<double>          cell_matrix;\\n \\xa0 \\n \\xa0     Vector<double> cell_rhs;\\n \\xa0     Vector<double> cell_sol;\\n \\xa0 \\n \\xa0     PostProcessScratchData(const FiniteElement<dim> &fe,\\n \\xa0                            const FiniteElement<dim> &fe_local,\\n \\xa0                            const QGauss<dim>        &quadrature_formula,\\n \\xa0                            const UpdateFlags         local_flags,\\n \\xa0                            const UpdateFlags         flags)\\n \\xa0       : fe_values_local(fe_local, quadrature_formula, local_flags)\\n \\xa0       , fe_values(fe, quadrature_formula, flags)\\n \\xa0       , u_values(quadrature_formula.size())\\n \\xa0       , u_gradients(quadrature_formula.size())\\n \\xa0       , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n \\xa0       , cell_rhs(fe.n_dofs_per_cell())\\n \\xa0       , cell_sol(fe.n_dofs_per_cell())\\n \\xa0     {}\\n \\xa0 \\n \\xa0     PostProcessScratchData(const PostProcessScratchData &sd)\\n \\xa0       : fe_values_local(sd.fe_values_local.get_fe(),\\n \\xa0                         sd.fe_values_local.get_quadrature(),\\n \\xa0                         sd.fe_values_local.get_update_flags())\\n \\xa0       , fe_values(sd.fe_values.get_fe(),\\n \\xa0                   sd.fe_values.get_quadrature(),\\n \\xa0                   sd.fe_values.get_update_flags())\\n \\xa0       , u_values(sd.u_values)\\n \\xa0       , u_gradients(sd.u_gradients)\\n \\xa0       , cell_matrix(sd.cell_matrix)\\n \\xa0       , cell_rhs(sd.cell_rhs)\\n \\xa0       , cell_sol(sd.cell_sol)\\n \\xa0     {}\\n \\xa0   };\\n```\\n\\n#### HDG::assemble\\\\_system\\n\\nThe `assemble_system` function is similar to the one on [step-32](step_32.html), where the quadrature formula and the update flags are set up, and then `WorkStream` is used to do the work in a multi-threaded manner. The `trace_reconstruct` input parameter is used to decide whether we are solving for the global skeleton solution (false) or the local solution (true).\\n\\nOne thing worth noting for the multi-threaded execution of assembly is the fact that the local computations in `assemble_system_one_cell()` call into BLAS and LAPACK functions if those are available in deal.II. Thus, the underlying BLAS/LAPACK library must support calls from multiple threads at the same time. Most implementations do support this, but some libraries need to be built in a specific way to avoid problems. For example, OpenBLAS compiled without multithreading inside the BLAS/LAPACK calls needs to built with a flag called `USE_LOCKING` set to true.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::assemble_system(const bool trace_reconstruct)\\n \\xa0   {\\n \\xa0     const QGauss<dim>     quadrature_formula(fe.degree + 1);\\n \\xa0     const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\\n \\xa0 \\n \\xa0     const UpdateFlags local_flags(update_values | update_gradients |\\n \\xa0                                   update_JxW_values | update_quadrature_points);\\n \\xa0 \\n \\xa0     const UpdateFlags local_face_flags(update_values);\\n \\xa0 \\n \\xa0     const UpdateFlags flags(update_values | update_normal_vectors |\\n \\xa0                             update_quadrature_points | update_JxW_values);\\n \\xa0 \\n \\xa0     PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\\n \\xa0     ScratchData scratch(fe,\\n \\xa0                         fe_local,\\n \\xa0                         quadrature_formula,\\n \\xa0                         face_quadrature_formula,\\n \\xa0                         local_flags,\\n \\xa0                         local_face_flags,\\n \\xa0                         flags);\\n \\xa0 \\n \\xa0     WorkStream::run(dof_handler.begin_active(),\\n \\xa0                     dof_handler.end(),\\n \\xa0                     *this,\\n \\xa0                     &HDG<dim>::assemble_system_one_cell,\\n \\xa0                     &HDG<dim>::copy_local_to_global,\\n \\xa0                     scratch,\\n \\xa0                     task_data);\\n \\xa0   }\\n```\\n\\n#### HDG::assemble\\\\_system\\\\_one\\\\_cell\\n\\nThe real work of the HDG program is done by `assemble_system_one_cell`. Assembling the local matrices \\\\(A, B, C\\\\) is done here, along with the local contributions of the global matrix \\\\(D\\\\).\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::assemble_system_one_cell(\\n \\xa0     const typename DoFHandler<dim>::active_cell_iterator &cell,\\n \\xa0     ScratchData                                          &scratch,\\n \\xa0     PerTaskData                                          &task_data)\\n \\xa0   {\\n```\\n\\nConstruct iterator for dof\\\\_handler\\\\_local for [FEValues](classFEValues.html) reinit function.\\n\\n```\\n \\xa0     const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n \\xa0       cell->as_dof_handler_iterator(dof_handler_local);\\n \\xa0 \\n \\xa0     const unsigned int n_q_points =\\n \\xa0       scratch.fe_values_local.get_quadrature().size();\\n \\xa0     const unsigned int n_face_q_points =\\n \\xa0       scratch.fe_face_values_local.get_quadrature().size();\\n \\xa0 \\n \\xa0     const unsigned int loc_dofs_per_cell =\\n \\xa0       scratch.fe_values_local.get_fe().n_dofs_per_cell();\\n \\xa0 \\n \\xa0     const FEValuesExtractors::Vector fluxes(0);\\n \\xa0     const FEValuesExtractors::Scalar scalar(dim);\\n \\xa0 \\n \\xa0     scratch.ll_matrix = 0;\\n \\xa0     scratch.l_rhs     = 0;\\n \\xa0     if (!task_data.trace_reconstruct)\\n \\xa0       {\\n \\xa0         scratch.lf_matrix     = 0;\\n \\xa0         scratch.fl_matrix     = 0;\\n \\xa0         task_data.cell_matrix = 0;\\n \\xa0         task_data.cell_vector = 0;\\n \\xa0       }\\n \\xa0     scratch.fe_values_local.reinit(loc_cell);\\n```\\n\\nWe first compute the cell-interior contribution to `ll_matrix` matrix (referred to as matrix \\\\(A\\\\) in the introduction) corresponding to local-local coupling, as well as the local right-hand-side vector. We store the values at each quadrature point for the basis functions, the right-hand-side value, and the convection velocity, in order to have quick access to these fields.\\n\\n```\\n \\xa0     for (unsigned int q = 0; q < n_q_points; ++q)\\n \\xa0       {\\n \\xa0         const double rhs_value = scratch.right_hand_side.value(\\n \\xa0           scratch.fe_values_local.quadrature_point(q));\\n \\xa0         const Tensor<1, dim> convection = scratch.convection_velocity.value(\\n \\xa0           scratch.fe_values_local.quadrature_point(q));\\n \\xa0         const double JxW = scratch.fe_values_local.JxW(q);\\n \\xa0         for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\\n \\xa0           {\\n \\xa0             scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\\n \\xa0             scratch.q_phi_div[k] =\\n \\xa0               scratch.fe_values_local[fluxes].divergence(k, q);\\n \\xa0             scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\\n \\xa0             scratch.u_phi_grad[k] =\\n \\xa0               scratch.fe_values_local[scalar].gradient(k, q);\\n \\xa0           }\\n \\xa0         for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\\n \\xa0           {\\n \\xa0             for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\\n \\xa0               scratch.ll_matrix(i, j) +=\\n \\xa0                 (scratch.q_phi[i] * scratch.q_phi[j] -\\n \\xa0                  scratch.q_phi_div[i] * scratch.u_phi[j] +\\n \\xa0                  scratch.u_phi[i] * scratch.q_phi_div[j] -\\n \\xa0                  (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\\n \\xa0                 JxW;\\n \\xa0             scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\\n \\xa0           }\\n \\xa0       }\\n```\\n\\nFace terms are assembled on all faces of all elements. This is in contrast to more traditional DG methods, where each face is only visited once in the assembly procedure.\\n\\n```\\n \\xa0     for (const auto face_no : cell->face_indices())\\n \\xa0       {\\n \\xa0         scratch.fe_face_values_local.reinit(loc_cell, face_no);\\n \\xa0         scratch.fe_face_values.reinit(cell, face_no);\\n```\\n\\nThe already obtained \\\\(\\\\hat{u}\\\\) values are needed when solving for the local variables.\\n\\n```\\n \\xa0         if (task_data.trace_reconstruct)\\n \\xa0           scratch.fe_face_values.get_function_values(solution,\\n \\xa0                                                      scratch.trace_values);\\n \\xa0 \\n \\xa0         for (unsigned int q = 0; q < n_face_q_points; ++q)\\n \\xa0           {\\n \\xa0             const double     JxW = scratch.fe_face_values.JxW(q);\\n \\xa0             const Point<dim> quadrature_point =\\n \\xa0               scratch.fe_face_values.quadrature_point(q);\\n \\xa0             const Tensor<1, dim> normal =\\n \\xa0               scratch.fe_face_values.normal_vector(q);\\n \\xa0             const Tensor<1, dim> convection =\\n \\xa0               scratch.convection_velocity.value(quadrature_point);\\n```\\n\\nHere we compute the stabilization parameter discussed in the introduction: since the diffusion is one and the diffusion length scale is set to 1/5, it simply results in a contribution of 5 for the diffusion part and the magnitude of convection through the element boundary in a centered scheme for the convection part.\\n\\n```\\n \\xa0             const double tau_stab = (5. + std::abs(convection * normal));\\n```\\n\\nWe store the non-zero flux and scalar values, making use of the support\\\\_on\\\\_face information we created in `ScratchData`.\\n\\n```\\n \\xa0             for (unsigned int k = 0;\\n \\xa0                  k < scratch.fe_local_support_on_face[face_no].size();\\n \\xa0                  ++k)\\n \\xa0               {\\n \\xa0                 const unsigned int kk =\\n \\xa0                   scratch.fe_local_support_on_face[face_no][k];\\n \\xa0                 scratch.q_phi[k] =\\n \\xa0                   scratch.fe_face_values_local[fluxes].value(kk, q);\\n \\xa0                 scratch.u_phi[k] =\\n \\xa0                   scratch.fe_face_values_local[scalar].value(kk, q);\\n \\xa0               }\\n```\\n\\nWhen `trace_reconstruct=false`, we are preparing to assemble the system for the skeleton variable \\\\(\\\\hat{u}\\\\). If this is the case, we must assemble all local matrices associated with the problem: local-local, local-face, face-local, and face-face. The face-face matrix is stored as `TaskData::cell_matrix`, so that it can be assembled into the global system by `copy_local_to_global`.\\n\\n```\\n \\xa0             if (!task_data.trace_reconstruct)\\n \\xa0               {\\n \\xa0                 for (unsigned int k = 0;\\n \\xa0                      k < scratch.fe_support_on_face[face_no].size();\\n \\xa0                      ++k)\\n \\xa0                   scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\\n \\xa0                     scratch.fe_support_on_face[face_no][k], q);\\n \\xa0                 for (unsigned int i = 0;\\n \\xa0                      i < scratch.fe_local_support_on_face[face_no].size();\\n \\xa0                      ++i)\\n \\xa0                   for (unsigned int j = 0;\\n \\xa0                        j < scratch.fe_support_on_face[face_no].size();\\n \\xa0                        ++j)\\n \\xa0                     {\\n \\xa0                       const unsigned int ii =\\n \\xa0                         scratch.fe_local_support_on_face[face_no][i];\\n \\xa0                       const unsigned int jj =\\n \\xa0                         scratch.fe_support_on_face[face_no][j];\\n \\xa0                       scratch.lf_matrix(ii, jj) +=\\n \\xa0                         ((scratch.q_phi[i] * normal +\\n \\xa0                           (convection * normal - tau_stab) * scratch.u_phi[i]) *\\n \\xa0                          scratch.tr_phi[j]) *\\n \\xa0                         JxW;\\n```\\n\\nNote the sign of the face\\\\_no-local matrix. We negate the sign during assembly here so that we can use the [FullMatrix::mmult](classFullMatrix.html#a21b873fcd180999ad0d268c3278a71ec) with addition when computing the Schur complement.\\n\\n```\\n \\xa0                       scratch.fl_matrix(jj, ii) -=\\n \\xa0                         ((scratch.q_phi[i] * normal +\\n \\xa0                           tau_stab * scratch.u_phi[i]) *\\n \\xa0                          scratch.tr_phi[j]) *\\n \\xa0                         JxW;\\n \\xa0                     }\\n \\xa0 \\n \\xa0                 for (unsigned int i = 0;\\n \\xa0                      i < scratch.fe_support_on_face[face_no].size();\\n \\xa0                      ++i)\\n \\xa0                   for (unsigned int j = 0;\\n \\xa0                        j < scratch.fe_support_on_face[face_no].size();\\n \\xa0                        ++j)\\n \\xa0                     {\\n \\xa0                       const unsigned int ii =\\n \\xa0                         scratch.fe_support_on_face[face_no][i];\\n \\xa0                       const unsigned int jj =\\n \\xa0                         scratch.fe_support_on_face[face_no][j];\\n \\xa0                       task_data.cell_matrix(ii, jj) +=\\n \\xa0                         ((convection * normal - tau_stab) * scratch.tr_phi[i] *\\n \\xa0                          scratch.tr_phi[j]) *\\n \\xa0                         JxW;\\n \\xa0                     }\\n \\xa0 \\n \\xa0                 if (cell->face(face_no)->at_boundary() &&\\n \\xa0                     (cell->face(face_no)->boundary_id() == 1))\\n \\xa0                   {\\n \\xa0                     const double neumann_value =\\n \\xa0                       -scratch.exact_solution.gradient(quadrature_point) *\\n \\xa0                         normal +\\n \\xa0                       convection * normal *\\n \\xa0                         scratch.exact_solution.value(quadrature_point);\\n \\xa0                     for (unsigned int i = 0;\\n \\xa0                          i < scratch.fe_support_on_face[face_no].size();\\n \\xa0                          ++i)\\n \\xa0                       {\\n \\xa0                         const unsigned int ii =\\n \\xa0                           scratch.fe_support_on_face[face_no][i];\\n \\xa0                         task_data.cell_vector(ii) +=\\n \\xa0                           scratch.tr_phi[i] * neumann_value * JxW;\\n \\xa0                       }\\n \\xa0                   }\\n \\xa0               }\\n```\\n\\nThis last term adds the contribution of the term \\\\(\\\\left<w,\\\\tau\\nu\\\\_h\\\\right>\\\\_{\\\\partial \\\\mathcal T}\\\\) to the local matrix. As opposed to the face matrices above, we need it in both assembly stages.\\n\\n```\\n \\xa0             for (unsigned int i = 0;\\n \\xa0                  i < scratch.fe_local_support_on_face[face_no].size();\\n \\xa0                  ++i)\\n \\xa0               for (unsigned int j = 0;\\n \\xa0                    j < scratch.fe_local_support_on_face[face_no].size();\\n \\xa0                    ++j)\\n \\xa0                 {\\n \\xa0                   const unsigned int ii =\\n \\xa0                     scratch.fe_local_support_on_face[face_no][i];\\n \\xa0                   const unsigned int jj =\\n \\xa0                     scratch.fe_local_support_on_face[face_no][j];\\n \\xa0                   scratch.ll_matrix(ii, jj) +=\\n \\xa0                     tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\\n \\xa0                 }\\n```\\n\\nWhen `trace_reconstruct=true`, we are solving for the local solutions on an element by element basis. The local right-hand-side is calculated by replacing the basis functions `tr_phi` in the `lf_matrix` computation by the computed values `trace_values`. Of course, the sign of the matrix is now minus since we have moved everything to the other side of the equation.\\n\\n```\\n \\xa0             if (task_data.trace_reconstruct)\\n \\xa0               for (unsigned int i = 0;\\n \\xa0                    i < scratch.fe_local_support_on_face[face_no].size();\\n \\xa0                    ++i)\\n \\xa0                 {\\n \\xa0                   const unsigned int ii =\\n \\xa0                     scratch.fe_local_support_on_face[face_no][i];\\n \\xa0                   scratch.l_rhs(ii) -=\\n \\xa0                     (scratch.q_phi[i] * normal +\\n \\xa0                      scratch.u_phi[i] * (convection * normal - tau_stab)) *\\n \\xa0                     scratch.trace_values[q] * JxW;\\n \\xa0                 }\\n \\xa0           }\\n \\xa0       }\\n```\\n\\nOnce assembly of all of the local contributions is complete, we must either: (1) assemble the global system, or (2) compute the local solution values and save them. In either case, the first step is to invert the local-local matrix.\\n\\n```\\n \\xa0     scratch.ll_matrix.gauss_jordan();\\n```\\n\\nFor (1), we compute the Schur complement and add it to the `cell_matrix`, matrix \\\\(D\\\\) in the introduction.\\n\\n```\\n \\xa0     if (task_data.trace_reconstruct == false)\\n \\xa0       {\\n \\xa0         scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\\n \\xa0         scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\\n \\xa0         scratch.tmp_matrix.mmult(task_data.cell_matrix,\\n \\xa0                                  scratch.lf_matrix,\\n \\xa0                                  true);\\n \\xa0         cell->get_dof_indices(task_data.dof_indices);\\n \\xa0       }\\n```\\n\\nFor (2), we are simply solving (ll\\\\_matrix).(solution\\\\_local) = (l\\\\_rhs). Hence, we multiply `l_rhs` by our already inverted local-local matrix and store the result using the `set_dof_values` function.\\n\\n```\\n \\xa0     else\\n \\xa0       {\\n \\xa0         scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\\n \\xa0         loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\\n \\xa0       }\\n \\xa0   }\\n```\\n\\n#### HDG::copy\\\\_local\\\\_to\\\\_global\\n\\nIf we are in the first step of the solution, i.e. `trace_reconstruct=false`, then we assemble the local matrices into the global system.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::copy_local_to_global(const PerTaskData &data)\\n \\xa0   {\\n \\xa0     if (data.trace_reconstruct == false)\\n \\xa0       constraints.distribute_local_to_global(data.cell_matrix,\\n \\xa0                                              data.cell_vector,\\n \\xa0                                              data.dof_indices,\\n \\xa0                                              system_matrix,\\n \\xa0                                              system_rhs);\\n \\xa0   }\\n```\\n\\n#### HDG::solve\\n\\nThe skeleton solution is solved for by using a BiCGStab solver with identity preconditioner.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::solve()\\n \\xa0   {\\n \\xa0     SolverControl                  solver_control(system_matrix.m() * 10,\\n \\xa0                                  1e-11 * system_rhs.l2_norm());\\n \\xa0     SolverBicgstab<Vector<double>> solver(solver_control);\\n \\xa0     solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n \\xa0 \\n \\xa0     std::cout << \"   Number of BiCGStab iterations: \"\\n \\xa0               << solver_control.last_step() << std::endl;\\n \\xa0 \\n \\xa0     system_matrix.clear();\\n \\xa0     sparsity_pattern.reinit(0, 0, 0, 1);\\n \\xa0 \\n \\xa0     constraints.distribute(solution);\\n```\\n\\nOnce we have solved for the skeleton solution, we can solve for the local solutions in an element-by-element fashion. We do this by re-using the same `assemble_system` function but switching `trace_reconstruct` to true.\\n\\n```\\n \\xa0     assemble_system(true);\\n \\xa0   }\\n```\\n\\n#### HDG::postprocess\\n\\nThe postprocess method serves two purposes. First, we want to construct a post-processed scalar variables in the element space of degree \\\\(p+1\\\\) that we hope will converge at order \\\\(p+2\\\\). This is again an element-by-element process and only involves the scalar solution as well as the gradient on the local cell. To do this, we introduce the already defined scratch data together with some update flags and run the work stream to do this in parallel.\\n\\nSecondly, we want to compute discretization errors just as we did in [step-7](step_7.html). The overall procedure is similar with calls to [VectorTools::integrate\\\\_difference](namespaceVectorTools.html#a6cac27efbc9169a5119497cf08463d3b). The difference is in how we compute the errors for the scalar variable and the gradient variable. In [step-7](step_7.html), we did this by computing `L2_norm` or `H1_seminorm` contributions. Here, we have a [DoFHandler](classDoFHandler.html) with these two contributions computed and sorted by their vector component, `[0, dim)` for the gradient and `dim` for the scalar. To compute their value, we hence use a [ComponentSelectFunction](classComponentSelectFunction.html) with either of them, together with the `SolutionAndGradient` class introduced above that contains the analytic parts of either of them. Eventually, we also compute the L2-error of the post-processed solution and add the results into the convergence table.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::postprocess()\\n \\xa0   {\\n \\xa0     {\\n \\xa0       const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\\n \\xa0       const UpdateFlags local_flags(update_values);\\n \\xa0       const UpdateFlags flags(update_values | update_gradients |\\n \\xa0                               update_JxW_values);\\n \\xa0 \\n \\xa0       PostProcessScratchData scratch(\\n \\xa0         fe_u_post, fe_local, quadrature_formula, local_flags, flags);\\n \\xa0 \\n \\xa0       WorkStream::run(\\n \\xa0         dof_handler_u_post.begin_active(),\\n \\xa0         dof_handler_u_post.end(),\\n \\xa0         [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\\n \\xa0                PostProcessScratchData                               &scratch,\\n \\xa0                unsigned int                                         &data) {\\n \\xa0           this->postprocess_one_cell(cell, scratch, data);\\n \\xa0         },\\n \\xa0         std::function<void(const unsigned int &)>(),\\n \\xa0         scratch,\\n \\xa0         0U);\\n \\xa0     }\\n \\xa0 \\n \\xa0     Vector<float> difference_per_cell(triangulation.n_active_cells());\\n \\xa0 \\n \\xa0     ComponentSelectFunction<dim> value_select(dim, dim + 1);\\n \\xa0     VectorTools::integrate_difference(dof_handler_local,\\n \\xa0                                       solution_local,\\n \\xa0                                       SolutionAndGradient<dim>(),\\n \\xa0                                       difference_per_cell,\\n \\xa0                                       QGauss<dim>(fe.degree + 2),\\n \\xa0                                       VectorTools::L2_norm,\\n \\xa0                                       &value_select);\\n \\xa0     const double L2_error =\\n \\xa0       VectorTools::compute_global_error(triangulation,\\n \\xa0                                         difference_per_cell,\\n \\xa0                                         VectorTools::L2_norm);\\n \\xa0 \\n \\xa0     ComponentSelectFunction<dim> gradient_select(\\n \\xa0       std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\\n \\xa0     VectorTools::integrate_difference(dof_handler_local,\\n \\xa0                                       solution_local,\\n \\xa0                                       SolutionAndGradient<dim>(),\\n \\xa0                                       difference_per_cell,\\n \\xa0                                       QGauss<dim>(fe.degree + 2),\\n \\xa0                                       VectorTools::L2_norm,\\n \\xa0                                       &gradient_select);\\n \\xa0     const double grad_error =\\n \\xa0       VectorTools::compute_global_error(triangulation,\\n \\xa0                                         difference_per_cell,\\n \\xa0                                         VectorTools::L2_norm);\\n \\xa0 \\n \\xa0     VectorTools::integrate_difference(dof_handler_u_post,\\n \\xa0                                       solution_u_post,\\n \\xa0                                       Solution<dim>(),\\n \\xa0                                       difference_per_cell,\\n \\xa0                                       QGauss<dim>(fe.degree + 3),\\n \\xa0                                       VectorTools::L2_norm);\\n \\xa0     const double post_error =\\n \\xa0       VectorTools::compute_global_error(triangulation,\\n \\xa0                                         difference_per_cell,\\n \\xa0                                         VectorTools::L2_norm);\\n \\xa0 \\n \\xa0     convergence_table.add_value(\"cells\", triangulation.n_active_cells());\\n \\xa0     convergence_table.add_value(\"dofs\", dof_handler.n_dofs());\\n \\xa0 \\n \\xa0     convergence_table.add_value(\"val L2\", L2_error);\\n \\xa0     convergence_table.set_scientific(\"val L2\", true);\\n \\xa0     convergence_table.set_precision(\"val L2\", 3);\\n \\xa0 \\n \\xa0     convergence_table.add_value(\"grad L2\", grad_error);\\n \\xa0     convergence_table.set_scientific(\"grad L2\", true);\\n \\xa0     convergence_table.set_precision(\"grad L2\", 3);\\n \\xa0 \\n \\xa0     convergence_table.add_value(\"val L2-post\", post_error);\\n \\xa0     convergence_table.set_scientific(\"val L2-post\", true);\\n \\xa0     convergence_table.set_precision(\"val L2-post\", 3);\\n \\xa0   }\\n```\\n\\n#### HDG::postprocess\\\\_one\\\\_cell\\n\\nThis is the actual work done for the postprocessing. According to the discussion in the introduction, we need to set up a system that projects the gradient part of the DG solution onto the gradient of the post-processed variable. Moreover, we need to set the average of the new post-processed variable to equal the average of the scalar DG solution on the cell.\\n\\nMore technically speaking, the projection of the gradient is a system that would potentially fills our `dofs_per_cell` times `dofs_per_cell` matrix but is singular (the sum of all rows would be zero because the constant function has zero gradient). Therefore, we take one row away and use it for imposing the average of the scalar value. We pick the first row for the scalar part, even though we could pick any row for \\\\(\\\\mathcal\\nQ\\\\_{-p}\\\\) elements. However, had we used [FE\\\\_DGP](classFE__DGP.html) elements instead, the first row would correspond to the constant part already and deleting e.g. the last row would give us a singular system. This way, our program can also be used for those elements.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::postprocess_one_cell(\\n \\xa0     const typename DoFHandler<dim>::active_cell_iterator &cell,\\n \\xa0     PostProcessScratchData                               &scratch,\\n \\xa0     unsigned int &)\\n \\xa0   {\\n \\xa0     const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n \\xa0       cell->as_dof_handler_iterator(dof_handler_local);\\n \\xa0 \\n \\xa0     scratch.fe_values_local.reinit(loc_cell);\\n \\xa0     scratch.fe_values.reinit(cell);\\n \\xa0 \\n \\xa0     const FEValuesExtractors::Vector fluxes(0);\\n \\xa0     const FEValuesExtractors::Scalar scalar(dim);\\n \\xa0 \\n \\xa0     const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\\n \\xa0     const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\\n \\xa0 \\n \\xa0     scratch.fe_values_local[scalar].get_function_values(solution_local,\\n \\xa0                                                         scratch.u_values);\\n \\xa0     scratch.fe_values_local[fluxes].get_function_values(solution_local,\\n \\xa0                                                         scratch.u_gradients);\\n \\xa0 \\n \\xa0     double sum = 0;\\n \\xa0     for (unsigned int i = 1; i < dofs_per_cell; ++i)\\n \\xa0       {\\n \\xa0         for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n \\xa0           {\\n \\xa0             sum = 0;\\n \\xa0             for (unsigned int q = 0; q < n_q_points; ++q)\\n \\xa0               sum += (scratch.fe_values.shape_grad(i, q) *\\n \\xa0                       scratch.fe_values.shape_grad(j, q)) *\\n \\xa0                      scratch.fe_values.JxW(q);\\n \\xa0             scratch.cell_matrix(i, j) = sum;\\n \\xa0           }\\n \\xa0 \\n \\xa0         sum = 0;\\n \\xa0         for (unsigned int q = 0; q < n_q_points; ++q)\\n \\xa0           sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\\n \\xa0                  scratch.fe_values.JxW(q);\\n \\xa0         scratch.cell_rhs(i) = sum;\\n \\xa0       }\\n \\xa0     for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n \\xa0       {\\n \\xa0         sum = 0;\\n \\xa0         for (unsigned int q = 0; q < n_q_points; ++q)\\n \\xa0           sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\\n \\xa0         scratch.cell_matrix(0, j) = sum;\\n \\xa0       }\\n \\xa0     {\\n \\xa0       sum = 0;\\n \\xa0       for (unsigned int q = 0; q < n_q_points; ++q)\\n \\xa0         sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\\n \\xa0       scratch.cell_rhs(0) = sum;\\n \\xa0     }\\n```\\n\\nHaving assembled all terms, we can again go on and solve the linear system. We invert the matrix and then multiply the inverse by the right hand side. An alternative (and more numerically stable) method would have been to only factorize the matrix and apply the factorization.\\n\\n```\\n \\xa0     scratch.cell_matrix.gauss_jordan();\\n \\xa0     scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\\n \\xa0     cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\\n \\xa0   }\\n```\\n\\n#### HDG::output\\\\_results\\n\\nWe have 3 sets of results that we would like to output: the local solution, the post-processed local solution, and the skeleton solution. The former 2 both \\'live\\' on element volumes, whereas the latter lives on codimension-1 surfaces of the triangulation. Our `output_results` function writes all local solutions to the same vtk file, even though they correspond to different [DoFHandler](classDoFHandler.html) objects. The graphical output for the skeleton variable is done through use of the [DataOutFaces](classDataOutFaces.html) class.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::output_results(const unsigned int cycle)\\n \\xa0   {\\n \\xa0     std::string filename;\\n \\xa0     switch (refinement_mode)\\n \\xa0       {\\n \\xa0         case global_refinement:\\n \\xa0           filename = \"solution-global\";\\n \\xa0           break;\\n \\xa0         case adaptive_refinement:\\n \\xa0           filename = \"solution-adaptive\";\\n \\xa0           break;\\n \\xa0         default:\\n \\xa0           DEAL_II_NOT_IMPLEMENTED();\\n \\xa0       }\\n \\xa0 \\n \\xa0     std::string face_out(filename);\\n \\xa0     face_out += \"-face\";\\n \\xa0 \\n \\xa0     filename += \"-q\" + Utilities::int_to_string(fe.degree, 1);\\n \\xa0     filename += \"-\" + Utilities::int_to_string(cycle, 2);\\n \\xa0     filename += \".vtk\";\\n \\xa0     std::ofstream output(filename);\\n \\xa0 \\n \\xa0     DataOut<dim> data_out;\\n```\\n\\nWe first define the names and types of the local solution, and add the data to `data_out`.\\n\\n```\\n \\xa0     std::vector<std::string> names(dim, \"gradient\");\\n \\xa0     names.emplace_back(\"solution\");\\n \\xa0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n \\xa0       component_interpretation(\\n \\xa0         dim + 1, DataComponentInterpretation::component_is_part_of_vector);\\n \\xa0     component_interpretation[dim] =\\n \\xa0       DataComponentInterpretation::component_is_scalar;\\n \\xa0     data_out.add_data_vector(dof_handler_local,\\n \\xa0                              solution_local,\\n \\xa0                              names,\\n \\xa0                              component_interpretation);\\n```\\n\\nThe second data item we add is the post-processed solution. In this case, it is a single scalar variable belonging to a different [DoFHandler](classDoFHandler.html).\\n\\n```\\n \\xa0     std::vector<std::string> post_name(1, \"u_post\");\\n \\xa0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n \\xa0       post_comp_type(1, DataComponentInterpretation::component_is_scalar);\\n \\xa0     data_out.add_data_vector(dof_handler_u_post,\\n \\xa0                              solution_u_post,\\n \\xa0                              post_name,\\n \\xa0                              post_comp_type);\\n \\xa0 \\n \\xa0     data_out.build_patches(fe.degree);\\n \\xa0     data_out.write_vtk(output);\\n \\xa0 \\n \\xa0     face_out += \"-q\" + Utilities::int_to_string(fe.degree, 1);\\n \\xa0     face_out += \"-\" + Utilities::int_to_string(cycle, 2);\\n \\xa0     face_out += \".vtk\";\\n \\xa0     std::ofstream face_output(face_out);\\n```\\n\\nThe `DataOutFaces` class works analogously to the `DataOut` class when we have a `DoFHandler` that defines the solution on the skeleton of the triangulation. We treat it as such here, and the code is similar to that above.\\n\\n```\\n \\xa0     DataOutFaces<dim>        data_out_face(false);\\n \\xa0     std::vector<std::string> face_name(1, \"u_hat\");\\n \\xa0     std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n \\xa0       face_component_type(1, DataComponentInterpretation::component_is_scalar);\\n \\xa0 \\n \\xa0     data_out_face.add_data_vector(dof_handler,\\n \\xa0                                   solution,\\n \\xa0                                   face_name,\\n \\xa0                                   face_component_type);\\n \\xa0 \\n \\xa0     data_out_face.build_patches(fe.degree);\\n \\xa0     data_out_face.write_vtk(face_output);\\n \\xa0   }\\n```\\n\\n#### HDG::refine\\\\_grid\\n\\nWe implement two different refinement cases for HDG, just as in `step-7`: adaptive\\\\_refinement and global\\\\_refinement. The global\\\\_refinement option recreates the entire triangulation every time. This is because we want to use a finer sequence of meshes than what we would get with one refinement step, namely 2, 3, 4, 6, 8, 12, 16, ... elements per direction.\\n\\nThe adaptive\\\\_refinement mode uses the `KellyErrorEstimator` to give a decent indication of the non-regular regions in the scalar local solutions.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::refine_grid(const unsigned int cycle)\\n \\xa0   {\\n \\xa0     if (cycle == 0)\\n \\xa0       {\\n \\xa0         GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\\n \\xa0         triangulation.refine_global(3 - dim);\\n \\xa0       }\\n \\xa0     else\\n \\xa0       switch (refinement_mode)\\n \\xa0         {\\n \\xa0           case global_refinement:\\n \\xa0             {\\n \\xa0               triangulation.clear();\\n \\xa0               GridGenerator::subdivided_hyper_cube(triangulation,\\n \\xa0                                                    2 + (cycle % 2),\\n \\xa0                                                    -1,\\n \\xa0                                                    1);\\n \\xa0               triangulation.refine_global(3 - dim + cycle / 2);\\n \\xa0               break;\\n \\xa0             }\\n \\xa0 \\n \\xa0           case adaptive_refinement:\\n \\xa0             {\\n \\xa0               Vector<float> estimated_error_per_cell(\\n \\xa0                 triangulation.n_active_cells());\\n \\xa0 \\n \\xa0               const FEValuesExtractors::Scalar scalar(dim);\\n \\xa0               std::map<types::boundary_id, const Function<dim> *>\\n \\xa0                 neumann_boundary;\\n \\xa0               KellyErrorEstimator<dim>::estimate(dof_handler_local,\\n \\xa0                                                  QGauss<dim - 1>(fe.degree + 1),\\n \\xa0                                                  neumann_boundary,\\n \\xa0                                                  solution_local,\\n \\xa0                                                  estimated_error_per_cell,\\n \\xa0                                                  fe_local.component_mask(\\n \\xa0                                                    scalar));\\n \\xa0 \\n \\xa0               GridRefinement::refine_and_coarsen_fixed_number(\\n \\xa0                 triangulation, estimated_error_per_cell, 0.3, 0.);\\n \\xa0 \\n \\xa0               triangulation.execute_coarsening_and_refinement();\\n \\xa0 \\n \\xa0               break;\\n \\xa0             }\\n \\xa0 \\n \\xa0           default:\\n \\xa0             {\\n \\xa0               DEAL_II_NOT_IMPLEMENTED();\\n \\xa0             }\\n \\xa0         }\\n```\\n\\nJust as in [step-7](step_7.html), we set the boundary indicator of two of the faces to 1 where we want to specify Neumann boundary conditions instead of Dirichlet conditions. Since we re-create the triangulation every time for global refinement, the flags are set in every refinement step, not just at the beginning.\\n\\n```\\n \\xa0     for (const auto &cell : triangulation.cell_iterators())\\n \\xa0       for (const auto &face : cell->face_iterators())\\n \\xa0         if (face->at_boundary())\\n \\xa0           if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\\n \\xa0               (std::fabs(face->center()[1] - (-1)) < 1e-12))\\n \\xa0             face->set_boundary_id(1);\\n \\xa0   }\\n```\\n\\n#### HDG::run\\n\\nThe functionality here is basically the same as `step-7`. We loop over 10 cycles, refining the grid on each one. At the end, convergence tables are created.\\n\\n```\\n \\xa0   template <int dim>\\n \\xa0   void HDG<dim>::run()\\n \\xa0   {\\n \\xa0     for (unsigned int cycle = 0; cycle < 10; ++cycle)\\n \\xa0       {\\n \\xa0         std::cout << \"Cycle \" << cycle << \\':\\' << std::endl;\\n \\xa0 \\n \\xa0         refine_grid(cycle);\\n \\xa0         setup_system();\\n \\xa0         assemble_system(false);\\n \\xa0         solve();\\n \\xa0         postprocess();\\n \\xa0         output_results(cycle);\\n \\xa0       }\\n```\\n\\nThere is one minor change for the convergence table compared to [step-7](step_7.html): Since we did not refine our mesh by a factor two in each cycle (but rather used the sequence 2, 3, 4, 6, 8, 12, ...), we need to tell the convergence rate evaluation about this. We do this by setting the number of cells as a reference column and additionally specifying the dimension of the problem, which gives the necessary information for the relation between number of cells and mesh size.\\n\\n```\\n \\xa0     if (refinement_mode == global_refinement)\\n \\xa0       {\\n \\xa0         convergence_table.evaluate_convergence_rates(\\n \\xa0           \"val L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n \\xa0         convergence_table.evaluate_convergence_rates(\\n \\xa0           \"grad L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n \\xa0         convergence_table.evaluate_convergence_rates(\\n \\xa0           \"val L2-post\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n \\xa0       }\\n \\xa0     convergence_table.write_text(std::cout);\\n \\xa0   }\\n \\xa0 \\n \\xa0 } // end of namespace Step51\\n \\xa0 \\n \\xa0 \\n \\xa0 \\n \\xa0 int main()\\n \\xa0 {\\n \\xa0   const unsigned int dim = 2;\\n \\xa0 \\n \\xa0   try\\n \\xa0     {\\n```\\n\\nNow for the three calls to the main class in complete analogy to [step-7](step_7.html).\\n\\n```\\n \\xa0       {\\n \\xa0         std::cout << \"Solving with Q1 elements, adaptive refinement\"\\n \\xa0                   << std::endl\\n \\xa0                   << \"=============================================\"\\n \\xa0                   << std::endl\\n \\xa0                   << std::endl;\\n \\xa0 \\n \\xa0         Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\\n \\xa0         hdg_problem.run();\\n \\xa0 \\n \\xa0         std::cout << std::endl;\\n \\xa0       }\\n \\xa0 \\n \\xa0       {\\n \\xa0         std::cout << \"Solving with Q1 elements, global refinement\" << std::endl\\n \\xa0                   << \"===========================================\" << std::endl\\n \\xa0                   << std::endl;\\n \\xa0 \\n \\xa0         Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\\n \\xa0         hdg_problem.run();\\n \\xa0 \\n \\xa0         std::cout << std::endl;\\n \\xa0       }\\n \\xa0 \\n \\xa0       {\\n \\xa0         std::cout << \"Solving with Q3 elements, global refinement\" << std::endl\\n \\xa0                   << \"===========================================\" << std::endl\\n \\xa0                   << std::endl;\\n \\xa0 \\n \\xa0         Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\\n \\xa0         hdg_problem.run();\\n \\xa0 \\n \\xa0         std::cout << std::endl;\\n \\xa0       }\\n \\xa0     }\\n \\xa0   catch (std::exception &exc)\\n \\xa0     {\\n \\xa0       std::cerr << std::endl\\n \\xa0                 << std::endl\\n \\xa0                 << \"----------------------------------------------------\"\\n \\xa0                 << std::endl;\\n \\xa0       std::cerr << \"Exception on processing: \" << std::endl\\n \\xa0                 << exc.what() << std::endl\\n \\xa0                 << \"Aborting!\" << std::endl\\n \\xa0                 << \"----------------------------------------------------\"\\n \\xa0                 << std::endl;\\n \\xa0       return 1;\\n \\xa0     }\\n \\xa0   catch (...)\\n \\xa0     {\\n \\xa0       std::cerr << std::endl\\n \\xa0                 << std::endl\\n \\xa0                 << \"----------------------------------------------------\"\\n \\xa0                 << std::endl;\\n \\xa0       std::cerr << \"Unknown exception!\" << std::endl\\n \\xa0                 << \"Aborting!\" << std::endl\\n \\xa0                 << \"----------------------------------------------------\"\\n \\xa0                 << std::endl;\\n \\xa0       return 1;\\n \\xa0     }\\n \\xa0 \\n \\xa0   return 0;\\n \\xa0 }\\n```\\n\\nResults\\n=======\\n\\n### Program output\\n\\nWe first have a look at the output generated by the program when run in 2D. In the four images below, we show the solution for polynomial degree \\\\(p=1\\\\) and cycles 2, 3, 4, and 8 of the program. In the plots, we overlay the data generated from the internal data (DG part) with the skeleton part ( \\\\(\\\\hat{u}\\\\)) into the same plot. We had to generate two different data sets because cells and faces represent different geometric entities, the combination of which (in the same file) is not supported in the VTK output of deal.II.\\n\\nThe images show the distinctive features of HDG: The cell solution (colored surfaces) is discontinuous between the cells. The solution on the skeleton variable sits on the faces and ties together the local parts. The skeleton solution is not continuous on the vertices where the faces meet, even though its values are quite close along lines in the same coordinate direction. The skeleton solution can be interpreted as a rubber spring between the two sides that balances the jumps in the solution (or rather, the flux \\\\(\\\\kappa \\\\nabla u\\n+ \\\\mathbf{c} u\\\\)). From the picture at the top left, it is clear that the bulk solution frequently over- and undershoots and that the skeleton variable in indeed a better approximation to the exact solution; this explains why we can get a better solution using a postprocessing step.\\n\\nAs the mesh is refined, the jumps between the cells get small (we represent a smooth solution), and the skeleton solution approaches the interior parts. For cycle 8, there is no visible difference in the two variables. We also see how boundary conditions are implemented weakly and that the interior variables do not exactly satisfy boundary conditions. On the lower and left boundaries, we set Neumann boundary conditions, whereas we set Dirichlet conditions on the right and top boundaries.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n|  |  |\\n\\nNext, we have a look at the post-processed solution, again at cycles 2, 3, 4, and 8. This is a discontinuous solution that is locally described by second order polynomials. While the solution does not look very good on the mesh of cycle two, it looks much better for cycles three and four. As shown by the convergence table below, we find that is also converges more quickly to the analytical solution.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n|  |  |\\n\\nFinally, we look at the solution for \\\\(p=3\\\\) at cycle 2. Despite the coarse mesh with only 64 cells, the post-processed solution is similar in quality to the linear solution (not post-processed) at cycle 8 with 4,096 cells. This clearly shows the superiority of high order methods for smooth solutions.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\n#### Convergence tables\\n\\nWhen the program is run, it also outputs information about the respective steps and convergence tables with errors in the various components in the end. In 2D, the convergence tables look the following:\\n\\n```\\nQ1 elements, adaptive refinement:\\ncells dofs   val L2    grad L2  val L2-post\\n   16    80 1.804e+01 2.207e+01   1.798e+01\\n   31   170 9.874e+00 1.322e+01   9.798e+00\\n   61   314 7.452e-01 3.793e+00   4.891e-01\\n  121   634 3.240e-01 1.511e+00   2.616e-01\\n  238  1198 8.585e-02 8.212e-01   1.808e-02\\n  454  2290 4.802e-02 5.178e-01   2.195e-02\\n  898  4378 2.561e-02 2.947e-01   4.318e-03\\n 1720  7864 1.306e-02 1.664e-01   2.978e-03\\n 3271 14638 7.025e-03 9.815e-02   1.075e-03\\n 6217 27214 4.119e-03 6.407e-02   9.975e-04\\n \\nQ1 elements, global refinement:\\ncells dofs      val L2        grad L2      val L2-post\\n   16    80 1.804e+01    - 2.207e+01    - 1.798e+01    -\\n   36   168 6.125e+00 2.66 9.472e+00 2.09 6.084e+00 2.67\\n   64   288 9.785e-01 6.38 4.260e+00 2.78 7.102e-01 7.47\\n  144   624 2.730e-01 3.15 1.866e+00 2.04 6.115e-02 6.05\\n  256  1088 1.493e-01 2.10 1.046e+00 2.01 2.880e-02 2.62\\n  576  2400 6.965e-02 1.88 4.846e-01 1.90 9.204e-03 2.81\\n 1024  4224 4.018e-02 1.91 2.784e-01 1.93 4.027e-03 2.87\\n 2304  9408 1.831e-02 1.94 1.264e-01 1.95 1.236e-03 2.91\\n 4096 16640 1.043e-02 1.96 7.185e-02 1.96 5.306e-04 2.94\\n 9216 37248 4.690e-03 1.97 3.228e-02 1.97 1.599e-04 2.96\\n \\nQ3 elements, global refinement:\\ncells dofs      val L2        grad L2      val L2-post\\n   16   160 3.613e-01    - 1.891e+00    - 3.020e-01    -\\n   36   336 6.411e-02 4.26 5.081e-01 3.24 3.238e-02 5.51\\n   64   576 3.480e-02 2.12 2.533e-01 2.42 5.277e-03 6.31\\n  144  1248 8.297e-03 3.54 5.924e-02 3.58 6.330e-04 5.23\\n  256  2176 2.254e-03 4.53 1.636e-02 4.47 1.403e-04 5.24\\n  576  4800 4.558e-04 3.94 3.277e-03 3.96 1.844e-05 5.01\\n 1024  8448 1.471e-04 3.93 1.052e-03 3.95 4.378e-06 5.00\\n 2304 18816 2.956e-05 3.96 2.104e-04 3.97 5.750e-07 5.01\\n 4096 33280 9.428e-06 3.97 6.697e-05 3.98 1.362e-07 5.01\\n 9216 74496 1.876e-06 3.98 1.330e-05 3.99 1.788e-08 5.01\\n```\\n\\nOne can see the error reduction upon grid refinement, and for the cases where global refinement was performed, also the convergence rates. The quadratic convergence rates of Q1 elements in the \\\\(L\\\\_2\\\\) norm for both the scalar variable and the gradient variable is apparent, as is the cubic rate for the postprocessed scalar variable in the \\\\(L\\\\_2\\\\) norm. Note this distinctive feature of an HDG solution. In typical continuous finite elements, the gradient of the solution of order \\\\(p\\\\) converges at rate \\\\(p\\\\) only, as opposed to \\\\(p+1\\\\) for the actual solution. Even though superconvergence results for finite elements are also available (e.g. superconvergent patch recovery first introduced by Zienkiewicz and Zhu), these are typically limited to structured meshes and other special cases. For Q3 HDG variables, the scalar variable and gradient converge at fourth order and the postprocessed scalar variable at fifth order.\\n\\nThe same convergence rates are observed in 3d.\\n\\n```\\nQ1 elements, adaptive refinement:\\ncells   dofs    val L2    grad L2  val L2-post\\n     8     144 7.122e+00 1.941e+01   6.102e+00\\n    29     500 3.309e+00 1.023e+01   2.145e+00\\n   113    1792 2.204e+00 1.023e+01   1.912e+00\\n   379    5732 6.085e-01 5.008e+00   2.233e-01\\n  1317   19412 1.543e-01 1.464e+00   4.196e-02\\n  4579   64768 5.058e-02 5.611e-01   9.521e-03\\n 14596  199552 2.129e-02 3.122e-01   4.569e-03\\n 46180  611400 1.033e-02 1.622e-01   1.684e-03\\n144859 1864212 5.007e-03 8.371e-02   7.364e-04\\n451060 5684508 2.518e-03 4.562e-02   3.070e-04\\n \\nQ1 elements, global refinement:\\ncells   dofs       val L2          grad L2       val L2-post\\n     8     144 7.122e+00    - 1.941e+01     - 6.102e+00    -\\n    27     432 5.491e+00 0.64 2.184e+01 -0.29 4.448e+00 0.78\\n    64     960 3.646e+00 1.42 1.299e+01  1.81 3.306e+00 1.03\\n   216    3024 1.595e+00 2.04 8.550e+00  1.03 1.441e+00 2.05\\n   512    6912 6.922e-01 2.90 5.306e+00  1.66 2.511e-01 6.07\\n  1728   22464 2.915e-01 2.13 2.490e+00  1.87 8.588e-02 2.65\\n  4096   52224 1.684e-01 1.91 1.453e+00  1.87 4.055e-02 2.61\\n 13824  172800 7.972e-02 1.84 6.861e-01  1.85 1.335e-02 2.74\\n 32768  405504 4.637e-02 1.88 3.984e-01  1.89 5.932e-03 2.82\\n110592 1354752 2.133e-02 1.92 1.830e-01  1.92 1.851e-03 2.87\\n \\nQ3 elements, global refinement:\\ncells   dofs       val L2        grad L2      val L2-post\\n     8     576 5.670e+00    - 1.868e+01    - 5.462e+00    -\\n    27    1728 1.048e+00 4.16 6.988e+00 2.42 8.011e-01 4.73\\n    64    3840 2.831e-01 4.55 2.710e+00 3.29 1.363e-01 6.16\\n   216   12096 7.883e-02 3.15 7.721e-01 3.10 2.158e-02 4.55\\n   512   27648 3.642e-02 2.68 3.305e-01 2.95 5.231e-03 4.93\\n  1728   89856 8.546e-03 3.58 7.581e-02 3.63 7.640e-04 4.74\\n  4096  208896 2.598e-03 4.14 2.313e-02 4.13 1.783e-04 5.06\\n 13824  691200 5.314e-04 3.91 4.697e-03 3.93 2.355e-05 4.99\\n 32768 1622016 1.723e-04 3.91 1.517e-03 3.93 5.602e-06 4.99\\n110592 5419008 3.482e-05 3.94 3.055e-04 3.95 7.374e-07 5.00\\n```\\n\\n### Comparison with continuous finite elements\\n\\n#### Results for 2D\\n\\nThe convergence tables verify the expected convergence rates stated in the introduction. Now, we want to show a quick comparison of the computational efficiency of the HDG method compared to a usual finite element (continuous Galkerin) method on the problem of this tutorial. Of course, stability aspects of the HDG method compared to continuous finite elements for transport-dominated problems are also important in practice, which is an aspect not seen on a problem with smooth analytic solution. In the picture below, we compare the \\\\(L\\\\_2\\\\) error as a function of the number of degrees of freedom (left) and of the computing time spent in the linear solver (right) for two space dimensions of continuous finite elements (CG) and the hybridized discontinuous Galerkin method presented in this tutorial. As opposed to the tutorial where we only use unpreconditioned BiCGStab, the times shown in the figures below use the Trilinos algebraic multigrid preconditioner in [TrilinosWrappers::PreconditionAMG](classTrilinosWrappers_1_1PreconditionAMG.html). For the HDG part, a wrapper around [ChunkSparseMatrix](classChunkSparseMatrix.html) for the trace variable has been used in order to utilize the block structure in the matrix on the finest level.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nThe results in the graphs show that the HDG method is slower than continuous finite elements at \\\\(p=1\\\\), about equally fast for cubic elements and faster for sixth order elements. However, we have seen above that the HDG method actually produces solutions which are more accurate than what is represented in the original variables. Therefore, in the next two plots below we instead display the error of the post-processed solution for HDG (denoted by \\\\(p=1^\\\\*\\\\) for example). We now see a clear advantage of HDG for the same amount of work for both \\\\(p=3\\\\) and \\\\(p=6\\\\), and about the same quality for \\\\(p=1\\\\).\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nSince the HDG method actually produces results converging as \\\\(h^{p+2}\\\\), we should compare it to a continuous Galerkin solution with the same asymptotic convergence behavior, i.e., [FE\\\\_Q](classFE__Q.html) with degree \\\\(p+1\\\\). If we do this, we get the convergence curves below. We see that CG with second order polynomials is again clearly better than HDG with linears. However, the advantage of HDG for higher orders remains.\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n\\nThe results are in line with properties of DG methods in general: Best performance is typically not achieved for linear elements, but rather at somewhat higher order, usually around \\\\(p=3\\\\). This is because of a volume-to-surface effect for discontinuous solutions with too much of the solution living on the surfaces and hence duplicating work when the elements are linear. Put in other words, DG methods are often most efficient when used at relatively high order, despite their focus on a discontinuous (and hence, seemingly low accurate) representation of solutions.\\n\\n#### Results for 3D\\n\\nWe now show the same figures in 3D: The first row shows the number of degrees of freedom and computing time versus the \\\\(L\\\\_2\\\\) error in the scalar variable \\\\(u\\\\) for CG and HDG at order \\\\(p\\\\), the second row shows the post-processed HDG solution instead of the original one, and the third row compares the post-processed HDG solution with CG at order \\\\(p+1\\\\). In 3D, the volume-to-surface effect makes the cost of HDG somewhat higher and the CG solution is clearly better than HDG for linears by any metric. For cubics, HDG and CG are of similar quality, whereas HDG is again more efficient for sixth order polynomials. One can alternatively also use the combination of [FE\\\\_DGP](classFE__DGP.html) and [FE\\\\_FaceP](classFE__FaceP.html) instead of ([FE\\\\_DGQ](classFE__DGQ.html), [FE\\\\_FaceQ](classFE__FaceQ.html)), which do not use tensor product polynomials of degree \\\\(p\\\\) but Legendre polynomials of *complete* degree \\\\(p\\\\). There are fewer degrees of freedom on the skeleton variable for [FE\\\\_FaceP](classFE__FaceP.html) for a given mesh size, but the solution quality (error vs. number of DoFs) is very similar to the results for [FE\\\\_FaceQ](classFE__FaceQ.html).\\n\\n|  |  |\\n| --- | --- |\\n|  |  |\\n|  |  |\\n|  |  |\\n\\nOne final note on the efficiency comparison: We tried to use general-purpose sparse matrix structures and similar solvers (optimal AMG preconditioners for both without particular tuning of the AMG parameters on any of them) to give a fair picture of the cost versus accuracy of two methods, on a toy example. It should be noted however that geometric multigrid (GMG) for continuous finite elements is about a factor four to five faster for \\\\(p=3\\\\) and \\\\(p=6\\\\). As of 2019, optimal-complexity iterative solvers for HDG are still under development in the research community. Also, there are other implementation aspects for CG available such as fast matrix-free approaches as shown in [step-37](step_37.html) that make higher order continuous elements more competitive. Again, it is not clear to the authors of the tutorial whether similar improvements could be made for HDG. We refer to [Kronbichler and Wall (2018)](https://dx.doi.org/10.1137/16M110455X) for a recent efficiency evaluation.\\n\\n### Possibilities for improvements\\n\\nAs already mentioned in the introduction, one possibility is to implement another post-processing technique as discussed in the literature.\\n\\nA second item that is not done optimally relates to the performance of this program, which is of course an issue in practical applications (weighing in also the better solution quality of (H)DG methods for transport-dominated problems). Let us look at the computing time of the tutorial program and the share of the individual components:\\n\\n|  |  | Setup | Assemble | Solve | Trace reconstruct | Post-processing | Output |\\n| --- | --- | --- | --- | --- | --- | --- | --- |\\n|  | Total time | Relative share | | | | | |\\n| 2D, Q1, cycle 9, 37,248 dofs | 5.34s | 0.7% | 1.2% | 89.5% | 0.9% | 2.3% | 5.4% |\\n| 2D, Q3, cycle 9, 74,496 dofs | 22.2s | 0.4% | 4.3% | 84.1% | 4.1% | 3.5% | 3.6% |\\n| 3D, Q1, cycle 7, 172,800 dofs | 9.06s | 3.1% | 8.9% | 42.7% | 7.0% | 20.6% | 17.7% |\\n| 3D, Q3, cycle 7, 691,200 dofs | 516s | 0.6% | 34.5% | 13.4% | 32.8% | 17.1% | 1.5% |\\n\\nAs can be seen from the table, the solver and assembly calls dominate the runtime of the program. This also gives a clear indication of where improvements would make the most sense:\\n\\n1. Better linear solvers: We use a BiCGStab iterative solver without preconditioner, where the number of iteration increases with increasing problem size (the number of iterations for Q1 elements and global refinements starts at 35 for the small sizes but increase up to 701 for the largest size). To do better, one could for example use an algebraic multigrid preconditioner from Trilinos, or some more advanced variants as the one discussed in [Kronbichler and Wall (2018)](https://dx.doi.org/10.1137/16M110455X). For diffusion-dominated problems such as the problem at hand with finer meshes, such a solver can be designed that uses the matrix-vector products from the more efficient [ChunkSparseMatrix](classChunkSparseMatrix.html) on the finest level, as long as we are not working in parallel with MPI. For MPI-parallelized computations, a standard [TrilinosWrappers::SparseMatrix](classTrilinosWrappers_1_1SparseMatrix.html) can be used.\\n2. Speed up assembly by pre-assembling parts that do not change from one cell to another (those that do neither contain variable coefficients nor mapping-dependent terms).\\n\\nThe plain program\\n=================\\n\\n```\\n/* ------------------------------------------------------------------------\\n *\\n * SPDX-License-Identifier: LGPL-2.1-or-later\\n * Copyright (C) 2013 - 2024 by the deal.II authors\\n *\\n * This file is part of the deal.II library.\\n *\\n * Part of the source code is dual licensed under Apache-2.0 WITH\\n * LLVM-exception OR LGPL-2.1-or-later. Detailed license information\\n * governing the source code and code contributions can be found in\\n * LICENSE.md and CONTRIBUTING.md at the top level directory of deal.II.\\n *\\n * ------------------------------------------------------------------------\\n *\\n * Author: Martin Kronbichler, Technical University of Munich,\\n *         Scott T. Miller, The Pennsylvania State University, 2013\\n */\\n \\n#include <deal.II/base/quadrature_lib.h>\\n#include <deal.II/base/function.h>\\n#include <deal.II/base/tensor_function.h>\\n#include <deal.II/base/exceptions.h>\\n#include <deal.II/base/work_stream.h>\\n#include <deal.II/base/convergence_table.h>\\n#include <deal.II/lac/vector.h>\\n#include <deal.II/lac/affine_constraints.h>\\n#include <deal.II/lac/full_matrix.h>\\n#include <deal.II/lac/dynamic_sparsity_pattern.h>\\n#include <deal.II/lac/solver_bicgstab.h>\\n#include <deal.II/lac/precondition.h>\\n#include <deal.II/grid/tria.h>\\n#include <deal.II/grid/grid_generator.h>\\n#include <deal.II/grid/grid_refinement.h>\\n#include <deal.II/dofs/dof_handler.h>\\n#include <deal.II/dofs/dof_renumbering.h>\\n#include <deal.II/dofs/dof_tools.h>\\n#include <deal.II/fe/fe_dgq.h>\\n#include <deal.II/fe/fe_system.h>\\n#include <deal.II/fe/fe_values.h>\\n#include <deal.II/numerics/vector_tools.h>\\n#include <deal.II/numerics/error_estimator.h>\\n#include <deal.II/numerics/data_out.h>\\n \\n#include <deal.II/fe/fe_face.h>\\n \\n#include <deal.II/lac/chunk_sparse_matrix.h>\\n \\n#include <deal.II/numerics/data_out_faces.h>\\n \\n#include <iostream>\\n \\n \\n \\nnamespace Step51\\n{\\n using namespace dealii;\\n \\n template <int dim>\\n class SolutionBase\\n  {\\n protected:\\n static const unsigned int n_source_centers = 3;\\n static const Point<dim>   source_centers[n_source_centers];\\n static const double       width;\\n  };\\n \\n \\n template <>\\n const Point<1>\\n    SolutionBase<1>::source_centers[SolutionBase<1>::n_source_centers] =\\n      {Point<1>(-1.0 / 3.0), Point<1>(0.0), Point<1>(+1.0 / 3.0)};\\n \\n \\n template <>\\n const Point<2>\\n    SolutionBase<2>::source_centers[SolutionBase<2>::n_source_centers] =\\n      {Point<2>(-0.5, +0.5), Point<2>(-0.5, -0.5), Point<2>(+0.5, -0.5)};\\n \\n template <>\\n const Point<3>\\n    SolutionBase<3>::source_centers[SolutionBase<3>::n_source_centers] = {\\n Point<3>(-0.5, +0.5, 0.25),\\n Point<3>(-0.6, -0.5, -0.125),\\n Point<3>(+0.5, -0.5, 0.5)};\\n \\n template <int dim>\\n const double SolutionBase<dim>::width = 1. / 5.;\\n \\n \\n template <int dim>\\n class Solution : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n virtual double value(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n double sum = 0;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n sum +=\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width));\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n \\n virtual Tensor<1, dim>\\n gradient(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n Tensor<1, dim> sum;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\n sum +=\\n            (-2 / (this->width * this->width) *\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)) *\\n             x_minus_xi);\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class SolutionAndGradient : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n    SolutionAndGradient()\\n      : Function<dim>(dim + 1)\\n    {}\\n \\n virtual void vector_value(const Point<dim> &p,\\n Vector<double>   &v) const override\\n {\\n AssertDimension(v.size(), dim + 1);\\n      Solution<dim>  solution;\\n Tensor<1, dim> grad = solution.gradient(p);\\n for (unsigned int d = 0; d < dim; ++d)\\n        v[d] = -grad[d];\\n      v[dim] = solution.value(p);\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class ConvectionVelocity : public TensorFunction<1, dim>\\n  {\\n public:\\n    ConvectionVelocity()\\n      : TensorFunction<1, dim>()\\n    {}\\n \\n virtual Tensor<1, dim> value(const Point<dim> &p) const override\\n {\\n Tensor<1, dim> convection;\\n switch (dim)\\n        {\\n case 1:\\n            convection[0] = 1;\\n break;\\n case 2:\\n            convection[0] = p[1];\\n            convection[1] = -p[0];\\n break;\\n case 3:\\n            convection[0] = p[1];\\n            convection[1] = -p[0];\\n            convection[2] = 1;\\n break;\\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n        }\\n return convection;\\n    }\\n  };\\n \\n \\n \\n template <int dim>\\n class RightHandSide : public Function<dim>, protected SolutionBase<dim>\\n  {\\n public:\\n virtual double value(const Point<dim> &p,\\n const unsigned int /*component*/ = 0) const override\\n {\\n      ConvectionVelocity<dim> convection_velocity;\\n Tensor<1, dim>          convection = convection_velocity.value(p);\\n double sum        = 0;\\n for (unsigned int i = 0; i < this->n_source_centers; ++i)\\n        {\\n const Tensor<1, dim> x_minus_xi = p - this->source_centers[i];\\n \\n sum +=\\n            ((2 * dim - 2 * convection * x_minus_xi -\\n              4 * x_minus_xi.norm_square() / (this->width * this->width)) /\\n             (this->width * this->width) *\\n std::exp(-x_minus_xi.norm_square() / (this->width * this->width)));\\n        }\\n \\n return sum /\\n std::pow(2. * numbers::PI * this->width * this->width, dim / 2.);\\n    }\\n  };\\n \\n \\n \\n \\n template <int dim>\\n class HDG\\n  {\\n public:\\n enum RefinementMode\\n    {\\n      global_refinement,\\n      adaptive_refinement\\n    };\\n \\n    HDG(const unsigned int degree, const RefinementMode refinement_mode);\\n void run();\\n \\n private:\\n void setup_system();\\n void assemble_system(const bool reconstruct_trace = false);\\n void solve();\\n void postprocess();\\n void refine_grid(const unsigned int cycle);\\n void output_results(const unsigned int cycle);\\n \\n struct PerTaskData;\\n struct ScratchData;\\n \\n struct PostProcessScratchData;\\n \\n void assemble_system_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n      ScratchData                                          &scratch,\\n      PerTaskData                                          &task_data);\\n \\n void copy_local_to_global(const PerTaskData &data);\\n \\n void postprocess_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n      PostProcessScratchData                               &scratch,\\n unsigned int                                         &empty_data);\\n \\n \\n Triangulation<dim> triangulation;\\n \\n const FESystem<dim> fe_local;\\n DoFHandler<dim>     dof_handler_local;\\n Vector<double>      solution_local;\\n \\n const FE_FaceQ<dim> fe;\\n DoFHandler<dim>     dof_handler;\\n Vector<double>      solution;\\n Vector<double>      system_rhs;\\n \\n const FE_DGQ<dim> fe_u_post;\\n DoFHandler<dim>   dof_handler_u_post;\\n Vector<double>    solution_u_post;\\n \\n AffineConstraints<double> constraints;\\n \\n ChunkSparsityPattern      sparsity_pattern;\\n ChunkSparseMatrix<double> system_matrix;\\n \\n const RefinementMode refinement_mode;\\n ConvergenceTable     convergence_table;\\n  };\\n \\n \\n template <int dim>\\n  HDG<dim>::HDG(const unsigned int degree, const RefinementMode refinement_mode)\\n    : fe_local(FE_DGQ<dim>(degree) ^ dim, FE_DGQ<dim>(degree))\\n    , dof_handler_local(triangulation)\\n    , fe(degree)\\n    , dof_handler(triangulation)\\n    , fe_u_post(degree + 1)\\n    , dof_handler_u_post(triangulation)\\n    , refinement_mode(refinement_mode)\\n  {}\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::setup_system()\\n  {\\n    dof_handler_local.distribute_dofs(fe_local);\\n    dof_handler.distribute_dofs(fe);\\n    dof_handler_u_post.distribute_dofs(fe_u_post);\\n \\n    std::cout << \"   Number of degrees of freedom: \" << dof_handler.n_dofs()\\n              << std::endl;\\n \\n    solution.reinit(dof_handler.n_dofs());\\n    system_rhs.reinit(dof_handler.n_dofs());\\n \\n    solution_local.reinit(dof_handler_local.n_dofs());\\n    solution_u_post.reinit(dof_handler_u_post.n_dofs());\\n \\n    constraints.clear();\\n DoFTools::make_hanging_node_constraints(dof_handler, constraints);\\n    std::map<types::boundary_id, const Function<dim> *> boundary_functions;\\n    Solution<dim>                                       solution_function;\\n    boundary_functions[0] = &solution_function;\\n VectorTools::project_boundary_values(dof_handler,\\n                                         boundary_functions,\\n QGauss<dim - 1>(fe.degree + 1),\\n                                         constraints);\\n    constraints.close();\\n \\n    {\\n DynamicSparsityPattern dsp(dof_handler.n_dofs());\\n DoFTools::make_sparsity_pattern(dof_handler, dsp, constraints, false);\\n      sparsity_pattern.copy_from(dsp, fe.n_dofs_per_face());\\n    }\\n    system_matrix.reinit(sparsity_pattern);\\n  }\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::PerTaskData\\n  {\\n FullMatrix<double> cell_matrix;\\n Vector<double>                       cell_vector;\\n    std::vector<types::global_dof_index> dof_indices;\\n \\n bool trace_reconstruct;\\n \\n    PerTaskData(const unsigned int n_dofs, const bool trace_reconstruct)\\n      : cell_matrix(n_dofs, n_dofs)\\n      , cell_vector(n_dofs)\\n      , dof_indices(n_dofs)\\n      , trace_reconstruct(trace_reconstruct)\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::ScratchData\\n  {\\n FEValues<dim>     fe_values_local;\\n FEFaceValues<dim> fe_face_values_local;\\n FEFaceValues<dim> fe_face_values;\\n \\n FullMatrix<double> ll_matrix;\\n FullMatrix<double> lf_matrix;\\n FullMatrix<double> fl_matrix;\\n FullMatrix<double> tmp_matrix;\\n Vector<double>     l_rhs;\\n Vector<double>     tmp_rhs;\\n \\n    std::vector<Tensor<1, dim>> q_phi;\\n    std::vector<double>         q_phi_div;\\n    std::vector<double>         u_phi;\\n    std::vector<Tensor<1, dim>> u_phi_grad;\\n    std::vector<double>         tr_phi;\\n    std::vector<double>         trace_values;\\n \\n    std::vector<std::vector<unsigned int>> fe_local_support_on_face;\\n    std::vector<std::vector<unsigned int>> fe_support_on_face;\\n \\n    ConvectionVelocity<dim> convection_velocity;\\n    RightHandSide<dim>      right_hand_side;\\n const Solution<dim>     exact_solution;\\n \\n    ScratchData(const FiniteElement<dim> &fe,\\n const FiniteElement<dim> &fe_local,\\n const QGauss<dim>        &quadrature_formula,\\n const QGauss<dim - 1>    &face_quadrature_formula,\\n const UpdateFlags         local_flags,\\n const UpdateFlags         local_face_flags,\\n const UpdateFlags         flags)\\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\\n      , fe_face_values_local(fe_local,\\n                             face_quadrature_formula,\\n                             local_face_flags)\\n      , fe_face_values(fe, face_quadrature_formula, flags)\\n      , ll_matrix(fe_local.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , lf_matrix(fe_local.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n      , fl_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , tmp_matrix(fe.n_dofs_per_cell(), fe_local.n_dofs_per_cell())\\n      , l_rhs(fe_local.n_dofs_per_cell())\\n      , tmp_rhs(fe_local.n_dofs_per_cell())\\n      , q_phi(fe_local.n_dofs_per_cell())\\n      , q_phi_div(fe_local.n_dofs_per_cell())\\n      , u_phi(fe_local.n_dofs_per_cell())\\n      , u_phi_grad(fe_local.n_dofs_per_cell())\\n      , tr_phi(fe.n_dofs_per_cell())\\n      , trace_values(face_quadrature_formula.size())\\n      , fe_local_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n      , fe_support_on_face(GeometryInfo<dim>::faces_per_cell)\\n      , exact_solution()\\n    {\\n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n        for (unsigned int i = 0; i < fe_local.n_dofs_per_cell(); ++i)\\n          {\\n if (fe_local.has_support_on_face(i, face_no))\\n              fe_local_support_on_face[face_no].push_back(i);\\n          }\\n \\n for (const unsigned int face_no : GeometryInfo<dim>::face_indices())\\n        for (unsigned int i = 0; i < fe.n_dofs_per_cell(); ++i)\\n          {\\n if (fe.has_support_on_face(i, face_no))\\n              fe_support_on_face[face_no].push_back(i);\\n          }\\n    }\\n \\n    ScratchData(const ScratchData &sd)\\n      : fe_values_local(sd.fe_values_local.get_fe(),\\n                        sd.fe_values_local.get_quadrature(),\\n                        sd.fe_values_local.get_update_flags())\\n      , fe_face_values_local(sd.fe_face_values_local.get_fe(),\\n                             sd.fe_face_values_local.get_quadrature(),\\n                             sd.fe_face_values_local.get_update_flags())\\n      , fe_face_values(sd.fe_face_values.get_fe(),\\n                       sd.fe_face_values.get_quadrature(),\\n                       sd.fe_face_values.get_update_flags())\\n      , ll_matrix(sd.ll_matrix)\\n      , lf_matrix(sd.lf_matrix)\\n      , fl_matrix(sd.fl_matrix)\\n      , tmp_matrix(sd.tmp_matrix)\\n      , l_rhs(sd.l_rhs)\\n      , tmp_rhs(sd.tmp_rhs)\\n      , q_phi(sd.q_phi)\\n      , q_phi_div(sd.q_phi_div)\\n      , u_phi(sd.u_phi)\\n      , u_phi_grad(sd.u_phi_grad)\\n      , tr_phi(sd.tr_phi)\\n      , trace_values(sd.trace_values)\\n      , fe_local_support_on_face(sd.fe_local_support_on_face)\\n      , fe_support_on_face(sd.fe_support_on_face)\\n      , exact_solution()\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n struct HDG<dim>::PostProcessScratchData\\n  {\\n FEValues<dim> fe_values_local;\\n FEValues<dim> fe_values;\\n \\n    std::vector<double>         u_values;\\n    std::vector<Tensor<1, dim>> u_gradients;\\n FullMatrix<double> cell_matrix;\\n \\n Vector<double> cell_rhs;\\n Vector<double> cell_sol;\\n \\n    PostProcessScratchData(const FiniteElement<dim> &fe,\\n const FiniteElement<dim> &fe_local,\\n const QGauss<dim>        &quadrature_formula,\\n const UpdateFlags         local_flags,\\n const UpdateFlags         flags)\\n      : fe_values_local(fe_local, quadrature_formula, local_flags)\\n      , fe_values(fe, quadrature_formula, flags)\\n      , u_values(quadrature_formula.size())\\n      , u_gradients(quadrature_formula.size())\\n      , cell_matrix(fe.n_dofs_per_cell(), fe.n_dofs_per_cell())\\n      , cell_rhs(fe.n_dofs_per_cell())\\n      , cell_sol(fe.n_dofs_per_cell())\\n    {}\\n \\n    PostProcessScratchData(const PostProcessScratchData &sd)\\n      : fe_values_local(sd.fe_values_local.get_fe(),\\n                        sd.fe_values_local.get_quadrature(),\\n                        sd.fe_values_local.get_update_flags())\\n      , fe_values(sd.fe_values.get_fe(),\\n                  sd.fe_values.get_quadrature(),\\n                  sd.fe_values.get_update_flags())\\n      , u_values(sd.u_values)\\n      , u_gradients(sd.u_gradients)\\n      , cell_matrix(sd.cell_matrix)\\n      , cell_rhs(sd.cell_rhs)\\n      , cell_sol(sd.cell_sol)\\n    {}\\n  };\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::assemble_system(const bool trace_reconstruct)\\n  {\\n const QGauss<dim>     quadrature_formula(fe.degree + 1);\\n const QGauss<dim - 1> face_quadrature_formula(fe.degree + 1);\\n \\n const UpdateFlags local_flags(update_values | update_gradients |\\n update_JxW_values | update_quadrature_points);\\n \\n const UpdateFlags local_face_flags(update_values);\\n \\n const UpdateFlags flags(update_values | update_normal_vectors |\\n update_quadrature_points | update_JxW_values);\\n \\n    PerTaskData task_data(fe.n_dofs_per_cell(), trace_reconstruct);\\n    ScratchData scratch(fe,\\n                        fe_local,\\n                        quadrature_formula,\\n                        face_quadrature_formula,\\n                        local_flags,\\n                        local_face_flags,\\n                        flags);\\n \\n WorkStream::run(dof_handler.begin_active(),\\n                    dof_handler.end(),\\n                    *this,\\n                    &HDG<dim>::assemble_system_one_cell,\\n                    &HDG<dim>::copy_local_to_global,\\n                    scratch,\\n                    task_data);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::assemble_system_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n    ScratchData                                          &scratch,\\n    PerTaskData                                          &task_data)\\n  {\\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n      cell->as_dof_handler_iterator(dof_handler_local);\\n \\n const unsigned int n_q_points =\\n      scratch.fe_values_local.get_quadrature().size();\\n const unsigned int n_face_q_points =\\n      scratch.fe_face_values_local.get_quadrature().size();\\n \\n const unsigned int loc_dofs_per_cell =\\n      scratch.fe_values_local.get_fe().n_dofs_per_cell();\\n \\n const FEValuesExtractors::Vector fluxes(0);\\n const FEValuesExtractors::Scalar scalar(dim);\\n \\n    scratch.ll_matrix = 0;\\n    scratch.l_rhs     = 0;\\n if (!task_data.trace_reconstruct)\\n      {\\n        scratch.lf_matrix     = 0;\\n        scratch.fl_matrix     = 0;\\n        task_data.cell_matrix = 0;\\n        task_data.cell_vector = 0;\\n      }\\n    scratch.fe_values_local.reinit(loc_cell);\\n \\n for (unsigned int q = 0; q < n_q_points; ++q)\\n      {\\n const double rhs_value = scratch.right_hand_side.value(\\n          scratch.fe_values_local.quadrature_point(q));\\n const Tensor<1, dim> convection = scratch.convection_velocity.value(\\n          scratch.fe_values_local.quadrature_point(q));\\n const double JxW = scratch.fe_values_local.JxW(q);\\n for (unsigned int k = 0; k < loc_dofs_per_cell; ++k)\\n          {\\n            scratch.q_phi[k] = scratch.fe_values_local[fluxes].value(k, q);\\n            scratch.q_phi_div[k] =\\n              scratch.fe_values_local[fluxes].divergence(k, q);\\n            scratch.u_phi[k] = scratch.fe_values_local[scalar].value(k, q);\\n            scratch.u_phi_grad[k] =\\n              scratch.fe_values_local[scalar].gradient(k, q);\\n          }\\n for (unsigned int i = 0; i < loc_dofs_per_cell; ++i)\\n          {\\n for (unsigned int j = 0; j < loc_dofs_per_cell; ++j)\\n              scratch.ll_matrix(i, j) +=\\n                (scratch.q_phi[i] * scratch.q_phi[j] -\\n                 scratch.q_phi_div[i] * scratch.u_phi[j] +\\n                 scratch.u_phi[i] * scratch.q_phi_div[j] -\\n                 (scratch.u_phi_grad[i] * convection) * scratch.u_phi[j]) *\\n                JxW;\\n            scratch.l_rhs(i) += scratch.u_phi[i] * rhs_value * JxW;\\n          }\\n      }\\n \\n for (const auto face_no : cell->face_indices())\\n      {\\n        scratch.fe_face_values_local.reinit(loc_cell, face_no);\\n        scratch.fe_face_values.reinit(cell, face_no);\\n \\n if (task_data.trace_reconstruct)\\n          scratch.fe_face_values.get_function_values(solution,\\n                                                     scratch.trace_values);\\n \\n for (unsigned int q = 0; q < n_face_q_points; ++q)\\n          {\\n const double     JxW = scratch.fe_face_values.JxW(q);\\n const Point<dim> quadrature_point =\\n              scratch.fe_face_values.quadrature_point(q);\\n const Tensor<1, dim> normal =\\n              scratch.fe_face_values.normal_vector(q);\\n const Tensor<1, dim> convection =\\n              scratch.convection_velocity.value(quadrature_point);\\n \\n const double tau_stab = (5. + std::abs(convection * normal));\\n \\n for (unsigned int k = 0;\\n                 k < scratch.fe_local_support_on_face[face_no].size();\\n                 ++k)\\n              {\\n const unsigned int kk =\\n                  scratch.fe_local_support_on_face[face_no][k];\\n                scratch.q_phi[k] =\\n                  scratch.fe_face_values_local[fluxes].value(kk, q);\\n                scratch.u_phi[k] =\\n                  scratch.fe_face_values_local[scalar].value(kk, q);\\n              }\\n \\n if (!task_data.trace_reconstruct)\\n              {\\n for (unsigned int k = 0;\\n                     k < scratch.fe_support_on_face[face_no].size();\\n                     ++k)\\n                  scratch.tr_phi[k] = scratch.fe_face_values.shape_value(\\n                    scratch.fe_support_on_face[face_no][k], q);\\n for (unsigned int i = 0;\\n                     i < scratch.fe_local_support_on_face[face_no].size();\\n                     ++i)\\n for (unsigned int j = 0;\\n                       j < scratch.fe_support_on_face[face_no].size();\\n                       ++j)\\n                    {\\n const unsigned int ii =\\n                        scratch.fe_local_support_on_face[face_no][i];\\n const unsigned int jj =\\n                        scratch.fe_support_on_face[face_no][j];\\n                      scratch.lf_matrix(ii, jj) +=\\n                        ((scratch.q_phi[i] * normal +\\n                          (convection * normal - tau_stab) * scratch.u_phi[i]) *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n \\n                      scratch.fl_matrix(jj, ii) -=\\n                        ((scratch.q_phi[i] * normal +\\n                          tau_stab * scratch.u_phi[i]) *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n                    }\\n \\n for (unsigned int i = 0;\\n                     i < scratch.fe_support_on_face[face_no].size();\\n                     ++i)\\n for (unsigned int j = 0;\\n                       j < scratch.fe_support_on_face[face_no].size();\\n                       ++j)\\n                    {\\n const unsigned int ii =\\n                        scratch.fe_support_on_face[face_no][i];\\n const unsigned int jj =\\n                        scratch.fe_support_on_face[face_no][j];\\n                      task_data.cell_matrix(ii, jj) +=\\n                        ((convection * normal - tau_stab) * scratch.tr_phi[i] *\\n                         scratch.tr_phi[j]) *\\n                        JxW;\\n                    }\\n \\n if (cell->face(face_no)->at_boundary() &&\\n                    (cell->face(face_no)->boundary_id() == 1))\\n                  {\\n const double neumann_value =\\n                      -scratch.exact_solution.gradient(quadrature_point) *\\n                        normal +\\n                      convection * normal *\\n                        scratch.exact_solution.value(quadrature_point);\\n for (unsigned int i = 0;\\n                         i < scratch.fe_support_on_face[face_no].size();\\n                         ++i)\\n                      {\\n const unsigned int ii =\\n                          scratch.fe_support_on_face[face_no][i];\\n                        task_data.cell_vector(ii) +=\\n                          scratch.tr_phi[i] * neumann_value * JxW;\\n                      }\\n                  }\\n              }\\n \\n for (unsigned int i = 0;\\n                 i < scratch.fe_local_support_on_face[face_no].size();\\n                 ++i)\\n for (unsigned int j = 0;\\n                   j < scratch.fe_local_support_on_face[face_no].size();\\n                   ++j)\\n                {\\n const unsigned int ii =\\n                    scratch.fe_local_support_on_face[face_no][i];\\n const unsigned int jj =\\n                    scratch.fe_local_support_on_face[face_no][j];\\n                  scratch.ll_matrix(ii, jj) +=\\n                    tau_stab * scratch.u_phi[i] * scratch.u_phi[j] * JxW;\\n                }\\n \\n if (task_data.trace_reconstruct)\\n for (unsigned int i = 0;\\n                   i < scratch.fe_local_support_on_face[face_no].size();\\n                   ++i)\\n                {\\n const unsigned int ii =\\n                    scratch.fe_local_support_on_face[face_no][i];\\n                  scratch.l_rhs(ii) -=\\n                    (scratch.q_phi[i] * normal +\\n                     scratch.u_phi[i] * (convection * normal - tau_stab)) *\\n                    scratch.trace_values[q] * JxW;\\n                }\\n          }\\n      }\\n \\n    scratch.ll_matrix.gauss_jordan();\\n \\n if (task_data.trace_reconstruct == false)\\n      {\\n        scratch.fl_matrix.mmult(scratch.tmp_matrix, scratch.ll_matrix);\\n        scratch.tmp_matrix.vmult_add(task_data.cell_vector, scratch.l_rhs);\\n        scratch.tmp_matrix.mmult(task_data.cell_matrix,\\n                                 scratch.lf_matrix,\\n true);\\n        cell->get_dof_indices(task_data.dof_indices);\\n      }\\n else\\n      {\\n        scratch.ll_matrix.vmult(scratch.tmp_rhs, scratch.l_rhs);\\n        loc_cell->set_dof_values(scratch.tmp_rhs, solution_local);\\n      }\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::copy_local_to_global(const PerTaskData &data)\\n  {\\n if (data.trace_reconstruct == false)\\n      constraints.distribute_local_to_global(data.cell_matrix,\\n                                             data.cell_vector,\\n                                             data.dof_indices,\\n                                             system_matrix,\\n                                             system_rhs);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::solve()\\n  {\\n SolverControl                  solver_control(system_matrix.m() * 10,\\n                                 1e-11 * system_rhs.l2_norm());\\n SolverBicgstab<Vector<double>> solver(solver_control);\\n    solver.solve(system_matrix, solution, system_rhs, PreconditionIdentity());\\n \\n    std::cout << \"   Number of BiCGStab iterations: \"\\n              << solver_control.last_step() << std::endl;\\n \\n    system_matrix.clear();\\n    sparsity_pattern.reinit(0, 0, 0, 1);\\n \\n    constraints.distribute(solution);\\n \\n    assemble_system(true);\\n  }\\n \\n \\n \\n \\n template <int dim>\\n void HDG<dim>::postprocess()\\n  {\\n    {\\n const QGauss<dim> quadrature_formula(fe_u_post.degree + 1);\\n const UpdateFlags local_flags(update_values);\\n const UpdateFlags flags(update_values | update_gradients |\\n update_JxW_values);\\n \\n      PostProcessScratchData scratch(\\n        fe_u_post, fe_local, quadrature_formula, local_flags, flags);\\n \\n WorkStream::run(\\n        dof_handler_u_post.begin_active(),\\n        dof_handler_u_post.end(),\\n        [this](const typename DoFHandler<dim>::active_cell_iterator &cell,\\n               PostProcessScratchData                               &scratch,\\n unsigned int                                         &data) {\\n          this->postprocess_one_cell(cell, scratch, data);\\n        },\\n        std::function<void(const unsigned int &)>(),\\n        scratch,\\n        0U);\\n    }\\n \\n Vector<float> difference_per_cell(triangulation.n_active_cells());\\n \\n ComponentSelectFunction<dim> value_select(dim, dim + 1);\\n VectorTools::integrate_difference(dof_handler_local,\\n                                      solution_local,\\n                                      SolutionAndGradient<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 2),\\n VectorTools::L2_norm,\\n                                      &value_select);\\n const double L2_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n ComponentSelectFunction<dim> gradient_select(\\n      std::pair<unsigned int, unsigned int>(0, dim), dim + 1);\\n VectorTools::integrate_difference(dof_handler_local,\\n                                      solution_local,\\n                                      SolutionAndGradient<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 2),\\n VectorTools::L2_norm,\\n                                      &gradient_select);\\n const double grad_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n VectorTools::integrate_difference(dof_handler_u_post,\\n                                      solution_u_post,\\n                                      Solution<dim>(),\\n                                      difference_per_cell,\\n QGauss<dim>(fe.degree + 3),\\n VectorTools::L2_norm);\\n const double post_error =\\n VectorTools::compute_global_error(triangulation,\\n                                        difference_per_cell,\\n VectorTools::L2_norm);\\n \\n    convergence_table.add_value(\"cells\", triangulation.n_active_cells());\\n    convergence_table.add_value(\"dofs\", dof_handler.n_dofs());\\n \\n    convergence_table.add_value(\"val L2\", L2_error);\\n    convergence_table.set_scientific(\"val L2\", true);\\n    convergence_table.set_precision(\"val L2\", 3);\\n \\n    convergence_table.add_value(\"grad L2\", grad_error);\\n    convergence_table.set_scientific(\"grad L2\", true);\\n    convergence_table.set_precision(\"grad L2\", 3);\\n \\n    convergence_table.add_value(\"val L2-post\", post_error);\\n    convergence_table.set_scientific(\"val L2-post\", true);\\n    convergence_table.set_precision(\"val L2-post\", 3);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::postprocess_one_cell(\\n const typename DoFHandler<dim>::active_cell_iterator &cell,\\n    PostProcessScratchData                               &scratch,\\n unsigned int &)\\n  {\\n const typename DoFHandler<dim>::active_cell_iterator loc_cell =\\n      cell->as_dof_handler_iterator(dof_handler_local);\\n \\n    scratch.fe_values_local.reinit(loc_cell);\\n    scratch.fe_values.reinit(cell);\\n \\n const FEValuesExtractors::Vector fluxes(0);\\n const FEValuesExtractors::Scalar scalar(dim);\\n \\n const unsigned int n_q_points = scratch.fe_values.get_quadrature().size();\\n const unsigned int dofs_per_cell = scratch.fe_values.dofs_per_cell;\\n \\n    scratch.fe_values_local[scalar].get_function_values(solution_local,\\n                                                        scratch.u_values);\\n    scratch.fe_values_local[fluxes].get_function_values(solution_local,\\n                                                        scratch.u_gradients);\\n \\n double sum = 0;\\n for (unsigned int i = 1; i < dofs_per_cell; ++i)\\n      {\\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n          {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n              sum += (scratch.fe_values.shape_grad(i, q) *\\n                      scratch.fe_values.shape_grad(j, q)) *\\n                     scratch.fe_values.JxW(q);\\n            scratch.cell_matrix(i, j) = sum;\\n          }\\n \\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n          sum -= (scratch.fe_values.shape_grad(i, q) * scratch.u_gradients[q]) *\\n                 scratch.fe_values.JxW(q);\\n        scratch.cell_rhs(i) = sum;\\n      }\\n for (unsigned int j = 0; j < dofs_per_cell; ++j)\\n      {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n          sum += scratch.fe_values.shape_value(j, q) * scratch.fe_values.JxW(q);\\n        scratch.cell_matrix(0, j) = sum;\\n      }\\n    {\\n sum = 0;\\n for (unsigned int q = 0; q < n_q_points; ++q)\\n        sum += scratch.u_values[q] * scratch.fe_values.JxW(q);\\n      scratch.cell_rhs(0) = sum;\\n    }\\n \\n    scratch.cell_matrix.gauss_jordan();\\n    scratch.cell_matrix.vmult(scratch.cell_sol, scratch.cell_rhs);\\n    cell->distribute_local_to_global(scratch.cell_sol, solution_u_post);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::output_results(const unsigned int cycle)\\n  {\\n    std::string filename;\\n switch (refinement_mode)\\n      {\\n case global_refinement:\\n          filename = \"solution-global\";\\n break;\\n case adaptive_refinement:\\n          filename = \"solution-adaptive\";\\n break;\\n default:\\n DEAL_II_NOT_IMPLEMENTED();\\n      }\\n \\n    std::string face_out(filename);\\n    face_out += \"-face\";\\n \\n    filename += \"-q\" + Utilities::int_to_string(fe.degree, 1);\\n    filename += \"-\" + Utilities::int_to_string(cycle, 2);\\n    filename += \".vtk\";\\n    std::ofstream output(filename);\\n \\n DataOut<dim> data_out;\\n \\n    std::vector<std::string> names(dim, \"gradient\");\\n    names.emplace_back(\"solution\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      component_interpretation(\\n        dim + 1, DataComponentInterpretation::component_is_part_of_vector);\\n    component_interpretation[dim] =\\n DataComponentInterpretation::component_is_scalar;\\n    data_out.add_data_vector(dof_handler_local,\\n                             solution_local,\\n                             names,\\n                             component_interpretation);\\n \\n    std::vector<std::string> post_name(1, \"u_post\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      post_comp_type(1, DataComponentInterpretation::component_is_scalar);\\n    data_out.add_data_vector(dof_handler_u_post,\\n                             solution_u_post,\\n                             post_name,\\n                             post_comp_type);\\n \\n    data_out.build_patches(fe.degree);\\n    data_out.write_vtk(output);\\n \\n    face_out += \"-q\" + Utilities::int_to_string(fe.degree, 1);\\n    face_out += \"-\" + Utilities::int_to_string(cycle, 2);\\n    face_out += \".vtk\";\\n    std::ofstream face_output(face_out);\\n \\n DataOutFaces<dim>        data_out_face(false);\\n    std::vector<std::string> face_name(1, \"u_hat\");\\n    std::vector<DataComponentInterpretation::DataComponentInterpretation>\\n      face_component_type(1, DataComponentInterpretation::component_is_scalar);\\n \\n    data_out_face.add_data_vector(dof_handler,\\n                                  solution,\\n                                  face_name,\\n                                  face_component_type);\\n \\n    data_out_face.build_patches(fe.degree);\\n    data_out_face.write_vtk(face_output);\\n  }\\n \\n \\n \\n template <int dim>\\n void HDG<dim>::refine_grid(const unsigned int cycle)\\n  {\\n if (cycle == 0)\\n      {\\n GridGenerator::subdivided_hyper_cube(triangulation, 2, -1, 1);\\n triangulation.refine_global(3 - dim);\\n      }\\n else\\n switch (refinement_mode)\\n        {\\n case global_refinement:\\n            {\\n triangulation.clear();\\n GridGenerator::subdivided_hyper_cube(triangulation,\\n                                                   2 + (cycle % 2),\\n                                                   -1,\\n                                                   1);\\n triangulation.refine_global(3 - dim + cycle / 2);\\n break;\\n            }\\n \\n case adaptive_refinement:\\n            {\\n Vector<float> estimated_error_per_cell(\\n triangulation.n_active_cells());\\n \\n const FEValuesExtractors::Scalar scalar(dim);\\n              std::map<types::boundary_id, const Function<dim> *>\\n                neumann_boundary;\\n KellyErrorEstimator<dim>::estimate(dof_handler_local,\\n QGauss<dim - 1>(fe.degree + 1),\\n                                                 neumann_boundary,\\n                                                 solution_local,\\n                                                 estimated_error_per_cell,\\n                                                 fe_local.component_mask(\\n                                                   scalar));\\n \\n GridRefinement::refine_and_coarsen_fixed_number(\\n triangulation, estimated_error_per_cell, 0.3, 0.);\\n \\n triangulation.execute_coarsening_and_refinement();\\n \\n break;\\n            }\\n \\n default:\\n            {\\n DEAL_II_NOT_IMPLEMENTED();\\n            }\\n        }\\n \\n for (const auto &cell : triangulation.cell_iterators())\\n      for (const auto &face : cell->face_iterators())\\n        if (face->at_boundary())\\n          if ((std::fabs(face->center()[0] - (-1)) < 1e-12) ||\\n              (std::fabs(face->center()[1] - (-1)) < 1e-12))\\n            face->set_boundary_id(1);\\n  }\\n \\n template <int dim>\\n void HDG<dim>::run()\\n  {\\n for (unsigned int cycle = 0; cycle < 10; ++cycle)\\n      {\\n        std::cout << \"Cycle \" << cycle << \\':\\' << std::endl;\\n \\n        refine_grid(cycle);\\n        setup_system();\\n        assemble_system(false);\\n        solve();\\n        postprocess();\\n        output_results(cycle);\\n      }\\n \\n if (refinement_mode == global_refinement)\\n      {\\n        convergence_table.evaluate_convergence_rates(\\n \"val L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n        convergence_table.evaluate_convergence_rates(\\n \"grad L2\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n        convergence_table.evaluate_convergence_rates(\\n \"val L2-post\", \"cells\", ConvergenceTable::reduction_rate_log2, dim);\\n      }\\n    convergence_table.write_text(std::cout);\\n  }\\n \\n} // end of namespace Step51\\n \\n \\n \\nint main()\\n{\\n const unsigned int dim = 2;\\n \\n try\\n    {\\n      {\\n        std::cout << \"Solving with Q1 elements, adaptive refinement\"\\n                  << std::endl\\n                  << \"=============================================\"\\n                  << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::adaptive_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n \\n      {\\n        std::cout << \"Solving with Q1 elements, global refinement\" << std::endl\\n                  << \"===========================================\" << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(1, Step51::HDG<dim>::global_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n \\n      {\\n        std::cout << \"Solving with Q3 elements, global refinement\" << std::endl\\n                  << \"===========================================\" << std::endl\\n                  << std::endl;\\n \\n        Step51::HDG<dim> hdg_problem(3, Step51::HDG<dim>::global_refinement);\\n        hdg_problem.run();\\n \\n        std::cout << std::endl;\\n      }\\n    }\\n catch (std::exception &exc)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \"----------------------------------------------------\"\\n                << std::endl;\\n      std::cerr << \"Exception on processing: \" << std::endl\\n                << exc.what() << std::endl\\n                << \"Aborting!\" << std::endl\\n                << \"----------------------------------------------------\"\\n                << std::endl;\\n return 1;\\n    }\\n catch (...)\\n    {\\n      std::cerr << std::endl\\n                << std::endl\\n                << \"----------------------------------------------------\"\\n                << std::endl;\\n      std::cerr << \"Unknown exception!\" << std::endl\\n                << \"Aborting!\" << std::endl\\n                << \"----------------------------------------------------\"\\n                << std::endl;\\n return 1;\\n    }\\n \\n return 0;\\n}\\n```\\n'}],\n",
       "  'temperature': 0.2,\n",
       "  'response_format': {'type': 'json_schema',\n",
       "   'json_schema': {'name': 'finetune_prompt-completion_pair',\n",
       "    'strict': True,\n",
       "    'description': 'A pair of prompt and completion for finetuning a code LLM',\n",
       "    'schema': {'type': 'object',\n",
       "     'properties': {'prompt': {'type': 'string',\n",
       "       'description': 'The prompt that a scientific user would ask of the code LLM, focusing on the theoretical aspect and not the technical one (so no reference to deal.II or C++)'},\n",
       "      'completion': {'type': 'string',\n",
       "       'description': 'The final code completion'}},\n",
       "     'additionalProperties': False,\n",
       "     'required': ['prompt', 'completion']}}}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3b39e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JSON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m content = \u001b[43mJSON\u001b[49m.loads(response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      2\u001b[39m prompt = content[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m completion = content[\u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'JSON' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "content = JSON.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "prompt = content[\"prompt\"]\n",
    "completion = content[\"completion\"]\n",
    "\n",
    "with open(\"completion.cpp\", \"w\") as f:\n",
    "    f.write(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
